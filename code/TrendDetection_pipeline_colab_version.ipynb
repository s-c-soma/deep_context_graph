{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrendDetection_pipeline.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d51b511c737b41ab846a167d5e934f34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c22662fda94f4efd92ae372e39a71687",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4e5202df885444e6b3126703b8140348",
              "IPY_MODEL_f3d891c0ac3347a69785c86c716b1f1b"
            ]
          }
        },
        "c22662fda94f4efd92ae372e39a71687": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4e5202df885444e6b3126703b8140348": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5b9188ac63634b9dae09fba87c866254",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8966ddf543f8496eb11b96acf7ca83a6"
          }
        },
        "f3d891c0ac3347a69785c86c716b1f1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4fa7e53049d9418e97dee36155893f33",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 414kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4d54004f9bec42bf8386c72509d61fde"
          }
        },
        "5b9188ac63634b9dae09fba87c866254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8966ddf543f8496eb11b96acf7ca83a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4fa7e53049d9418e97dee36155893f33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4d54004f9bec42bf8386c72509d61fde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "72778c0f871d46ae8beb512a91b98c38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c3446589739e4ae2828d1b11ae28cd9f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a129ae5021364fc684759fbb7479e44e",
              "IPY_MODEL_fd5da834d2da45a5bfb4af01bde800ed"
            ]
          }
        },
        "c3446589739e4ae2828d1b11ae28cd9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a129ae5021364fc684759fbb7479e44e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3eb0fa2c12474cc18b50c7cf70953916",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6af320a038b04e728a11fa4fd674f55a"
          }
        },
        "fd5da834d2da45a5bfb4af01bde800ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8821650883e245018bce02b7ff4f3ed8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 222B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c159eea4fa90426a921df7d3c3d718e2"
          }
        },
        "3eb0fa2c12474cc18b50c7cf70953916": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6af320a038b04e728a11fa4fd674f55a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8821650883e245018bce02b7ff4f3ed8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c159eea4fa90426a921df7d3c3d718e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4fc8279aadd94c07aa910a675a7bc1b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_77819468aa694b05b5dd25b0ae852ed4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_10bc6b2da9ad44239f2b9edad12d7031",
              "IPY_MODEL_0b39a048235a419d9626d2aed8a9addd"
            ]
          }
        },
        "77819468aa694b05b5dd25b0ae852ed4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "10bc6b2da9ad44239f2b9edad12d7031": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_164be9b1b41b422aa788fdbe8965f68c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0b03595f6c594725ac159d2034114c3e"
          }
        },
        "0b39a048235a419d9626d2aed8a9addd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1c1affee94054a63a6c43be9f48bd355",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 1.83MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_167b764c57a54841823f8c163939b4f6"
          }
        },
        "164be9b1b41b422aa788fdbe8965f68c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0b03595f6c594725ac159d2034114c3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1c1affee94054a63a6c43be9f48bd355": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "167b764c57a54841823f8c163939b4f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a7e37c4e13d14672b930d61a86650299": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_32a132887f5f427ebd89d39bd2ddc56c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5e12f9cfc8a343ddb60f50c6de3275ed",
              "IPY_MODEL_6faee1983f564d5993aee157c9deccc6"
            ]
          }
        },
        "32a132887f5f427ebd89d39bd2ddc56c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5e12f9cfc8a343ddb60f50c6de3275ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0728253c9a0c44959e491c5d59061a72",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 442,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 442,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d96cf7785c304b2d97aed740e9a0dffe"
          }
        },
        "6faee1983f564d5993aee157c9deccc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_70769eb544f84c5fb688859594f2c635",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 442/442 [00:00&lt;00:00, 4.47kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2ef86a3bd09143d897b6aed270c9f4bc"
          }
        },
        "0728253c9a0c44959e491c5d59061a72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d96cf7785c304b2d97aed740e9a0dffe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "70769eb544f84c5fb688859594f2c635": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2ef86a3bd09143d897b6aed270c9f4bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bbeeed0f42b44431b2ae60f49526f4cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_daf66f65ae614e3b8883b36ed0a2dce2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_502ed2954ecd4b4e8716749994f80a26",
              "IPY_MODEL_ad5a760951964a1caa1a9ebdb5382df5"
            ]
          }
        },
        "daf66f65ae614e3b8883b36ed0a2dce2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "502ed2954ecd4b4e8716749994f80a26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_62aa5006f8ac4876a918f2e7bd34d234",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 267967963,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 267967963,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a0db0184f95a426eac7b42d5d1654208"
          }
        },
        "ad5a760951964a1caa1a9ebdb5382df5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d47392e81951406495627a879bc16911",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 268M/268M [00:07&lt;00:00, 37.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8d69df1e63804d55965233b99a2ffdf4"
          }
        },
        "62aa5006f8ac4876a918f2e7bd34d234": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a0db0184f95a426eac7b42d5d1654208": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d47392e81951406495627a879bc16911": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8d69df1e63804d55965233b99a2ffdf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s-c-soma/deep_context_graph/blob/main/code/TrendDetection_pipeline_colab_version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyPuEQQ-IBoM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c8adfe0-6cfb-4d62-fda6-bb291fe1e0d9"
      },
      "source": [
        "import os\n",
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOwqe1yW8_NX"
      },
      "source": [
        "# Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rM1DyIDL8_Nl"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwWqkEx78_Nm",
        "outputId": "bc5f8e8b-623e-4294-cfa9-1e055a899c09"
      },
      "source": [
        "!pip install dateparser"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting dateparser\n",
            "  Downloading dateparser-1.0.0-py2.py3-none-any.whl (279 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▏                              | 10 kB 26.6 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20 kB 31.3 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 30 kB 37.2 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 40 kB 39.0 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 51 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |███████                         | 61 kB 34.2 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 71 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 81 kB 28.7 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 92 kB 30.3 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 102 kB 31.9 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 112 kB 31.9 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 122 kB 31.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 133 kB 31.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 143 kB 31.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 153 kB 31.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 163 kB 31.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 174 kB 31.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 184 kB 31.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 194 kB 31.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 204 kB 31.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 215 kB 31.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 225 kB 31.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 235 kB 31.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 245 kB 31.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 256 kB 31.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 266 kB 31.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 276 kB 31.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 279 kB 31.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from dateparser) (2.8.1)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from dateparser) (1.5.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from dateparser) (2018.9)\n",
            "Requirement already satisfied: regex!=2019.02.19 in /usr/local/lib/python3.7/dist-packages (from dateparser) (2019.12.20)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->dateparser) (1.15.0)\n",
            "Installing collected packages: dateparser\n",
            "Successfully installed dateparser-1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0Bw88v98_No"
      },
      "source": [
        "#Import the dependencies\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import requests\n",
        "import urllib.request\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from dateparser.search import search_dates\n",
        "import re\n",
        "from abc import ABC, abstractmethod\n",
        "from typing import List"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEzmGbhSIa7f"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fonNa_5IgVh"
      },
      "source": [
        "URL = 'https://papers.nips.cc/paper/2020' ## conference paper link\n",
        "#topic_count = 5 ## topic count for passing to the custom query enginine; must stay in limit (<50) for free service\n",
        "ngramsCount =3 ##no of n grams\n",
        "\n",
        "conf_name = 'neurips' ## required for api search\n",
        "topic_file_name = 'neurips_topics_2020_' # to store the result in a csv file\n",
        "file_name = 'neurips_trend_withRanking_2020_' # to store the result in a csv file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBa76Iuo8_Np"
      },
      "source": [
        "## Init"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7UHYkbG8_Nq"
      },
      "source": [
        "#Create lists to store the scraped data\n",
        "#type\ttitle\tauthors\tabstract\tcategory\tkeywords\turl\n",
        "\n",
        "sources = []\n",
        "urls = []\n",
        "titles = []\n",
        "summaries = []\n",
        "dates = []\n",
        "ratings = []\n",
        "bodies = []\n",
        "authors= []\n",
        "publishdate = []\n",
        "relatedlinks = []\n",
        "claims = []\n",
        "abstracts = []\n",
        "type_ = []\n",
        "MATCH_ALL = r'.*'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EF9qGTV8_Nq"
      },
      "source": [
        "## Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoGyXHnK8_Nr"
      },
      "source": [
        "def like(string):\n",
        "    \"\"\"\n",
        "    Return a compiled regular expression that matches the given\n",
        "    string with any prefix and postfix, e.g. if string = \"hello\",\n",
        "    the returned regex matches r\".*hello.*\"\n",
        "    \"\"\"\n",
        "    string_ = string\n",
        "    if not isinstance(string_, str):\n",
        "        string_ = str(string_)\n",
        "    regex = MATCH_ALL + re.escape(string_) + MATCH_ALL\n",
        "    return re.compile(regex, flags=re.DOTALL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snIYiBD28_Ns"
      },
      "source": [
        "def find_by_text(soup, text, tag, **kwargs):\n",
        "    \"\"\"\n",
        "    Find the tag in soup that matches all provided kwargs, and contains the\n",
        "    text.\n",
        "\n",
        "    If no match is found, return None.\n",
        "    If more than one match is found, raise ValueError.\n",
        "    \"\"\"\n",
        "    elements = soup.find_all(tag, **kwargs)\n",
        "    matches = []\n",
        "    for element in elements:\n",
        "        if element.find(text=like(text)):\n",
        "            matches.append(element)\n",
        "    if len(matches) == 0:\n",
        "        return None\n",
        "\n",
        "    return matches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2WsDarM8_Nt"
      },
      "source": [
        "def extract_claim_and_review(parsed_claim_review_page, url):\n",
        "        urls.append(url)\n",
        "        sources.append(\"washingtonpost\")\n",
        "\n",
        "        \n",
        "        # title\n",
        "        title = parsed_claim_review_page.find(\"h1\", {\"class\": \" font--headline gray-darkest pb-sm null \"})\n",
        "        #print(\"title\", title.text)\n",
        "        #soup = BeautifulSoup(title.text)\n",
        "        #print(\"title\", soup.text)\n",
        "        titles.append(title.text)\n",
        "        \n",
        "\n",
        "        # date\n",
        "        date_ = parsed_claim_review_page.find('div', {\"class\": \"display-date \"})#.find(\"p\")\n",
        "        #print(\"date_\", date_)\n",
        "        if date_:\n",
        "            date_str = search_dates(date_.text)[0][1].strftime(\"%Y-%m-%d\")\n",
        "            #print(\"url_date\", url_date)\n",
        "            dates.append(date_str)\n",
        "\n",
        "        # body\n",
        "        body = parsed_claim_review_page.find(\"div\", {\"class\": \"article-body\"})\n",
        "        #print(\"body=\", body.get_text())\n",
        "        #claim.set_body(body.get_text())\n",
        "        bodies.append(body.get_text())\n",
        "        \n",
        "\n",
        "        # related links\n",
        "        divTag = parsed_claim_review_page.find(\"div\", {\"class\": \"article-body\"})\n",
        "        related_links = []\n",
        "        for link in divTag.findAll('a', href=True):\n",
        "            related_links.append(link['href'])\n",
        "        relatedlinks.append(related_links)\n",
        "\n",
        "     \n",
        "        #claims\n",
        "        tags = []\n",
        "        for tag in parsed_claim_review_page.findAll('meta', {\"property\": \"article:tag\"}):\n",
        "            tags.append(tag[\"content\"])\n",
        "        claims.append(\", \".join(tags))\n",
        "       \n",
        "        return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNpm-NLV8_Ns"
      },
      "source": [
        " def extract_urls(parsed_listing_page):\n",
        "        urls = list()\n",
        "        titles = list()\n",
        "        authors = list()\n",
        "        # links = parsed_listing_page.find('ui').findAll('a', href=True)\n",
        "        # finding all li tags in ul and printing the text within it\n",
        "        body = parsed_listing_page.find(\"div\", {\"class\": \"col\"})\n",
        "        data1 = body.find('ul')\n",
        "        #print(data1)\n",
        "        for li in data1.findAll('a', href=True): \n",
        "            url = \"https://papers.nips.cc\" + str(li['href'])\n",
        "            max_claims = 0\n",
        "            if 0 < max_claims <= len(urls):\n",
        "                break\n",
        "            #if url not in self.configuration.avoid_urls:\n",
        "            urls.append(url)\n",
        "            titles.append(li.text)\n",
        "        soup = ''\n",
        "        for li in data1.findAll('i'): \n",
        "            #print(li)\n",
        "            soup = BeautifulSoup(li.text)\n",
        "            #print(soup.text)\n",
        "            authors.append(soup.text)\n",
        "            #break\n",
        "        return urls,titles,authors  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bj9_dMJA1Eqv"
      },
      "source": [
        "def extract_abstract(parsed_listing_page):\n",
        "    sources.append(\"neurips\")\n",
        "    type_.append(\"conference\")\n",
        "\n",
        "    abstracts = list()\n",
        "    body = parsed_listing_page.find(\"div\", {\"class\": \"col\"})\n",
        "    p_tags = body.find_all([\"p\"])\n",
        "    \n",
        "    if len(p_tags)>3:\n",
        "      #print(p_tags[3].text)\n",
        "      abstracts.append(p_tags[3].text)\n",
        "    else: \n",
        "      #print(p_tags)\n",
        "      abstracts.append(p_tags.text)\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhRPZCRTBRkL"
      },
      "source": [
        "abstracts = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9j7JjVMP7EpZ"
      },
      "source": [
        "def extract_abstract2(soup):\n",
        "    sources.append(\"neurips\")\n",
        "    type_.append(\"conference\")\n",
        "\n",
        "    #abstracts = list()\n",
        "    body = soup.find(\"div\", {\"class\": \"col\"})\n",
        "    p_tags = body.find_all([\"p\"])\n",
        "    \n",
        "    body = soup.find(\"div\", {\"class\": \"col\"})\n",
        "    #body\n",
        "    p_tags = body.find_all([\"p\"])\n",
        "\n",
        "    soup1=''\n",
        "    if len(p_tags)>=3:\n",
        "          #print(p_tags)\n",
        "          soup1 = BeautifulSoup(p_tags[2].text)\n",
        "          #print(soup1.text)\n",
        "          abstracts.append(soup1.text)\n",
        "    else: \n",
        "          #print(p_tags)\n",
        "          soup1 = BeautifulSoup(p_tags.text)\n",
        "          #print(soup1.text)\n",
        "          abstracts.append(soup1.text)\n",
        "          #print(p_tags)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqRHdbwu8_Nt"
      },
      "source": [
        "## 1.Scrape Urls [.scrapeURLs()]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQIm4l6-ujcE",
        "outputId": "a324c380-4e4f-437c-8a59-da8617336904"
      },
      "source": [
        "page_number = 2\n",
        "URL = 'https://papers.nips.cc/paper/2020'\n",
        "webpage = requests.get(URL)  #Make a request to the website\n",
        "soup = BeautifulSoup(webpage.text, \"html.parser\")\n",
        "#print(soup.prettify())\n",
        "\n",
        "extract_url,titles, authors = extract_urls(soup)\n",
        "extract_url"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['https://papers.nips.cc/paper/2020/hash/0004d0b59e19461ff126e3a08a814c33-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/00482b9bed15a272730fcb590ffebddd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0060ef47b12160b9198302ebdb144dcf-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/007ff380ee5ac49ffc34442f5c2a2b86-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0084ae4bc24c0795d1e6a4f58444d39b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/00a03ec6533ca7f5c644d198d815329c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/00ac8ed3b4327bdd4ebbebcb2ba10a00-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/00e26af6ac3b1c1c49d7c3d79c60d000-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/012a91467f210472fab4e11359bbfef6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/012d9fe15b2493f21902cd55603382ec-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0163cceb20f5ca7b313419c068abd9dc-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0169cf885f882efd795951253db5cdfb-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0172d289da48c48de8c5ebf3de9f7ee1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/019fa4fdf1c04cf73ba25aa2223769cd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/01a0683665f38d8e5e567b3b15ca98bf-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/01c9d2c5b3ff5cbba349ec39a570b5e3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/01e00f2f4bfcbb7505cb641066f2859b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/021bbc7ee20b71134d53e20206bd6feb-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/021f6dd88a11ca489936ae770e4634ad-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/022e0ee5162c13d9a7bb3bd00fb032ce-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/023d0a5671efd29e80b4deef8262e297-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/024d2d699e6c1a82c9ba986386f4d824-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/02a3c7fb3f489288ae6942498498db20-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/02e74f10e0327ad868d138f2b4fdd6f0-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/02ed812220b0705fabb868ddbf17ea20-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/02f657d55eaf1c4840ce8d66fcdaf90c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/03255088ed63354a54e0e5ed957e9008-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/03287fcce194dbd958c2ec5b33705912-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0332d694daab22e0e0eaf7a5e88433f9-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/033cc385728c51d97360020ed57776f0-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/03593ce517feac573fdaafa6dcedef61-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/03793ef7d06ffd63d34ade9d091f1ced-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/03fa2f7502f5f6b9169e67d17cbf51bb-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0415740eaa4d9decbc8da001d3fd805f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/045117b0e0a11a242b9765e79cbf113f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/04ecb1fa28506ccb6f72b12c0245ddbc-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/05128e44e27c36bdba71221bfccf735d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/051928341be67dcba03f0e04104d9047-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0561bc7ecba98e39ca7994f93311ba23-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/05a624166c8eb8273b8464e8d9cb5bd9-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/05e2a0647e260c355dd2b2175edb45b8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/05ee45de8d877c3949760a94fa691533-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/05f971b5ec196b8c65b75d2ef8267331-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0607f4c705595b911a4f3e7a127b44e0-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/061412e4a03c02f9902576ec55ebbe77-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0660895c22f8a14eb039bfb9beb0778f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0663a4ddceacb40b095eda264a85f15c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/066ca7bf90807fcd8e4f1eaef4e4e8f7-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/066f182b787111ed4cb65ed437f0855b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0678ca2eae02d542cc931e81b74de122-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/06964dce9addb1c5cb5d6e3d9838f733-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/06a9d51e04213572ef0720dd27a84792-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/06d5ae105ea1bea4d800bc96491876e9-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/070dbb6024b5ef93784428afc71f2146-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/07168af6cb0ef9f78dae15739dd73255-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/07211688a0869d995947a8fb11b215d6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/07217414eb3fbe24d4e5b6cafb91ca18-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0740bb92e583cd2b88ec7c59f985cb41-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/074177d3eb6371e32c16c55a3b8f706b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/075b051ec3d22dac7b33f788da631fd4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/07cb5f86508f146774a2fac4373a8e50-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/07fc15c9d169ee48573edd749d25945d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/08058bf500242562c0d031ff830ad094-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/08425b881bcde94a383cd258cea331be-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0887f1a5b9970ad13f46b8c1485f7900-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/08e5d8066881eab185d0de9db3b36c7f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/08f38e0434442128fab5ead6217ca759-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/08fa43588c2571ade19bc0fa5936e028-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/08fb104b0f2f838f3ce2d2b3741a12c2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0912d0f15f1394268c66639e39b26215-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/093b60fd0557804c8ba0cbf1453da22f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/093f65e080a295f8076b1c5722a46aa2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0987b8b338d6c90bbedd8631bc499221-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/098d86c982354a96556bd861823ebfbd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/099fe6b0b444c23836c4a5d07346082b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/09ccf3183d9e90e5ae1f425d5f9b2c00-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0a2298a72858d90d5c4b4fee954b6896-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0a3b6f64f0523984e51323fe53b8c504-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0a4dc6dae338c9cb08947c07581f77a2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0a5052334511e344f15ae0bfafd47a67-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0a656cc19f3f5b41530182a9e03982a4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0a716fe8c7745e51a3185fc8be6ca23a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0a73de68f10e15626eb98701ecf03adb-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0a93091da5efb0d9d5649e7f6b2ad9d7-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0afe095e81a6ac76ff3f69975cb3e7ae-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0b1ec366924b26fc98fa7b71a9c249cf-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0b5e29aa1acf8bdc5d8935d7036fa4f5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0b6ace9e8971cf36f1782aa982a708db-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0b8aff0438617c055eb55f0ba5d226fa-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0b96d81f0494fde5428c7aea243c9157-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0baf163c24ed14b515aaf57a9de5501c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0c0a7566915f4f24853fc4192689aa7e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0c7119e3a6a2209da6a5b90e5b5b75bd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0c72cb7ee1512f800abe27823a792d03-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0cb5ebb1b34ec343dfe135db691e4a85-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0cbc5671ae26f67871cb914d81ef8fc1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0cc24cb7c26586310cc95c8cb1a81cbc-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0cc6928e741d75e7a92396317522069e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0cc6ee01c82fc49c28706e0918f57e2d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0d2b2061826a5df3221116a5085a6052-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0d352b4d3a317e3eae221199fdb49651-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0d5501edb21a59a43435efa67f200828-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0d5bd023a3ee11c7abca5b42a93c4866-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0d770c496aa3da6d2c3f2bd19e7b9d6b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0d82627e10660af39ea7eb69c3568955-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0d85eb24e2add96ff1a7021f83c1abc9-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0dc23b6a0e4abc39904388dd3ffadcd1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0dd1bc593a91620daecf7723d2235624-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0e1bacf07b14673fcdb553da51b999a5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0e1ebad68af7f0ae4830b7ac92bc3c6f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0e230b1a582d76526b7ad7fc62ae937d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0e4ceef65add6cf21c0f3f9da53b71c0-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0e900ad84f63618452210ab8baae0218-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0ea6f098a59fcf2462afc50d130ff034-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0eac690d7059a8de4b48e90f14510391-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0ec96be397dd6d3cf2fecb4a2d627c1c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0ed9422357395a0d4879191c66f4faa2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0f0e13216262f4a201bec128044dd30f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0f34132b15dd02f282a11ea1e322a96d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0f34314d2dd0c1b9311cb8f40eb4f255-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0ff8033cf9437c213ee13937b1c4c455-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0ffaca95e3e5242ba1097ad8a9a6e95d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1006ff12c465532f8c574aeaa4461b16-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1010cedf85f6a7e24b087e63235dc12e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/102f0bb6efb3a6128a3c750dd16729be-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/103303dd56a731e377d01f6a37badae3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1068bceb19323fe72b2b344ccf85c254-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1091660f3dff84fd648efe31391c5524-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/10c72a9d42dd07a028ee910f7854da5d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/10eb6500bd1e4a3704818012a1593cc3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/10fb6cfa4c990d2bad5ddef4f70e8ba2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1102a326d5f7c9e04fc3c89d0ede88c9-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/11348e03e23b137d55d94464250a67a2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1160453108d3e537255e9f7b931f4e90-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/118bd558033a1016fcc82560c65cca5f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/11953163dd7fb12669b41a48f78a29b6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/11958dfee29b6709f48a9ba0387a2431-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/11f38f8ecd71867b42433548d1078e38-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/122e27d57ae8ecb37f3f1da67abb33cb-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/123650dd0560587918b3d771cf0c0171-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/123b7f02433572a0a560e620311a469c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/12780ea688a71dabc284b064add459a4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/12b1e42dc0746f22cf361267de07073f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/12bcd658ef0a540cabc36cdf2b1046fd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/12d16adf4a9355513f9d574b76087a08-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/12ffb0968f2f56e51a59a6beb37b2859-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1325cdae3b6f0f91a1b629307bf2d498-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1349b36b01e0e804a6c2909a6d0ec72a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1359aa933b48b754a2f54adb688bfa77-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1373b284bc381890049e92d324f56de0-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1385974ed5904a438616ff7bdb3f7439-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/13b919438259814cd5be8cb45877d577-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/13d4635deccc230c944e4ff6e03404b5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/13e36f06c66134ad65f532e90d898545-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/13ec9935e17e00bed6ec8f06230e33a9-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/13f320e7b5ead1024ac95c3b208610db-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/13f3cf8c531952d72e5847c4183e6910-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/13fe9d84310e77f13a6d184dbf1232f3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/146f7dd4c91bc9d80cf4458ad6d6cd1b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1487987e862c44b91a0296cf3866387e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/149ef6419512be56a93169cd5e6fa8fd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/14da15db887a4b50efe5c1bc66537089-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/14faf969228fc18fcd4fcf59437b0c97-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/151d21647527d1079781ba6ae6571ffd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/15231a7ce4ba789d13b722cc5c955834-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1534b76d325a8f591b52d302e7181331-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/155fa09596c7e18e50b58eb7e0c6ccb4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/15825aee15eb335cc13f9b559f166ee8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/15ae3b9d6286f1b2a489ea4f3f4abaed-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/15bb63b28926cd083b15e3b97567bbea-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/16002f7a455a94aa4e91cc34ebdb9f2d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/165a59f7cf3b5c4396ba65953d679f17-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/16837163fee34175358a47e0b51485ff-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/168efc366c449fab9c2843e9b54e2a18-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/169806bb68ccbf5e6f96ddc60c40a044-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/16f8e136ee5693823268874e58795216-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/170f6aa36530c364b77ddf83a84e7351-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/171ae1bbb81475eb96287dd78565b38b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/17256f049f1e3fede17c7a313f7657f4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/17257e81a344982579af1ae6415a7b8c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/172ef5a94b4dd0aa120c6878fc29f70c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1730f69e6f66d5f0c741799e82351f81-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1731592aca5fb4d789c4119c65c10b4b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/174f8f613332b27e9e8a5138adb7e920-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1763ea5a7e72dd7ee64073c2dda7a7a8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1764183ef03fc7324eb58c3842bd9a57-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/176bf6219855a6eb1f3a30903e34b6fb-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/17b3c7061788dbe82de5abe9f6fe22b3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/17f98ddf040204eda0af36a108cbdea4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/18064d61b6f93dab8681a460779b8429-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1819020b02e926785cf3be594d957696-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/186b690e29892f137b4c34cfa40a3a4d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/187acf7982f3c169b3075132380986e4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1896a3bf730516dd643ba67b4c447d36-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/18a010d2a9813e91907ce88cd9143fdf-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/18a411989b47ed75a60ac69d9da05aa5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/18df51b97ccd68128e994804f3eccc87-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/18fc72d8b8aba03a4d84f66efabce82e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/191595dc11b4d6e54f01504e3aa92f96-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/192fc044e74dffea144f9ac5dc9f3395-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/193002e668758ea9762904da1a22337c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1943102704f8f8f3302c2b730728e023-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1959eb9d5a0f7ebc58ebde81d5df400d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1963bd5135521d623f6c29e6b1174975-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/196f5641aa9dc87067da4ff90fd81e7b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/19aa6c6fb4ba9fcf39e893ff1fd5b5bd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/19eca5979ccbb752778e6c5f090dc9b6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1a669e81c8093745261889539694be7f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1a77befc3b608d6ed363567685f70e1e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1aa3d9c6ce672447e1e5d0f1b5207e85-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1abb1e1ea5f481b589da52303b091cbb-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1ac978c8020be6d7212aa71d4f040fc3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1ae6464c6b5d51b363d7d96f97132c75-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1b0251ccb8bd5f9ccf444e4bda7713e3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1b113258af3968aaf3969ca67e744ff8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1b33d16fc562464579b7199ca3114982-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1b69ebedb522700034547abc5652ffac-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1b742ae215adf18b75449c6e272fd92d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1b84c4cee2b8b3d823b30e2d604b1878-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1b9a80606d74d3da6db2f1274557e644-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1ba922ac006a8e5f2b123684c2f4d65f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1bd413de70f32142f4a33a94134c5690-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1bd69c7df3112fb9a584fbd9edfc6c90-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1bda4c789c38754f639a376716c5859f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1c104b9c0accfca52ef21728eaf01453-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1c336b8080f82bcc2cd2499b4c57261d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1c383cd30b7c298ab50293adfecb7b18-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1cb524b5a3f3f82be4a7d954063c07e2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1cc8a8ea51cd0adddf5dab504a285915-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1cd138d0499a68f4bb72bee04bbec2d7-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1cdf14d1e3699d61d237cf76ce1c2dca-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1cf44d7975e6c86cffa70cae95b5fbb2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1cfa81af29c6f2d8cacb44921722e753-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1d8d70dddf147d2d92a634817f01b239-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1da546f25222c1ee710cf7e2f7a3ff0c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1dc3a89d0d440ba31729b0ba74b93a33-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1de7d2b90d554be9f0db1c338e80197d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1def1713ebf17722cbe300cfc1c88558-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1e04b969bf040acd252e1faafb51f829-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1e0b802d5c0e1e8434a771ba7ff2c301-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1e14bfe2714193e7af5abc64ecbd6b46-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1e591403ff232de0f0f139ac51d99295-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1e6e25d952a0d639b676ee20d0519ee2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1e7875cf32d306989d80c14308f3a099-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1e9491470749d5b0e361ce4f0b24d037-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1ea97de85eb634d580161c603422437f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1ee942c6b182d0f041a2312947385b23-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1ef91c212e30e14bf125e9374262401f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1f10c3650a3aa5912dccc5789fd515e8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1f1baa5b8edac74eb4eaa329f14a0361-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1f47cef5e38c952f94c5d61726027439-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1f89885d556929e98d3ef9b86448f951-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1f8d87e1161af68b81bace188a1ec624-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1fc214004c9481e4c8073e85323bfd4b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1fc30b9d4319760b04fab735fbfed9a9-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1fd09c5f59a8ff35d499c0ee25a1d47e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1fd6c4e41e2c6a6b092eb13ee72bce95-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1fdc0ee9d95c71d73df82ac8f0721459-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2000f6325dfc4fc3201fc45ed01c7a5d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/20125fd9b2d43e340a35fb0278da235d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/201d7288b4c18a679e48b31c72c30ded-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/20479c788fb27378c2c99eadcf207e7f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2051bd70fc110a2208bdbd4a743e7f79-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/205e73579f21c2ed134dbd6ce7e4a1ea-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/20b02dc95171540bc52912baf3aa709d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/20b5e1cf8694af7a3c1ba4a87f073021-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/20c86a628232a67e7bd46f76fba7ce12-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/20d749bc05f47d2bd3026ce457dcfd8e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2109737282d2c2de4fc5534be26c9bb6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/211b39255232ab59ce78f2e28cd0292b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/212ab20dbdf4191cbcdcf015511783f4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/21327ba33b3689e713cdff1641128004-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/216f44e2d28d4e175a194492bde9148f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2172fde49301047270b2897085e4319d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/217eedd1ba8c592db97d0dbe54c7adfc-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/219e052492f4008818b8adb6366c7ed6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/21d144c75af2c3a1cb90441bbb7d8b40-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/222afbe0d68c61de60374b96f1d86715-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/227f6afd3b7f89b96c4bb91f95d50f6d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/228669109aa3ab1b4ec06b7722efb105-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2288f691b58edecadcc9a8691762b4fd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2290a7385ed77cc5592dc2153229f082-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/229aeb9e2ae66f2fac1149e5240b2fdd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/22bb543b251c39ccdad8063d486987bb-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/22eda830d1051274a2581d6466c06e6c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/22f791da07b0d8a2504c2537c560001c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/23378a2d0a25c6ade2c1da1c06c5213f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/234833147b97bb6aed53a8f4f1c7a7d8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/234b941e88b755b7a72a1c1dd5022f30-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/234e691320c0ad5b45ee3c96d0d7b8f8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/23685a2431acad7789c1e3d43ea1522c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/236f119f58f5fd102c5a2ca609fdcbd8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/23937b42f9273974570fb5a56a6652ee-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/23ad3e314e2a2b43b4c720507cec0723-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/23af4b45f1e166141a790d1a3126e77a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/240ac9371ec2671ae99847c3ae2e6384-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/24357dd085d2c4b1a88a7e0692e60294-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/24368c745de15b3d2d6279667debcba3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/24389bfe4fe2eba8bf9aa9203a44cdad-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/243be2818a23c980ad664f30f48e5d19-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/244edd7e85dc81602b7615cd705545f5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/24aef8cb3281a2422a59b51659f1ad2e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/24bcb4d0caa4120575bb45c8a156b651-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/24bea84d52e6a1f8025e313c2ffff50a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/24f2f931f12a4d9149876a5bef93e96a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2517756c5a9be6ac007fe9bb7fb92611-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/258be18e31c8188555c2ff05b4d542c3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/25ddc0f8c9d3e22e03d3076f98d83cb2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/26178fc759d2b89c45dd31962f81dc61-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/26588e932c7ccfa1df309280702fe1b5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/26b58a41da329e0cbde0cbf956640a58-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/26d88423fc6da243ffddf161ca712757-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/26ed695e9b7b9f6463ef4bc1fd74fc87-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/27059a11c58ade9b03bde05c2ca7c285-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/272e11700558e27be60f7489d2d782e7-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/274e6fcf4a583de4a81c6376f17673e7-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/275d7fb2fd45098ad5c3ece2ed4a2824-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2779fda014fbadb761f67dd708c1325e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2794f6a20ee0685f4006210f40799acd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/27b587bbe83aecf9a98c8fe6ab48cacc-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/27d8d40b22f812a1ba6c26f8ef7df480-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/27e9661e033a73a6ad8cefcde965c54d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/28538c394c36e4d5ea8ff5ad60562a93-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/285baacbdf8fda1de94b19282acd23e2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/285f89b802bcb2651801455c86d78f2a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/288cd2567953f06e460a33951f55daaf-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/28a7602724ba16600d5ccc644c19bf18-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/28e209b61a52482a0ae1cb9f5959c792-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/28f248e9279ac845995c4e9f8af35c2b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/291597a100aadd814d197af4f4bab3a7-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/291dbc18539ba7e19b8abb7d85aa204e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/293835c2cc75b585649498ee74b395f5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/29405e2a4c22866a205f557559c7fa4b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/294e09f267683c7ddc6cc5134a7e68a8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2952351097998ac1240cb2ab7333a3d2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/29539ed932d32f1c56324cded92c07c2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/29586cb449c90e249f1f09a0a4ee245a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2974788b53f73e7950e8aa49f3a306db-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/299dc35e747eb77177d9cea10a802da2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/29a6aa8af3c942a277478a90aa4cae21-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/29c0605a3bab4229e46723f89cf59d83-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/29e48b79ae6fc68e9b6480b677453586-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2a084e55c87b1ebcdaad1f62fdbbac8e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2a27b8144ac02f67687f76782a3b5d8f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2adcfc3929e7c03fac3100d3ad51da26-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2adee8815dd939548ee6b2772524b6f2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2b346a0aa375a07f5a90a344a61416c4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2b64c2f19d868305aa8bbc2d72902cc5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2ba596643cbbbc20318224181fa46b28-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2ba61cc3a8f44143e1f2f13b2b729ab3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2bba9f4124283edd644799e0cecd45ca-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2be5f9c2e3620eb73c2972d7552b6cb5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2c29d89cc56cdb191c60db2f0bae796b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2c5201a7391fedbc40c3cc6aa057a029-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2c6a0bae0f071cbbf0bb3d5b11d90a82-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2c75cf2681788adaca63aa95ae028b22-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2cb274e6ce940f47beb8011d8ecb1462-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2cd2915e69546904e4e5d4a2ac9e1652-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2cd4e8a2ce081c3d7c32c3cde4312ef7-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2cfa3753d6a524711acb5fce38eeca1a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2cfa8f9e50e0f510ede9d12338a5f564-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2d16ad1968844a4300e9a490588ff9f8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2df45244f09369e16ea3f9117ca45157-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2dfe1946b3003933b7f8ddd71f24dbb1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2e1b24a664f5e9c18f407b2f9c73e821-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2e255d2d6bf9bb33030246d31f1a79ca-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2e2c4bf7ceaa4712a72dd5ee136dc9a8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2e6d9c6052e99fcdfa61d9b9da273ca2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2e85d72295b67c5b649290dfbf019285-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2f10c1578a0706e06b6d7db6f0b4a6af-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2f2b265625d76a6704b08093c652fd79-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2f380b99d45812a211da102c04dc1ddb-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2f3bbb9730639e9ea48f309d9a79ff01-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2f73168bf3656f697507752ec592c437-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2fd5d41ec6cfab47e32164d5624269b1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3000311ca56a1cb93397bc676c0b7fff-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/300891a62162b960cf02ce3827bb363c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/305ddad049f65a2c241dbb6e6f746c54-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/309fee4e541e51de2e41f21bebb342aa-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/30da227c6b5b9e2482b6b221c711edfd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/30de24287a6d8f07b37c716ad51623a7-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/30de9ece7cf3790c8c39ccff1a044209-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/30ee748d38e21392de740e2f9dc686b6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/30f0641c041f03d94e95a76b9d8bd58f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/310614fca8fb8e5491295336298c340f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/310cc7ca5a76a446f85c1a0d641ba96d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/313f422ac583444ba6045cd122653b0e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/31784d9fc1fa0d25d04eae50ac9bf787-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3181d59d19e76e902666df5c7821259a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/31fefc0e570cb3860f2a6d4b38c6490d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3202111cf90e7c816a472aaceb72b0df-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3214a6d842cc69597f9edf26df552e43-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/322f62469c5e3c7dc3e58f5a4d1ea399-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/32508f53f24c46f685870a075eaaa29c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3261769be720b0fefbfffec05e9d9202-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/328e5d4c166bb340b314d457a208dc83-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3295c76acbf4caaed33c36b1b5fc2cb1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/32bb90e8976aab5298d5da10fe66f21d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/32cfdce9631d8c7906e8e9d6e68b514b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/32e54441e6382a7fbacbbbaf3c450059-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/32fcc8cfe1fa4c77b5c58dafd36d1a98-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/331316d4efb44682092a006307b9ae3a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3341f6f048384ec73a7ba2e77d2db48b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/335cd1b90bfa4ee70b39d08a4ae0cf2d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/339a18def9898dd60a634b2ad8fbbd58-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/33a5435d4f945aa6154b31a73bab3b73-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/33a854e247155d590883b93bca53848a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/33c5f5bff65aa05a8cd3e5d2597f44ae-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/33cc2b872dfe481abef0f61af181dfcf-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/33cf42b38bbcf1dd6ba6b0f0cd005328-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/33d3b157ddc0896addfb22fa2a519097-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/33dd6dba1d56e826aac1cbf23cdcca87-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/33e75ff09dd601bbe69f351039152189-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/342285bb2a8cadef22f667eeb6a63732-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/342c472b95d00421be10e9512b532866-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3430095c577593aad3c39c701712bcfe-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/34609bdc08a07ace4e1526bbb1777673-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3465ab6e0c21086020e382f09a482ced-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3472ab80b6dff70c54758fd6dfc800c2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3493894fa4ea036cfc6433c3e2ee63b0-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3501672ebc68a5524629080e3ef60aef-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/350a7f5ee27d22dbe36698b10930ff96-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/35464c848f410e55a13bb9d78e7fddd0-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/354ac345fd8c6d7ef634d9a8e3d47b83-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/356dc40642abeb3a437e7e06f178701c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/357a6fdf7642bf815a88822c447d9dc4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/35adf1ae7eb5734122c84b7a9ea5cc13-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/36ac8e558ac7690b6f44e2cb5ef93322-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/36dcd524971019336af02550264b8a08-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/373e4c5d8edfa8b74fd4b6791d0cf6dc-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/37693cfc748049e45d87b8c7d8b9aacd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/37740d59bb0eb7b4493725b2e0e5289b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/37aa5dfc44dddd0d19d4311e2c7a0240-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/37bc5e7fb6931a50b3464ec66179085f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/37d097caf1299d9aa79c2c2b843d2d78-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/37e7897f62e8d91b1ce60515829ca282-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/37e79373884f0f0b70b5cb91fb947148-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/37f76c6fe3ab45e0cd7ecb176b5a046d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3812f9a59b634c2a9c574610eaba5bed-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/385822e359afa26d52b5b286226f2cea-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/386854131f58a556343e056f03626e00-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/38a77aa456fc813af07bb428f2363c8d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/38a8e18d75e95ca619af8df0da1417f2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/39016cfe079db1bfb359ca72fcba3fd8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3948ead63a9f2944218de038d8934305-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/397d6b4c83c91021fe928a8c4220386b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/39d0a8908fbe6c18039ea8227f827023-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/39d4b545fb02556829aab1db805021c3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3a01fc0853ebeba94fde4d1cc6fb842a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3a029f04d76d32e79367c4b3255dda4d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3a0772443a0739141292a5429b952fe6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3a077e8acfc4a2b463c47f2125fdfac5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3a30be93eb45566a90f4e95ee72a089a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3a37abdeefe1dab1b30f7c5c7e581b93-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3a4496776767aaa99f9804d0905fe584-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3a61ed715ee66c48bacf237fa7bb5289-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3a93a609b97ec0ab0ff5539eb79ef33a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3ab6be46e1d6b21d59a3c3a0b9d0f6ef-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3ac48664b7886cf4e4ab4aba7e6b6bc9-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3acb2a202ae4bea8840224e6fce16fd0-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3ad7c2ebb96fcba7cda0cf54a2e802f5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3b13b1eb44b05f57735764786fab9c2c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3b2acfe2e38102074656ed938abf4ac3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3bb585ea00014b0e3ebe4c6dd165a358-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3be0214185d6177a9aa6adea5a720b09-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3c09bb10e2189124fdd8f467cc8b55a7-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3c0de3fec9ab8a3df01109251f137119-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3c56fe2f24038c4d22b9eb0aca78f590-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3c8f9a173f749710d6377d3150cf90da-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3cc697419ea18cc98d525999665cb94a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3ce3bd7d63a2c9c81983cc8e9bd02ae5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3d2d8ccb37df977cb6d9da15b76c3f3a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3d8e03e8b133b16f13a586f0c01b6866-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3d9dabe52805a1ea21864b09f3397593-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3db54f5573cd617a0112d35dd1e6b1ef-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3def184ad8f4755ff269862ea77393dd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3df80af53dce8435cf9ad6c3e7a403fd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3e5190eeb51ebe6c5bbc54ee8950c548-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3e91970f771a2c473ae36b60d1146068-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3eb46aa5d93b7a5939616af91addfa88-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3f13cf4ddf6fc50c0d39a1d5aeb57dd8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3f1656d9668dffcf8119e3ecff873558-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3f2dff7862a70f97a59a1fa02c3ec110-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3f8b2a81da929223ae025fcec26dde0d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3fb04953d95a94367bb133f862402bce-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3fe230348e9a12c13120749e3f9fa4cd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3fe78a8acf5fda99de95303940a2420c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3fe94a002317b5f9259f82690aeea4cd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/405075699f065e43581f27d67bb68478-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/412604be30f701b1b1e3124c252065e6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/415e1af7ea95f89f4e375162b21ae38c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4175a4b46a45813fccf4bd34c779d817-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/417fbbf2e9d5a28a855a11894b2e795a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/418db2ea5d227a9ea8db8e5357ca2084-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/41c542dfe6e4fc3deb251d64cf6ed2e4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/41d80bfc327ef980528426fc810a6d7a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/41e7637e7b6a9f27a98b84d3a185c7c0-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/42299f06ee419aa5d9d07798b56779e2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/426f990b332ef8193a61cc90516c1245-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/42ae1544956fbe6e09242e6cd752444c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/42cd63cb189c30ed03e42ce2c069566c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4311359ed4969e8401880e3c1836fbe1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/43207fd5e34f87c48d584fc5c11befb8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4324e8d0d37b110ee1a4f1633ac52df5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4379cf00e1a95a97a33dac10ce454ca4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/438124b4c06f3a5caffab2c07863b617-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/439d8c975f26e5005dcdbf41b0d84161-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/439fca360bc99c315c5882c4432ae7a4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/43a7c24e2d1fe375ce60d84ac901819f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/43bb733c1b62a5e374c63cb22fa457b4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/43e4e6a6f341e00671e123714de019a8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/440924c5948e05070663f88e69e8242b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/440e7c3eb9bbcd4c33c3535354a51605-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/443dec3062d0286986e21dc0631734c9-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/445e1050156c6ae8c082a8422bb7dfc0-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/448d5eda79895153938a8431919f4c9f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4491777b1aa8b5b32c2e8666dbe1a495-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4496bf24afe7fab6f046bf4923da8de6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/44bf89b63173d40fb39f9842e308b3f9-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/44e76e99b5e194377e955b13fb12f630-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/44ece762ae7e41e3a0b1301488907eaa-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/44f683a84163b3523afe57c2e008bc8c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/44feb0096faa8326192570788b38c1d1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/456048afb7253926e1fbb7486e699180-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/45713f6ff2041d3fdfae927b82488db8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/45c166d697d65080d54501403b433256-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/45f31d16b1058d586fc3be7207b58053-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/45fbc6d3e05ebd93369ce542e8f2322d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/460191c72f67e90150a093b4585e7eb4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4607f7fff0dce694258e1c637512aa9d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/464074179972cbbd75a39abc6954cd12-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/46489c17893dfdcf028883202cefd6d1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/46a4378f835dc8040c8057beb6a2da52-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/473803f0f2ebd77d83ee60daaa61f381-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/475d66314dc56a0df8fb8f7c5dbbaf78-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/477bdb55b231264bb53a7942fd84254d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/47951a40efc0d2f7da8ff1ecbfde80f4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/47a3893cc405396a5c30d91320572d6d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/47a658229eb2368a99f1d032c8848542-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/47ce0875420b2dbacfc5535f94e68433-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/47d40767c7e9df50249ebfd9c7cfff77-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/47fd3c87f42f55d4b233417d49c34783-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/481d462e46c2ab976294271a175b8929-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/481fbfa59da2581098e841b7afc122f1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/48237d9f2dea8c74c2a72126cf63d933-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/483101a6bc4e6c46a86222eb65fbcb6a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/488e4104520c6aab692863cc1dba45af-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/48db71587df6c7c442e5b76cc723169a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/48e59000d7dfcf6c1d96ce4a603ed738-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/48f7d3043bc03e6c48a6f0ebc0f258a8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/490640b43519c77281cb2f8471e61a71-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/492114f6915a69aa3dd005aa4233ef51-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/49562478de4c54fafd4ec46fdb297de5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/497476fe61816251905e8baafdf54c23-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/49856ed476ad01fcff881d57e161d73f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/49ca03822497d26a3943d5084ed59130-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/49f85a9ed090b20c8bed85a5923c669f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4a4526b1ec301744aba9526d78fcb2a6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4a46fbfca3f1465a27b210f4bdfe6ab3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4a5876b450b45371f6cfe5047ac8cd45-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4a5cfa9281924139db466a8a19291aff-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4aaa76178f8567e05c8e8295c96171d8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4afd521d77158e02aed37e2274b90c9c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4b0091f82f50ff7095647fe893580d60-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4b21cf96d4cf612f239a6c322b10c8fe-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4b29fa4efe4fb7bc667c7b301b74d52d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4b86ca48d90bd5f0978afa3a012503a4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4bb236de7787ceedafdff83bb8ea4710-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4be2c8f27b8a420492f2d44463933eb6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4bfbd52f4e8466dc12aaf30b7e057b66-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4c2e5eaae9152079b9e95845750bb9ab-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4c5bcfec8584af0d967f1ab10179ca4b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4cc05b35c2f937c5bd9e7d41d3686fff-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4cc5400e63624c44fadeda99f57588a6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4cea2358d3cc5f8cd32397ca9bc51b94-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4d410063822cd9be28f86701c0bc3a31-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4d771504ddcd28037b4199740df767e6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4d7e0d72898ae7ea3593eb5ebf20c744-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4d95d05a4fc4eadbc3b9dde67afdca39-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4db73860ecb5533b5a6c710341d5bbec-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4dbf29d90d5780cab50897fb955e4373-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4dc3ed26a29c9c3df3ec373524377a5b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4dd9cec1c21bc54eecb53786a2c5fa09-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4dea382d82666332fb564f2e711cbc71-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4df5bde009073d3ef60da64d736724d6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4e0928de075538c593fbdabb0c5ef2c3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4e668929edb3bf915e1a3a9d96c3c97e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4eab60e55fe4c7dd567a0be28016bff3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4eb7d41ae6005f60fe401e56277ebd4e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4ebd440d99504722d80de606ea8507da-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4ecb679fd35dcfd0f0894c399590be1a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4ee78d4122ef8503fe01cdad3e9ea4ee-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4ef2f8259495563cb3a8ea4449ec4f9f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4ef42b32bccc9485b10b8183507e5d82-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4eff0720836a198b6174eecf02cbfdbf-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4f00921114932db3f8662a41b44ee68f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4f20f7f5d2e7a1b640ebc8244428558c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4f87658ef0de194413056248a00ce009-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4fbe073f17f161810fdf3dab1307b30f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4fc28b7093b135c21c7183ac07e928a6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5034a5d62f91942d2a7aeaf527dfe111-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/50905d7b2216bfeccb5b41016357176b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/50c1f44e426560f3f2cdcb3e19e39903-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/50cf0fe63e0ff857e1c9d01d827267ca-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/510f2318f324cf07fce24c3a4b89c771-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/51200d29d1fc15f5a71c1dab4bb54f7c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/512c5cad6c37edb98ae91c8a76c3a291-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/51311013e51adebc3c34d2cc591fefee-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5133aa1d673894d5a05b9d83809b9dbe-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/517f24c02e620d5a4dac1db388664a63-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/518a38cc9a0173d0b2dc088166981cf8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/51cdbd2611e844ece5d80878eb770436-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/51f4efbfb3e18f4ea053c4d3d282c4e2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5227fa9a19dce7ba113f50a405dcaf09-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/524f141e189d2a00968c3d48cadd4159-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5265d33c184af566aeb7ef8afd0b9b03-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/52aaa62e71f829d41d74892a18a11d59-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/52cf49fea5ff66588408852f65cf8272-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/52d2752b150f9c35ccb6869cbf074e48-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/52f4691a4de70b3c441bca6c546979d9-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5301c4d888f5204274439e6dcf5fdb54-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/531d29a813ef9471aad0a5558d449a73-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/537d9b6c927223c796cac288cced29df-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/53c04118df112c13a8c34b38343b9c10-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/53c5b2affa12eed84dfec9bfd83550b1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/54391c872fe1c8b4f98095c5d6ec7ec7-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/543e83748234f7cbab21aa0ade66565f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/54e0e46b6647aa736c13ef9d09eab432-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/54f3bc04830d762a3b56a789b6ff62df-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/55053683268957697aa39fba6f231c68-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/551fdbb810aff145c114b93867dd8bfd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/55479c55ebd1efd3ff125f1337100388-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/555d6702c950ecb729a966504af0a635-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/55d491cf951b1b920900684d71419282-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5607fe8879e4fd269e88387e8cb30b7e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/564127c03caab942e503ee6f810f54fd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/56577889b3c1cd083b6d7b32d32f99d5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/565e8a413d0562de9ee4378402d2b481-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/566f0ea4f6c2e947f36795c8f58ba901-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/567b8f5f423af15818a068235807edc0-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/569ff987c643b4bedf504efda8f786c2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/56dc0997d871e9177069bb472574eb29-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/56f9f88906aebf4ad985aaec7fa01313-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/572201a4497b0b9f02d4f279b09ec30d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5763abe87ed1938799203fb6e8650025-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5781a2637b476d781eb3134581b32044-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/57cd30d9088b0185cf0ebca1a472ff1d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/57e5cb96e22546001f1d6520ff11d9ba-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/588cb956d6bbe67078f29f8de420a13d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5898d8095428ee310bf7fa3da1864ff7-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/58ae23d878a47004366189884c2f8440-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/58c54802a9fb9526cd0923353a34a7ae-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5938b4d054136e5d59ada6ec9c295d7a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/593906af0d138e69f49d251d3e7cbed0-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/595373f017b659cb7743291e920a8857-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/59587bffec1c7846f3e34230141556ae-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/597c7b407a02cc0a92167e7a371eca25-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/59a3adea76fadcb6dd9e54c96fc155d1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/59accb9fe696ce55e28b7d23a009e2d1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5a01f0597ac4bdf35c24846734ee9a76-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5a16bce575f3ddce9c819de125ba0029-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5a29503a4909fcade36b1823e7cebcf5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5a378f8490c8d6af8647a753812f6e31-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5a5eab21ca2a8fef4af5e35709ecca15-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5a66b9200f29ac3fa0ae244cc2a51b39-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5a751d6a0b6ef05cfe51b86e5d1458e6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5a7b238ba0f6502e5d6be14424b20ded-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5b0fa0e4c041548bb6289e15d865a696-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5b8e9841e87fb8fc590434f5d933c92c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5bca8566db79f3788be9efd96c9ed70d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5bce843dd76db8c939d5323dd3e54ec9-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5bd844f11fa520d54fa5edec06ea2507-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5bf8aaef51c6e0d363cbe554acaf3f20-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5c3b99e8f92532e5ad1556e53ceea00c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5c528e25e1fdeaf9d8160dc24dbf4d60-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5c9452254bccd24b8ad0bb1ab4408ad1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5ca359ab1e9e3b9c478459944a2d9ca5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5ca41a86596a5ed567d15af0be224952-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5cb0e249689cd6d8369c4885435a56c2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5cc3749a6e56ef6d656735dff9176074-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5cc4bb753030a3d804351b2dfec0d8b5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5cd5058bca53951ffa7801bcdf421651-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5d0cb12f8c9ad6845110317afc6e2183-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5d0d5594d24f0f955548f0fc0ff83d10-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5d151d1059a6281335a10732fc49620e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5d40954183d62a82257835477ccad3d2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5d44ee6f2c3f71b73125876103c8f6c4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5d79099fcdf499f12b79770834c0164a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5d97f4dd7c44b2905c799db681b80ce0-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5dbc8390f17e019d300d5a162c3ce3bc-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5de8a36008b04a6167761fa19b61aa6c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5df0385cba256a135be596dbe28fa7aa-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5e1b18c4c6a6d31695acbae3fd70ecc6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5e5dd00d770ef3e9154a4257edcb80b8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5e98d23afe19a774d1b2dcbefd5103eb-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5ef20b89bab8fed38253e98a12f26316-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5f0ad4db43d8723d18169b2e4817a160-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5f14615696649541a025d3d0f8e0447f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5f268dfb0fbef44de0f668a022707b86-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5f7695debd8cde8db5abcb9f161b49ea-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5f8b73c0d4b1bf60dd7173b660b87c29-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5fb37d5bbdbbae16dea2f3104d7f9439-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/60495b4e033e9f60b32a6607b587aadd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/604b37ea63ea51fa5fb3d8a89ec056e6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/604f2c31e67034642b288d76a8df11d5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/607bc9ebe4abfcd65181bfbef6252830-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/609a199881ca4ba9c95688235cd6ac5c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/609c5e5089a9aa967232aba2a4d03114-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/609e9d4bcc8157c00808993f612f1acd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/60a70bb05b08d6cd95deb3bdb750dce8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/60cb558c40e4f18479664069d9642d5a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/60e1deb043af37db5ea4ce9ae8d2c9ea-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6101903146e4bbf4999c449d78441606-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/618491e20a9b686b79e158c293ab4f91-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/618790ae971abb5610b16c826fb72d01-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/61a10e6abb1149ad9d08f303267f9bc4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/61c66a2f4e6e10dc9c16ddf9d19745d6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/61d77652c97ef636343742fc3dcf3ba9-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/62000dee5a05a6a71de3a6127a68778a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6217b2f7e4634fa665d31d3b4df81b56-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/62326dc7c4f7b849d6f013ba46489d6c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6244b2ba957c48bc64582cf2bcec3d04-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6271faadeedd7626d661856b7a004e27-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6275d7071d005260ab9d0766d6df1145-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/62d75fb2e3075506e8837d8f55021ab1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/62da5a6d47be0029801ba74a17e47e1a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/62db9e3397c76207a687c360e0243317-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/630eff1b380505a67570dff952ce4ad7-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/631e9c01c190fc1515b9fe3865abbb15-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/634841a6831464b64c072c8510c7f35c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/636efd4f9aeb5781e9ea815cdd633e52-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/63c17d596f401acb520efe4a2a7a01ee-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/63c3ddcc7b23daa1e42dc41f9a44a873-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/63d5fb54a858dd033fe90e6e4a74b0f0-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/63f44623dd8686aba388944c8810087f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/641d77dd5271fca28764612a028d9c8e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/645e6bfdd05d1a69c5e47b20f0a91d46-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/64714a86909d401f8feb83e8c2d94b23-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6495cf7ca745a9443508b86951b8e33a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/64986d86a17424eeac96b08a6d519059-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/649d45bf179296e31731adfd4df25588-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/64a08e5f1e6c39faeb90108c430eb120-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/64dcf3c521a00dbb4d2a10a27a95a9d8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/652c208b21f13f6e995bfc1154a1a2e5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6547884cea64550284728eb26b0947ef-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/65586803f1435736f42a541d3a924595-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/657b96f0592803e25a4f07166fff289a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/65a99bb7a3115fdede20da98b08a370f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/65ae450c5536606c266f49f1c08321f2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/65cf25ef90de99d93fa96dc49d0d8b3c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/66121d1f782d29b62a286909165517bc-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/661b1e76b95cc50a7a11a85619a67d95-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/662a2e96162905620397b19c9d249781-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6646b06b90bd13dabc11ddba01270d23-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/665d5cbb82b5785d9f344c46417c6c36-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/66de6afdfb5fb3c21d0e3b5c3226bf00-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/670c26185a3783678135b4697f7dbd1a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/672cf3025399742b1a047c8dc6b1e992-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6734fa703f6633ab896eecbdfad8953a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/673de96b04fa3adcae1aacda704217ef-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6740526b78c0b230e41ae61d8ca07cf5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6754e06e46dfa419d5afe3c9781cecad-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/67d16d00201083a2b118dd5128dd6f59-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/67e235e7f2fa8800d8375409b566e6b6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/67ff32d40fb51f1a2fd2c4f1b1019785-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/680390c55bbd9ce416d1d69a9ab4760d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6811f9b2bf86bf64e3f320973119b959-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6822951732be44edf818dc5a97d32ca6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/685ac8cadc1be5ac98da9556bc1c8d9e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/685bfde03eb646c27ed565881917c71c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/68a9750337a418a86fe06c1991a1d64c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/68ce199ec2c5517597ce0a4d89620f55-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/68d3743587f71fbaa5062152985aff40-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/68dd09b9ff11f0df5624a690fe0f6729-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/690d83983a63aa1818423fd6edd3bfdb-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/690f44c8c2b7ded579d01abe8fdb6110-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/691dcb1d65f31967a874d18383b9da75-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6925f2a16026e36e4fc112f82dd79406-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6933b5648c59d618bbb30986c84080fe-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6950aa02ae8613af620668146dd11840-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/69bfa2aa2b7b139ff581a806abf0a886-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/69d1fc78dbda242c43ad6590368912d4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/69eba34671b3ef1ef38ee85caae6b2a1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6a508a60aa3bf9510ea6acb021c94b48-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6a61d423d02a1c56250dc23ae7ff12f3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6aaba9a124857622930ca4e50f5afed2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6abba5d8ab1f4f32243e174beb754661-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6ad4174eba19ecb5fed17411a34ff5e6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6affee954d76859baa2800e1c49e2c5d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6b39183e7053a0106e4376f4e9c5c74d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6b493230205f780e1bc26945df7481e5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6b5617315c9ac918215fc7514bef514b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6b8b8e3bd6ad94b985c1b1f1b7a94cb2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6ba3af5d7b2790e73f0de32e5c8c1798-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6bb56208f672af0dd65451f869fedfd9-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6c1e55ec7c43dc51a37472ddcbd756fb-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6c250b592dc94d4de38a79db4d2b18f2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6c81c83c4bd0b58850495f603ab45a93-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6cd9313ed34ef58bad3fdd504355e72c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6ce8d8f3b038f737cefcdafcf3752452-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6cfe0e6127fa25df2a0ef2ae1067d915-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6d0c932802f6953f70eb20931645fa40-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6d34d468ac8876333c4d7173b85efed9-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6d70cb65d15211726dcce4c0e971e21c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6d79e030371e47e6231337805a7a2685-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6d7d394c9d0c886e9247542e06ebb705-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6dbbe6abe5f14af882ff977fc3f35501-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6dd4e10e3296fa63738371ec0d5df818-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6df182582740607da754e4515b70e32d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6dfe08eda761bd321f8a9b239f6f4ec3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6e01383fd96a17ae51cc3e15447e7533-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6e17a5fd135fcaf4b49f2860c2474c7c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6e69ebbfad976d4637bb4b39de261bf7-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6ef1173b096aa200158bfbc8af3ae8e3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6f1d0705c91c2145201df18a1a0c7345-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6f2268bd1d3d3ebaabb04d6b5d099425-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6f3a770e5af1fd4cadc5f004b81e1040-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6f5216f8d89b086c18298e043bfe48ed-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6f5e4e86a87220e5d361ad82f1ebc335-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6fbd841e2e4b2938351a4f9b68f12e6b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6fd86e0ad726b778e37cf270fa0247d7-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6fd9a99a5abed788d9afc9d52d54e91b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6fe43269967adbb64ec6149852b5cc3e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6fec24eac8f18ed793f5eaad3dd7977c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/703957b6dd9e3a7980e040bee50ded65-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/70431e77d378d760c3c5456519f06efe-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7078971350bcefbc6ec2779c9b84a9bd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/70d85f35a1fdc0ab701ff78779306407-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/70feb62b69f16e0238f741fab228fec2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/712a3c9878efeae8ff06d57432016ceb-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7137debd45ae4d0ab9aa953017286b20-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/713fd63d76c8a57b16fc433fb4ae718a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7183145a2a3e0ce2b68cd3735186b1d5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/71a58e8cb75904f24cde464161c3e766-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/71c1806ca28b555c76650f52bb0d2810-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/71e9c6620d381d60196ebe694840aaaa-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7212a6567c8a6c513f33b858d868ff80-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7221e5c8ec6b08ef6d3f9ff3ce6eb1d1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/722caafb4825ef5d8670710fa29087cf-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/723e8f97fde15f7a8d5ff8d558ea3f16-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7250eb93b3c18cc9daa29cf58af7a004-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7261925973c9bf0a74d85ae968a57e5f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7288251b27c8f0e73f4d7f483b06a785-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/72ab54f9b8c11fae5b923d7f854ef06a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/72b32a1f754ba1c09b3695e0cb6cde7f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/72e6d3238361fe70f22fb0ac624a7072-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/731309c4bb223491a9f67eac5214fb2e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/731c83db8d2ff01bdc000083fd3c3740-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/735ddec196a9ca5745c05bec0eaa4bf9-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/73634c1dcbe056c1f7dcf5969da406c8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/73740ea85c4ec25f00f9acbd859f861d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/738a6457be8432bab553e21b4235dd97-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/73a427badebe0e32caa2e1fc7530b7f3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/73b817090081cef1bca77232f4532c5d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/73d02e4344f71a0b0d51a925246990e7-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/73f95ee473881dea4afd89c06165fa66-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/747c1bcceb6109a4ef936bc70cfe67de-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/747d3443e319a22747fbb873e8b2f9f2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/747e32ab0fea7fbd2ad9ec03daa3f840-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/74dbd1111727a31a2b825d615d80b2e7-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/74de5f915765ea59816e770a8e686f38-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7503cfacd12053d309b6bed5c89de212-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7504adad8bb96320eb3afdd4df6e1f60-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/751d51528afe5e6f7fe95dece4ed32ba-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/751f6b6b02bf39c41025f3bcfd9948ad-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7520fa31d14f45add6d61e52df5a03ff-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/753a043674f0193523abc1bbce678686-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/75800f73fa80f935216b8cfbedf77bfa-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/75877cb75154206c4e65e76b88a12712-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/75a7c30fc0063c4952d7eb044a3c0897-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/75c58d36157505a600e0695ed0b3a22d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/75df63609809c7a2052fdffe5c00a84e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/75ebb02f92fc30a8040bbd625af999f1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7612936dcc85282c6fa4dd9d4ffe57f1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/766d856ef1a6b02f93d894415e6bfa0e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/766e428d1e232bbdd58664b41346196c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/768e78024aa8fdb9b8fe87be86f64745-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/769c3bce651ce5feaa01ce3b75986420-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/76cf99d3614e23eabab16fb27e944bf9-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/76dc611d6ebaafc66cc0879c71b5db5c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/770f8e448d07586afbf77bb59f698587-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/77133be2e96a577bd4794928976d2ae2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/77305c2f862ad1d353f55bf38e5a5183-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/77330e1330ae2b086e5bfcae50d9ffae-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/774412967f19ea61d448977ad9749078-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/778609db5dc7e1a8315717a9cdd8fd6f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/780261c4b9a55cd803080619d0cc3e11-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/781397bc0630d47ab531ea850bddcf63-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/781877bda0783aac5f1cf765c128b437-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/786ab8c4d7ee758f80d57e65582e609d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/78719f11fa2df9917de3110133506521-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7880d7226e872b776d8b9f23975e2a3d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/788d986905533aba051261497ecffcbb-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/789ba2ae4d335e8a2ad283a3f7effced-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/78f7d96ea21ccae89a7b581295f34135-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7967cc8e3ab559e68cc944c44b1cf3e8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/798d1c2813cbdf8bcdb388db0e32d496-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/79a3308b13cd31f096d8a4a34f96b66b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/79f56e5e3e0e999b3c139f225838d41f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7a006957be65e608e863301eb98e1808-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7a1d9028a78f418cb8f01909a348d9b2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7a22c0c0a4515485e31f95fd372050c9-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7a43ed4e82d06a1e6b2e88518fb8c2b0-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7a53928fa4dd31e82c6ef826f341daec-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7a674153c63cff1ad7f0e261c369ab2c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7a677bb4477ae2dd371add568dd19e23-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7a685d9edd95508471a9d3d6fcace432-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7a6a74cbe87bc60030a4bd041dd47b78-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7a8b8402b2f0fc78cf726ee484a0a2b7-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7a9a322cbe0d06a98667fdc5160dc6f8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7ac52e3f2729d1b3f6d2b7e8f6467226-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7b41bfa5085806dfa24b8c9de0ce567f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7b497aa1b2a83ec63d1777a88676b0c2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7ba0691b7777b6581397456412a41390-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7bab7650be60b0738e22c3b8745f937d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7bcdf75ad237b8e02e301f4091fb6bc8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7bd28f15a49d5e5848d6ec70e584e625-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7cac11e2f46ed46c339ec3d569853759-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7cc538b1337957dae283c30ad46def38-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7cc980b0f894bd0cf05c37c246f215f3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7d265aa7147bd3913fb84c7963a209d1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7d3d5bcad324d3edc08e40738e663554-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7d420e2b2939762031eed0447a9be19f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7d97667a3e056acab9aaf653807b4a03-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7e05d6f828574fbc975a896b25bb011e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7e0a0209b929d097bd3e8ef30567a5c1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7ec0dbeee45813422897e04ad8424a5e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7ec2442aa04c157590b2fa1a7d093a33-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7f141cf8e7136ce8701dc6636c2a6fe4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7f2be1b45d278ac18804b79207a24c53-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7f2cba89a7116c7c6b0a769572d5fad9-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7f6caf1f0ba788cd7953d817724c2b6e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7fa215c9efebb3811a7ef58409907899-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7fc63ff01769c4fa7d9279e97e307829-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7fd3b80fb1884e2927df46a7139bb8bf-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/803ef56843860e4a48fc4cdb3065e8ce-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/804741413d7fe0e515b19a7ffc7b3027-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/806beafe154032a5b818e97b4420ad98-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/80b618ebcac7aa97a6dac2ba65cb7e36-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/8169e05e2a0debcb15458f2cc1eff0ea-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/8171ac2c5544a5cb54ac0f38bf477af4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/819f46e52c25763a55cc642422644317-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/81e3225c6ad49623167a4309eb4b2e75-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/81e793dc8317a3dbc3534ed3f242c418-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/81f7acabd411274fcf65ce2070ed568a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/82039d16dce0aab3913b6a7ac73deff7-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/821fa74b50ba3f7cba1e6c53e8fa6845-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/8248a99e81e752cb9b41da3fc43fbe7f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/82674fc29bc0d9895cee346548c2cb5c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/8289889263db4a40463e3f358bb7c7a1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/82b04cd5aa016d979fe048f3ddf0e8d3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/82e9e7a12665240d13d0b928be28f230-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/83004190b1793d7aa15f8d0d49a13eba-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/837a7924b8c0aa866e41b2721f66135c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/8396b14c5dff55d13eea57487bf8ed26-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/83adc9225e4deb67d7ce42d58fe5157c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/83d3d4b6c9579515e1679aca8cbc8033-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/83eaa6722798a773dd55e8fc7443aa09-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/83fa5a432ae55c253d0e60dbfa716723-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/8493eeaccb772c0878f99d60a0bd2bb3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/84c230a5b1bc3495046ef916957c7238-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/84c578f202616448a2f80e6f56d5f16d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/84ddfb34126fc3a48ee38d7044e87276-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/84fec9a8e45846340fdf5c7c9f7ed66c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/8511df98c02ab60aea1b2356c013bc0f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/85690f81aadc1749175c187784afc9ee-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/858e47701162578e5e627cd93ab0938a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/85934679f30131d812a8c7475a7d0f74-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/85b42dd8aae56e01379be5736db5b496-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/85b9a5ac91cd629bd3afe396ec07270a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/85c9f9efab89cee90a95cb98f15feacd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/85fc37b18c57097425b52fc7afbb6969-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/8606bdb6f1fa707fc6ca309943eea443-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/860b37e28ec7ba614f00f9246949561d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/861637a425ef06e6d539aaaff113d1d5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/865dfbde8a344b44095495f3591f7407-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/866d90e0921ac7b024b47d672445a086-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/8682cc30db9c025ecd3fee433f8ab54c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/86b94dae7c6517ec1ac767fd2c136580-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/86c51678350f656dcc7f490a43946ee5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/86d7c8a08b4aaa1bc7c599473f5dddda-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/8763d72bba4a7ade23f9ae1f09f4efc7-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/8767bccb1ff4231a9962e3914f4f1f8f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/87736972ed2fb48230f1052699dedbe7-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/884d247c6f65a96a7da4d1105d584ddd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/885b2c7a6deb4fea10f319c4ce993e02-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/887caadc3642e304ede659b734f79b00-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/88855547570f7ff053fff7c54e5148cc-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/8929c70f8d710e412d38da624b21c3c8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/89562dccfeb1d0394b9ae7e09544dc70-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/8965f76632d7672e7d3cf29c87ecaa0c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/8977ecbb8cb82d77fb091c7a7f186163-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/8989e07fc124e7a9bcbdebcc8ace2bc0-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/89ae0fe22c47d374bc9350ef99e01685-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/89b9e0a6f6d1505fe13dea0f18a2dcfa-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/8a1276c25f5efe85f0fc4020fbf5b4f8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/8a50bae297807da9e97722a0b3fd8f27-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/8a7129b8f3edd95b7d969dfc2c8e9d9d-Abstract.html',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxZ3884S8_Nv"
      },
      "source": [
        "## 2.Scrape Abstracts from 1st Level Urls [scrapeDetails()]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BnnMzgi3TcI",
        "outputId": "dc59e741-c76d-4da2-dd34-2ed389abf031"
      },
      "source": [
        "print(len(extract_url))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1898\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIMLDN-d8_Nv"
      },
      "source": [
        "\n",
        "#extract_url = ['https://papers.nips.cc/paper/2020/hash/012d9fe15b2493f21902cd55603382ec-Abstract.html']\n",
        "for URL in extract_url:\n",
        "  #print(URL)\n",
        "  webpage = requests.get(URL)\n",
        "  soup = BeautifulSoup(webpage.text, \"html.parser\") #Parse the text from the website\n",
        "  #print(soup.prettify())\n",
        "  extract_abstract2(soup)\n",
        "  #print(\"****************************\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eccdyGoR8_Nw"
      },
      "source": [
        "### Building Dataframe From Extracted URLs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-DxrF6egM89",
        "outputId": "3c677dab-367d-4046-f5db-c7174a017c8d"
      },
      "source": [
        "len(titles)\n",
        "print(len(abstracts))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1898\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfpgJUchG4UX",
        "outputId": "0f60fe9b-a712-478b-8c1c-1c9a71113304"
      },
      "source": [
        "authors[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Seongmin Ok'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkqX8Mtt8_Nw",
        "outputId": "a09eb354-9c6f-4162-bd40-4ee8df8819e6"
      },
      "source": [
        "#Create a new dataFrame \n",
        "data = pd.DataFrame(columns = ['type', 'sources', 'titles', 'authors', 'abstract', 'urls']) \n",
        "data['type'] = type_\n",
        "data['sources'] = sources\n",
        "data['titles'] = titles\n",
        "data['authors'] = authors\n",
        "data['abstract'] = abstracts\n",
        "data['urls'] = extract_url\n",
        "\n",
        "#Show the data set\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>sources</th>\n",
              "      <th>titles</th>\n",
              "      <th>authors</th>\n",
              "      <th>abstract</th>\n",
              "      <th>urls</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>conference</td>\n",
              "      <td>neurips</td>\n",
              "      <td>A graph similarity for deep learning</td>\n",
              "      <td>Seongmin Ok</td>\n",
              "      <td>Graph neural networks (GNNs) have been success...</td>\n",
              "      <td>https://papers.nips.cc/paper/2020/hash/0004d0b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>conference</td>\n",
              "      <td>neurips</td>\n",
              "      <td>An Unsupervised Information-Theoretic Perceptu...</td>\n",
              "      <td>Sangnie Bhardwaj, Ian Fischer, Johannes Ballé,...</td>\n",
              "      <td>Tractable models of human perception have prov...</td>\n",
              "      <td>https://papers.nips.cc/paper/2020/hash/00482b9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>conference</td>\n",
              "      <td>neurips</td>\n",
              "      <td>Self-Supervised MultiModal Versatile Networks</td>\n",
              "      <td>Jean-Baptiste Alayrac, Adria Recasens, Rosalia...</td>\n",
              "      <td>Videos are a rich source of multi-modal superv...</td>\n",
              "      <td>https://papers.nips.cc/paper/2020/hash/0060ef4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>conference</td>\n",
              "      <td>neurips</td>\n",
              "      <td>Benchmarking Deep Inverse Models over time, an...</td>\n",
              "      <td>Simiao Ren, Willie Padilla, Jordan Malof</td>\n",
              "      <td>We consider the task of solving generic invers...</td>\n",
              "      <td>https://papers.nips.cc/paper/2020/hash/007ff38...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>conference</td>\n",
              "      <td>neurips</td>\n",
              "      <td>Off-Policy Evaluation and Learning for Externa...</td>\n",
              "      <td>Masatoshi Uehara, Masahiro Kato, Shota Yasui</td>\n",
              "      <td>We consider the evaluation and training of a n...</td>\n",
              "      <td>https://papers.nips.cc/paper/2020/hash/0084ae4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1893</th>\n",
              "      <td>conference</td>\n",
              "      <td>neurips</td>\n",
              "      <td>Distributed Distillation for On-Device Learning</td>\n",
              "      <td>Ilai Bistritz, Ariana Mann, Nicholas Bambos</td>\n",
              "      <td>On-device learning promises collaborative trai...</td>\n",
              "      <td>https://papers.nips.cc/paper/2020/hash/fef6f97...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1894</th>\n",
              "      <td>conference</td>\n",
              "      <td>neurips</td>\n",
              "      <td>COOT: Cooperative Hierarchical Transformer for...</td>\n",
              "      <td>Simon Ging, Mohammadreza Zolfaghari, Hamed Pir...</td>\n",
              "      <td>Many real-world video-text tasks involve diffe...</td>\n",
              "      <td>https://papers.nips.cc/paper/2020/hash/ff0abbc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1895</th>\n",
              "      <td>conference</td>\n",
              "      <td>neurips</td>\n",
              "      <td>Passport-aware Normalization for Deep Model Pr...</td>\n",
              "      <td>Jie Zhang, Dongdong Chen, Jing Liao, Weiming Z...</td>\n",
              "      <td>Despite tremendous success in many application...</td>\n",
              "      <td>https://papers.nips.cc/paper/2020/hash/ff1418e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1896</th>\n",
              "      <td>conference</td>\n",
              "      <td>neurips</td>\n",
              "      <td>Sampling-Decomposable Generative Adversarial R...</td>\n",
              "      <td>Binbin Jin, Defu Lian, Zheng Liu, Qi Liu, Jian...</td>\n",
              "      <td>Recommendation techniques are important approa...</td>\n",
              "      <td>https://papers.nips.cc/paper/2020/hash/ff42b03...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1897</th>\n",
              "      <td>conference</td>\n",
              "      <td>neurips</td>\n",
              "      <td>Limits to Depth Efficiencies of Self-Attention</td>\n",
              "      <td>Yoav Levine, Noam Wies, Or Sharir, Hofit Bata,...</td>\n",
              "      <td>Self-attention architectures, which are rapidl...</td>\n",
              "      <td>https://papers.nips.cc/paper/2020/hash/ff4dfdf...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1898 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            type  ...                                               urls\n",
              "0     conference  ...  https://papers.nips.cc/paper/2020/hash/0004d0b...\n",
              "1     conference  ...  https://papers.nips.cc/paper/2020/hash/00482b9...\n",
              "2     conference  ...  https://papers.nips.cc/paper/2020/hash/0060ef4...\n",
              "3     conference  ...  https://papers.nips.cc/paper/2020/hash/007ff38...\n",
              "4     conference  ...  https://papers.nips.cc/paper/2020/hash/0084ae4...\n",
              "...          ...  ...                                                ...\n",
              "1893  conference  ...  https://papers.nips.cc/paper/2020/hash/fef6f97...\n",
              "1894  conference  ...  https://papers.nips.cc/paper/2020/hash/ff0abbc...\n",
              "1895  conference  ...  https://papers.nips.cc/paper/2020/hash/ff1418e...\n",
              "1896  conference  ...  https://papers.nips.cc/paper/2020/hash/ff42b03...\n",
              "1897  conference  ...  https://papers.nips.cc/paper/2020/hash/ff4dfdf...\n",
              "\n",
              "[1898 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gh94MkmACBy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2GajxlfAMaZ"
      },
      "source": [
        "file_path = '/content/drive/Shared drives/1DeepContextGraph/1DeepContextGraph/code/data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhgVVkK3AZvS"
      },
      "source": [
        "#data.to_csv(file_path+'neurips_data_2020.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGCnlmjmJBiX"
      },
      "source": [
        "## 3.Transitive Topic Extraction from N-grams [.extractTopic()]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4ybI8yjgBNJ"
      },
      "source": [
        "# import pandas as pd\n",
        "# file_path = '/content/drive/Shared drives/1DeepContextGraph/1DeepContextGraph/code/data/'\n",
        "# data=pd.read_csv(file_path+\"neurips_data_2020.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "id": "RcocyKVCpHOq",
        "outputId": "9e8baa8d-4884-4656-f4d6-f88291f979bf"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>sources</th>\n",
              "      <th>titles</th>\n",
              "      <th>authors</th>\n",
              "      <th>abstract</th>\n",
              "      <th>urls</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>conference</td>\n",
              "      <td>neurips</td>\n",
              "      <td>A graph similarity for deep learning</td>\n",
              "      <td>Seongmin Ok</td>\n",
              "      <td>Graph neural networks (GNNs) have been success...</td>\n",
              "      <td>https://papers.nips.cc/paper/2020/hash/0004d0b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>conference</td>\n",
              "      <td>neurips</td>\n",
              "      <td>An Unsupervised Information-Theoretic Perceptu...</td>\n",
              "      <td>Sangnie Bhardwaj, Ian Fischer, Johannes Ballé,...</td>\n",
              "      <td>Tractable models of human perception have prov...</td>\n",
              "      <td>https://papers.nips.cc/paper/2020/hash/00482b9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>conference</td>\n",
              "      <td>neurips</td>\n",
              "      <td>Self-Supervised MultiModal Versatile Networks</td>\n",
              "      <td>Jean-Baptiste Alayrac, Adria Recasens, Rosalia...</td>\n",
              "      <td>Videos are a rich source of multi-modal superv...</td>\n",
              "      <td>https://papers.nips.cc/paper/2020/hash/0060ef4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>conference</td>\n",
              "      <td>neurips</td>\n",
              "      <td>Benchmarking Deep Inverse Models over time, an...</td>\n",
              "      <td>Simiao Ren, Willie Padilla, Jordan Malof</td>\n",
              "      <td>We consider the task of solving generic invers...</td>\n",
              "      <td>https://papers.nips.cc/paper/2020/hash/007ff38...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>conference</td>\n",
              "      <td>neurips</td>\n",
              "      <td>Off-Policy Evaluation and Learning for Externa...</td>\n",
              "      <td>Masatoshi Uehara, Masahiro Kato, Shota Yasui</td>\n",
              "      <td>We consider the evaluation and training of a n...</td>\n",
              "      <td>https://papers.nips.cc/paper/2020/hash/0084ae4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1893</th>\n",
              "      <td>conference</td>\n",
              "      <td>neurips</td>\n",
              "      <td>Distributed Distillation for On-Device Learning</td>\n",
              "      <td>Ilai Bistritz, Ariana Mann, Nicholas Bambos</td>\n",
              "      <td>On-device learning promises collaborative trai...</td>\n",
              "      <td>https://papers.nips.cc/paper/2020/hash/fef6f97...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1894</th>\n",
              "      <td>conference</td>\n",
              "      <td>neurips</td>\n",
              "      <td>COOT: Cooperative Hierarchical Transformer for...</td>\n",
              "      <td>Simon Ging, Mohammadreza Zolfaghari, Hamed Pir...</td>\n",
              "      <td>Many real-world video-text tasks involve diffe...</td>\n",
              "      <td>https://papers.nips.cc/paper/2020/hash/ff0abbc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1895</th>\n",
              "      <td>conference</td>\n",
              "      <td>neurips</td>\n",
              "      <td>Passport-aware Normalization for Deep Model Pr...</td>\n",
              "      <td>Jie Zhang, Dongdong Chen, Jing Liao, Weiming Z...</td>\n",
              "      <td>Despite tremendous success in many application...</td>\n",
              "      <td>https://papers.nips.cc/paper/2020/hash/ff1418e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1896</th>\n",
              "      <td>conference</td>\n",
              "      <td>neurips</td>\n",
              "      <td>Sampling-Decomposable Generative Adversarial R...</td>\n",
              "      <td>Binbin Jin, Defu Lian, Zheng Liu, Qi Liu, Jian...</td>\n",
              "      <td>Recommendation techniques are important approa...</td>\n",
              "      <td>https://papers.nips.cc/paper/2020/hash/ff42b03...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1897</th>\n",
              "      <td>conference</td>\n",
              "      <td>neurips</td>\n",
              "      <td>Limits to Depth Efficiencies of Self-Attention</td>\n",
              "      <td>Yoav Levine, Noam Wies, Or Sharir, Hofit Bata,...</td>\n",
              "      <td>Self-attention architectures, which are rapidl...</td>\n",
              "      <td>https://papers.nips.cc/paper/2020/hash/ff4dfdf...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1898 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            type  ...                                               urls\n",
              "0     conference  ...  https://papers.nips.cc/paper/2020/hash/0004d0b...\n",
              "1     conference  ...  https://papers.nips.cc/paper/2020/hash/00482b9...\n",
              "2     conference  ...  https://papers.nips.cc/paper/2020/hash/0060ef4...\n",
              "3     conference  ...  https://papers.nips.cc/paper/2020/hash/007ff38...\n",
              "4     conference  ...  https://papers.nips.cc/paper/2020/hash/0084ae4...\n",
              "...          ...  ...                                                ...\n",
              "1893  conference  ...  https://papers.nips.cc/paper/2020/hash/fef6f97...\n",
              "1894  conference  ...  https://papers.nips.cc/paper/2020/hash/ff0abbc...\n",
              "1895  conference  ...  https://papers.nips.cc/paper/2020/hash/ff1418e...\n",
              "1896  conference  ...  https://papers.nips.cc/paper/2020/hash/ff42b03...\n",
              "1897  conference  ...  https://papers.nips.cc/paper/2020/hash/ff4dfdf...\n",
              "\n",
              "[1898 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYyfrRXcJKsu"
      },
      "source": [
        "### Set-up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGH2_FKWJMtK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84aa7963-160f-4694-9385-0261bceb34e6"
      },
      "source": [
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install stop_words\n",
        "!pip install nlpretext"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting stop_words\n",
            "  Downloading stop-words-2018.7.23.tar.gz (31 kB)\n",
            "Building wheels for collected packages: stop-words\n",
            "  Building wheel for stop-words (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stop-words: filename=stop_words-2018.7.23-py3-none-any.whl size=32911 sha256=f96436983c93a8a97cec29148040ff5bc88fd15effbddd1cb84ef09d37ece626\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/86/b2/277b10b1ce9f73ce15059bf6975d4547cc4ec3feeb651978e9\n",
            "Successfully built stop-words\n",
            "Installing collected packages: stop-words\n",
            "Successfully installed stop-words-2018.7.23\n",
            "Collecting nlpretext\n",
            "  Downloading nlpretext-1.0.4-py3-none-any.whl (92 kB)\n",
            "\u001b[K     |████████████████████████████████| 92 kB 218 kB/s \n",
            "\u001b[?25hCollecting nlpaug==1.0.1\n",
            "  Downloading nlpaug-1.0.1-py3-none-any.whl (376 kB)\n",
            "\u001b[K     |████████████████████████████████| 376 kB 39.9 MB/s \n",
            "\u001b[?25hCollecting emoji>=0.5.2\n",
            "  Downloading emoji-1.4.1.tar.gz (185 kB)\n",
            "\u001b[K     |████████████████████████████████| 185 kB 42.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet==3.0.4 in /usr/local/lib/python3.7/dist-packages (from nlpretext) (3.0.4)\n",
            "Collecting regex==2019.8.19\n",
            "  Downloading regex-2019.08.19.tar.gz (654 kB)\n",
            "\u001b[K     |████████████████████████████████| 654 kB 36.9 MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.23.2\n",
            "  Downloading scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 43.7 MB/s \n",
            "\u001b[?25hCollecting sacremoses==0.0.13\n",
            "  Downloading sacremoses-0.0.13.tar.gz (118 kB)\n",
            "\u001b[K     |████████████████████████████████| 118 kB 53.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: stop-words==2018.7.23 in /usr/local/lib/python3.7/dist-packages (from nlpretext) (2018.7.23)\n",
            "Collecting nltk>=3.4.5\n",
            "  Downloading nltk-3.6.2-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 33.1 MB/s \n",
            "\u001b[?25hCollecting flashtext==2.7\n",
            "  Downloading flashtext-2.7.tar.gz (14 kB)\n",
            "Requirement already satisfied: numpy>1.15.4 in /usr/local/lib/python3.7/dist-packages (from nlpretext) (1.19.5)\n",
            "Collecting mosestokenizer==1.1.0\n",
            "  Downloading mosestokenizer-1.1.0.tar.gz (37 kB)\n",
            "Collecting phonenumbers==8.10.12\n",
            "  Downloading phonenumbers-8.10.12-py2.py3-none-any.whl (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 32.9 MB/s \n",
            "\u001b[?25hCollecting ftfy<5.0.0,>=4.2.0\n",
            "  Downloading ftfy-4.4.3.tar.gz (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 3.8 MB/s \n",
            "\u001b[?25hCollecting spacy==2.3.4\n",
            "  Downloading spacy-2.3.4-cp37-cp37m-manylinux2014_x86_64.whl (10.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4 MB 13.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from mosestokenizer==1.1.0->nlpretext) (0.6.2)\n",
            "Collecting openfile\n",
            "  Downloading openfile-0.0.7-py3-none-any.whl (2.4 kB)\n",
            "Collecting uctools\n",
            "  Downloading uctools-1.3.0.tar.gz (4.6 kB)\n",
            "Collecting toolwrapper\n",
            "  Downloading toolwrapper-2.1.0.tar.gz (3.2 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.13->nlpretext) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.13->nlpretext) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.13->nlpretext) (1.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.13->nlpretext) (4.41.1)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-2.2.0-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2->nlpretext) (1.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.4->nlpretext) (3.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.4->nlpretext) (57.2.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.4->nlpretext) (1.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.4->nlpretext) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.4->nlpretext) (2.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.4->nlpretext) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.4->nlpretext) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.4->nlpretext) (0.8.2)\n",
            "Collecting thinc<7.5.0,>=7.4.1\n",
            "  Downloading thinc-7.4.5-cp37-cp37m-manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 44.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.4->nlpretext) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.4->nlpretext) (1.0.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy==2.3.4->nlpretext) (4.6.1)\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.7/dist-packages (from ftfy<5.0.0,>=4.2.0->nlpretext) (1.0.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy<5.0.0,>=4.2.0->nlpretext) (0.2.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy==2.3.4->nlpretext) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy==2.3.4->nlpretext) (3.7.4.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.4->nlpretext) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.4->nlpretext) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.4->nlpretext) (2.10)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from html5lib->ftfy<5.0.0,>=4.2.0->nlpretext) (0.5.1)\n",
            "Building wheels for collected packages: flashtext, mosestokenizer, regex, sacremoses, emoji, ftfy, toolwrapper, uctools\n",
            "  Building wheel for flashtext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flashtext: filename=flashtext-2.7-py2.py3-none-any.whl size=9309 sha256=5ca2eb56d7f3cc255df7c9024f941f7188ab6b0952b49bff330402c2fa544002\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/19/58/4e8fdd0009a7f89dbce3c18fff2e0d0fa201d5cdfd16f113b7\n",
            "  Building wheel for mosestokenizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mosestokenizer: filename=mosestokenizer-1.1.0-py3-none-any.whl size=49119 sha256=74bcbdf7cb7e89863777db91e00e75f0d4ec7d073a70591487e59e11b47a07b8\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/31/94/fef279382208e85a65c1a7f5c4d0020115477b0af74f296b57\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2019.8.19-cp37-cp37m-linux_x86_64.whl size=609807 sha256=dac64b75044bcccd82cb3438da1ec6ec7ae3cc9e12d8ed5718bc9c3708e0fe1a\n",
            "  Stored in directory: /root/.cache/pip/wheels/28/8f/a2/6a273ec4395fdf35dc0fcb842e6f32a0f8f65190f5f0cbe5ad\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.13-py3-none-any.whl size=154729 sha256=ecad9bfcaf7b0d24255f95cf9771bbc1a7b3adbb003d393db7dbc95b799402c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/38/9f/ae9fce563ce84aead39e1b7893ac7cbb3428c24ebea487eb52\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.4.1-py3-none-any.whl size=186393 sha256=4df1629dadc26e38b7b9ef432193f01b77d76ef29500c6830a11a0d5a7de763d\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/68/ac/537456a5331f1405779f2b3c2a578429d2f6d7419e440330d8\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-4.4.3-py3-none-any.whl size=41082 sha256=03348fed8c0f8fe5a1d2375a51aed2bc61088f512bebfa53a96a7f64d4d3ea56\n",
            "  Stored in directory: /root/.cache/pip/wheels/b0/66/08/c65b9e8a3b674f10739790db0cbbc846afaa20a3f80f0b9e42\n",
            "  Building wheel for toolwrapper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for toolwrapper: filename=toolwrapper-2.1.0-py3-none-any.whl size=3353 sha256=f3f5f100507d21e02096cae40727392dea838d2c059329cf0037d3d9e9a28d6e\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/4f/33/54741ffe08e38ececb1d28068a153729b4fe820bafa0a0691f\n",
            "  Building wheel for uctools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for uctools: filename=uctools-1.3.0-py3-none-any.whl size=6161 sha256=e4e7a88df3cd4451bdd5dd1e3fe84f29cd455211bdcabdb9cd2177b4182e7e1a\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/44/e9/914cf8fa71f0141f9314f862538d1218fcf2b94542a0fb7d35\n",
            "Successfully built flashtext mosestokenizer regex sacremoses emoji ftfy toolwrapper uctools\n",
            "Installing collected packages: uctools, toolwrapper, threadpoolctl, thinc, regex, openfile, spacy, scikit-learn, sacremoses, phonenumbers, nltk, nlpaug, mosestokenizer, ftfy, flashtext, emoji, nlpretext\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed emoji-1.4.1 flashtext-2.7 ftfy-4.4.3 mosestokenizer-1.1.0 nlpaug-1.0.1 nlpretext-1.0.4 nltk-3.6.2 openfile-0.0.7 phonenumbers-8.10.12 regex-2019.8.19 sacremoses-0.0.13 scikit-learn-0.23.2 spacy-2.3.4 thinc-7.4.5 threadpoolctl-2.2.0 toolwrapper-2.1.0 uctools-1.3.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "regex"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7aRFnffJP_m"
      },
      "source": [
        "import requests\n",
        "import nlpretext as nlp\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9VTLl8nKt5P"
      },
      "source": [
        "### Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-12-17T02:03:33.356005Z",
          "start_time": "2019-12-17T02:03:33.336089Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOH8A6emDoZj",
        "outputId": "07369b9e-4979-41b1-af83-ea592a6f0309"
      },
      "source": [
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stopwords = stopwords.words('english')\n",
        "\n",
        "def join_tokens(list_of_tokens):\n",
        "    outstr = TreebankWordDetokenizer().detokenize(list_of_tokens)\n",
        "    return outstr\n",
        "\n",
        "def filter_stopwords_from_list(titles):\n",
        "    word_list = titles\n",
        "    title_list = []\n",
        "    new_word_list = []\n",
        "    new_title_list= []\n",
        "    for title in titles:\n",
        "            #print (title)\n",
        "            title_list =  nltk.word_tokenize(title)\n",
        "            #print (words)\n",
        "            for word in title_list:\n",
        "                print (word)\n",
        "                if word.lower() not in stopwords:\n",
        "                    new_word_list.append(word)\n",
        "                    #print(\"joined {} :\".format(word))\n",
        "            #print (\"new title list :\",new_word_list)\n",
        "            new_title = join_tokens(new_word_list)\n",
        "            #print (\"\\n New title : \", new_title)\n",
        "            new_word_list =[]\n",
        "            # print (\"old : {}  \\n -----> new : {}\\n\\n\".format(title, new_title))\n",
        "            new_title_list.append(new_title)\n",
        "    # print (\"========================\\n\")\n",
        "    # print (\"new list of titles: \\n: ===> \",new_title_list )\n",
        "    return new_title_list\n",
        "        #print (new_line)\n",
        "        #filtered_words = [word for word in words if word.lower() not in stopwords]\n",
        "        #print (words)\n",
        "\n",
        "# receives a list of texts and creates n-grams for each of the text as well as for the entire corpus\n",
        "def getNGramsConcat(lstText, ngramsCount):\n",
        "  import re\n",
        "  from nltk.util import ngrams\n",
        "  s = \" \".join(lstText) # this may be needed to crea\n",
        "  s = s.lower()\n",
        "  s = re.sub(r'[^a-zA-Z0-9\\s]', ' ', s)\n",
        "  tokens = [token for token in s.split(\" \") if token != \"\"]\n",
        "  corpusNGrams = list(ngrams(tokens, ngramsCount))\n",
        "  corpusNGramsConcat = [\"-\".join(e) for e in corpusNGrams]\n",
        "\n",
        "  txtNGrams = []\n",
        "  txtNGramsConcat = []\n",
        "  for t in lstText:\n",
        "    t2 = t.lower()\n",
        "    t2 = re.sub(r'[^a-zA-Z0-9\\s]', ' ', t2)\n",
        "    tokens2 = [token2 for token2 in t2.split(\" \") if token2 != \"\"]\n",
        "    ng = list(ngrams(tokens2, ngramsCount))\n",
        "    txtNGrams.append(ng)\n",
        "    txtNGramsConcat.append( [\"-\".join(e) for e in ng])\n",
        "\n",
        "  return (txtNGramsConcat, corpusNGramsConcat)\n",
        "\n",
        "# titles = dfEvents[\"title\"]\n",
        "# filteredTitles = filter_stopwords_from_list(titles)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxJw0wAAKyjQ"
      },
      "source": [
        "### Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dm62M4NgD7Kq"
      },
      "source": [
        "df = data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BImt3QuCD7D"
      },
      "source": [
        "df= df.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBqDAF11K9PR"
      },
      "source": [
        "### Remove small words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MENnkjEMCD7E"
      },
      "source": [
        "import nlpretext as nlp\n",
        "from nlpretext.token.preprocess import remove_smallwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZzLfhFfNiv_"
      },
      "source": [
        "### Compute N-Gram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4oEBqvPXVBlz",
        "outputId": "16227f3c-ddea-4ae0-ad24-654ec7a26f49"
      },
      "source": [
        "df[\"titles\"][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'A graph similarity for deep learning'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4RiuD6ANk6R",
        "outputId": "3adac607-5736-415c-da4c-a31b977cb256"
      },
      "source": [
        "texts = df[\"titles\"] #+ \". \" + df[\"abstract\"]\n",
        "texts"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                    A graph similarity for deep learning\n",
              "1       An Unsupervised Information-Theoretic Perceptu...\n",
              "2           Self-Supervised MultiModal Versatile Networks\n",
              "3       Benchmarking Deep Inverse Models over time, an...\n",
              "4       Off-Policy Evaluation and Learning for Externa...\n",
              "                              ...                        \n",
              "1893      Distributed Distillation for On-Device Learning\n",
              "1894    COOT: Cooperative Hierarchical Transformer for...\n",
              "1895    Passport-aware Normalization for Deep Model Pr...\n",
              "1896    Sampling-Decomposable Generative Adversarial R...\n",
              "1897       Limits to Depth Efficiencies of Self-Attention\n",
              "Name: titles, Length: 1898, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxbsMKZYU7Vr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b68b74b-788b-4be7-a496-1552125e41f7"
      },
      "source": [
        "filteredTexts = filter_stopwords_from_list(texts)\n",
        "(lstNGrams, corpusNGrams) = getNGramsConcat(filteredTexts, ngramsCount = ngramsCount)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Switching\n",
            "System\n",
            "Perspective\n",
            "and\n",
            "Convergence\n",
            "Analysis\n",
            "of\n",
            "Q-Learning\n",
            "Algorithms\n",
            "Kernel\n",
            "Alignment\n",
            "Risk\n",
            "Estimator\n",
            ":\n",
            "Risk\n",
            "Prediction\n",
            "from\n",
            "Training\n",
            "Data\n",
            "Calibrating\n",
            "CNNs\n",
            "for\n",
            "Lifelong\n",
            "Learning\n",
            "Online\n",
            "Convex\n",
            "Optimization\n",
            "Over\n",
            "Erdos-Renyi\n",
            "Random\n",
            "Networks\n",
            "Robustness\n",
            "of\n",
            "Bayesian\n",
            "Neural\n",
            "Networks\n",
            "to\n",
            "Gradient-Based\n",
            "Attacks\n",
            "Parametric\n",
            "Instance\n",
            "Classification\n",
            "for\n",
            "Unsupervised\n",
            "Visual\n",
            "Feature\n",
            "learning\n",
            "Sparse\n",
            "Weight\n",
            "Activation\n",
            "Training\n",
            "Collapsing\n",
            "Bandits\n",
            "and\n",
            "Their\n",
            "Application\n",
            "to\n",
            "Public\n",
            "Health\n",
            "Intervention\n",
            "Neural\n",
            "Sparse\n",
            "Voxel\n",
            "Fields\n",
            "A\n",
            "Flexible\n",
            "Framework\n",
            "for\n",
            "Designing\n",
            "Trainable\n",
            "Priors\n",
            "with\n",
            "Adaptive\n",
            "Smoothing\n",
            "and\n",
            "Game\n",
            "Encoding\n",
            "The\n",
            "Discrete\n",
            "Gaussian\n",
            "for\n",
            "Differential\n",
            "Privacy\n",
            "Robust\n",
            "Sub-Gaussian\n",
            "Principal\n",
            "Component\n",
            "Analysis\n",
            "and\n",
            "Width-Independent\n",
            "Schatten\n",
            "Packing\n",
            "Adaptive\n",
            "Importance\n",
            "Sampling\n",
            "for\n",
            "Finite-Sum\n",
            "Optimization\n",
            "and\n",
            "Sampling\n",
            "with\n",
            "Decreasing\n",
            "Step-Sizes\n",
            "Learning\n",
            "efficient\n",
            "task-dependent\n",
            "representations\n",
            "with\n",
            "synaptic\n",
            "plasticity\n",
            "A\n",
            "Contour\n",
            "Stochastic\n",
            "Gradient\n",
            "Langevin\n",
            "Dynamics\n",
            "Algorithm\n",
            "for\n",
            "Simulations\n",
            "of\n",
            "Multi-modal\n",
            "Distributions\n",
            "Error\n",
            "Bounds\n",
            "of\n",
            "Imitating\n",
            "Policies\n",
            "and\n",
            "Environments\n",
            "Disentangling\n",
            "Human\n",
            "Error\n",
            "from\n",
            "Ground\n",
            "Truth\n",
            "in\n",
            "Segmentation\n",
            "of\n",
            "Medical\n",
            "Images\n",
            "Consequences\n",
            "of\n",
            "Misaligned\n",
            "AI\n",
            "Promoting\n",
            "Coordination\n",
            "through\n",
            "Policy\n",
            "Regularization\n",
            "in\n",
            "Multi-Agent\n",
            "Deep\n",
            "Reinforcement\n",
            "Learning\n",
            "Emergent\n",
            "Reciprocity\n",
            "and\n",
            "Team\n",
            "Formation\n",
            "from\n",
            "Randomized\n",
            "Uncertain\n",
            "Social\n",
            "Preferences\n",
            "Hitting\n",
            "the\n",
            "High\n",
            "Notes\n",
            ":\n",
            "Subset\n",
            "Selection\n",
            "for\n",
            "Maximizing\n",
            "Expected\n",
            "Order\n",
            "Statistics\n",
            "Towards\n",
            "Scale-Invariant\n",
            "Graph-related\n",
            "Problem\n",
            "Solving\n",
            "by\n",
            "Iterative\n",
            "Homogeneous\n",
            "GNNs\n",
            "Regret\n",
            "Bounds\n",
            "without\n",
            "Lipschitz\n",
            "Continuity\n",
            ":\n",
            "Online\n",
            "Learning\n",
            "with\n",
            "Relative-Lipschitz\n",
            "Losses\n",
            "The\n",
            "Lottery\n",
            "Ticket\n",
            "Hypothesis\n",
            "for\n",
            "Pre-trained\n",
            "BERT\n",
            "Networks\n",
            "Label-Aware\n",
            "Neural\n",
            "Tangent\n",
            "Kernel\n",
            ":\n",
            "Toward\n",
            "Better\n",
            "Generalization\n",
            "and\n",
            "Local\n",
            "Elasticity\n",
            "Beyond\n",
            "Perturbations\n",
            ":\n",
            "Learning\n",
            "Guarantees\n",
            "with\n",
            "Arbitrary\n",
            "Adversarial\n",
            "Test\n",
            "Examples\n",
            "AdvFlow\n",
            ":\n",
            "Inconspicuous\n",
            "Black-box\n",
            "Adversarial\n",
            "Attacks\n",
            "using\n",
            "Normalizing\n",
            "Flows\n",
            "Few-shot\n",
            "Image\n",
            "Generation\n",
            "with\n",
            "Elastic\n",
            "Weight\n",
            "Consolidation\n",
            "On\n",
            "the\n",
            "Expressiveness\n",
            "of\n",
            "Approximate\n",
            "Inference\n",
            "in\n",
            "Bayesian\n",
            "Neural\n",
            "Networks\n",
            "Non-Crossing\n",
            "Quantile\n",
            "Regression\n",
            "for\n",
            "Distributional\n",
            "Reinforcement\n",
            "Learning\n",
            "Dark\n",
            "Experience\n",
            "for\n",
            "General\n",
            "Continual\n",
            "Learning\n",
            ":\n",
            "a\n",
            "Strong\n",
            ",\n",
            "Simple\n",
            "Baseline\n",
            "Learning\n",
            "to\n",
            "Utilize\n",
            "Shaping\n",
            "Rewards\n",
            ":\n",
            "A\n",
            "New\n",
            "Approach\n",
            "of\n",
            "Reward\n",
            "Shaping\n",
            "Neural\n",
            "encoding\n",
            "with\n",
            "visual\n",
            "attention\n",
            "On\n",
            "the\n",
            "linearity\n",
            "of\n",
            "large\n",
            "non-linear\n",
            "models\n",
            ":\n",
            "when\n",
            "and\n",
            "why\n",
            "the\n",
            "tangent\n",
            "kernel\n",
            "is\n",
            "constant\n",
            "PLLay\n",
            ":\n",
            "Efficient\n",
            "Topological\n",
            "Layer\n",
            "based\n",
            "on\n",
            "Persistent\n",
            "Landscapes\n",
            "Decentralized\n",
            "Langevin\n",
            "Dynamics\n",
            "for\n",
            "Bayesian\n",
            "Learning\n",
            "Shared\n",
            "Space\n",
            "Transfer\n",
            "Learning\n",
            "for\n",
            "analyzing\n",
            "multi-site\n",
            "fMRI\n",
            "data\n",
            "The\n",
            "Diversified\n",
            "Ensemble\n",
            "Neural\n",
            "Network\n",
            "Inductive\n",
            "Quantum\n",
            "Embedding\n",
            "Variational\n",
            "Bayesian\n",
            "Unlearning\n",
            "Batched\n",
            "Coarse\n",
            "Ranking\n",
            "in\n",
            "Multi-Armed\n",
            "Bandits\n",
            "Understanding\n",
            "and\n",
            "Improving\n",
            "Fast\n",
            "Adversarial\n",
            "Training\n",
            "Coded\n",
            "Sequential\n",
            "Matrix\n",
            "Multiplication\n",
            "For\n",
            "Straggler\n",
            "Mitigation\n",
            "Attack\n",
            "of\n",
            "the\n",
            "Tails\n",
            ":\n",
            "Yes\n",
            ",\n",
            "You\n",
            "Really\n",
            "Can\n",
            "Backdoor\n",
            "Federated\n",
            "Learning\n",
            "Certifiably\n",
            "Adversarially\n",
            "Robust\n",
            "Detection\n",
            "of\n",
            "Out-of-Distribution\n",
            "Data\n",
            "Domain\n",
            "Generalization\n",
            "via\n",
            "Entropy\n",
            "Regularization\n",
            "Bayesian\n",
            "Meta-Learning\n",
            "for\n",
            "the\n",
            "Few-Shot\n",
            "Setting\n",
            "via\n",
            "Deep\n",
            "Kernels\n",
            "Skeleton-bridged\n",
            "Point\n",
            "Completion\n",
            ":\n",
            "From\n",
            "Global\n",
            "Inference\n",
            "to\n",
            "Local\n",
            "Adjustment\n",
            "Compressing\n",
            "Images\n",
            "by\n",
            "Encoding\n",
            "Their\n",
            "Latent\n",
            "Representations\n",
            "with\n",
            "Relative\n",
            "Entropy\n",
            "Coding\n",
            "Improved\n",
            "Guarantees\n",
            "for\n",
            "k-means++\n",
            "and\n",
            "k-means++\n",
            "Parallel\n",
            "Sparse\n",
            "Spectrum\n",
            "Warped\n",
            "Input\n",
            "Measures\n",
            "for\n",
            "Nonstationary\n",
            "Kernel\n",
            "Learning\n",
            "An\n",
            "Efficient\n",
            "Adversarial\n",
            "Attack\n",
            "for\n",
            "Tree\n",
            "Ensembles\n",
            "Learning\n",
            "Continuous\n",
            "System\n",
            "Dynamics\n",
            "from\n",
            "Irregularly-Sampled\n",
            "Partial\n",
            "Observations\n",
            "Online\n",
            "Bayesian\n",
            "Persuasion\n",
            "Robust\n",
            "Pre-Training\n",
            "by\n",
            "Adversarial\n",
            "Contrastive\n",
            "Learning\n",
            "Random\n",
            "Walk\n",
            "Graph\n",
            "Neural\n",
            "Networks\n",
            "Explore\n",
            "Aggressively\n",
            ",\n",
            "Update\n",
            "Conservatively\n",
            ":\n",
            "Stochastic\n",
            "Extragradient\n",
            "Methods\n",
            "with\n",
            "Variable\n",
            "Stepsize\n",
            "Scaling\n",
            "Fast\n",
            "and\n",
            "Accurate\n",
            "$\n",
            "k\n",
            "$\n",
            "-means++\n",
            "via\n",
            "Rejection\n",
            "Sampling\n",
            "Variational\n",
            "Amodal\n",
            "Object\n",
            "Completion\n",
            "When\n",
            "Counterpoint\n",
            "Meets\n",
            "Chinese\n",
            "Folk\n",
            "Melodies\n",
            "Sub-linear\n",
            "Regret\n",
            "Bounds\n",
            "for\n",
            "Bayesian\n",
            "Optimisation\n",
            "in\n",
            "Unknown\n",
            "Search\n",
            "Spaces\n",
            "Universal\n",
            "Domain\n",
            "Adaptation\n",
            "through\n",
            "Self\n",
            "Supervision\n",
            "Patch2Self\n",
            ":\n",
            "Denoising\n",
            "Diffusion\n",
            "MRI\n",
            "with\n",
            "Self-Supervised\n",
            "Learning​\n",
            "Stochastic\n",
            "Normalization\n",
            "Constrained\n",
            "episodic\n",
            "reinforcement\n",
            "learning\n",
            "in\n",
            "concave-convex\n",
            "and\n",
            "knapsack\n",
            "settings\n",
            "On\n",
            "Learning\n",
            "Ising\n",
            "Models\n",
            "under\n",
            "Huber\n",
            "'s\n",
            "Contamination\n",
            "Model\n",
            "Cross-validation\n",
            "Confidence\n",
            "Intervals\n",
            "for\n",
            "Test\n",
            "Error\n",
            "DeepSVG\n",
            ":\n",
            "A\n",
            "Hierarchical\n",
            "Generative\n",
            "Network\n",
            "for\n",
            "Vector\n",
            "Graphics\n",
            "Animation\n",
            "Bayesian\n",
            "Attention\n",
            "Modules\n",
            "Robustness\n",
            "Analysis\n",
            "of\n",
            "Non-Convex\n",
            "Stochastic\n",
            "Gradient\n",
            "Descent\n",
            "using\n",
            "Biased\n",
            "Expectations\n",
            "SoftFlow\n",
            ":\n",
            "Probabilistic\n",
            "Framework\n",
            "for\n",
            "Normalizing\n",
            "Flow\n",
            "on\n",
            "Manifolds\n",
            "A\n",
            "meta-learning\n",
            "approach\n",
            "to\n",
            "(\n",
            "re\n",
            ")\n",
            "discover\n",
            "plasticity\n",
            "rules\n",
            "that\n",
            "carve\n",
            "a\n",
            "desired\n",
            "function\n",
            "into\n",
            "a\n",
            "neural\n",
            "network\n",
            "Greedy\n",
            "Optimization\n",
            "Provably\n",
            "Wins\n",
            "the\n",
            "Lottery\n",
            ":\n",
            "Logarithmic\n",
            "Number\n",
            "of\n",
            "Winning\n",
            "Tickets\n",
            "is\n",
            "Enough\n",
            "Path\n",
            "Integral\n",
            "Based\n",
            "Convolution\n",
            "and\n",
            "Pooling\n",
            "for\n",
            "Graph\n",
            "Neural\n",
            "Networks\n",
            "Estimating\n",
            "the\n",
            "Effects\n",
            "of\n",
            "Continuous-valued\n",
            "Interventions\n",
            "using\n",
            "Generative\n",
            "Adversarial\n",
            "Networks\n",
            "Latent\n",
            "Dynamic\n",
            "Factor\n",
            "Analysis\n",
            "of\n",
            "High-Dimensional\n",
            "Neural\n",
            "Recordings\n",
            "Conditioning\n",
            "and\n",
            "Processing\n",
            ":\n",
            "Techniques\n",
            "to\n",
            "Improve\n",
            "Information-Theoretic\n",
            "Generalization\n",
            "Bounds\n",
            "Bongard-LOGO\n",
            ":\n",
            "A\n",
            "New\n",
            "Benchmark\n",
            "for\n",
            "Human-Level\n",
            "Concept\n",
            "Learning\n",
            "and\n",
            "Reasoning\n",
            "GAN\n",
            "Memory\n",
            "with\n",
            "No\n",
            "Forgetting\n",
            "Deep\n",
            "Reinforcement\n",
            "Learning\n",
            "with\n",
            "Stacked\n",
            "Hierarchical\n",
            "Attention\n",
            "for\n",
            "Text-based\n",
            "Games\n",
            "Gaussian\n",
            "Gated\n",
            "Linear\n",
            "Networks\n",
            "Node\n",
            "Classification\n",
            "on\n",
            "Graphs\n",
            "with\n",
            "Few-Shot\n",
            "Novel\n",
            "Labels\n",
            "via\n",
            "Meta\n",
            "Transformed\n",
            "Network\n",
            "Embedding\n",
            "Online\n",
            "Fast\n",
            "Adaptation\n",
            "and\n",
            "Knowledge\n",
            "Accumulation\n",
            "(\n",
            "OSAKA\n",
            ")\n",
            ":\n",
            "a\n",
            "New\n",
            "Approach\n",
            "to\n",
            "Continual\n",
            "Learning\n",
            "Convex\n",
            "optimization\n",
            "based\n",
            "on\n",
            "global\n",
            "lower\n",
            "second-order\n",
            "models\n",
            "Simultaneously\n",
            "Learning\n",
            "Stochastic\n",
            "and\n",
            "Adversarial\n",
            "Episodic\n",
            "MDPs\n",
            "with\n",
            "Known\n",
            "Transition\n",
            "Relative\n",
            "gradient\n",
            "optimization\n",
            "of\n",
            "the\n",
            "Jacobian\n",
            "term\n",
            "in\n",
            "unsupervised\n",
            "deep\n",
            "learning\n",
            "Self-Supervised\n",
            "Visual\n",
            "Representation\n",
            "Learning\n",
            "from\n",
            "Hierarchical\n",
            "Grouping\n",
            "Optimal\n",
            "Variance\n",
            "Control\n",
            "of\n",
            "the\n",
            "Score-Function\n",
            "Gradient\n",
            "Estimator\n",
            "for\n",
            "Importance-Weighted\n",
            "Bounds\n",
            "Explicit\n",
            "Regularisation\n",
            "in\n",
            "Gaussian\n",
            "Noise\n",
            "Injections\n",
            "Numerically\n",
            "Solving\n",
            "Parametric\n",
            "Families\n",
            "of\n",
            "High-Dimensional\n",
            "Kolmogorov\n",
            "Partial\n",
            "Differential\n",
            "Equations\n",
            "via\n",
            "Deep\n",
            "Learning\n",
            "Finite-Time\n",
            "Analysis\n",
            "for\n",
            "Double\n",
            "Q-learning\n",
            "Learning\n",
            "to\n",
            "Detect\n",
            "Objects\n",
            "with\n",
            "a\n",
            "1\n",
            "Megapixel\n",
            "Event\n",
            "Camera\n",
            "End-to-End\n",
            "Learning\n",
            "and\n",
            "Intervention\n",
            "in\n",
            "Games\n",
            "Least\n",
            "Squares\n",
            "Regression\n",
            "with\n",
            "Markovian\n",
            "Data\n",
            ":\n",
            "Fundamental\n",
            "Limits\n",
            "and\n",
            "Algorithms\n",
            "Predictive\n",
            "coding\n",
            "in\n",
            "balanced\n",
            "neural\n",
            "networks\n",
            "with\n",
            "noise\n",
            ",\n",
            "chaos\n",
            "and\n",
            "delays\n",
            "Interpolation\n",
            "Technique\n",
            "to\n",
            "Speed\n",
            "Up\n",
            "Gradients\n",
            "Propagation\n",
            "in\n",
            "Neural\n",
            "ODEs\n",
            "On\n",
            "the\n",
            "Equivalence\n",
            "between\n",
            "Online\n",
            "and\n",
            "Private\n",
            "Learnability\n",
            "beyond\n",
            "Binary\n",
            "Classification\n",
            "AViD\n",
            "Dataset\n",
            ":\n",
            "Anonymized\n",
            "Videos\n",
            "from\n",
            "Diverse\n",
            "Countries\n",
            "Probably\n",
            "Approximately\n",
            "Correct\n",
            "Constrained\n",
            "Learning\n",
            "RATT\n",
            ":\n",
            "Recurrent\n",
            "Attention\n",
            "to\n",
            "Transient\n",
            "Tasks\n",
            "for\n",
            "Continual\n",
            "Image\n",
            "Captioning\n",
            "Decisions\n",
            ",\n",
            "Counterfactual\n",
            "Explanations\n",
            "and\n",
            "Strategic\n",
            "Behavior\n",
            "Hierarchical\n",
            "Patch\n",
            "VAE-GAN\n",
            ":\n",
            "Generating\n",
            "Diverse\n",
            "Videos\n",
            "from\n",
            "a\n",
            "Single\n",
            "Sample\n",
            "A\n",
            "Feasible\n",
            "Level\n",
            "Proximal\n",
            "Point\n",
            "Method\n",
            "for\n",
            "Nonconvex\n",
            "Sparse\n",
            "Constrained\n",
            "Optimization\n",
            "Reservoir\n",
            "Computing\n",
            "meets\n",
            "Recurrent\n",
            "Kernels\n",
            "and\n",
            "Structured\n",
            "Transforms\n",
            "Comprehensive\n",
            "Attention\n",
            "Self-Distillation\n",
            "for\n",
            "Weakly-Supervised\n",
            "Object\n",
            "Detection\n",
            "Linear\n",
            "Dynamical\n",
            "Systems\n",
            "as\n",
            "a\n",
            "Core\n",
            "Computational\n",
            "Primitive\n",
            "Ratio\n",
            "Trace\n",
            "Formulation\n",
            "of\n",
            "Wasserstein\n",
            "Discriminant\n",
            "Analysis\n",
            "PAC-Bayes\n",
            "Analysis\n",
            "Beyond\n",
            "the\n",
            "Usual\n",
            "Bounds\n",
            "Few-shot\n",
            "Visual\n",
            "Reasoning\n",
            "with\n",
            "Meta-Analogical\n",
            "Contrastive\n",
            "Learning\n",
            "MPNet\n",
            ":\n",
            "Masked\n",
            "and\n",
            "Permuted\n",
            "Pre-training\n",
            "for\n",
            "Language\n",
            "Understanding\n",
            "Reinforcement\n",
            "Learning\n",
            "with\n",
            "Feedback\n",
            "Graphs\n",
            "Zap\n",
            "Q-Learning\n",
            "With\n",
            "Nonlinear\n",
            "Function\n",
            "Approximation\n",
            "Lipschitz-Certifiable\n",
            "Training\n",
            "with\n",
            "a\n",
            "Tight\n",
            "Outer\n",
            "Bound\n",
            "Fast\n",
            "Adaptive\n",
            "Non-Monotone\n",
            "Submodular\n",
            "Maximization\n",
            "Subject\n",
            "to\n",
            "a\n",
            "Knapsack\n",
            "Constraint\n",
            "Conformal\n",
            "Symplectic\n",
            "and\n",
            "Relativistic\n",
            "Optimization\n",
            "Bayes\n",
            "Consistency\n",
            "vs.\n",
            "H-Consistency\n",
            ":\n",
            "The\n",
            "Interplay\n",
            "between\n",
            "Surrogate\n",
            "Loss\n",
            "Functions\n",
            "and\n",
            "the\n",
            "Scoring\n",
            "Function\n",
            "Class\n",
            "Inverting\n",
            "Gradients\n",
            "-\n",
            "How\n",
            "easy\n",
            "is\n",
            "it\n",
            "to\n",
            "break\n",
            "privacy\n",
            "in\n",
            "federated\n",
            "learning\n",
            "?\n",
            "Dynamic\n",
            "allocation\n",
            "of\n",
            "limited\n",
            "memory\n",
            "resources\n",
            "in\n",
            "reinforcement\n",
            "learning\n",
            "CryptoNAS\n",
            ":\n",
            "Private\n",
            "Inference\n",
            "on\n",
            "a\n",
            "ReLU\n",
            "Budget\n",
            "A\n",
            "Stochastic\n",
            "Path\n",
            "Integral\n",
            "Differential\n",
            "EstimatoR\n",
            "Expectation\n",
            "Maximization\n",
            "Algorithm\n",
            "CHIP\n",
            ":\n",
            "A\n",
            "Hawkes\n",
            "Process\n",
            "Model\n",
            "for\n",
            "Continuous-time\n",
            "Networks\n",
            "with\n",
            "Scalable\n",
            "and\n",
            "Consistent\n",
            "Estimation\n",
            "SAC\n",
            ":\n",
            "Accelerating\n",
            "and\n",
            "Structuring\n",
            "Self-Attention\n",
            "via\n",
            "Sparse\n",
            "Adaptive\n",
            "Connection\n",
            "Design\n",
            "Space\n",
            "for\n",
            "Graph\n",
            "Neural\n",
            "Networks\n",
            "HiFi-GAN\n",
            ":\n",
            "Generative\n",
            "Adversarial\n",
            "Networks\n",
            "for\n",
            "Efficient\n",
            "and\n",
            "High\n",
            "Fidelity\n",
            "Speech\n",
            "Synthesis\n",
            "Unbalanced\n",
            "Sobolev\n",
            "Descent\n",
            "Identifying\n",
            "Mislabeled\n",
            "Data\n",
            "using\n",
            "the\n",
            "Area\n",
            "Under\n",
            "the\n",
            "Margin\n",
            "Ranking\n",
            "Combining\n",
            "Deep\n",
            "Reinforcement\n",
            "Learning\n",
            "and\n",
            "Search\n",
            "for\n",
            "Imperfect-Information\n",
            "Games\n",
            "High-Throughput\n",
            "Synchronous\n",
            "Deep\n",
            "RL\n",
            "Contrastive\n",
            "Learning\n",
            "with\n",
            "Adversarial\n",
            "Examples\n",
            "Mixed\n",
            "Hamiltonian\n",
            "Monte\n",
            "Carlo\n",
            "for\n",
            "Mixed\n",
            "Discrete\n",
            "and\n",
            "Continuous\n",
            "Variables\n",
            "Adversarial\n",
            "Sparse\n",
            "Transformer\n",
            "for\n",
            "Time\n",
            "Series\n",
            "Forecasting\n",
            "The\n",
            "Surprising\n",
            "Simplicity\n",
            "of\n",
            "the\n",
            "Early-Time\n",
            "Learning\n",
            "Dynamics\n",
            "of\n",
            "Neural\n",
            "Networks\n",
            "CLEARER\n",
            ":\n",
            "Multi-Scale\n",
            "Neural\n",
            "Architecture\n",
            "Search\n",
            "for\n",
            "Image\n",
            "Restoration\n",
            "Hierarchical\n",
            "Gaussian\n",
            "Process\n",
            "Priors\n",
            "for\n",
            "Bayesian\n",
            "Neural\n",
            "Network\n",
            "Weights\n",
            "Compositional\n",
            "Explanations\n",
            "of\n",
            "Neurons\n",
            "Calibrated\n",
            "Reliable\n",
            "Regression\n",
            "using\n",
            "Maximum\n",
            "Mean\n",
            "Discrepancy\n",
            "Directional\n",
            "convergence\n",
            "and\n",
            "alignment\n",
            "in\n",
            "deep\n",
            "learning\n",
            "Functional\n",
            "Regularization\n",
            "for\n",
            "Representation\n",
            "Learning\n",
            ":\n",
            "A\n",
            "Unified\n",
            "Theoretical\n",
            "Perspective\n",
            "Provably\n",
            "Efficient\n",
            "Online\n",
            "Hyperparameter\n",
            "Optimization\n",
            "with\n",
            "Population-Based\n",
            "Bandits\n",
            "Understanding\n",
            "Global\n",
            "Feature\n",
            "Contributions\n",
            "With\n",
            "Additive\n",
            "Importance\n",
            "Measures\n",
            "Online\n",
            "Non-Convex\n",
            "Optimization\n",
            "with\n",
            "Imperfect\n",
            "Feedback\n",
            "Co-Tuning\n",
            "for\n",
            "Transfer\n",
            "Learning\n",
            "Multifaceted\n",
            "Uncertainty\n",
            "Estimation\n",
            "for\n",
            "Label-Efficient\n",
            "Deep\n",
            "Learning\n",
            "Continuous\n",
            "Surface\n",
            "Embeddings\n",
            "Succinct\n",
            "and\n",
            "Robust\n",
            "Multi-Agent\n",
            "Communication\n",
            "With\n",
            "Temporal\n",
            "Message\n",
            "Control\n",
            "Big\n",
            "Bird\n",
            ":\n",
            "Transformers\n",
            "for\n",
            "Longer\n",
            "Sequences\n",
            "Neural\n",
            "Execution\n",
            "Engines\n",
            ":\n",
            "Learning\n",
            "to\n",
            "Execute\n",
            "Subroutines\n",
            "Random\n",
            "Reshuffling\n",
            ":\n",
            "Simple\n",
            "Analysis\n",
            "with\n",
            "Vast\n",
            "Improvements\n",
            "Long-Horizon\n",
            "Visual\n",
            "Planning\n",
            "with\n",
            "Goal-Conditioned\n",
            "Hierarchical\n",
            "Predictors\n",
            "Statistical\n",
            "Optimal\n",
            "Transport\n",
            "posed\n",
            "as\n",
            "Learning\n",
            "Kernel\n",
            "Embedding\n",
            "Dual-Resolution\n",
            "Correspondence\n",
            "Networks\n",
            "Advances\n",
            "in\n",
            "Black-Box\n",
            "VI\n",
            ":\n",
            "Normalizing\n",
            "Flows\n",
            ",\n",
            "Importance\n",
            "Weighting\n",
            ",\n",
            "and\n",
            "Optimization\n",
            "f-Divergence\n",
            "Variational\n",
            "Inference\n",
            "Unfolding\n",
            "recurrence\n",
            "by\n",
            "Green\n",
            "’\n",
            "s\n",
            "functions\n",
            "for\n",
            "optimized\n",
            "reservoir\n",
            "computing\n",
            "The\n",
            "Dilemma\n",
            "of\n",
            "TriHard\n",
            "Loss\n",
            "and\n",
            "an\n",
            "Element-Weighted\n",
            "TriHard\n",
            "Loss\n",
            "for\n",
            "Person\n",
            "Re-Identification\n",
            "Disentangling\n",
            "by\n",
            "Subspace\n",
            "Diffusion\n",
            "Towards\n",
            "Neural\n",
            "Programming\n",
            "Interfaces\n",
            "Discovering\n",
            "Symbolic\n",
            "Models\n",
            "from\n",
            "Deep\n",
            "Learning\n",
            "with\n",
            "Inductive\n",
            "Biases\n",
            "Real\n",
            "World\n",
            "Games\n",
            "Look\n",
            "Like\n",
            "Spinning\n",
            "Tops\n",
            "Cooperative\n",
            "Heterogeneous\n",
            "Deep\n",
            "Reinforcement\n",
            "Learning\n",
            "Mitigating\n",
            "Forgetting\n",
            "in\n",
            "Online\n",
            "Continual\n",
            "Learning\n",
            "via\n",
            "Instance-Aware\n",
            "Parameterization\n",
            "ImpatientCapsAndRuns\n",
            ":\n",
            "Approximately\n",
            "Optimal\n",
            "Algorithm\n",
            "Configuration\n",
            "from\n",
            "an\n",
            "Infinite\n",
            "Pool\n",
            "Dense\n",
            "Correspondences\n",
            "between\n",
            "Human\n",
            "Bodies\n",
            "via\n",
            "Learning\n",
            "Transformation\n",
            "Synchronization\n",
            "on\n",
            "Graphs\n",
            "Reasoning\n",
            "about\n",
            "Uncertainties\n",
            "in\n",
            "Discrete-Time\n",
            "Dynamical\n",
            "Systems\n",
            "using\n",
            "Polynomial\n",
            "Forms\n",
            ".\n",
            "Applications\n",
            "of\n",
            "Common\n",
            "Entropy\n",
            "for\n",
            "Causal\n",
            "Inference\n",
            "SGD\n",
            "with\n",
            "shuffling\n",
            ":\n",
            "optimal\n",
            "rates\n",
            "without\n",
            "component\n",
            "convexity\n",
            "and\n",
            "large\n",
            "epoch\n",
            "requirements\n",
            "Unsupervised\n",
            "Joint\n",
            "k-node\n",
            "Graph\n",
            "Representations\n",
            "with\n",
            "Compositional\n",
            "Energy-Based\n",
            "Models\n",
            "Neural\n",
            "Manifold\n",
            "Ordinary\n",
            "Differential\n",
            "Equations\n",
            "CO-Optimal\n",
            "Transport\n",
            "Continuous\n",
            "Meta-Learning\n",
            "without\n",
            "Tasks\n",
            "A\n",
            "mathematical\n",
            "theory\n",
            "of\n",
            "cooperative\n",
            "communication\n",
            "Penalized\n",
            "Langevin\n",
            "dynamics\n",
            "with\n",
            "vanishing\n",
            "penalty\n",
            "for\n",
            "smooth\n",
            "and\n",
            "log-concave\n",
            "targets\n",
            "Learning\n",
            "Invariances\n",
            "in\n",
            "Neural\n",
            "Networks\n",
            "from\n",
            "Training\n",
            "Data\n",
            "A\n",
            "Finite-Time\n",
            "Analysis\n",
            "of\n",
            "Two\n",
            "Time-Scale\n",
            "Actor-Critic\n",
            "Methods\n",
            "Pruning\n",
            "Filter\n",
            "in\n",
            "Filter\n",
            "Learning\n",
            "to\n",
            "Mutate\n",
            "with\n",
            "Hypergradient\n",
            "Guided\n",
            "Population\n",
            "A\n",
            "convex\n",
            "optimization\n",
            "formulation\n",
            "for\n",
            "multivariate\n",
            "regression\n",
            "Online\n",
            "Meta-Critic\n",
            "Learning\n",
            "for\n",
            "Off-Policy\n",
            "Actor-Critic\n",
            "Methods\n",
            "The\n",
            "All-or-Nothing\n",
            "Phenomenon\n",
            "in\n",
            "Sparse\n",
            "Tensor\n",
            "PCA\n",
            "Synthesize\n",
            ",\n",
            "Execute\n",
            "and\n",
            "Debug\n",
            ":\n",
            "Learning\n",
            "to\n",
            "Repair\n",
            "for\n",
            "Neural\n",
            "Program\n",
            "Synthesis\n",
            "ARMA\n",
            "Nets\n",
            ":\n",
            "Expanding\n",
            "Receptive\n",
            "Field\n",
            "for\n",
            "Dense\n",
            "Prediction\n",
            "Diversity-Guided\n",
            "Multi-Objective\n",
            "Bayesian\n",
            "Optimization\n",
            "With\n",
            "Batch\n",
            "Evaluations\n",
            "SOLOv2\n",
            ":\n",
            "Dynamic\n",
            "and\n",
            "Fast\n",
            "Instance\n",
            "Segmentation\n",
            "Robust\n",
            "Recovery\n",
            "via\n",
            "Implicit\n",
            "Bias\n",
            "of\n",
            "Discrepant\n",
            "Learning\n",
            "Rates\n",
            "for\n",
            "Double\n",
            "Over-parameterization\n",
            "Axioms\n",
            "for\n",
            "Learning\n",
            "from\n",
            "Pairwise\n",
            "Comparisons\n",
            "Continuous\n",
            "Regularized\n",
            "Wasserstein\n",
            "Barycenters\n",
            "Spectral\n",
            "Temporal\n",
            "Graph\n",
            "Neural\n",
            "Network\n",
            "for\n",
            "Multivariate\n",
            "Time-series\n",
            "Forecasting\n",
            "Online\n",
            "Multitask\n",
            "Learning\n",
            "with\n",
            "Long-Term\n",
            "Memory\n",
            "Fewer\n",
            "is\n",
            "More\n",
            ":\n",
            "A\n",
            "Deep\n",
            "Graph\n",
            "Metric\n",
            "Learning\n",
            "Perspective\n",
            "Using\n",
            "Fewer\n",
            "Proxies\n",
            "Adaptive\n",
            "Graph\n",
            "Convolutional\n",
            "Recurrent\n",
            "Network\n",
            "for\n",
            "Traffic\n",
            "Forecasting\n",
            "On\n",
            "Reward-Free\n",
            "Reinforcement\n",
            "Learning\n",
            "with\n",
            "Linear\n",
            "Function\n",
            "Approximation\n",
            "Robustness\n",
            "of\n",
            "Community\n",
            "Detection\n",
            "to\n",
            "Random\n",
            "Geometric\n",
            "Perturbations\n",
            "Learning\n",
            "outside\n",
            "the\n",
            "Black-Box\n",
            ":\n",
            "The\n",
            "pursuit\n",
            "of\n",
            "interpretable\n",
            "models\n",
            "Breaking\n",
            "Reversibility\n",
            "Accelerates\n",
            "Langevin\n",
            "Dynamics\n",
            "for\n",
            "Non-Convex\n",
            "Optimization\n",
            "Robust\n",
            "large-margin\n",
            "learning\n",
            "in\n",
            "hyperbolic\n",
            "space\n",
            "Replica-Exchange\n",
            "Nos\\\n",
            "'\n",
            "e-Hoover\n",
            "Dynamics\n",
            "for\n",
            "Bayesian\n",
            "Learning\n",
            "on\n",
            "Large\n",
            "Datasets\n",
            "Adversarially\n",
            "Robust\n",
            "Few-Shot\n",
            "Learning\n",
            ":\n",
            "A\n",
            "Meta-Learning\n",
            "Approach\n",
            "Neural\n",
            "Anisotropy\n",
            "Directions\n",
            "Digraph\n",
            "Inception\n",
            "Convolutional\n",
            "Networks\n",
            "PAC-Bayesian\n",
            "Bound\n",
            "for\n",
            "the\n",
            "Conditional\n",
            "Value\n",
            "at\n",
            "Risk\n",
            "Stochastic\n",
            "Stein\n",
            "Discrepancies\n",
            "On\n",
            "the\n",
            "Role\n",
            "of\n",
            "Sparsity\n",
            "and\n",
            "DAG\n",
            "Constraints\n",
            "for\n",
            "Learning\n",
            "Linear\n",
            "DAGs\n",
            "Cream\n",
            "of\n",
            "the\n",
            "Crop\n",
            ":\n",
            "Distilling\n",
            "Prioritized\n",
            "Paths\n",
            "For\n",
            "One-Shot\n",
            "Neural\n",
            "Architecture\n",
            "Search\n",
            "Fair\n",
            "Multiple\n",
            "Decision\n",
            "Making\n",
            "Through\n",
            "Soft\n",
            "Interventions\n",
            "Representation\n",
            "Learning\n",
            "for\n",
            "Integrating\n",
            "Multi-domain\n",
            "Outcomes\n",
            "to\n",
            "Optimize\n",
            "Individualized\n",
            "Treatment\n",
            "Learning\n",
            "to\n",
            "Play\n",
            "No-Press\n",
            "Diplomacy\n",
            "with\n",
            "Best\n",
            "Response\n",
            "Policy\n",
            "Iteration\n",
            "Inverse\n",
            "Learning\n",
            "of\n",
            "Symmetries\n",
            "DiffGCN\n",
            ":\n",
            "Graph\n",
            "Convolutional\n",
            "Networks\n",
            "via\n",
            "Differential\n",
            "Operators\n",
            "and\n",
            "Algebraic\n",
            "Multigrid\n",
            "Pooling\n",
            "Distributed\n",
            "Newton\n",
            "Can\n",
            "Communicate\n",
            "Less\n",
            "and\n",
            "Resist\n",
            "Byzantine\n",
            "Workers\n",
            "Efficient\n",
            "Nonmyopic\n",
            "Bayesian\n",
            "Optimization\n",
            "via\n",
            "One-Shot\n",
            "Multi-Step\n",
            "Trees\n",
            "Effective\n",
            "Diversity\n",
            "in\n",
            "Population\n",
            "Based\n",
            "Reinforcement\n",
            "Learning\n",
            "Elastic-InfoGAN\n",
            ":\n",
            "Unsupervised\n",
            "Disentangled\n",
            "Representation\n",
            "Learning\n",
            "in\n",
            "Class-Imbalanced\n",
            "Data\n",
            "Direct\n",
            "Policy\n",
            "Gradients\n",
            ":\n",
            "Direct\n",
            "Optimization\n",
            "of\n",
            "Policies\n",
            "in\n",
            "Discrete\n",
            "Action\n",
            "Spaces\n",
            "Hybrid\n",
            "Models\n",
            "for\n",
            "Learning\n",
            "to\n",
            "Branch\n",
            "WoodFisher\n",
            ":\n",
            "Efficient\n",
            "Second-Order\n",
            "Approximation\n",
            "for\n",
            "Neural\n",
            "Network\n",
            "Compression\n",
            "Bi-level\n",
            "Score\n",
            "Matching\n",
            "for\n",
            "Learning\n",
            "Energy-based\n",
            "Latent\n",
            "Variable\n",
            "Models\n",
            "Counterfactual\n",
            "Contrastive\n",
            "Learning\n",
            "for\n",
            "Weakly-Supervised\n",
            "Vision-Language\n",
            "Grounding\n",
            "Decision\n",
            "trees\n",
            "as\n",
            "partitioning\n",
            "machines\n",
            "to\n",
            "characterize\n",
            "their\n",
            "generalization\n",
            "properties\n",
            "Learning\n",
            "to\n",
            "Prove\n",
            "Theorems\n",
            "by\n",
            "Learning\n",
            "to\n",
            "Generate\n",
            "Theorems\n",
            "3D\n",
            "Self-Supervised\n",
            "Methods\n",
            "for\n",
            "Medical\n",
            "Imaging\n",
            "Bayesian\n",
            "filtering\n",
            "unifies\n",
            "adaptive\n",
            "and\n",
            "non-adaptive\n",
            "neural\n",
            "network\n",
            "optimization\n",
            "methods\n",
            "Worst-Case\n",
            "Analysis\n",
            "for\n",
            "Randomly\n",
            "Collected\n",
            "Data\n",
            "Truthful\n",
            "Data\n",
            "Acquisition\n",
            "via\n",
            "Peer\n",
            "Prediction\n",
            "Learning\n",
            "Robust\n",
            "Decision\n",
            "Policies\n",
            "from\n",
            "Observational\n",
            "Data\n",
            "Byzantine\n",
            "Resilient\n",
            "Distributed\n",
            "Multi-Task\n",
            "Learning\n",
            "Reinforcement\n",
            "Learning\n",
            "in\n",
            "Factored\n",
            "MDPs\n",
            ":\n",
            "Oracle-Efficient\n",
            "Algorithms\n",
            "and\n",
            "Tighter\n",
            "Regret\n",
            "Bounds\n",
            "for\n",
            "the\n",
            "Non-Episodic\n",
            "Setting\n",
            "Improving\n",
            "model\n",
            "calibration\n",
            "with\n",
            "accuracy\n",
            "versus\n",
            "uncertainty\n",
            "optimization\n",
            "The\n",
            "Convolution\n",
            "Exponential\n",
            "and\n",
            "Generalized\n",
            "Sylvester\n",
            "Flows\n",
            "An\n",
            "Improved\n",
            "Analysis\n",
            "of\n",
            "Stochastic\n",
            "Gradient\n",
            "Descent\n",
            "with\n",
            "Momentum\n",
            "Precise\n",
            "expressions\n",
            "for\n",
            "random\n",
            "projections\n",
            ":\n",
            "Low-rank\n",
            "approximation\n",
            "and\n",
            "randomized\n",
            "Newton\n",
            "The\n",
            "MAGICAL\n",
            "Benchmark\n",
            "for\n",
            "Robust\n",
            "Imitation\n",
            "X-CAL\n",
            ":\n",
            "Explicit\n",
            "Calibration\n",
            "for\n",
            "Survival\n",
            "Analysis\n",
            "Decentralized\n",
            "Accelerated\n",
            "Proximal\n",
            "Gradient\n",
            "Descent\n",
            "Making\n",
            "Non-Stochastic\n",
            "Control\n",
            "(\n",
            "Almost\n",
            ")\n",
            "as\n",
            "Easy\n",
            "as\n",
            "Stochastic\n",
            "BERT\n",
            "Loses\n",
            "Patience\n",
            ":\n",
            "Fast\n",
            "and\n",
            "Robust\n",
            "Inference\n",
            "with\n",
            "Early\n",
            "Exit\n",
            "Optimal\n",
            "and\n",
            "Practical\n",
            "Algorithms\n",
            "for\n",
            "Smooth\n",
            "and\n",
            "Strongly\n",
            "Convex\n",
            "Decentralized\n",
            "Optimization\n",
            "BAIL\n",
            ":\n",
            "Best-Action\n",
            "Imitation\n",
            "Learning\n",
            "for\n",
            "Batch\n",
            "Deep\n",
            "Reinforcement\n",
            "Learning\n",
            "Regularizing\n",
            "Towards\n",
            "Permutation\n",
            "Invariance\n",
            "In\n",
            "Recurrent\n",
            "Models\n",
            "What\n",
            "Did\n",
            "You\n",
            "Think\n",
            "Would\n",
            "Happen\n",
            "?\n",
            "Explaining\n",
            "Agent\n",
            "Behaviour\n",
            "through\n",
            "Intended\n",
            "Outcomes\n",
            "Batch\n",
            "normalization\n",
            "provably\n",
            "avoids\n",
            "ranks\n",
            "collapse\n",
            "for\n",
            "randomly\n",
            "initialised\n",
            "deep\n",
            "networks\n",
            "Choice\n",
            "Bandits\n",
            "What\n",
            "if\n",
            "Neural\n",
            "Networks\n",
            "had\n",
            "SVDs\n",
            "?\n",
            "A\n",
            "Matrix\n",
            "Chernoff\n",
            "Bound\n",
            "for\n",
            "Markov\n",
            "Chains\n",
            "and\n",
            "Its\n",
            "Application\n",
            "to\n",
            "Co-occurrence\n",
            "Matrices\n",
            "CoMIR\n",
            ":\n",
            "Contrastive\n",
            "Multimodal\n",
            "Image\n",
            "Representation\n",
            "for\n",
            "Registration\n",
            "Ensuring\n",
            "Fairness\n",
            "Beyond\n",
            "the\n",
            "Training\n",
            "Data\n",
            "How\n",
            "do\n",
            "fair\n",
            "decisions\n",
            "fare\n",
            "in\n",
            "long-term\n",
            "qualification\n",
            "?\n",
            "Pre-training\n",
            "via\n",
            "Paraphrasing\n",
            "GCN\n",
            "meets\n",
            "GPU\n",
            ":\n",
            "Decoupling\n",
            "“\n",
            "When\n",
            "to\n",
            "Sample\n",
            "”\n",
            "from\n",
            "“\n",
            "How\n",
            "to\n",
            "Sample\n",
            "”\n",
            "Continual\n",
            "Learning\n",
            "of\n",
            "a\n",
            "Mixed\n",
            "Sequence\n",
            "of\n",
            "Similar\n",
            "and\n",
            "Dissimilar\n",
            "Tasks\n",
            "All\n",
            "your\n",
            "loss\n",
            "are\n",
            "belong\n",
            "to\n",
            "Bayes\n",
            "HAWQ-V2\n",
            ":\n",
            "Hessian\n",
            "Aware\n",
            "trace-Weighted\n",
            "Quantization\n",
            "of\n",
            "Neural\n",
            "Networks\n",
            "Sample-Efficient\n",
            "Reinforcement\n",
            "Learning\n",
            "of\n",
            "Undercomplete\n",
            "POMDPs\n",
            "Non-Convex\n",
            "SGD\n",
            "Learns\n",
            "Halfspaces\n",
            "with\n",
            "Adversarial\n",
            "Label\n",
            "Noise\n",
            "A\n",
            "Tight\n",
            "Lower\n",
            "Bound\n",
            "and\n",
            "Efficient\n",
            "Reduction\n",
            "for\n",
            "Swap\n",
            "Regret\n",
            "DisCor\n",
            ":\n",
            "Corrective\n",
            "Feedback\n",
            "in\n",
            "Reinforcement\n",
            "Learning\n",
            "via\n",
            "Distribution\n",
            "Correction\n",
            "OTLDA\n",
            ":\n",
            "A\n",
            "Geometry-aware\n",
            "Optimal\n",
            "Transport\n",
            "Approach\n",
            "for\n",
            "Topic\n",
            "Modeling\n",
            "Measuring\n",
            "Robustness\n",
            "to\n",
            "Natural\n",
            "Distribution\n",
            "Shifts\n",
            "in\n",
            "Image\n",
            "Classification\n",
            "Can\n",
            "I\n",
            "Trust\n",
            "My\n",
            "Fairness\n",
            "Metric\n",
            "?\n",
            "Assessing\n",
            "Fairness\n",
            "with\n",
            "Unlabeled\n",
            "Data\n",
            "and\n",
            "Bayesian\n",
            "Inference\n",
            "RandAugment\n",
            ":\n",
            "Practical\n",
            "Automated\n",
            "Data\n",
            "Augmentation\n",
            "with\n",
            "a\n",
            "Reduced\n",
            "Search\n",
            "Space\n",
            "Asymptotic\n",
            "normality\n",
            "and\n",
            "confidence\n",
            "intervals\n",
            "for\n",
            "derivatives\n",
            "of\n",
            "2-layers\n",
            "neural\n",
            "network\n",
            "in\n",
            "the\n",
            "random\n",
            "features\n",
            "model\n",
            "DisARM\n",
            ":\n",
            "An\n",
            "Antithetic\n",
            "Gradient\n",
            "Estimator\n",
            "for\n",
            "Binary\n",
            "Latent\n",
            "Variables\n",
            "Variational\n",
            "Inference\n",
            "for\n",
            "Graph\n",
            "Convolutional\n",
            "Networks\n",
            "in\n",
            "the\n",
            "Absence\n",
            "of\n",
            "Graph\n",
            "Data\n",
            "and\n",
            "Adversarial\n",
            "Settings\n",
            "Supervised\n",
            "Contrastive\n",
            "Learning\n",
            "Learning\n",
            "Optimal\n",
            "Representations\n",
            "with\n",
            "the\n",
            "Decodable\n",
            "Information\n",
            "Bottleneck\n",
            "Meta-trained\n",
            "agents\n",
            "implement\n",
            "Bayes-optimal\n",
            "agents\n",
            "Learning\n",
            "Agent\n",
            "Representations\n",
            "for\n",
            "Ice\n",
            "Hockey\n",
            "Weak\n",
            "Form\n",
            "Generalized\n",
            "Hamiltonian\n",
            "Learning\n",
            "Neural\n",
            "Non-Rigid\n",
            "Tracking\n",
            "Collegial\n",
            "Ensembles\n",
            "ICNet\n",
            ":\n",
            "Intra-saliency\n",
            "Correlation\n",
            "Network\n",
            "for\n",
            "Co-Saliency\n",
            "Detection\n",
            "Improved\n",
            "Variational\n",
            "Bayesian\n",
            "Phylogenetic\n",
            "Inference\n",
            "with\n",
            "Normalizing\n",
            "Flows\n",
            "Deep\n",
            "Metric\n",
            "Learning\n",
            "with\n",
            "Spherical\n",
            "Embedding\n",
            "Preference-based\n",
            "Reinforcement\n",
            "Learning\n",
            "with\n",
            "Finite-Time\n",
            "Guarantees\n",
            "AdaBelief\n",
            "Optimizer\n",
            ":\n",
            "Adapting\n",
            "Stepsizes\n",
            "by\n",
            "the\n",
            "Belief\n",
            "in\n",
            "Observed\n",
            "Gradients\n",
            "Interpretable\n",
            "Sequence\n",
            "Learning\n",
            "for\n",
            "Covid-19\n",
            "Forecasting\n",
            "Off-policy\n",
            "Policy\n",
            "Evaluation\n",
            "For\n",
            "Sequential\n",
            "Decisions\n",
            "Under\n",
            "Unobserved\n",
            "Confounding\n",
            "Modern\n",
            "Hopfield\n",
            "Networks\n",
            "and\n",
            "Attention\n",
            "for\n",
            "Immune\n",
            "Repertoire\n",
            "Classification\n",
            "One\n",
            "Ring\n",
            "to\n",
            "Rule\n",
            "Them\n",
            "All\n",
            ":\n",
            "Certifiably\n",
            "Robust\n",
            "Geometric\n",
            "Perception\n",
            "with\n",
            "Outliers\n",
            "Task-Robust\n",
            "Model-Agnostic\n",
            "Meta-Learning\n",
            "R-learning\n",
            "in\n",
            "actor-critic\n",
            "model\n",
            "offers\n",
            "a\n",
            "biologically\n",
            "relevant\n",
            "mechanism\n",
            "for\n",
            "sequential\n",
            "decision-making\n",
            "Revisiting\n",
            "Frank-Wolfe\n",
            "for\n",
            "Polytopes\n",
            ":\n",
            "Strict\n",
            "Complementarity\n",
            "and\n",
            "Sparsity\n",
            "Fast\n",
            "Convergence\n",
            "of\n",
            "Langevin\n",
            "Dynamics\n",
            "on\n",
            "Manifold\n",
            ":\n",
            "Geodesics\n",
            "meet\n",
            "Log-Sobolev\n",
            "Tensor\n",
            "Completion\n",
            "Made\n",
            "Practical\n",
            "Optimization\n",
            "and\n",
            "Generalization\n",
            "Analysis\n",
            "of\n",
            "Transduction\n",
            "through\n",
            "Gradient\n",
            "Boosting\n",
            "and\n",
            "Application\n",
            "to\n",
            "Multi-scale\n",
            "Graph\n",
            "Neural\n",
            "Networks\n",
            "Content\n",
            "Provider\n",
            "Dynamics\n",
            "and\n",
            "Coordination\n",
            "in\n",
            "Recommendation\n",
            "Ecosystems\n",
            "Almost\n",
            "Surely\n",
            "Stable\n",
            "Deep\n",
            "Dynamics\n",
            "Experimental\n",
            "design\n",
            "for\n",
            "MRI\n",
            "by\n",
            "greedy\n",
            "policy\n",
            "search\n",
            "Expert-Supervised\n",
            "Reinforcement\n",
            "Learning\n",
            "for\n",
            "Offline\n",
            "Policy\n",
            "Learning\n",
            "and\n",
            "Evaluation\n",
            "ColdGANs\n",
            ":\n",
            "Taming\n",
            "Language\n",
            "GANs\n",
            "with\n",
            "Cautious\n",
            "Sampling\n",
            "Strategies\n",
            "Hedging\n",
            "in\n",
            "games\n",
            ":\n",
            "Faster\n",
            "convergence\n",
            "of\n",
            "external\n",
            "and\n",
            "swap\n",
            "regrets\n",
            "The\n",
            "Origins\n",
            "and\n",
            "Prevalence\n",
            "of\n",
            "Texture\n",
            "Bias\n",
            "in\n",
            "Convolutional\n",
            "Neural\n",
            "Networks\n",
            "Time-Reversal\n",
            "Symmetric\n",
            "ODE\n",
            "Network\n",
            "Provable\n",
            "Overlapping\n",
            "Community\n",
            "Detection\n",
            "in\n",
            "Weighted\n",
            "Graphs\n",
            "Fast\n",
            "Unbalanced\n",
            "Optimal\n",
            "Transport\n",
            "on\n",
            "a\n",
            "Tree\n",
            "Acceleration\n",
            "with\n",
            "a\n",
            "Ball\n",
            "Optimization\n",
            "Oracle\n",
            "Avoiding\n",
            "Side\n",
            "Effects\n",
            "By\n",
            "Considering\n",
            "Future\n",
            "Tasks\n",
            "Handling\n",
            "Missing\n",
            "Data\n",
            "with\n",
            "Graph\n",
            "Representation\n",
            "Learning\n",
            "Improving\n",
            "Auto-Augment\n",
            "via\n",
            "Augmentation-Wise\n",
            "Weight\n",
            "Sharing\n",
            "MMA\n",
            "Regularization\n",
            ":\n",
            "Decorrelating\n",
            "Weights\n",
            "of\n",
            "Neural\n",
            "Networks\n",
            "by\n",
            "Maximizing\n",
            "the\n",
            "Minimal\n",
            "Angles\n",
            "HRN\n",
            ":\n",
            "A\n",
            "Holistic\n",
            "Approach\n",
            "to\n",
            "One\n",
            "Class\n",
            "Learning\n",
            "The\n",
            "Generalized\n",
            "Lasso\n",
            "with\n",
            "Nonlinear\n",
            "Observations\n",
            "and\n",
            "Generative\n",
            "Priors\n",
            "Fair\n",
            "regression\n",
            "via\n",
            "plug-in\n",
            "estimator\n",
            "and\n",
            "recalibration\n",
            "with\n",
            "statistical\n",
            "guarantees\n",
            "Modeling\n",
            "Shared\n",
            "responses\n",
            "in\n",
            "Neuroimaging\n",
            "Studies\n",
            "through\n",
            "MultiView\n",
            "ICA\n",
            "Efficient\n",
            "Planning\n",
            "in\n",
            "Large\n",
            "MDPs\n",
            "with\n",
            "Weak\n",
            "Linear\n",
            "Function\n",
            "Approximation\n",
            "Efficient\n",
            "Learning\n",
            "of\n",
            "Generative\n",
            "Models\n",
            "via\n",
            "Finite-Difference\n",
            "Score\n",
            "Matching\n",
            "Semialgebraic\n",
            "Optimization\n",
            "for\n",
            "Lipschitz\n",
            "Constants\n",
            "of\n",
            "ReLU\n",
            "Networks\n",
            "Linear-Sample\n",
            "Learning\n",
            "of\n",
            "Low-Rank\n",
            "Distributions\n",
            "Transferable\n",
            "Calibration\n",
            "with\n",
            "Lower\n",
            "Bias\n",
            "and\n",
            "Variance\n",
            "in\n",
            "Domain\n",
            "Adaptation\n",
            "Generalization\n",
            "bound\n",
            "of\n",
            "globally\n",
            "optimal\n",
            "non-convex\n",
            "neural\n",
            "network\n",
            "training\n",
            ":\n",
            "Transportation\n",
            "map\n",
            "estimation\n",
            "by\n",
            "infinite\n",
            "dimensional\n",
            "Langevin\n",
            "dynamics\n",
            "Online\n",
            "Bayesian\n",
            "Goal\n",
            "Inference\n",
            "for\n",
            "Boundedly\n",
            "Rational\n",
            "Planning\n",
            "Agents\n",
            "BayReL\n",
            ":\n",
            "Bayesian\n",
            "Relational\n",
            "Learning\n",
            "for\n",
            "Multi-omics\n",
            "Data\n",
            "Integration\n",
            "Weakly\n",
            "Supervised\n",
            "Deep\n",
            "Functional\n",
            "Maps\n",
            "for\n",
            "Shape\n",
            "Matching\n",
            "Domain\n",
            "Adaptation\n",
            "with\n",
            "Conditional\n",
            "Distribution\n",
            "Matching\n",
            "and\n",
            "Generalized\n",
            "Label\n",
            "Shift\n",
            "Rethinking\n",
            "the\n",
            "Value\n",
            "of\n",
            "Labels\n",
            "for\n",
            "Improving\n",
            "Class-Imbalanced\n",
            "Learning\n",
            "Provably\n",
            "Robust\n",
            "Metric\n",
            "Learning\n",
            "Iterative\n",
            "Deep\n",
            "Graph\n",
            "Learning\n",
            "for\n",
            "Graph\n",
            "Neural\n",
            "Networks\n",
            ":\n",
            "Better\n",
            "and\n",
            "Robust\n",
            "Node\n",
            "Embeddings\n",
            "COPT\n",
            ":\n",
            "Coordinated\n",
            "Optimal\n",
            "Transport\n",
            "on\n",
            "Graphs\n",
            "No\n",
            "Subclass\n",
            "Left\n",
            "Behind\n",
            ":\n",
            "Fine-Grained\n",
            "Robustness\n",
            "in\n",
            "Coarse-Grained\n",
            "Classification\n",
            "Problems\n",
            "Model\n",
            "Rubik\n",
            "’\n",
            "s\n",
            "Cube\n",
            ":\n",
            "Twisting\n",
            "Resolution\n",
            ",\n",
            "Depth\n",
            "and\n",
            "Width\n",
            "for\n",
            "TinyNets\n",
            "Self-Adaptive\n",
            "Training\n",
            ":\n",
            "beyond\n",
            "Empirical\n",
            "Risk\n",
            "Minimization\n",
            "Effective\n",
            "Dimension\n",
            "Adaptive\n",
            "Sketching\n",
            "Methods\n",
            "for\n",
            "Faster\n",
            "Regularized\n",
            "Least-Squares\n",
            "Optimization\n",
            "Near-Optimal\n",
            "Comparison\n",
            "Based\n",
            "Clustering\n",
            "Multi-Task\n",
            "Temporal\n",
            "Shift\n",
            "Attention\n",
            "Networks\n",
            "for\n",
            "On-Device\n",
            "Contactless\n",
            "Vitals\n",
            "Measurement\n",
            "A\n",
            "new\n",
            "convergent\n",
            "variant\n",
            "of\n",
            "Q-learning\n",
            "with\n",
            "linear\n",
            "function\n",
            "approximation\n",
            "TaylorGAN\n",
            ":\n",
            "Neighbor-Augmented\n",
            "Policy\n",
            "Update\n",
            "Towards\n",
            "Sample-Efficient\n",
            "Natural\n",
            "Language\n",
            "Generation\n",
            "Neural\n",
            "Networks\n",
            "with\n",
            "Small\n",
            "Weights\n",
            "and\n",
            "Depth-Separation\n",
            "Barriers\n",
            "Untangling\n",
            "tradeoffs\n",
            "between\n",
            "recurrence\n",
            "and\n",
            "self-attention\n",
            "in\n",
            "artificial\n",
            "neural\n",
            "networks\n",
            "Dual-Free\n",
            "Stochastic\n",
            "Decentralized\n",
            "Optimization\n",
            "with\n",
            "Variance\n",
            "Reduction\n",
            "Online\n",
            "Learning\n",
            "in\n",
            "Contextual\n",
            "Bandits\n",
            "using\n",
            "Gated\n",
            "Linear\n",
            "Networks\n",
            "Throughput-Optimal\n",
            "Topology\n",
            "Design\n",
            "for\n",
            "Cross-Silo\n",
            "Federated\n",
            "Learning\n",
            "Quantized\n",
            "Variational\n",
            "Inference\n",
            "Asymptotically\n",
            "Optimal\n",
            "Exact\n",
            "Minibatch\n",
            "Metropolis-Hastings\n",
            "Learning\n",
            "Search\n",
            "Space\n",
            "Partition\n",
            "for\n",
            "Black-box\n",
            "Optimization\n",
            "using\n",
            "Monte\n",
            "Carlo\n",
            "Tree\n",
            "Search\n",
            "Feature\n",
            "Shift\n",
            "Detection\n",
            ":\n",
            "Localizing\n",
            "Which\n",
            "Features\n",
            "Have\n",
            "Shifted\n",
            "via\n",
            "Conditional\n",
            "Distribution\n",
            "Tests\n",
            "Unifying\n",
            "Activation-\n",
            "and\n",
            "Timing-based\n",
            "Learning\n",
            "Rules\n",
            "for\n",
            "Spiking\n",
            "Neural\n",
            "Networks\n",
            "Space-Time\n",
            "Correspondence\n",
            "as\n",
            "a\n",
            "Contrastive\n",
            "Random\n",
            "Walk\n",
            "The\n",
            "Flajolet-Martin\n",
            "Sketch\n",
            "Itself\n",
            "Preserves\n",
            "Differential\n",
            "Privacy\n",
            ":\n",
            "Private\n",
            "Counting\n",
            "with\n",
            "Minimal\n",
            "Space\n",
            "Exponential\n",
            "ergodicity\n",
            "of\n",
            "mirror-Langevin\n",
            "diffusions\n",
            "An\n",
            "Efficient\n",
            "Framework\n",
            "for\n",
            "Clustered\n",
            "Federated\n",
            "Learning\n",
            "Autoencoders\n",
            "that\n",
            "do\n",
            "n't\n",
            "overfit\n",
            "towards\n",
            "the\n",
            "Identity\n",
            "Polynomial-Time\n",
            "Computation\n",
            "of\n",
            "Optimal\n",
            "Correlated\n",
            "Equilibria\n",
            "in\n",
            "Two-Player\n",
            "Extensive-Form\n",
            "Games\n",
            "with\n",
            "Public\n",
            "Chance\n",
            "Moves\n",
            "and\n",
            "Beyond\n",
            "Parameterized\n",
            "Explainer\n",
            "for\n",
            "Graph\n",
            "Neural\n",
            "Network\n",
            "Recursive\n",
            "Inference\n",
            "for\n",
            "Variational\n",
            "Autoencoders\n",
            "Flexible\n",
            "mean\n",
            "field\n",
            "variational\n",
            "inference\n",
            "using\n",
            "mixtures\n",
            "of\n",
            "non-overlapping\n",
            "exponential\n",
            "families\n",
            "HYDRA\n",
            ":\n",
            "Pruning\n",
            "Adversarially\n",
            "Robust\n",
            "Neural\n",
            "Networks\n",
            "NVAE\n",
            ":\n",
            "A\n",
            "Deep\n",
            "Hierarchical\n",
            "Variational\n",
            "Autoencoder\n",
            "Can\n",
            "Temporal-Diﬀerence\n",
            "and\n",
            "Q-Learning\n",
            "Learn\n",
            "Representation\n",
            "?\n",
            "A\n",
            "Mean-Field\n",
            "Theory\n",
            "What\n",
            "Do\n",
            "Neural\n",
            "Networks\n",
            "Learn\n",
            "When\n",
            "Trained\n",
            "With\n",
            "Random\n",
            "Labels\n",
            "?\n",
            "Counterfactual\n",
            "Prediction\n",
            "for\n",
            "Bundle\n",
            "Treatment\n",
            "Beta\n",
            "Embeddings\n",
            "for\n",
            "Multi-Hop\n",
            "Logical\n",
            "Reasoning\n",
            "in\n",
            "Knowledge\n",
            "Graphs\n",
            "Learning\n",
            "Disentangled\n",
            "Representations\n",
            "and\n",
            "Group\n",
            "Structure\n",
            "of\n",
            "Dynamical\n",
            "Environments\n",
            "Learning\n",
            "Linear\n",
            "Programs\n",
            "from\n",
            "Optimal\n",
            "Decisions\n",
            "Wisdom\n",
            "of\n",
            "the\n",
            "Ensemble\n",
            ":\n",
            "Improving\n",
            "Consistency\n",
            "of\n",
            "Deep\n",
            "Learning\n",
            "Models\n",
            "Universal\n",
            "Function\n",
            "Approximation\n",
            "on\n",
            "Graphs\n",
            "Accelerating\n",
            "Reinforcement\n",
            "Learning\n",
            "through\n",
            "GPU\n",
            "Atari\n",
            "Emulation\n",
            "EvolveGraph\n",
            ":\n",
            "Multi-Agent\n",
            "Trajectory\n",
            "Prediction\n",
            "with\n",
            "Dynamic\n",
            "Relational\n",
            "Reasoning\n",
            "Comparator-Adaptive\n",
            "Convex\n",
            "Bandits\n",
            "Model-based\n",
            "Reinforcement\n",
            "Learning\n",
            "for\n",
            "Semi-Markov\n",
            "Decision\n",
            "Processes\n",
            "with\n",
            "Neural\n",
            "ODEs\n",
            "The\n",
            "Adaptive\n",
            "Complexity\n",
            "of\n",
            "Maximizing\n",
            "a\n",
            "Gross\n",
            "Substitutes\n",
            "Valuation\n",
            "A\n",
            "Robust\n",
            "Functional\n",
            "EM\n",
            "Algorithm\n",
            "for\n",
            "Incomplete\n",
            "Panel\n",
            "Count\n",
            "Data\n",
            "Graph\n",
            "Stochastic\n",
            "Neural\n",
            "Networks\n",
            "for\n",
            "Semi-supervised\n",
            "Learning\n",
            "Compositional\n",
            "Zero-Shot\n",
            "Learning\n",
            "via\n",
            "Fine-Grained\n",
            "Dense\n",
            "Feature\n",
            "Composition\n",
            "A\n",
            "Benchmark\n",
            "for\n",
            "Systematic\n",
            "Generalization\n",
            "in\n",
            "Grounded\n",
            "Language\n",
            "Understanding\n",
            "Weston-Watkins\n",
            "Hinge\n",
            "Loss\n",
            "and\n",
            "Ordered\n",
            "Partitions\n",
            "Reinforcement\n",
            "Learning\n",
            "with\n",
            "Augmented\n",
            "Data\n",
            "Towards\n",
            "Minimax\n",
            "Optimal\n",
            "Reinforcement\n",
            "Learning\n",
            "in\n",
            "Factored\n",
            "Markov\n",
            "Decision\n",
            "Processes\n",
            "Graduated\n",
            "Assignment\n",
            "for\n",
            "Joint\n",
            "Multi-Graph\n",
            "Matching\n",
            "and\n",
            "Clustering\n",
            "with\n",
            "Application\n",
            "to\n",
            "Unsupervised\n",
            "Graph\n",
            "Matching\n",
            "Network\n",
            "Learning\n",
            "Estimating\n",
            "Training\n",
            "Data\n",
            "Influence\n",
            "by\n",
            "Tracing\n",
            "Gradient\n",
            "Descent\n",
            "Joint\n",
            "Policy\n",
            "Search\n",
            "for\n",
            "Multi-agent\n",
            "Collaboration\n",
            "with\n",
            "Imperfect\n",
            "Information\n",
            "Adversarial\n",
            "Bandits\n",
            "with\n",
            "Corruptions\n",
            ":\n",
            "Regret\n",
            "Lower\n",
            "Bound\n",
            "and\n",
            "No-regret\n",
            "Algorithm\n",
            "Beta\n",
            "R-CNN\n",
            ":\n",
            "Looking\n",
            "into\n",
            "Pedestrian\n",
            "Detection\n",
            "from\n",
            "Another\n",
            "Perspective\n",
            "Batch\n",
            "Normalization\n",
            "Biases\n",
            "Residual\n",
            "Blocks\n",
            "Towards\n",
            "the\n",
            "Identity\n",
            "Function\n",
            "in\n",
            "Deep\n",
            "Networks\n",
            "Learning\n",
            "Retrospective\n",
            "Knowledge\n",
            "with\n",
            "Reverse\n",
            "Reinforcement\n",
            "Learning\n",
            "Dialog\n",
            "without\n",
            "Dialog\n",
            "Data\n",
            ":\n",
            "Learning\n",
            "Visual\n",
            "Dialog\n",
            "Agents\n",
            "from\n",
            "VQA\n",
            "Data\n",
            "GCOMB\n",
            ":\n",
            "Learning\n",
            "Budget-constrained\n",
            "Combinatorial\n",
            "Algorithms\n",
            "over\n",
            "Billion-sized\n",
            "Graphs\n",
            "A\n",
            "General\n",
            "Large\n",
            "Neighborhood\n",
            "Search\n",
            "Framework\n",
            "for\n",
            "Solving\n",
            "Integer\n",
            "Linear\n",
            "Programs\n",
            "A\n",
            "Theoretical\n",
            "Framework\n",
            "for\n",
            "Target\n",
            "Propagation\n",
            "OrganITE\n",
            ":\n",
            "Optimal\n",
            "transplant\n",
            "donor\n",
            "organ\n",
            "offering\n",
            "using\n",
            "an\n",
            "individual\n",
            "treatment\n",
            "effect\n",
            "The\n",
            "Complete\n",
            "Lasso\n",
            "Tradeoff\n",
            "Diagram\n",
            "On\n",
            "the\n",
            "universality\n",
            "of\n",
            "deep\n",
            "learning\n",
            "Regression\n",
            "with\n",
            "reject\n",
            "option\n",
            "and\n",
            "application\n",
            "to\n",
            "kNN\n",
            "The\n",
            "Primal-Dual\n",
            "method\n",
            "for\n",
            "Learning\n",
            "Augmented\n",
            "Algorithms\n",
            "FLAMBE\n",
            ":\n",
            "Structural\n",
            "Complexity\n",
            "and\n",
            "Representation\n",
            "Learning\n",
            "of\n",
            "Low\n",
            "Rank\n",
            "MDPs\n",
            "A\n",
            "Class\n",
            "of\n",
            "Algorithms\n",
            "for\n",
            "General\n",
            "Instrumental\n",
            "Variable\n",
            "Models\n",
            "Black-Box\n",
            "Ripper\n",
            ":\n",
            "Copying\n",
            "black-box\n",
            "models\n",
            "using\n",
            "generative\n",
            "evolutionary\n",
            "algorithms\n",
            "Bayesian\n",
            "Optimization\n",
            "of\n",
            "Risk\n",
            "Measures\n",
            "TorsionNet\n",
            ":\n",
            "A\n",
            "Reinforcement\n",
            "Learning\n",
            "Approach\n",
            "to\n",
            "Sequential\n",
            "Conformer\n",
            "Search\n",
            "GRAF\n",
            ":\n",
            "Generative\n",
            "Radiance\n",
            "Fields\n",
            "for\n",
            "3D-Aware\n",
            "Image\n",
            "Synthesis\n",
            "PIE-NET\n",
            ":\n",
            "Parametric\n",
            "Inference\n",
            "of\n",
            "Point\n",
            "Cloud\n",
            "Edges\n",
            "A\n",
            "Simple\n",
            "Language\n",
            "Model\n",
            "for\n",
            "Task-Oriented\n",
            "Dialogue\n",
            "A\n",
            "Continuous-Time\n",
            "Mirror\n",
            "Descent\n",
            "Approach\n",
            "to\n",
            "Sparse\n",
            "Phase\n",
            "Retrieval\n",
            "Confidence\n",
            "sequences\n",
            "for\n",
            "sampling\n",
            "without\n",
            "replacement\n",
            "A\n",
            "mean-field\n",
            "analysis\n",
            "of\n",
            "two-player\n",
            "zero-sum\n",
            "games\n",
            "Leap-Of-Thought\n",
            ":\n",
            "Teaching\n",
            "Pre-Trained\n",
            "Models\n",
            "to\n",
            "Systematically\n",
            "Reason\n",
            "Over\n",
            "Implicit\n",
            "Knowledge\n",
            "Pipeline\n",
            "PSRO\n",
            ":\n",
            "A\n",
            "Scalable\n",
            "Approach\n",
            "for\n",
            "Finding\n",
            "Approximate\n",
            "Nash\n",
            "Equilibria\n",
            "in\n",
            "Large\n",
            "Games\n",
            "Improving\n",
            "Sparse\n",
            "Vector\n",
            "Technique\n",
            "with\n",
            "Renyi\n",
            "Differential\n",
            "Privacy\n",
            "Latent\n",
            "Template\n",
            "Induction\n",
            "with\n",
            "Gumbel-CRFs\n",
            "Instance\n",
            "Based\n",
            "Approximations\n",
            "to\n",
            "Profile\n",
            "Maximum\n",
            "Likelihood\n",
            "Factorizable\n",
            "Graph\n",
            "Convolutional\n",
            "Networks\n",
            "Guided\n",
            "Adversarial\n",
            "Attack\n",
            "for\n",
            "Evaluating\n",
            "and\n",
            "Enhancing\n",
            "Adversarial\n",
            "Defenses\n",
            "A\n",
            "Study\n",
            "on\n",
            "Encodings\n",
            "for\n",
            "Neural\n",
            "Architecture\n",
            "Search\n",
            "Noise2Same\n",
            ":\n",
            "Optimizing\n",
            "A\n",
            "Self-Supervised\n",
            "Bound\n",
            "for\n",
            "Image\n",
            "Denoising\n",
            "Early-Learning\n",
            "Regularization\n",
            "Prevents\n",
            "Memorization\n",
            "of\n",
            "Noisy\n",
            "Labels\n",
            "LAPAR\n",
            ":\n",
            "Linearly-Assembled\n",
            "Pixel-Adaptive\n",
            "Regression\n",
            "Network\n",
            "for\n",
            "Single\n",
            "Image\n",
            "Super-resolution\n",
            "and\n",
            "Beyond\n",
            "Learning\n",
            "Parities\n",
            "with\n",
            "Neural\n",
            "Networks\n",
            "Consistent\n",
            "Plug-in\n",
            "Classifiers\n",
            "for\n",
            "Complex\n",
            "Objectives\n",
            "and\n",
            "Constraints\n",
            "Movement\n",
            "Pruning\n",
            ":\n",
            "Adaptive\n",
            "Sparsity\n",
            "by\n",
            "Fine-Tuning\n",
            "Sanity-Checking\n",
            "Pruning\n",
            "Methods\n",
            ":\n",
            "Random\n",
            "Tickets\n",
            "can\n",
            "Win\n",
            "the\n",
            "Jackpot\n",
            "Online\n",
            "Matrix\n",
            "Completion\n",
            "with\n",
            "Side\n",
            "Information\n",
            "Position-based\n",
            "Scaled\n",
            "Gradient\n",
            "for\n",
            "Model\n",
            "Quantization\n",
            "and\n",
            "Pruning\n",
            "Online\n",
            "Learning\n",
            "with\n",
            "Primary\n",
            "and\n",
            "Secondary\n",
            "Losses\n",
            "Graph\n",
            "Information\n",
            "Bottleneck\n",
            "The\n",
            "Complexity\n",
            "of\n",
            "Adversarially\n",
            "Robust\n",
            "Proper\n",
            "Learning\n",
            "of\n",
            "Halfspaces\n",
            "with\n",
            "Agnostic\n",
            "Noise\n",
            "Adaptive\n",
            "Online\n",
            "Estimation\n",
            "of\n",
            "Piecewise\n",
            "Polynomial\n",
            "Trends\n",
            "RNNPool\n",
            ":\n",
            "Efficient\n",
            "Non-linear\n",
            "Pooling\n",
            "for\n",
            "RAM\n",
            "Constrained\n",
            "Inference\n",
            "Agnostic\n",
            "Learning\n",
            "with\n",
            "Multiple\n",
            "Objectives\n",
            "3D\n",
            "Multi-bodies\n",
            ":\n",
            "Fitting\n",
            "Sets\n",
            "of\n",
            "Plausible\n",
            "3D\n",
            "Human\n",
            "Models\n",
            "to\n",
            "Ambiguous\n",
            "Image\n",
            "Data\n",
            "Auto-Panoptic\n",
            ":\n",
            "Cooperative\n",
            "Multi-Component\n",
            "Architecture\n",
            "Search\n",
            "for\n",
            "Panoptic\n",
            "Segmentation\n",
            "Differentiable\n",
            "Top-k\n",
            "with\n",
            "Optimal\n",
            "Transport\n",
            "Information-theoretic\n",
            "Task\n",
            "Selection\n",
            "for\n",
            "Meta-Reinforcement\n",
            "Learning\n",
            "A\n",
            "Limitation\n",
            "of\n",
            "the\n",
            "PAC-Bayes\n",
            "Framework\n",
            "On\n",
            "Completeness-aware\n",
            "Concept-Based\n",
            "Explanations\n",
            "in\n",
            "Deep\n",
            "Neural\n",
            "Networks\n",
            "Stochastic\n",
            "Recursive\n",
            "Gradient\n",
            "Descent\n",
            "Ascent\n",
            "for\n",
            "Stochastic\n",
            "Nonconvex-Strongly-Concave\n",
            "Minimax\n",
            "Problems\n",
            "Why\n",
            "Normalizing\n",
            "Flows\n",
            "Fail\n",
            "to\n",
            "Detect\n",
            "Out-of-Distribution\n",
            "Data\n",
            "Explaining\n",
            "Naive\n",
            "Bayes\n",
            "and\n",
            "Other\n",
            "Linear\n",
            "Classifiers\n",
            "with\n",
            "Polynomial\n",
            "Time\n",
            "and\n",
            "Delay\n",
            "Unsupervised\n",
            "Translation\n",
            "of\n",
            "Programming\n",
            "Languages\n",
            "Adversarial\n",
            "Style\n",
            "Mining\n",
            "for\n",
            "One-Shot\n",
            "Unsupervised\n",
            "Domain\n",
            "Adaptation\n",
            "Optimally\n",
            "Deceiving\n",
            "a\n",
            "Learning\n",
            "Leader\n",
            "in\n",
            "Stackelberg\n",
            "Games\n",
            "Online\n",
            "Optimization\n",
            "with\n",
            "Memory\n",
            "and\n",
            "Competitive\n",
            "Control\n",
            "IDEAL\n",
            ":\n",
            "Inexact\n",
            "DEcentralized\n",
            "Accelerated\n",
            "Augmented\n",
            "Lagrangian\n",
            "Method\n",
            "Evolving\n",
            "Graphical\n",
            "Planner\n",
            ":\n",
            "Contextual\n",
            "Global\n",
            "Planning\n",
            "for\n",
            "Vision-and-Language\n",
            "Navigation\n",
            "Learning\n",
            "from\n",
            "Failure\n",
            ":\n",
            "De-biasing\n",
            "Classifier\n",
            "from\n",
            "Biased\n",
            "Classifier\n",
            "Likelihood\n",
            "Regret\n",
            ":\n",
            "An\n",
            "Out-of-Distribution\n",
            "Detection\n",
            "Score\n",
            "For\n",
            "Variational\n",
            "Auto-encoder\n",
            "Deep\n",
            "Diffusion-Invariant\n",
            "Wasserstein\n",
            "Distributional\n",
            "Classification\n",
            "Finding\n",
            "All\n",
            "$\n",
            "\\epsilon\n",
            "$\n",
            "-Good\n",
            "Arms\n",
            "in\n",
            "Stochastic\n",
            "Bandits\n",
            "Meta-Learning\n",
            "through\n",
            "Hebbian\n",
            "Plasticity\n",
            "in\n",
            "Random\n",
            "Networks\n",
            "A\n",
            "Computational\n",
            "Separation\n",
            "between\n",
            "Private\n",
            "Learning\n",
            "and\n",
            "Online\n",
            "Learning\n",
            "Top-KAST\n",
            ":\n",
            "Top-K\n",
            "Always\n",
            "Sparse\n",
            "Training\n",
            "Meta-Learning\n",
            "with\n",
            "Adaptive\n",
            "Hyperparameters\n",
            "Tight\n",
            "last-iterate\n",
            "convergence\n",
            "rates\n",
            "for\n",
            "no-regret\n",
            "learning\n",
            "in\n",
            "multi-player\n",
            "games\n",
            "Curvature\n",
            "Regularization\n",
            "to\n",
            "Prevent\n",
            "Distortion\n",
            "in\n",
            "Graph\n",
            "Embedding\n",
            "Perturbing\n",
            "Across\n",
            "the\n",
            "Feature\n",
            "Hierarchy\n",
            "to\n",
            "Improve\n",
            "Standard\n",
            "and\n",
            "Strict\n",
            "Blackbox\n",
            "Attack\n",
            "Transferability\n",
            "Statistical\n",
            "and\n",
            "Topological\n",
            "Properties\n",
            "of\n",
            "Sliced\n",
            "Probability\n",
            "Divergences\n",
            "Probabilistic\n",
            "Active\n",
            "Meta-Learning\n",
            "Knowledge\n",
            "Distillation\n",
            "in\n",
            "Wide\n",
            "Neural\n",
            "Networks\n",
            ":\n",
            "Risk\n",
            "Bound\n",
            ",\n",
            "Data\n",
            "Efficiency\n",
            "and\n",
            "Imperfect\n",
            "Teacher\n",
            "Adversarial\n",
            "Attacks\n",
            "on\n",
            "Deep\n",
            "Graph\n",
            "Matching\n",
            "The\n",
            "Generalization-Stability\n",
            "Tradeoff\n",
            "In\n",
            "Neural\n",
            "Network\n",
            "Pruning\n",
            "Gradient-EM\n",
            "Bayesian\n",
            "Meta-Learning\n",
            "Logarithmic\n",
            "Regret\n",
            "Bound\n",
            "in\n",
            "Partially\n",
            "Observable\n",
            "Linear\n",
            "Dynamical\n",
            "Systems\n",
            "Linearly\n",
            "Converging\n",
            "Error\n",
            "Compensated\n",
            "SGD\n",
            "Canonical\n",
            "3D\n",
            "Deformer\n",
            "Maps\n",
            ":\n",
            "Unifying\n",
            "parametric\n",
            "and\n",
            "non-parametric\n",
            "methods\n",
            "for\n",
            "dense\n",
            "weakly-supervised\n",
            "category\n",
            "reconstruction\n",
            "A\n",
            "Self-Tuning\n",
            "Actor-Critic\n",
            "Algorithm\n",
            "The\n",
            "Cone\n",
            "of\n",
            "Silence\n",
            ":\n",
            "Speech\n",
            "Separation\n",
            "by\n",
            "Localization\n",
            "High-Dimensional\n",
            "Bayesian\n",
            "Optimization\n",
            "via\n",
            "Nested\n",
            "Riemannian\n",
            "Manifolds\n",
            "Train-by-Reconnect\n",
            ":\n",
            "Decoupling\n",
            "Locations\n",
            "of\n",
            "Weights\n",
            "from\n",
            "Their\n",
            "Values\n",
            "Learning\n",
            "discrete\n",
            "distributions\n",
            ":\n",
            "user\n",
            "vs\n",
            "item-level\n",
            "privacy\n",
            "Matrix\n",
            "Completion\n",
            "with\n",
            "Quantified\n",
            "Uncertainty\n",
            "through\n",
            "Low\n",
            "Rank\n",
            "Gaussian\n",
            "Copula\n",
            "Sparse\n",
            "and\n",
            "Continuous\n",
            "Attention\n",
            "Mechanisms\n",
            "Generalized\n",
            "Focal\n",
            "Loss\n",
            ":\n",
            "Learning\n",
            "Qualified\n",
            "and\n",
            "Distributed\n",
            "Bounding\n",
            "Boxes\n",
            "for\n",
            "Dense\n",
            "Object\n",
            "Detection\n",
            "Learning\n",
            "by\n",
            "Minimizing\n",
            "the\n",
            "Sum\n",
            "of\n",
            "Ranked\n",
            "Range\n",
            "Robust\n",
            "Deep\n",
            "Reinforcement\n",
            "Learning\n",
            "against\n",
            "Adversarial\n",
            "Perturbations\n",
            "on\n",
            "State\n",
            "Observations\n",
            "Understanding\n",
            "Anomaly\n",
            "Detection\n",
            "with\n",
            "Deep\n",
            "Invertible\n",
            "Networks\n",
            "through\n",
            "Hierarchies\n",
            "of\n",
            "Distributions\n",
            "and\n",
            "Features\n",
            "Fair\n",
            "Hierarchical\n",
            "Clustering\n",
            "Self-training\n",
            "Avoids\n",
            "Using\n",
            "Spurious\n",
            "Features\n",
            "Under\n",
            "Domain\n",
            "Shift\n",
            "Improving\n",
            "Online\n",
            "Rent-or-Buy\n",
            "Algorithms\n",
            "with\n",
            "Sequential\n",
            "Decision\n",
            "Making\n",
            "and\n",
            "ML\n",
            "Predictions\n",
            "CircleGAN\n",
            ":\n",
            "Generative\n",
            "Adversarial\n",
            "Learning\n",
            "across\n",
            "Spherical\n",
            "Circles\n",
            "WOR\n",
            "and\n",
            "$\n",
            "p\n",
            "$\n",
            "'s\n",
            ":\n",
            "Sketches\n",
            "for\n",
            "$\n",
            "\\ell_p\n",
            "$\n",
            "-Sampling\n",
            "Without\n",
            "Replacement\n",
            "Hypersolvers\n",
            ":\n",
            "Toward\n",
            "Fast\n",
            "Continuous-Depth\n",
            "Models\n",
            "Log-Likelihood\n",
            "Ratio\n",
            "Minimizing\n",
            "Flows\n",
            ":\n",
            "Towards\n",
            "Robust\n",
            "and\n",
            "Quantifiable\n",
            "Neural\n",
            "Distribution\n",
            "Alignment\n",
            "Escaping\n",
            "the\n",
            "Gravitational\n",
            "Pull\n",
            "of\n",
            "Softmax\n",
            "Regret\n",
            "in\n",
            "Online\n",
            "Recommendation\n",
            "Systems\n",
            "On\n",
            "Convergence\n",
            "and\n",
            "Generalization\n",
            "of\n",
            "Dropout\n",
            "Training\n",
            "Second\n",
            "Order\n",
            "Optimality\n",
            "in\n",
            "Decentralized\n",
            "Non-Convex\n",
            "Optimization\n",
            "via\n",
            "Perturbed\n",
            "Gradient\n",
            "Tracking\n",
            "Implicit\n",
            "Regularization\n",
            "in\n",
            "Deep\n",
            "Learning\n",
            "May\n",
            "Not\n",
            "Be\n",
            "Explainable\n",
            "by\n",
            "Norms\n",
            "POMO\n",
            ":\n",
            "Policy\n",
            "Optimization\n",
            "with\n",
            "Multiple\n",
            "Optima\n",
            "for\n",
            "Reinforcement\n",
            "Learning\n",
            "Uncertainty-aware\n",
            "Self-training\n",
            "for\n",
            "Few-shot\n",
            "Text\n",
            "Classification\n",
            "Learning\n",
            "to\n",
            "Learn\n",
            "with\n",
            "Feedback\n",
            "and\n",
            "Local\n",
            "Plasticity\n",
            "Every\n",
            "View\n",
            "Counts\n",
            ":\n",
            "Cross-View\n",
            "Consistency\n",
            "in\n",
            "3D\n",
            "Object\n",
            "Detection\n",
            "with\n",
            "Hybrid-Cylindrical-Spherical\n",
            "Voxelization\n",
            "Sharper\n",
            "Generalization\n",
            "Bounds\n",
            "for\n",
            "Pairwise\n",
            "Learning\n",
            "A\n",
            "Measure-Theoretic\n",
            "Approach\n",
            "to\n",
            "Kernel\n",
            "Conditional\n",
            "Mean\n",
            "Embeddings\n",
            "Quantifying\n",
            "the\n",
            "Empirical\n",
            "Wasserstein\n",
            "Distance\n",
            "to\n",
            "a\n",
            "Set\n",
            "of\n",
            "Measures\n",
            ":\n",
            "Beating\n",
            "the\n",
            "Curse\n",
            "of\n",
            "Dimensionality\n",
            "Bootstrap\n",
            "Your\n",
            "Own\n",
            "Latent\n",
            "-\n",
            "A\n",
            "New\n",
            "Approach\n",
            "to\n",
            "Self-Supervised\n",
            "Learning\n",
            "Towards\n",
            "Theoretically\n",
            "Understanding\n",
            "Why\n",
            "Sgd\n",
            "Generalizes\n",
            "Better\n",
            "Than\n",
            "Adam\n",
            "in\n",
            "Deep\n",
            "Learning\n",
            "RSKDD-Net\n",
            ":\n",
            "Random\n",
            "Sample-based\n",
            "Keypoint\n",
            "Detector\n",
            "and\n",
            "Descriptor\n",
            "Efficient\n",
            "Clustering\n",
            "for\n",
            "Stretched\n",
            "Mixtures\n",
            ":\n",
            "Landscape\n",
            "and\n",
            "Optimality\n",
            "A\n",
            "Group-Theoretic\n",
            "Framework\n",
            "for\n",
            "Data\n",
            "Augmentation\n",
            "The\n",
            "Statistical\n",
            "Cost\n",
            "of\n",
            "Robust\n",
            "Kernel\n",
            "Hyperparameter\n",
            "Turning\n",
            "How\n",
            "does\n",
            "Weight\n",
            "Correlation\n",
            "Affect\n",
            "Generalisation\n",
            "Ability\n",
            "of\n",
            "Deep\n",
            "Neural\n",
            "Networks\n",
            "?\n",
            "ContraGAN\n",
            ":\n",
            "Contrastive\n",
            "Learning\n",
            "for\n",
            "Conditional\n",
            "Image\n",
            "Generation\n",
            "On\n",
            "the\n",
            "distance\n",
            "between\n",
            "two\n",
            "neural\n",
            "networks\n",
            "and\n",
            "the\n",
            "stability\n",
            "of\n",
            "learning\n",
            "A\n",
            "Topological\n",
            "Filter\n",
            "for\n",
            "Learning\n",
            "with\n",
            "Label\n",
            "Noise\n",
            "Personalized\n",
            "Federated\n",
            "Learning\n",
            "with\n",
            "Moreau\n",
            "Envelopes\n",
            "Avoiding\n",
            "Side\n",
            "Effects\n",
            "in\n",
            "Complex\n",
            "Environments\n",
            "No-regret\n",
            "Learning\n",
            "in\n",
            "Price\n",
            "Competitions\n",
            "under\n",
            "Consumer\n",
            "Reference\n",
            "Effects\n",
            "Geometric\n",
            "Dataset\n",
            "Distances\n",
            "via\n",
            "Optimal\n",
            "Transport\n",
            "Task-Agnostic\n",
            "Amortized\n",
            "Inference\n",
            "of\n",
            "Gaussian\n",
            "Process\n",
            "Hyperparameters\n",
            "A\n",
            "novel\n",
            "variational\n",
            "form\n",
            "of\n",
            "the\n",
            "Schatten-\n",
            "$\n",
            "p\n",
            "$\n",
            "quasi-norm\n",
            "Energy-based\n",
            "Out-of-distribution\n",
            "Detection\n",
            "On\n",
            "the\n",
            "Loss\n",
            "Landscape\n",
            "of\n",
            "Adversarial\n",
            "Training\n",
            ":\n",
            "Identifying\n",
            "Challenges\n",
            "and\n",
            "How\n",
            "to\n",
            "Overcome\n",
            "Them\n",
            "User-Dependent\n",
            "Neural\n",
            "Sequence\n",
            "Models\n",
            "for\n",
            "Continuous-Time\n",
            "Event\n",
            "Data\n",
            "Active\n",
            "Structure\n",
            "Learning\n",
            "of\n",
            "Causal\n",
            "DAGs\n",
            "via\n",
            "Directed\n",
            "Clique\n",
            "Trees\n",
            "Convergence\n",
            "and\n",
            "Stability\n",
            "of\n",
            "Graph\n",
            "Convolutional\n",
            "Networks\n",
            "on\n",
            "Large\n",
            "Random\n",
            "Graphs\n",
            "BoTorch\n",
            ":\n",
            "A\n",
            "Framework\n",
            "for\n",
            "Efficient\n",
            "Monte-Carlo\n",
            "Bayesian\n",
            "Optimization\n",
            "Reconsidering\n",
            "Generative\n",
            "Objectives\n",
            "For\n",
            "Counterfactual\n",
            "Reasoning\n",
            "Robust\n",
            "Federated\n",
            "Learning\n",
            ":\n",
            "The\n",
            "Case\n",
            "of\n",
            "Affine\n",
            "Distribution\n",
            "Shifts\n",
            "Quantile\n",
            "Propagation\n",
            "for\n",
            "Wasserstein-Approximate\n",
            "Gaussian\n",
            "Processes\n",
            "Generating\n",
            "Adjacency-Constrained\n",
            "Subgoals\n",
            "in\n",
            "Hierarchical\n",
            "Reinforcement\n",
            "Learning\n",
            "High-contrast\n",
            "“\n",
            "gaudy\n",
            "”\n",
            "images\n",
            "improve\n",
            "the\n",
            "training\n",
            "of\n",
            "deep\n",
            "neural\n",
            "network\n",
            "models\n",
            "of\n",
            "visual\n",
            "cortex\n",
            "Duality-Induced\n",
            "Regularizer\n",
            "for\n",
            "Tensor\n",
            "Factorization\n",
            "Based\n",
            "Knowledge\n",
            "Graph\n",
            "Completion\n",
            "Distributed\n",
            "Training\n",
            "with\n",
            "Heterogeneous\n",
            "Data\n",
            ":\n",
            "Bridging\n",
            "Median-\n",
            "and\n",
            "Mean-Based\n",
            "Algorithms\n",
            "H-Mem\n",
            ":\n",
            "Harnessing\n",
            "synaptic\n",
            "plasticity\n",
            "with\n",
            "Hebbian\n",
            "Memory\n",
            "Networks\n",
            "Neural\n",
            "Unsigned\n",
            "Distance\n",
            "Fields\n",
            "for\n",
            "Implicit\n",
            "Function\n",
            "Learning\n",
            "Curriculum\n",
            "By\n",
            "Smoothing\n",
            "Fast\n",
            "Transformers\n",
            "with\n",
            "Clustered\n",
            "Attention\n",
            "The\n",
            "Convex\n",
            "Relaxation\n",
            "Barrier\n",
            ",\n",
            "Revisited\n",
            ":\n",
            "Tightened\n",
            "Single-Neuron\n",
            "Relaxations\n",
            "for\n",
            "Neural\n",
            "Network\n",
            "Verification\n",
            "Strongly\n",
            "Incremental\n",
            "Constituency\n",
            "Parsing\n",
            "with\n",
            "Graph\n",
            "Neural\n",
            "Networks\n",
            "AOT\n",
            ":\n",
            "Appearance\n",
            "Optimal\n",
            "Transport\n",
            "Based\n",
            "Identity\n",
            "Swapping\n",
            "for\n",
            "Forgery\n",
            "Detection\n",
            "Uncertainty-Aware\n",
            "Learning\n",
            "for\n",
            "Zero-Shot\n",
            "Semantic\n",
            "Segmentation\n",
            "Delta-STN\n",
            ":\n",
            "Efficient\n",
            "Bilevel\n",
            "Optimization\n",
            "for\n",
            "Neural\n",
            "Networks\n",
            "using\n",
            "Structured\n",
            "Response\n",
            "Jacobians\n",
            "First-Order\n",
            "Methods\n",
            "for\n",
            "Large-Scale\n",
            "Market\n",
            "Equilibrium\n",
            "Computation\n",
            "Minimax\n",
            "Optimal\n",
            "Nonparametric\n",
            "Estimation\n",
            "of\n",
            "Heterogeneous\n",
            "Treatment\n",
            "Effects\n",
            "Residual\n",
            "Force\n",
            "Control\n",
            "for\n",
            "Agile\n",
            "Human\n",
            "Behavior\n",
            "Imitation\n",
            "and\n",
            "Extended\n",
            "Motion\n",
            "Synthesis\n",
            "A\n",
            "General\n",
            "Method\n",
            "for\n",
            "Robust\n",
            "Learning\n",
            "from\n",
            "Batches\n",
            "Not\n",
            "All\n",
            "Unlabeled\n",
            "Data\n",
            "are\n",
            "Equal\n",
            ":\n",
            "Learning\n",
            "to\n",
            "Weight\n",
            "Data\n",
            "in\n",
            "Semi-supervised\n",
            "Learning\n",
            "Hard\n",
            "Negative\n",
            "Mixing\n",
            "for\n",
            "Contrastive\n",
            "Learning\n",
            "MOReL\n",
            ":\n",
            "Model-Based\n",
            "Offline\n",
            "Reinforcement\n",
            "Learning\n",
            "Weisfeiler\n",
            "and\n",
            "Leman\n",
            "go\n",
            "sparse\n",
            ":\n",
            "Towards\n",
            "scalable\n",
            "higher-order\n",
            "graph\n",
            "embeddings\n",
            "Adversarial\n",
            "Crowdsourcing\n",
            "Through\n",
            "Robust\n",
            "Rank-One\n",
            "Matrix\n",
            "Completion\n",
            "Learning\n",
            "Semantic-aware\n",
            "Normalization\n",
            "for\n",
            "Generative\n",
            "Adversarial\n",
            "Networks\n",
            "Differentiable\n",
            "Causal\n",
            "Discovery\n",
            "from\n",
            "Interventional\n",
            "Data\n",
            "One-sample\n",
            "Guided\n",
            "Object\n",
            "Representation\n",
            "Disassembling\n",
            "Extrapolation\n",
            "Towards\n",
            "Imaginary\n",
            "0-Nearest\n",
            "Neighbour\n",
            "and\n",
            "Its\n",
            "Improved\n",
            "Convergence\n",
            "Rate\n",
            "Robust\n",
            "Persistence\n",
            "Diagrams\n",
            "using\n",
            "Reproducing\n",
            "Kernels\n",
            "Contextual\n",
            "Games\n",
            ":\n",
            "Multi-Agent\n",
            "Learning\n",
            "with\n",
            "Side\n",
            "Information\n",
            "Goal-directed\n",
            "Generation\n",
            "of\n",
            "Discrete\n",
            "Structures\n",
            "with\n",
            "Conditional\n",
            "Generative\n",
            "Models\n",
            "Beyond\n",
            "Lazy\n",
            "Training\n",
            "for\n",
            "Over-parameterized\n",
            "Tensor\n",
            "Decomposition\n",
            "Denoised\n",
            "Smoothing\n",
            ":\n",
            "A\n",
            "Provable\n",
            "Defense\n",
            "for\n",
            "Pretrained\n",
            "Classifiers\n",
            "Minibatch\n",
            "Stochastic\n",
            "Approximate\n",
            "Proximal\n",
            "Point\n",
            "Methods\n",
            "Attribute\n",
            "Prototype\n",
            "Network\n",
            "for\n",
            "Zero-Shot\n",
            "Learning\n",
            "CrossTransformers\n",
            ":\n",
            "spatially-aware\n",
            "few-shot\n",
            "transfer\n",
            "Learning\n",
            "Latent\n",
            "Space\n",
            "Energy-Based\n",
            "Prior\n",
            "Model\n",
            "SEVIR\n",
            ":\n",
            "A\n",
            "Storm\n",
            "Event\n",
            "Imagery\n",
            "Dataset\n",
            "for\n",
            "Deep\n",
            "Learning\n",
            "Applications\n",
            "in\n",
            "Radar\n",
            "and\n",
            "Satellite\n",
            "Meteorology\n",
            "Lightweight\n",
            "Generative\n",
            "Adversarial\n",
            "Networks\n",
            "for\n",
            "Text-Guided\n",
            "Image\n",
            "Manipulation\n",
            "High-Dimensional\n",
            "Contextual\n",
            "Policy\n",
            "Search\n",
            "with\n",
            "Unknown\n",
            "Context\n",
            "Rewards\n",
            "using\n",
            "Bayesian\n",
            "Optimization\n",
            "Model\n",
            "Fusion\n",
            "via\n",
            "Optimal\n",
            "Transport\n",
            "On\n",
            "the\n",
            "Stability\n",
            "and\n",
            "Convergence\n",
            "of\n",
            "Robust\n",
            "Adversarial\n",
            "Reinforcement\n",
            "Learning\n",
            ":\n",
            "A\n",
            "Case\n",
            "Study\n",
            "on\n",
            "Linear\n",
            "Quadratic\n",
            "Systems\n",
            "Learning\n",
            "Individually\n",
            "Inferred\n",
            "Communication\n",
            "for\n",
            "Multi-Agent\n",
            "Cooperation\n",
            "Set2Graph\n",
            ":\n",
            "Learning\n",
            "Graphs\n",
            "From\n",
            "Sets\n",
            "Graph\n",
            "Random\n",
            "Neural\n",
            "Networks\n",
            "for\n",
            "Semi-Supervised\n",
            "Learning\n",
            "on\n",
            "Graphs\n",
            "Gradient\n",
            "Boosted\n",
            "Normalizing\n",
            "Flows\n",
            "Open\n",
            "Graph\n",
            "Benchmark\n",
            ":\n",
            "Datasets\n",
            "for\n",
            "Machine\n",
            "Learning\n",
            "on\n",
            "Graphs\n",
            "Towards\n",
            "Understanding\n",
            "Hierarchical\n",
            "Learning\n",
            ":\n",
            "Benefits\n",
            "of\n",
            "Neural\n",
            "Representations\n",
            "Texture\n",
            "Interpolation\n",
            "for\n",
            "Probing\n",
            "Visual\n",
            "Perception\n",
            "Hierarchical\n",
            "Neural\n",
            "Architecture\n",
            "Search\n",
            "for\n",
            "Deep\n",
            "Stereo\n",
            "Matching\n",
            "MuSCLE\n",
            ":\n",
            "Multi\n",
            "Sweep\n",
            "Compression\n",
            "of\n",
            "LiDAR\n",
            "using\n",
            "Deep\n",
            "Entropy\n",
            "Models\n",
            "Implicit\n",
            "Bias\n",
            "in\n",
            "Deep\n",
            "Linear\n",
            "Classification\n",
            ":\n",
            "Initialization\n",
            "Scale\n",
            "vs\n",
            "Training\n",
            "Accuracy\n",
            "Focus\n",
            "of\n",
            "Attention\n",
            "Improves\n",
            "Information\n",
            "Transfer\n",
            "in\n",
            "Visual\n",
            "Features\n",
            "Auditing\n",
            "Differentially\n",
            "Private\n",
            "Machine\n",
            "Learning\n",
            ":\n",
            "How\n",
            "Private\n",
            "is\n",
            "Private\n",
            "SGD\n",
            "?\n",
            "A\n",
            "Dynamical\n",
            "Central\n",
            "Limit\n",
            "Theorem\n",
            "for\n",
            "Shallow\n",
            "Neural\n",
            "Networks\n",
            "Measuring\n",
            "Systematic\n",
            "Generalization\n",
            "in\n",
            "Neural\n",
            "Proof\n",
            "Generation\n",
            "with\n",
            "Transformers\n",
            "Big\n",
            "Self-Supervised\n",
            "Models\n",
            "are\n",
            "Strong\n",
            "Semi-Supervised\n",
            "Learners\n",
            "Learning\n",
            "from\n",
            "Label\n",
            "Proportions\n",
            ":\n",
            "A\n",
            "Mutual\n",
            "Contamination\n",
            "Framework\n",
            "Fast\n",
            "Matrix\n",
            "Square\n",
            "Roots\n",
            "with\n",
            "Applications\n",
            "to\n",
            "Gaussian\n",
            "Processes\n",
            "and\n",
            "Bayesian\n",
            "Optimization\n",
            "Self-Adaptively\n",
            "Learning\n",
            "to\n",
            "Demoiré\n",
            "from\n",
            "Focused\n",
            "and\n",
            "Defocused\n",
            "Image\n",
            "Pairs\n",
            "Confounding-Robust\n",
            "Policy\n",
            "Evaluation\n",
            "in\n",
            "Infinite-Horizon\n",
            "Reinforcement\n",
            "Learning\n",
            "Model\n",
            "Class\n",
            "Reliance\n",
            "for\n",
            "Random\n",
            "Forests\n",
            "Follow\n",
            "the\n",
            "Perturbed\n",
            "Leader\n",
            ":\n",
            "Optimism\n",
            "and\n",
            "Fast\n",
            "Parallel\n",
            "Algorithms\n",
            "for\n",
            "Smooth\n",
            "Minimax\n",
            "Games\n",
            "Agnostic\n",
            "$\n",
            "Q\n",
            "$\n",
            "-learning\n",
            "with\n",
            "Function\n",
            "Approximation\n",
            "in\n",
            "Deterministic\n",
            "Systems\n",
            ":\n",
            "Near-Optimal\n",
            "Bounds\n",
            "on\n",
            "Approximation\n",
            "Error\n",
            "and\n",
            "Sample\n",
            "Complexity\n",
            "Learning\n",
            "to\n",
            "Adapt\n",
            "to\n",
            "Evolving\n",
            "Domains\n",
            "Synthesizing\n",
            "Tasks\n",
            "for\n",
            "Block-based\n",
            "Programming\n",
            "Scalable\n",
            "Belief\n",
            "Propagation\n",
            "via\n",
            "Relaxed\n",
            "Scheduling\n",
            "Firefly\n",
            "Neural\n",
            "Architecture\n",
            "Descent\n",
            ":\n",
            "a\n",
            "General\n",
            "Approach\n",
            "for\n",
            "Growing\n",
            "Neural\n",
            "Networks\n",
            "Risk-Sensitive\n",
            "Reinforcement\n",
            "Learning\n",
            ":\n",
            "Near-Optimal\n",
            "Risk-Sample\n",
            "Tradeoff\n",
            "in\n",
            "Regret\n",
            "Learning\n",
            "to\n",
            "Decode\n",
            ":\n",
            "Reinforcement\n",
            "Learning\n",
            "for\n",
            "Decoding\n",
            "of\n",
            "Sparse\n",
            "Graph-Based\n",
            "Channel\n",
            "Codes\n",
            "Faster\n",
            "DBSCAN\n",
            "via\n",
            "subsampled\n",
            "similarity\n",
            "queries\n",
            "De-Anonymizing\n",
            "Text\n",
            "by\n",
            "Fingerprinting\n",
            "Language\n",
            "Generation\n",
            "Multiparameter\n",
            "Persistence\n",
            "Image\n",
            "for\n",
            "Topological\n",
            "Machine\n",
            "Learning\n",
            "PLANS\n",
            ":\n",
            "Neuro-Symbolic\n",
            "Program\n",
            "Learning\n",
            "from\n",
            "Videos\n",
            "Matrix\n",
            "Inference\n",
            "and\n",
            "Estimation\n",
            "in\n",
            "Multi-Layer\n",
            "Models\n",
            "MeshSDF\n",
            ":\n",
            "Differentiable\n",
            "Iso-Surface\n",
            "Extraction\n",
            "Variational\n",
            "Interaction\n",
            "Information\n",
            "Maximization\n",
            "for\n",
            "Cross-domain\n",
            "Disentanglement\n",
            "Provably\n",
            "Efficient\n",
            "Exploration\n",
            "for\n",
            "Reinforcement\n",
            "Learning\n",
            "Using\n",
            "Unsupervised\n",
            "Learning\n",
            "Faithful\n",
            "Embeddings\n",
            "for\n",
            "Knowledge\n",
            "Base\n",
            "Queries\n",
            "Wasserstein\n",
            "Distances\n",
            "for\n",
            "Stereo\n",
            "Disparity\n",
            "Estimation\n",
            "Multi-agent\n",
            "Trajectory\n",
            "Prediction\n",
            "with\n",
            "Fuzzy\n",
            "Query\n",
            "Attention\n",
            "Multilabel\n",
            "Classification\n",
            "by\n",
            "Hierarchical\n",
            "Partitioning\n",
            "and\n",
            "Data-dependent\n",
            "Grouping\n",
            "An\n",
            "Analysis\n",
            "of\n",
            "SVD\n",
            "for\n",
            "Deep\n",
            "Rotation\n",
            "Estimation\n",
            "Can\n",
            "the\n",
            "Brain\n",
            "Do\n",
            "Backpropagation\n",
            "?\n",
            "--\n",
            "-\n",
            "Exact\n",
            "Implementation\n",
            "of\n",
            "Backpropagation\n",
            "in\n",
            "Predictive\n",
            "Coding\n",
            "Networks\n",
            "Manifold\n",
            "GPLVMs\n",
            "for\n",
            "discovering\n",
            "non-Euclidean\n",
            "latent\n",
            "structure\n",
            "in\n",
            "neural\n",
            "data\n",
            "Distributed\n",
            "Distillation\n",
            "for\n",
            "On-Device\n",
            "Learning\n",
            "COOT\n",
            ":\n",
            "Cooperative\n",
            "Hierarchical\n",
            "Transformer\n",
            "for\n",
            "Video-Text\n",
            "Representation\n",
            "Learning\n",
            "Passport-aware\n",
            "Normalization\n",
            "for\n",
            "Deep\n",
            "Model\n",
            "Protection\n",
            "Sampling-Decomposable\n",
            "Generative\n",
            "Adversarial\n",
            "Recommender\n",
            "Limits\n",
            "to\n",
            "Depth\n",
            "Efficiencies\n",
            "of\n",
            "Self-Attention\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kgekq-SPhtrr",
        "outputId": "0fee075d-c556-412b-dc74-8e0b785720a3"
      },
      "source": [
        "corpusNGrams[0]\n",
        "print(len(corpusNGrams))\n",
        "print(len(filteredTexts))\n",
        "print(len(lstNGrams))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13255\n",
            "1898\n",
            "1898\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hus7LvysN50t",
        "outputId": "708a7cb4-ec9f-48d4-919d-2d0c61716b74"
      },
      "source": [
        "lstNGrams[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['graph-similarity-deep', 'similarity-deep-learning']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rrjSrZYjeY4",
        "outputId": "636bf740-2ac8-45cb-c934-fdea776d4bfb"
      },
      "source": [
        "len(lstNGrams)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1898"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsPJC5iVcKuT"
      },
      "source": [
        "### Transitive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gB1kJLdigSq3",
        "outputId": "00c8f986-aa6e-4629-e743-a4a131932496"
      },
      "source": [
        "!pip install sentence-transformers\n",
        "!pip install LexRank\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.0.0.tar.gz (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 3.7 MB/s \n",
            "\u001b[?25hCollecting transformers<5.0.0,>=4.6.0\n",
            "  Downloading transformers-4.9.1-py3-none-any.whl (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 38.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.41.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.9.0+cu102)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.10.0+cu102)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.23.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.6.2)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 46.9 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.0.14-py3-none-any.whl (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.0.13)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 38.5 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 44.3 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2019.8.19)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (4.6.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.0.0-py3-none-any.whl size=126709 sha256=648a8cfd1ef5c7cae288134cdb1f7bfd78b340eecaee3811cc17650e1335b0db\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/c1/0f/faafd427f705c4b012274ba60d9a91d75830306811e1355293\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: tokenizers, pyyaml, huggingface-hub, transformers, sentencepiece, sentence-transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.12 pyyaml-5.4.1 sentence-transformers-2.0.0 sentencepiece-0.1.96 tokenizers-0.10.3 transformers-4.9.1\n",
            "Collecting LexRank\n",
            "  Downloading lexrank-0.1.0-py3-none-any.whl (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 6.6 MB/s \n",
            "\u001b[?25hCollecting urlextract>=0.7\n",
            "  Downloading urlextract-1.3.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from LexRank) (0.18.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from LexRank) (1.19.5)\n",
            "Requirement already satisfied: regex>=2017.11.9 in /usr/local/lib/python3.7/dist-packages (from LexRank) (2019.8.19)\n",
            "Collecting path.py>=10.5\n",
            "  Downloading path.py-12.5.0-py3-none-any.whl (2.3 kB)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from LexRank) (1.4.1)\n",
            "Collecting path\n",
            "  Downloading path-16.2.0-py3-none-any.whl (21 kB)\n",
            "Collecting uritools\n",
            "  Downloading uritools-3.0.2-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from urlextract>=0.7->LexRank) (3.0.12)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from urlextract>=0.7->LexRank) (1.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from urlextract>=0.7->LexRank) (2.10)\n",
            "Installing collected packages: uritools, path, urlextract, path.py, LexRank\n",
            "Successfully installed LexRank-0.1.0 path-16.2.0 path.py-12.5.0 uritools-3.0.2 urlextract-1.3.0\n",
            "Collecting en_core_web_sm==2.3.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 28.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<2.4.0,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.3.1) (2.3.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (57.2.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.23.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.41.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.5)\n",
            "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.5.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.10)\n",
            "Building wheels for collected packages: en-core-web-sm\n",
            "  Building wheel for en-core-web-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-sm: filename=en_core_web_sm-2.3.1-py3-none-any.whl size=12047105 sha256=3c45ee7ecc2965b1b6cb3a31d6335d6629cb4a478bc40536e0c2811f68f65ed4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ozp4xdnx/wheels/b7/0d/f0/7ecae8427c515065d75410989e15e5785dd3975fe06e795cd9\n",
            "Successfully built en-core-web-sm\n",
            "Installing collected packages: en-core-web-sm\n",
            "  Attempting uninstall: en-core-web-sm\n",
            "    Found existing installation: en-core-web-sm 2.2.5\n",
            "    Uninstalling en-core-web-sm-2.2.5:\n",
            "      Successfully uninstalled en-core-web-sm-2.2.5\n",
            "Successfully installed en-core-web-sm-2.3.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dL--dEGZgFCd",
        "outputId": "eb369fde-2a75-408e-fe02-933eed311a26"
      },
      "source": [
        "\n",
        "from lexrank import STOPWORDS, LexRank\n",
        "from path import Path\n",
        "import json\n",
        "import os\n",
        "# For caculating approximate time to process notebook (IGNORE)\n",
        "import datetime\n",
        "datetime.datetime.now()\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import operator\n",
        "import pickle as pkl \n",
        "import matplotlib.pyplot as plt\n",
        "import nltk as nl\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "import statistics\n",
        "import random\n",
        "import warnings\n",
        "from string import punctuation\n",
        "from matplotlib import pyplot\n",
        "from pandas import Series, datetime\n",
        "from pandas.plotting import scatter_matrix, autocorrelation_plot\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV, TimeSeriesSplit\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, mean_squared_error\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from spacy import displacy \n",
        "import nltk\n",
        "import re\n",
        "import io\n",
        "import requests\n",
        "import time\n",
        "import gensim\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "import nltk.sentiment\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import numpy as np\n",
        "import spacy\n",
        "from spacy.lang.en import English\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('brown')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wq2BSMpgMN2Z",
        "outputId": "2a7f197e-93ae-43d5-f6ae-75ecc9219c32"
      },
      "source": [
        "len(lstNGrams)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1898"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wd31aFH5fx1R",
        "outputId": "8037f76b-e205-462c-bec7-846b82378c13"
      },
      "source": [
        "lstNGrams[5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['neural-methods-point',\n",
              " 'methods-point-wise',\n",
              " 'point-wise-dependency',\n",
              " 'wise-dependency-estimation']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1PeR8LaDNW5q",
        "outputId": "1be0f694-36ef-4c64-a21d-c53f142e2e40"
      },
      "source": [
        "str_ =lstNGrams[5][0].replace('-', ' ')\n",
        "str_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'neural methods point'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M43GuW21OibK"
      },
      "source": [
        "#### Making Topic from N-grams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKiVy0M2Nszx"
      },
      "source": [
        "topic_list = []\n",
        "\n",
        "for i in range(len(lstNGrams)):\n",
        "  temp_str = ''\n",
        "  j_len = len(lstNGrams[i])\n",
        "  for j in range(j_len):\n",
        "    temp_str = temp_str +' ' +lstNGrams[i][j].replace('-', ' ')\n",
        "  #print(temp_str)\n",
        "  topic_list.append(temp_str.strip())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82_vrYsFR5LF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f145beb-f55b-499d-8098-f34bcbb0dd66"
      },
      "source": [
        "topic_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['graph similarity deep similarity deep learning',\n",
              " 'unsupervised information theoretic information theoretic perceptual theoretic perceptual quality perceptual quality metric',\n",
              " 'self supervised multimodal supervised multimodal versatile multimodal versatile networks',\n",
              " 'benchmarking deep inverse deep inverse models inverse models time models time neural time neural adjoint neural adjoint method',\n",
              " 'off policy evaluation policy evaluation learning evaluation learning external learning external validity external validity covariate validity covariate shift',\n",
              " 'neural methods point methods point wise point wise dependency wise dependency estimation',\n",
              " 'fast flexible temporal flexible temporal point temporal point processes point processes triangular processes triangular maps',\n",
              " 'backpropagating linearly improves linearly improves transferability improves transferability adversarial transferability adversarial examples',\n",
              " 'pyglove symbolic programming symbolic programming automated programming automated machine automated machine learning',\n",
              " 'fourier sparse leverage sparse leverage scores leverage scores approximate scores approximate kernel approximate kernel learning',\n",
              " 'improved algorithms online algorithms online submodular online submodular maximization submodular maximization via maximization via first via first order first order regret order regret bounds',\n",
              " 'synbols probing learning probing learning algorithms learning algorithms synthetic algorithms synthetic datasets',\n",
              " 'adversarially robust streaming robust streaming algorithms streaming algorithms via algorithms via differential via differential privacy',\n",
              " 'trading personalization accuracy personalization accuracy data accuracy data debugging data debugging collaborative debugging collaborative filtering',\n",
              " 'cascaded text generation text generation markov generation markov transformers',\n",
              " 'improving local identifiability local identifiability probabilistic identifiability probabilistic box probabilistic box embeddings',\n",
              " 'permute and flip and flip new flip new mechanism new mechanism differentially mechanism differentially private differentially private selection',\n",
              " 'deep reconstruction strange reconstruction strange attractors strange attractors time attractors time series',\n",
              " 'reciprocal adversarial learning adversarial learning via learning via characteristic via characteristic functions',\n",
              " 'statistical guarantees distributed guarantees distributed nearest distributed nearest neighbor nearest neighbor classification',\n",
              " 'stein self repulsive self repulsive dynamics repulsive dynamics benefits dynamics benefits past benefits past samples',\n",
              " 'statistical complexity early complexity early stopped early stopped mirror stopped mirror descent',\n",
              " 'algorithmic recourse imperfect recourse imperfect causal imperfect causal knowledge causal knowledge probabilistic knowledge probabilistic approach',\n",
              " 'quantitative propagation chaos propagation chaos sgd chaos sgd wide sgd wide neural wide neural networks',\n",
              " 'causal view robustness view robustness neural robustness neural networks',\n",
              " 'minimax classification 0 classification 0 1 0 1 loss 1 loss performance loss performance guarantees',\n",
              " 'learn useful critic useful critic model critic model based model based action based action gradient action gradient estimator gradient estimator policy estimator policy optimization',\n",
              " 'coresets regressions panel regressions panel data',\n",
              " 'learning composable energy composable energy surrogates energy surrogates pde surrogates pde order pde order reduction',\n",
              " 'efficient contextual bandits contextual bandits continuous bandits continuous actions',\n",
              " 'achieving equalized odds equalized odds resampling odds resampling sensitive resampling sensitive attributes',\n",
              " 'multi robot collision robot collision avoidance collision avoidance uncertainty avoidance uncertainty probabilistic uncertainty probabilistic safety probabilistic safety barrier safety barrier certificates',\n",
              " 'hard shape constrained shape constrained kernel constrained kernel machines',\n",
              " 'closer look training look training strategy training strategy modern strategy modern meta modern meta learning',\n",
              " 'value out of out of distribution of distribution testing distribution testing example testing example goodhart example goodhart s goodhart s law',\n",
              " 'generalised bayesian filtering bayesian filtering via filtering via sequential via sequential monte sequential monte carlo',\n",
              " 'deterministic approximation submodular approximation submodular maximization submodular maximization matroid maximization matroid nearly matroid nearly linear nearly linear time',\n",
              " 'flows simultaneous manifold simultaneous manifold learning manifold learning density learning density estimation',\n",
              " 'simultaneous preference metric preference metric learning metric learning paired learning paired comparisons',\n",
              " 'efficient variational inference variational inference sparse inference sparse deep sparse deep learning deep learning theoretical learning theoretical guarantee',\n",
              " 'learning manifold implicitly manifold implicitly via implicitly via explicit via explicit heat explicit heat kernel heat kernel learning',\n",
              " 'deep relational topic relational topic modeling topic modeling via modeling via graph via graph poisson graph poisson gamma poisson gamma belief gamma belief network',\n",
              " 'one bit supervision bit supervision image supervision image classification',\n",
              " 'transferred transfer learning',\n",
              " 'submodular maximization barrier maximization barrier functions',\n",
              " 'neural networks recurrent networks recurrent generative recurrent generative feedback',\n",
              " 'learning extrapolate knowledge extrapolate knowledge transductive knowledge transductive few transductive few shot few shot out shot out of out of graph of graph link graph link prediction',\n",
              " 'exploiting weakly supervised weakly supervised visual supervised visual patterns visual patterns learn patterns learn partial learn partial annotations',\n",
              " 'improving inference neural inference neural image neural image compression',\n",
              " 'neuron merging compensating merging compensating pruned compensating pruned neurons',\n",
              " 'fixmatch simplifying semi simplifying semi supervised semi supervised learning supervised learning consistency learning consistency confidence',\n",
              " 'reinforcement learning combinatorial learning combinatorial actions combinatorial actions application actions application vehicle application vehicle routing',\n",
              " 'towards playing full playing full moba full moba games moba games deep games deep reinforcement deep reinforcement learning',\n",
              " 'rankmax adaptive projection adaptive projection alternative projection alternative softmax alternative softmax function',\n",
              " 'online agnostic boosting agnostic boosting via boosting via regret via regret minimization',\n",
              " 'causal intervention weakly intervention weakly supervised weakly supervised semantic supervised semantic segmentation',\n",
              " 'belief propagation neural propagation neural networks',\n",
              " 'over parameterized adversarial parameterized adversarial training adversarial training analysis training analysis overcoming analysis overcoming curse overcoming curse dimensionality',\n",
              " 'post training iterative training iterative hierarchical iterative hierarchical data hierarchical data augmentation data augmentation deep augmentation deep networks',\n",
              " 'debugging tests model tests model explanations',\n",
              " 'robust compressed sensing compressed sensing using sensing using generative using generative models',\n",
              " 'fairness without demographics without demographics adversarially demographics adversarially reweighted adversarially reweighted learning',\n",
              " 'stochastic latent actor latent actor critic actor critic deep critic deep reinforcement deep reinforcement learning reinforcement learning latent learning latent variable latent variable model',\n",
              " 'ridge rider finding rider finding diverse finding diverse solutions diverse solutions following solutions following eigenvectors following eigenvectors hessian',\n",
              " 'route chaos routing chaos routing games routing games price games price anarchy price anarchy optimistic',\n",
              " 'online algorithm unsupervised algorithm unsupervised sequential unsupervised sequential selection sequential selection contextual selection contextual information',\n",
              " 'adapting neural architectures neural architectures domains',\n",
              " 'went wrong instance wrong instance wise instance wise feature wise feature importance feature importance time importance time series time series black series black box black box models',\n",
              " 'towards better generalization better generalization adaptive generalization adaptive gradient adaptive gradient methods',\n",
              " 'learning guidance rewards guidance rewards trajectory rewards trajectory space trajectory space smoothing',\n",
              " 'variance reduction via reduction via accelerated via accelerated dual accelerated dual averaging dual averaging finite averaging finite sum finite sum optimization',\n",
              " 'tree tree low tree low dimensional low dimensional hyperbolic dimensional hyperbolic embedding',\n",
              " 'deep structural causal structural causal models causal models tractable models tractable counterfactual tractable counterfactual inference',\n",
              " 'convolutional generation textured generation textured 3d textured 3d meshes',\n",
              " 'statistical framework low framework low bitwidth low bitwidth training bitwidth training deep training deep neural deep neural networks',\n",
              " 'better set representations set representations relational representations relational reasoning',\n",
              " 'autosync learning synchronize learning synchronize data synchronize data parallel data parallel distributed parallel distributed deep distributed deep learning',\n",
              " 'combinatorial perspective transfer perspective transfer learning',\n",
              " 'hardness learning neural learning neural networks neural networks natural networks natural weights',\n",
              " 'higher order spectral order spectral clustering spectral clustering directed clustering directed graphs',\n",
              " 'primal dual mesh dual mesh convolutional mesh convolutional neural convolutional neural networks',\n",
              " 'advantage conditional meta conditional meta learning meta learning biased learning biased regularization biased regularization fine regularization fine tuning',\n",
              " 'watch motion blurring motion blurring vision blurring vision deep vision deep neural deep neural networks',\n",
              " 'sinkhorn barycenter via barycenter via functional via functional gradient functional gradient descent',\n",
              " 'coresets near convex near convex functions',\n",
              " 'bayesian deep ensembles deep ensembles via ensembles via neural via neural tangent neural tangent kernel',\n",
              " 'improved schemes episodic schemes episodic memory episodic memory based memory based lifelong based lifelong learning',\n",
              " 'adaptive sampling stochastic sampling stochastic risk stochastic risk averse risk averse learning',\n",
              " 'deep wiener deconvolution wiener deconvolution wiener deconvolution wiener meets wiener meets deep meets deep learning deep learning image learning image deblurring',\n",
              " 'discovering reinforcement learning reinforcement learning algorithms',\n",
              " 'taming discrete integration discrete integration via integration via boon via boon dimensionality',\n",
              " 'blind video temporal video temporal consistency temporal consistency via consistency via deep via deep video deep video prior',\n",
              " 'simplify robustify negative robustify negative sampling negative sampling implicit sampling implicit collaborative implicit collaborative filtering',\n",
              " 'model selection production selection production system production system via system via automated via automated online automated online experiments',\n",
              " 'almost sure convergence sure convergence stochastic convergence stochastic gradient stochastic gradient descent gradient descent non descent non convex non convex problems',\n",
              " 'automatic perturbation analysis perturbation analysis scalable analysis scalable certified scalable certified robustness certified robustness beyond',\n",
              " 'adaptation properties allow properties allow identification allow identification optimized identification optimized neural optimized neural codes',\n",
              " 'global convergence variance convergence variance reduction variance reduction class reduction class nonconvex class nonconvex nonconcave nonconvex nonconcave minimax nonconcave minimax problems',\n",
              " 'model based multi based multi agent multi agent rl agent rl zero rl zero sum zero sum markov sum markov games markov games near games near optimal near optimal sample optimal sample complexity',\n",
              " 'conservative q learning q learning offline learning offline reinforcement offline reinforcement learning',\n",
              " 'online influence maximization influence maximization linear maximization linear threshold linear threshold model',\n",
              " 'ensembling geophysical models geophysical models bayesian models bayesian neural bayesian neural networks',\n",
              " 'delving cyclic mechanism cyclic mechanism semi mechanism semi supervised semi supervised video supervised video object video object segmentation',\n",
              " 'asymmetric shapley values shapley values incorporating values incorporating causal incorporating causal knowledge causal knowledge model knowledge model agnostic model agnostic explainability',\n",
              " 'understanding deep architecture deep architecture reasoning architecture reasoning layer',\n",
              " 'planning markov decision markov decision processes decision processes gap processes gap dependent gap dependent sample dependent sample complexity',\n",
              " 'provably good batch good batch off batch off policy off policy reinforcement policy reinforcement learning reinforcement learning without learning without great without great exploration',\n",
              " 'detection regression certified regression certified object certified object detection object detection median detection median smoothing',\n",
              " 'contextual reserve price reserve price optimization price optimization auctions optimization auctions via auctions via mixed via mixed integer mixed integer programming',\n",
              " 'expandnets linear over linear over parameterization over parameterization train parameterization train compact train compact convolutional compact convolutional networks',\n",
              " 'flexor trainable fractional trainable fractional quantization',\n",
              " 'implications local correlation local correlation learning correlation learning deep learning deep functions',\n",
              " 'learning search efficiently search efficiently causally efficiently causally near causally near optimal near optimal treatments',\n",
              " 'game theoretic analysis theoretic analysis additive analysis additive adversarial additive adversarial attacks adversarial attacks defenses',\n",
              " 'posterior network uncertainty network uncertainty estimation uncertainty estimation without estimation without ood without ood samples ood samples via samples via density via density based density based pseudo based pseudo counts',\n",
              " 'recurrent quantum neural quantum neural networks',\n",
              " 'no regret learning regret learning mixed learning mixed nash mixed nash equilibria nash equilibria mix',\n",
              " 'unifying view optimism view optimism episodic optimism episodic reinforcement episodic reinforcement learning',\n",
              " 'continuous submodular maximization submodular maximization beyond maximization beyond dr beyond dr submodularity',\n",
              " 'asymptotically optimal primal optimal primal dual primal dual incremental dual incremental algorithm incremental algorithm contextual algorithm contextual linear contextual linear bandits',\n",
              " 'assessing satnet s satnet s ability s ability solve ability solve symbol solve symbol grounding symbol grounding problem',\n",
              " 'bayesian nonparametrics view nonparametrics view deep view deep representations',\n",
              " 'similarity laplace neural laplace neural tangent neural tangent kernels',\n",
              " 'causal view compositional view compositional zero compositional zero shot zero shot recognition',\n",
              " 'hippo recurrent memory recurrent memory optimal memory optimal polynomial optimal polynomial projections',\n",
              " 'auto learning attention',\n",
              " 'castle regularization via regularization via auxiliary via auxiliary causal auxiliary causal graph causal graph discovery',\n",
              " 'long tailed classification tailed classification keeping classification keeping good keeping good removing good removing bad removing bad momentum bad momentum causal momentum causal effect',\n",
              " '',\n",
              " 'deep archimedean copulas',\n",
              " 're examining linear examining linear embeddings linear embeddings high embeddings high dimensional high dimensional bayesian dimensional bayesian optimization',\n",
              " 'unmodnet learning unwrap learning unwrap modulo unwrap modulo image modulo image high image high dynamic high dynamic range dynamic range imaging',\n",
              " 'thunder fast coordinate fast coordinate selection coordinate selection solver selection solver sparse solver sparse learning',\n",
              " 'neural networks fail networks fail learn fail learn periodic learn periodic functions periodic functions fix',\n",
              " 'distribution matching crowd matching crowd counting',\n",
              " 'correspondence learning via learning via linearly via linearly invariant linearly invariant embedding',\n",
              " 'learning dispatch job dispatch job shop job shop scheduling shop scheduling via scheduling via deep via deep reinforcement deep reinforcement learning',\n",
              " 'adaptive attacks adversarial attacks adversarial example adversarial example defenses',\n",
              " 'sinkhorn natural gradient natural gradient generative gradient generative models',\n",
              " 'online sinkhorn optimal sinkhorn optimal transport optimal transport distances transport distances sample distances sample streams',\n",
              " 'ultrahyperbolic representation learning',\n",
              " 'locally adaptive nonparametric adaptive nonparametric online nonparametric online learning',\n",
              " 'compositional generalization via generalization via neural via neural symbolic neural symbolic stack symbolic stack machines',\n",
              " 'graphon neural networks neural networks transferability networks transferability graph transferability graph neural graph neural networks',\n",
              " 'unreasonable effectiveness greedy effectiveness greedy algorithms greedy algorithms multi algorithms multi armed multi armed bandit armed bandit many bandit many arms',\n",
              " 'gamma models generative models generative temporal generative temporal difference temporal difference learning difference learning infinite learning infinite horizon infinite horizon prediction',\n",
              " 'deep transformers latent transformers latent depth',\n",
              " 'neural mesh flow mesh flow 3d flow 3d manifold 3d manifold mesh manifold mesh generation mesh generation via generation via diffeomorphic via diffeomorphic flows',\n",
              " 'statistical control spatio control spatio temporal spatio temporal meg temporal meg eeg meg eeg source eeg source imaging source imaging desparsified imaging desparsified mutli desparsified mutli task mutli task lasso',\n",
              " 'scalable mip based mip based method based method learning method learning optimal learning optimal multivariate optimal multivariate decision multivariate decision trees',\n",
              " 'efficient exact verification exact verification binarized verification binarized neural binarized neural networks',\n",
              " 'ultra low precision low precision 4 precision 4 bit 4 bit training bit training deep training deep neural deep neural networks',\n",
              " 'bridging gap sample gap sample based sample based one based one shot one shot neural shot neural architecture neural architecture search architecture search bonas',\n",
              " 'numerosity deep neural deep neural networks',\n",
              " 'outlier robust mean robust mean estimation mean estimation subgaussian estimation subgaussian rates subgaussian rates via rates via stability',\n",
              " 'self supervised relationship supervised relationship probing',\n",
              " 'information theoretic counterfactual theoretic counterfactual learning counterfactual learning missing learning missing not missing not at not at random at random feedback',\n",
              " 'prophet attention predicting attention predicting attention predicting attention future attention future attention',\n",
              " 'language models few models few shot few shot learners',\n",
              " 'margins insufficient explaining insufficient explaining gradient explaining gradient boosting',\n",
              " 'fourier transform based transform based attribution based attribution priors attribution priors improve priors improve interpretability improve interpretability stability interpretability stability deep stability deep learning deep learning models learning models genomics',\n",
              " 'momentumrnn integrating momentum integrating momentum recurrent momentum recurrent neural recurrent neural networks',\n",
              " 'marginal utility planning utility planning continuous planning continuous large continuous large discrete large discrete action discrete action spaces',\n",
              " 'projected stein variational stein variational gradient variational gradient descent',\n",
              " 'minimax lower bounds lower bounds transfer bounds transfer learning transfer learning linear learning linear one linear one hidden one hidden layer hidden layer neural layer neural networks',\n",
              " 'se 3 transformers 3 transformers 3d transformers 3d roto 3d roto translation roto translation equivariant translation equivariant attention equivariant attention networks',\n",
              " 'equivalence molecular graph molecular graph convolution graph convolution molecular convolution molecular wave molecular wave function wave function poor function poor basis poor basis set',\n",
              " 'power predictions online predictions online control',\n",
              " 'learning affordance landscapes affordance landscapes interaction landscapes interaction exploration interaction exploration 3d exploration 3d environments',\n",
              " 'cooperative multi player multi player bandit player bandit optimization',\n",
              " 'tight first second first second order second order regret order regret bounds regret bounds adversarial bounds adversarial linear adversarial linear bandits',\n",
              " 'pick sign optimizing sign optimizing deep optimizing deep multitask deep multitask models multitask models gradient models gradient sign gradient sign dropout',\n",
              " 'loss function generative function generative neural generative neural networks neural networks based networks based watson based watson perceptual watson perceptual model',\n",
              " 'dynamic fusion eye fusion eye movement eye movement data movement data verbal data verbal narrations verbal narrations knowledge narrations knowledge rich knowledge rich domains',\n",
              " 'scalable multi agent multi agent reinforcement agent reinforcement learning reinforcement learning networked learning networked systems networked systems average systems average reward',\n",
              " 'optimizing neural networks neural networks via networks via koopman via koopman operator koopman operator theory',\n",
              " 'svgd kernelized wasserstein kernelized wasserstein gradient wasserstein gradient flow gradient flow chi flow chi squared chi squared divergence',\n",
              " 'adversarial robustness supervised robustness supervised sparse supervised sparse coding',\n",
              " 'differentiable meta learning meta learning bandit learning bandit policies',\n",
              " 'biologically inspired mechanisms inspired mechanisms adversarial mechanisms adversarial robustness',\n",
              " 'statistical query lower query lower bounds lower bounds via bounds via functional via functional gradients',\n",
              " 'near optimal reinforcement optimal reinforcement learning reinforcement learning self learning self play',\n",
              " 'network diffusions via diffusions via neural via neural mean neural mean field mean field dynamics',\n",
              " 'self distillation instance distillation instance specific instance specific label specific label smoothing',\n",
              " 'towards problem dependent problem dependent optimal dependent optimal learning optimal learning rates',\n",
              " 'cross lingual retrieval lingual retrieval iterative retrieval iterative self iterative self supervised self supervised training',\n",
              " 'rethinking pooling graph pooling graph neural graph neural networks',\n",
              " 'pointer graph networks',\n",
              " 'gradient regularized v regularized v learning v learning dynamic learning dynamic treatment dynamic treatment regimes',\n",
              " 'faster wasserstein distance wasserstein distance estimation distance estimation sinkhorn estimation sinkhorn divergence',\n",
              " 'forethought hindsight credit hindsight credit assignment',\n",
              " 'robust recursive partitioning recursive partitioning heterogeneous partitioning heterogeneous treatment heterogeneous treatment effects treatment effects uncertainty effects uncertainty quantification',\n",
              " 'rescuing neural spike neural spike train spike train models train models bad models bad mle',\n",
              " 'lower bounds optimal bounds optimal algorithms optimal algorithms personalized algorithms personalized federated personalized federated learning',\n",
              " 'black box certification box certification randomized certification randomized smoothing randomized smoothing functional smoothing functional optimization functional optimization based optimization based framework',\n",
              " 'deep imitation learning imitation learning bimanual learning bimanual robotic bimanual robotic manipulation',\n",
              " 'stationary activations uncertainty activations uncertainty calibration uncertainty calibration deep calibration deep learning',\n",
              " 'ensemble distillation robust distillation robust model robust model fusion model fusion federated fusion federated learning',\n",
              " 'falcon fast spectral fast spectral inference spectral inference encrypted inference encrypted data',\n",
              " 'power laws deep laws deep ensembles',\n",
              " 'practical quasi newton quasi newton methods newton methods training methods training deep training deep neural deep neural networks',\n",
              " 'approximation based variance based variance reduction variance reduction reparameterization reduction reparameterization gradients',\n",
              " 'inference stage optimization stage optimization cross optimization cross scenario cross scenario 3d scenario 3d human 3d human pose human pose estimation',\n",
              " 'consistent feature selection feature selection analytic selection analytic deep analytic deep neural deep neural networks',\n",
              " 'glance focus dynamic focus dynamic approach dynamic approach reducing approach reducing spatial reducing spatial redundancy spatial redundancy image redundancy image classification',\n",
              " 'information maximization few maximization few shot few shot learning',\n",
              " 'inverse reinforcement learning reinforcement learning gradient learning gradient based gradient based learner',\n",
              " 'bayesian multi type multi type mean type mean field mean field multi field multi agent multi agent imitation agent imitation learning',\n",
              " 'bayesian robust optimization robust optimization imitation optimization imitation learning',\n",
              " 'multiview neural surface neural surface reconstruction surface reconstruction disentangling reconstruction disentangling geometry disentangling geometry appearance',\n",
              " 'riemannian continuous normalizing continuous normalizing flows',\n",
              " 'attention gated brain gated brain propagation brain propagation brain propagation brain implement brain implement reward implement reward based reward based error based error backpropagation',\n",
              " 'asymptotic guarantees generative guarantees generative modeling generative modeling based modeling based smooth based smooth wasserstein smooth wasserstein distance',\n",
              " 'online robust regression robust regression via regression via sgd via sgd l1 sgd l1 loss',\n",
              " 'prank motion prediction motion prediction based prediction based ranking',\n",
              " 'fighting copycat agents copycat agents behavioral agents behavioral cloning behavioral cloning observation cloning observation histories',\n",
              " 'tight nonparametric convergence nonparametric convergence rates convergence rates stochastic rates stochastic gradient stochastic gradient descent gradient descent noiseless descent noiseless linear noiseless linear model',\n",
              " 'structured prediction conditional prediction conditional meta conditional meta learning',\n",
              " 'optimal lottery tickets lottery tickets via tickets via subset via subset sum subset sum logarithmic sum logarithmic over logarithmic over parameterization over parameterization sufficient',\n",
              " 'hateful memes challenge memes challenge detecting challenge detecting hate detecting hate speech hate speech multimodal speech multimodal memes',\n",
              " 'stochasticity deterministic gradient deterministic gradient descent gradient descent large descent large learning large learning rate learning rate multiscale rate multiscale objective multiscale objective function',\n",
              " 'identifying learning rules learning rules neural rules neural network neural network observables',\n",
              " 'optimal approximation smoothness approximation smoothness tradeoffs smoothness tradeoffs soft tradeoffs soft max soft max functions',\n",
              " 'weakly supervised reinforcement supervised reinforcement learning reinforcement learning controllable learning controllable behavior',\n",
              " 'improving policy constrained policy constrained kidney constrained kidney exchange kidney exchange via exchange via pre via pre screening',\n",
              " 'learning abstract structure abstract structure drawing structure drawing efficient drawing efficient motor efficient motor program motor program induction',\n",
              " 'deep residual networks residual networks generalize networks generalize better generalize better deep better deep feedforward deep feedforward networks feedforward networks neural networks neural tangent neural tangent kernel tangent kernel perspective',\n",
              " 'dual instrumental variable instrumental variable regression',\n",
              " 'stochastic gradient descent gradient descent correlated descent correlated settings correlated settings study settings study gaussian study gaussian processes',\n",
              " 'interventional few shot few shot learning',\n",
              " 'minimax value interval value interval off interval off policy off policy evaluation policy evaluation policy evaluation policy optimization',\n",
              " 'biased stochastic first stochastic first order first order methods order methods conditional methods conditional stochastic conditional stochastic optimization stochastic optimization applications optimization applications meta applications meta learning',\n",
              " 'shiftaddnet hardware inspired hardware inspired deep inspired deep network',\n",
              " 'network to network to network translation network translation conditional translation conditional invertible conditional invertible neural invertible neural networks',\n",
              " 'intra processing methods processing methods debiasing methods debiasing neural debiasing neural networks',\n",
              " 'finding second order second order stationary order stationary points stationary points efficiently points efficiently smooth efficiently smooth nonconvex smooth nonconvex linearly nonconvex linearly constrained linearly constrained optimization constrained optimization problems',\n",
              " 'model based policy based policy optimization policy optimization unsupervised optimization unsupervised model unsupervised model adaptation',\n",
              " 'implicit regularization convergence regularization convergence weight convergence weight normalization',\n",
              " 'geometric all way all way boolean way boolean tensor boolean tensor decomposition',\n",
              " 'modular meta learning meta learning shrinkage',\n",
              " 'a b testing b testing dense testing dense large dense large scale large scale networks scale networks design networks design inference',\n",
              " 'neural networks memorize networks memorize discovering memorize discovering long discovering long tail long tail via tail via influence via influence estimation',\n",
              " 'partially view aligned view aligned clustering',\n",
              " 'partial optimal tranport optimal tranport applications tranport applications positive applications positive unlabeled positive unlabeled learning',\n",
              " 'toward fundamental limits fundamental limits imitation limits imitation learning',\n",
              " 'logarithmic pruning need',\n",
              " 'hold tight influence tight influence discriminative influence discriminative features discriminative features deep features deep network deep network boundaries',\n",
              " 'learning mixtures private mixtures private public private public populations',\n",
              " 'adversarial weight perturbation weight perturbation helps perturbation helps robust helps robust generalization',\n",
              " 'stateful posted pricing posted pricing vanishing pricing vanishing regret vanishing regret via regret via dynamic via dynamic deterministic dynamic deterministic markov deterministic markov decision markov decision processes',\n",
              " 'adversarial self supervised self supervised contrastive supervised contrastive learning',\n",
              " 'normalizing kalman filters kalman filters multivariate filters multivariate time multivariate time series time series analysis',\n",
              " 'learning summarize human summarize human feedback',\n",
              " 'fourier spectrum discrepancies spectrum discrepancies deep discrepancies deep network deep network generated network generated images',\n",
              " 'lamina specific neuronal specific neuronal properties neuronal properties promote properties promote robust promote robust stable robust stable signal stable signal propagation signal propagation feedforward propagation feedforward networks',\n",
              " 'learning dynamic belief dynamic belief graphs belief graphs generalize graphs generalize text generalize text based text based games',\n",
              " 'triple descent two descent two kinds two kinds overfitting kinds overfitting appear',\n",
              " 'multimodal graph networks graph networks compositional networks compositional generalization compositional generalization visual generalization visual question visual question answering',\n",
              " 'learning graph structure graph structure finite structure finite state finite state automaton state automaton layer',\n",
              " 'universal approximation theorem approximation theorem deep theorem deep neural deep neural networks neural networks expressing networks expressing probability expressing probability distributions',\n",
              " 'unsupervised object centric object centric video centric video generation video generation decomposition generation decomposition 3d',\n",
              " 'domain generalization medical generalization medical imaging medical imaging classification imaging classification linear classification linear dependency linear dependency regularization',\n",
              " 'multi label classification label classification hamming classification hamming loss hamming loss subset loss subset accuracy subset accuracy really accuracy really conflict',\n",
              " 'novel automated curriculum automated curriculum strategy curriculum strategy solve strategy solve hard solve hard sokoban hard sokoban planning sokoban planning instances',\n",
              " 'causal analysis covid analysis covid 19 covid 19 spread 19 spread germany',\n",
              " 'locally private non private non asymptotic non asymptotic testing asymptotic testing discrete testing discrete distributions discrete distributions faster distributions faster using faster using interactive using interactive mechanisms',\n",
              " 'adaptive gradient quantization gradient quantization data quantization data parallel data parallel sgd',\n",
              " 'finite continuum armed continuum armed bandits',\n",
              " 'removing bias multi bias multi modal multi modal classifiers modal classifiers regularization classifiers regularization maximizing regularization maximizing functional maximizing functional entropies',\n",
              " 'compact task representations task representations normative representations normative model normative model higher model higher order higher order brain order brain activity',\n",
              " 'robust adaptive control adaptive control linear control linear systems linear systems beyond systems beyond quadratic beyond quadratic costs',\n",
              " 'co exposure maximization exposure maximization online maximization online social online social networks',\n",
              " 'uclid net single net single view single view reconstruction view reconstruction object reconstruction object space',\n",
              " 'reinforcement learning control learning control multiple control multiple frequencies',\n",
              " 'complex dynamics simple dynamics simple neural simple neural networks neural networks understanding networks understanding gradient understanding gradient flow gradient flow phase flow phase retrieval',\n",
              " 'neural message passing message passing multi passing multi relational multi relational ordered relational ordered recursive ordered recursive hypergraphs',\n",
              " 'unified view label view label shift label shift estimation',\n",
              " 'optimal private median private median estimation median estimation minimal estimation minimal distributional minimal distributional assumptions',\n",
              " 'breaking communication privacy communication privacy accuracy privacy accuracy trilemma',\n",
              " 'audeo audio generation audio generation silent generation silent performance silent performance video',\n",
              " '',\n",
              " 'self distillation amplifies distillation amplifies regularization amplifies regularization hilbert regularization hilbert space',\n",
              " 'coupling based invertible based invertible neural invertible neural networks neural networks universal networks universal diffeomorphism universal diffeomorphism approximators',\n",
              " 'community detection using detection using fast using fast low fast low cardinality low cardinality semidefinite cardinality semidefinite programming',\n",
              " 'modeling noisy annotations noisy annotations crowd annotations crowd counting',\n",
              " 'operator view policy view policy gradient policy gradient methods',\n",
              " 'demystifying contrastive self contrastive self supervised self supervised learning supervised learning invariances learning invariances augmentations invariances augmentations dataset augmentations dataset biases',\n",
              " 'online map inference map inference determinantal inference determinantal point determinantal point processes',\n",
              " 'video object segmentation object segmentation adaptive segmentation adaptive feature adaptive feature bank feature bank uncertain bank uncertain region uncertain region refinement',\n",
              " 'inferring learning rules learning rules animal rules animal decision animal decision making',\n",
              " 'input aware dynamic aware dynamic backdoor dynamic backdoor attack',\n",
              " 'hard distinguish graphs distinguish graphs graph graphs graph neural graph neural networks',\n",
              " 'minimax regret switching regret switching constrained switching constrained online constrained online convex online convex optimization convex optimization phase optimization phase transition',\n",
              " 'dual manifold adversarial manifold adversarial robustness adversarial robustness defense robustness defense lp defense lp non lp non lp non lp adversarial lp adversarial attacks',\n",
              " 'cross scale internal scale internal graph internal graph neural graph neural network neural network image network image super image super resolution',\n",
              " 'unsupervised representation learning representation learning invariance learning invariance propagation',\n",
              " 'restoring negative information negative information few information few shot few shot object shot object detection',\n",
              " 'adversarially robust imagenet robust imagenet models imagenet models transfer models transfer better',\n",
              " 'robust correction sampling correction sampling bias sampling bias using bias using cumulative using cumulative distribution cumulative distribution functions',\n",
              " 'personalized federated learning federated learning theoretical learning theoretical guarantees theoretical guarantees model guarantees model agnostic model agnostic meta agnostic meta learning meta learning approach',\n",
              " 'pixel level cycle level cycle association cycle association new association new perspective new perspective domain perspective domain adaptive domain adaptive semantic adaptive semantic segmentation',\n",
              " 'classification valid adaptive valid adaptive coverage',\n",
              " 'learning global transparent global transparent models transparent models consistent models consistent local consistent local contrastive local contrastive explanations',\n",
              " 'learning approximate bregman approximate bregman divergence',\n",
              " 'diverse image captioning image captioning context captioning context object context object split object split latent split latent spaces',\n",
              " 'learning disentangled representations disentangled representations videos representations videos missing videos missing data',\n",
              " 'natural graph networks',\n",
              " 'continual learning node learning node importance node importance based importance based adaptive based adaptive group adaptive group sparse group sparse regularization',\n",
              " 'towards crowdsourced training crowdsourced training large training large neural large neural networks neural networks using networks using decentralized using decentralized mixture decentralized mixture of mixture of experts',\n",
              " 'bidirectional convolutional poisson convolutional poisson gamma poisson gamma dynamical gamma dynamical systems',\n",
              " 'deep reinforcement infomax reinforcement infomax learning',\n",
              " 'ranking via sorting via sorting estimated sorting estimated expected estimated expected utility',\n",
              " 'distribution free binary free binary classification binary classification prediction classification prediction sets prediction sets confidence sets confidence intervals confidence intervals calibration',\n",
              " 'closing dequantization gap dequantization gap pixelcnn gap pixelcnn single pixelcnn single layer single layer flow',\n",
              " 'sequence multi sequence multi sequence learning sequence learning via learning via conditional via conditional chain conditional chain mapping chain mapping mixture mapping mixture signals',\n",
              " 'variance reduction random reduction random coordinate random coordinate descent coordinate descent langevin descent langevin monte langevin monte carlo',\n",
              " 'language cognitive tool cognitive tool imagine tool imagine goals imagine goals curiosity goals curiosity driven curiosity driven exploration',\n",
              " 'word embeddings one embeddings one embedding',\n",
              " 'primal dual interpretation dual interpretation proximal interpretation proximal stochastic proximal stochastic gradient stochastic gradient langevin gradient langevin algorithm',\n",
              " 'characterize landscape overparameterized landscape overparameterized convolutional overparameterized convolutional neural convolutional neural networks',\n",
              " 'tightness semidefinite relaxations semidefinite relaxations certifying relaxations certifying robustness certifying robustness adversarial robustness adversarial examples',\n",
              " 'submodular meta learning',\n",
              " 'rethinking pre training pre training self training self training',\n",
              " 'unsupervised sound separation sound separation using separation using mixture using mixture invariant mixture invariant training',\n",
              " 'adaptive discretization model discretization model based model based reinforcement based reinforcement learning',\n",
              " 'codecmr cross modal cross modal retrieval modal retrieval function retrieval function level function level binary level binary source binary source code source code matching',\n",
              " 'warm starting neural starting neural network neural network training',\n",
              " 'dags fears closer fears closer look closer look continuous look continuous optimization continuous optimization learning optimization learning bayesian learning bayesian networks',\n",
              " 'ood maml meta maml meta learning meta learning few learning few shot few shot out shot out of out of distribution of distribution detection distribution detection classification',\n",
              " 'imitation observation approach observation approach transfer approach transfer learning transfer learning dynamics learning dynamics mismatch',\n",
              " 'learning objects learning objects learning interact',\n",
              " 'learning discrete distributions discrete distributions infinite distributions infinite support',\n",
              " 'dissecting neural odes',\n",
              " 'teaching gan learn',\n",
              " 'counterfactual data augmentation data augmentation using augmentation using locally using locally factored locally factored dynamics',\n",
              " 'rethinking learnable tree learnable tree filter tree filter generic filter generic feature generic feature transform',\n",
              " 'self supervised relational supervised relational reasoning relational reasoning representation reasoning representation learning',\n",
              " 'sufficient dimension reduction dimension reduction classification reduction classification using classification using principal using principal optimal principal optimal transport optimal transport direction',\n",
              " 'fast epigraphical projection epigraphical projection based projection based incremental based incremental algorithms incremental algorithms wasserstein algorithms wasserstein distributionally wasserstein distributionally robust distributionally robust support robust support vector support vector machine',\n",
              " 'differentially private clustering private clustering tight clustering tight approximation tight approximation ratios',\n",
              " 'power louvain stochastic louvain stochastic block stochastic block model',\n",
              " 'fairness overlapping groups overlapping groups probabilistic groups probabilistic perspective',\n",
              " 'attendlight universal attention universal attention based attention based reinforcement based reinforcement learning reinforcement learning model learning model traffic model traffic signal traffic signal control',\n",
              " 'searching low bit low bit weights bit weights quantized weights quantized neural quantized neural networks',\n",
              " 'adaptive reduced rank reduced rank regression',\n",
              " 'predictions decisions using decisions using lookahead using lookahead regularization',\n",
              " 'sequential bayesian experimental bayesian experimental design experimental design variable design variable cost variable cost structure',\n",
              " 'predictive inference free inference free jackknife free jackknife after jackknife after bootstrap',\n",
              " 'counterfactual predictions runtime predictions runtime confounding',\n",
              " 'learning loss test loss test time test time augmentation',\n",
              " 'balanced meta softmax meta softmax long softmax long tailed long tailed visual tailed visual recognition',\n",
              " 'efficient exploration reward exploration reward functions reward functions inverse functions inverse reinforcement inverse reinforcement learning reinforcement learning via learning via bayesian via bayesian optimization',\n",
              " 'mdp homomorphic networks homomorphic networks group networks group symmetries group symmetries reinforcement symmetries reinforcement learning',\n",
              " 'explain empirical study empirical study deep study deep neural deep neural network neural network explanation network explanation methods',\n",
              " 'error resistance hinge resistance hinge loss hinge loss minimization',\n",
              " 'munchausen reinforcement learning',\n",
              " 'object goal navigation goal navigation using navigation using goal using goal oriented goal oriented semantic oriented semantic exploration',\n",
              " 'efficient semidefinite programming semidefinite programming based programming based inference based inference binary inference binary multi binary multi class multi class mrfs',\n",
              " 'funnel transformer filtering transformer filtering sequential filtering sequential redundancy sequential redundancy efficient redundancy efficient language efficient language processing',\n",
              " 'semantic visual navigation visual navigation watching navigation watching youtube watching youtube videos',\n",
              " 'heavy tailed representations tailed representations text representations text polarity text polarity classification polarity classification data classification data augmentation',\n",
              " 'superloss generic loss generic loss robust loss robust curriculum robust curriculum learning',\n",
              " 'cogmol target specific target specific selective specific selective drug selective drug design drug design covid design covid 19 covid 19 using 19 using deep using deep generative deep generative models',\n",
              " 'memory based trajectory based trajectory conditioned trajectory conditioned policies conditioned policies learning policies learning sparse learning sparse rewards',\n",
              " 'liberty depth deep depth deep bayesian deep bayesian neural bayesian neural nets neural nets need nets need complex need complex weight complex weight posterior weight posterior approximations',\n",
              " 'improving sample complexity sample complexity bounds complexity bounds natural bounds natural actor natural actor critic actor critic algorithms',\n",
              " 'learning differential equations differential equations easy equations easy solve',\n",
              " 'stability stochastic gradient stochastic gradient descent gradient descent nonsmooth descent nonsmooth convex nonsmooth convex losses',\n",
              " 'influence augmented online augmented online planning online planning complex planning complex environments',\n",
              " 'pac bayes learning bayes learning bounds learning bounds sample bounds sample dependent sample dependent priors',\n",
              " 'reward rational implicit rational implicit choice implicit choice unifying choice unifying formalism unifying formalism reward formalism reward learning',\n",
              " 'probabilistic time series time series forecasting series forecasting shape forecasting shape temporal shape temporal diversity',\n",
              " 'low distortion block distortion block resampling block resampling spatially resampling spatially stochastic spatially stochastic networks',\n",
              " 'continual deep learning deep learning functional learning functional regularisation functional regularisation memorable regularisation memorable past',\n",
              " 'distance encoding design encoding design provably design provably powerful provably powerful neural powerful neural networks neural networks graph networks graph representation graph representation learning',\n",
              " 'fast fourier convolution',\n",
              " 'unsupervised learning dense learning dense visual dense visual representations',\n",
              " 'higher order certification order certification randomized certification randomized smoothing',\n",
              " 'learning structured distributions structured distributions untrusted distributions untrusted batches untrusted batches faster batches faster simpler',\n",
              " 'hierarchical quantized autoencoders',\n",
              " 'diversity transferred output transferred output diversification output diversification white diversification white black white black box black box attacks',\n",
              " 'poly hoot monte hoot monte carlo monte carlo planning carlo planning continuous planning continuous space continuous space mdps space mdps non mdps non asymptotic non asymptotic analysis',\n",
              " 'ave assistance via assistance via empowerment',\n",
              " 'variational policy gradient policy gradient method gradient method reinforcement method reinforcement learning reinforcement learning general learning general utilities',\n",
              " 'reverse engineering recurrent engineering recurrent neural recurrent neural network neural network solutions network solutions hierarchical solutions hierarchical inference hierarchical inference task inference task mice',\n",
              " 'temporal positive unlabeled positive unlabeled learning unlabeled learning biomedical learning biomedical hypothesis biomedical hypothesis generation hypothesis generation via generation via risk via risk estimation',\n",
              " 'efficient low rank low rank gaussian rank gaussian variational gaussian variational inference variational inference neural inference neural networks',\n",
              " 'privacy amplification via amplification via random via random check random check ins',\n",
              " 'probabilistic circuits variational circuits variational inference variational inference discrete inference discrete graphical discrete graphical models',\n",
              " 'classifier secretly suffice secretly suffice multi suffice multi source multi source domain source domain adaptation',\n",
              " 'labelling unlabelled videos unlabelled videos scratch videos scratch multi scratch multi modal multi modal self modal self supervision',\n",
              " 'non asymptotic analysis asymptotic analysis stein analysis stein variational stein variational gradient variational gradient descent',\n",
              " 'robust meta learning meta learning mixed learning mixed linear mixed linear regression linear regression small regression small batches',\n",
              " 'bayesian deep learning deep learning probabilistic learning probabilistic perspective probabilistic perspective generalization',\n",
              " 'unsupervised learning object learning object landmarks object landmarks via landmarks via self via self training self training correspondence',\n",
              " 'randomized tests high tests high dimensional high dimensional regression dimensional regression efficient regression efficient powerful efficient powerful solution',\n",
              " 'learning representations audio representations audio visual audio visual spatial visual spatial alignment',\n",
              " 'generative view synthesis view synthesis single synthesis single view single view semantics view semantics novel semantics novel view novel view images',\n",
              " 'towards practical adversarial practical adversarial attacks adversarial attacks graph attacks graph neural graph neural networks',\n",
              " 'multi task reinforcement task reinforcement learning reinforcement learning soft learning soft modularization',\n",
              " 'causal shapley values shapley values exploiting values exploiting causal exploiting causal knowledge causal knowledge explain knowledge explain individual explain individual predictions individual predictions complex predictions complex models',\n",
              " 'training dynamics deep dynamics deep networks deep networks l networks l 2 l 2 regularization',\n",
              " 'improved algorithms convex algorithms convex concave convex concave minimax concave minimax optimization',\n",
              " 'deep variational instance variational instance segmentation',\n",
              " 'learning implicit functions implicit functions topology functions topology varying topology varying dense varying dense 3d dense 3d shape 3d shape correspondence',\n",
              " 'deep multimodal fusion multimodal fusion channel fusion channel exchanging',\n",
              " 'hierarchically organized latent organized latent modules latent modules exploratory modules exploratory search exploratory search morphogenetic search morphogenetic systems',\n",
              " 'ai feynman 2 feynman 2 0 2 0 pareto 0 pareto optimal pareto optimal symbolic optimal symbolic regression symbolic regression exploiting regression exploiting graph exploiting graph modularity',\n",
              " 'delay cooperation nonstochastic cooperation nonstochastic linear nonstochastic linear bandits',\n",
              " 'probabilistic orientation estimation orientation estimation matrix estimation matrix fisher matrix fisher distributions',\n",
              " 'minimax dynamics optimally dynamics optimally balanced optimally balanced spiking balanced spiking networks spiking networks excitatory networks excitatory inhibitory excitatory inhibitory neurons',\n",
              " 'telescoping density ratio density ratio estimation',\n",
              " 'towards deeper graph deeper graph neural graph neural networks neural networks differentiable networks differentiable group differentiable group normalization',\n",
              " 'stochastic optimization performative optimization performative prediction',\n",
              " 'learning differentiable programs differentiable programs admissible programs admissible neural admissible neural heuristics',\n",
              " 'improved guarantees multiple guarantees multiple descent multiple descent curve descent curve column curve column subset column subset selection subset selection nystrom selection nystrom method',\n",
              " 'domain adaptation problem adaptation problem inference problem inference graphical inference graphical models',\n",
              " 'network size size size size weights size weights memorization weights memorization two memorization two layers two layers neural layers neural networks',\n",
              " 'certifying strategyproof auction strategyproof auction networks',\n",
              " 'continual learning control learning control primitives control primitives skill primitives skill discovery skill discovery via discovery via reset via reset games',\n",
              " 'hoi analysis integrating analysis integrating decomposing integrating decomposing human decomposing human object human object interaction',\n",
              " 'strongly local p local p norm p norm cut norm cut algorithms cut algorithms semi algorithms semi supervised semi supervised learning supervised learning local learning local graph local graph clustering',\n",
              " 'deep direct likelihood direct likelihood knockoffs',\n",
              " '',\n",
              " 'neural dynamic policies dynamic policies end policies end to end to end to end sensorimotor end sensorimotor learning',\n",
              " 'new inference approach inference approach training approach training shallow training shallow deep shallow deep generalized deep generalized linear generalized linear models linear models noisy models noisy interacting noisy interacting neurons',\n",
              " 'decision making auto making auto encoding auto encoding variational encoding variational bayes',\n",
              " 'attribution preservation network preservation network compression network compression reliable compression reliable network reliable network interpretation',\n",
              " 'feature importance ranking importance ranking deep ranking deep learning',\n",
              " 'causal estimation functional estimation functional confounders',\n",
              " 'model inversion networks inversion networks model networks model based model based optimization',\n",
              " 'hausdorff dimension heavy dimension heavy tails heavy tails generalization tails generalization neural generalization neural networks',\n",
              " 'exact expressions double expressions double descent double descent implicit descent implicit regularization implicit regularization via regularization via surrogate via surrogate random surrogate random design',\n",
              " 'certifying confidence via confidence via randomized via randomized smoothing',\n",
              " 'learning physical constraints physical constraints neural constraints neural projections',\n",
              " 'robust optimization fairness optimization fairness noisy fairness noisy protected noisy protected groups',\n",
              " 'noise contrastive estimation contrastive estimation multivariate estimation multivariate point multivariate point processes',\n",
              " 'game theoretic analysis theoretic analysis empirical analysis empirical revenue empirical revenue maximization revenue maximization algorithm maximization algorithm endogenous algorithm endogenous sampling',\n",
              " 'neural path features path features neural features neural path neural path kernel path kernel understanding kernel understanding role understanding role gates role gates deep gates deep learning',\n",
              " 'multiscale deep equilibrium deep equilibrium models',\n",
              " 'sparse graphical memory graphical memory robust memory robust planning',\n",
              " 'second order pac order pac bayesian pac bayesian bounds bayesian bounds weighted bounds weighted majority weighted majority vote',\n",
              " 'dirichlet graph variational graph variational autoencoder',\n",
              " 'modeling task effects task effects meaning effects meaning representation meaning representation brain representation brain via brain via zero via zero shot zero shot meg shot meg prediction',\n",
              " 'counterfactual vision and vision and language and language navigation language navigation unravelling navigation unravelling unseen',\n",
              " 'robust quantization one quantization one model one model rule',\n",
              " 'enabling certification verification certification verification agnostic verification agnostic networks agnostic networks via networks via memory via memory efficient memory efficient semidefinite efficient semidefinite programming',\n",
              " 'federated accelerated stochastic accelerated stochastic gradient stochastic gradient descent',\n",
              " 'robust density estimation density estimation besov estimation besov ipm besov ipm losses',\n",
              " 'analytic theory shallow theory shallow networks shallow networks dynamics networks dynamics hinge dynamics hinge loss hinge loss classification',\n",
              " 'fixed support wasserstein support wasserstein barycenters wasserstein barycenters computational barycenters computational hardness computational hardness fast hardness fast algorithm',\n",
              " 'learning orient surfaces orient surfaces self surfaces self supervised self supervised spherical supervised spherical cnns',\n",
              " 'adam bandit sampling bandit sampling deep sampling deep learning',\n",
              " 'parabolic approximation line approximation line search line search dnns',\n",
              " 'agnostic learning single learning single neuron single neuron gradient neuron gradient descent',\n",
              " 'statistical efficiency thompson efficiency thompson sampling thompson sampling combinatorial sampling combinatorial semi combinatorial semi bandits',\n",
              " 'analytic characterization hessian characterization hessian shallow hessian shallow relu shallow relu models relu models tale models tale symmetry',\n",
              " 'generative causal explanations causal explanations black explanations black box black box classifiers',\n",
              " 'sub sampling efficient sampling efficient non efficient non parametric non parametric bandit parametric bandit exploration',\n",
              " 'learning model misspecification model misspecification applications misspecification applications variational applications variational ensemble variational ensemble methods',\n",
              " 'language prism spectral prism spectral approach spectral approach multiscale approach multiscale language multiscale language representations',\n",
              " 'dverge diversifying vulnerabilities diversifying vulnerabilities enhanced vulnerabilities enhanced robust enhanced robust generation robust generation ensembles',\n",
              " 'towards practical differentially practical differentially private differentially private causal private causal graph causal graph discovery',\n",
              " 'independent policy gradient policy gradient methods gradient methods competitive methods competitive reinforcement competitive reinforcement learning',\n",
              " 'value equivalence principle equivalence principle model principle model based model based reinforcement based reinforcement learning',\n",
              " 'structured convolutions efficient convolutions efficient neural efficient neural network neural network design',\n",
              " 'latent world models world models intrinsically models intrinsically motivated intrinsically motivated exploration',\n",
              " 'estimating rank one rank one spikes one spikes heavy spikes heavy tailed heavy tailed noise tailed noise via noise via self via self avoiding self avoiding walks',\n",
              " 'policy improvement via improvement via imitation via imitation multiple imitation multiple oracles',\n",
              " 'training generative adversarial generative adversarial networks adversarial networks solving networks solving ordinary solving ordinary differential ordinary differential equations',\n",
              " 'learning discrete graphical discrete graphical models graphical models neural models neural networks',\n",
              " 'reppoints v2 verification v2 verification meets verification meets regression meets regression object regression object detection',\n",
              " 'unfolding alternating optimization alternating optimization blind optimization blind super blind super resolution',\n",
              " 'entrywise convergence iterative convergence iterative methods iterative methods eigenproblems',\n",
              " 'learning object centric object centric representations centric representations multi representations multi object multi object scenes object scenes multiple scenes multiple views',\n",
              " 'catalyst framework minimax framework minimax optimization',\n",
              " 'self supervised co supervised co training co training video training video representation video representation learning',\n",
              " 'gradient estimation stochastic estimation stochastic softmax stochastic softmax tricks',\n",
              " 'meta learning requires learning requires meta requires meta augmentation',\n",
              " 'slip learning predict learning predict unknown predict unknown dynamical unknown dynamical systems dynamical systems long systems long term long term memory',\n",
              " 'improving gan training gan training probability training probability ratio probability ratio clipping ratio clipping sample clipping sample reweighting',\n",
              " 'bayesian bits unifying bits unifying quantization unifying quantization pruning',\n",
              " '',\n",
              " 'gaussian process bandit process bandit optimization bandit optimization thermodynamic optimization thermodynamic variational thermodynamic variational objective',\n",
              " 'minilm deep self deep self attention self attention distillation attention distillation task distillation task agnostic task agnostic compression agnostic compression pre compression pre trained pre trained transformers',\n",
              " 'optimal epoch stochastic epoch stochastic gradient stochastic gradient descent gradient descent ascent descent ascent methods ascent methods min methods min max min max optimization',\n",
              " 'woodbury transformations deep transformations deep generative deep generative flows',\n",
              " 'graph contrastive learning contrastive learning augmentations',\n",
              " 'gradient surgery multi surgery multi task multi task learning',\n",
              " 'bayesian probabilistic numerical probabilistic numerical integration numerical integration tree integration tree based tree based models',\n",
              " 'deep learning versus learning versus kernel versus kernel learning kernel learning empirical learning empirical study empirical study loss study loss landscape loss landscape geometry landscape geometry time geometry time evolution time evolution neural evolution neural tangent neural tangent kernel',\n",
              " 'graph meta learning meta learning via learning via local via local subgraphs',\n",
              " 'stochastic deep gaussian deep gaussian processes gaussian processes graphs',\n",
              " 'bayesian causal structural causal structural learning structural learning zero learning zero inflated zero inflated poisson inflated poisson bayesian poisson bayesian networks',\n",
              " 'evaluating attribution graph attribution graph neural graph neural networks',\n",
              " 'second order behaviour order behaviour augmented behaviour augmented neural augmented neural odes',\n",
              " 'neuron shapley discovering shapley discovering responsible discovering responsible neurons',\n",
              " 'stochastic normalizing flows',\n",
              " 'gpu accelerated primal accelerated primal learning primal learning extremely learning extremely fast extremely fast large fast large scale large scale classification',\n",
              " 'random reshuffling always reshuffling always better',\n",
              " 'model agnostic multilevel agnostic multilevel explanations',\n",
              " 'neumiss networks differentiable networks differentiable programming differentiable programming supervised programming supervised learning supervised learning missing learning missing values',\n",
              " 'revisiting parameter sharing parameter sharing automatic sharing automatic neural automatic neural channel neural channel number channel number search',\n",
              " 'differentially private federated private federated linear federated linear bandits',\n",
              " 'plug in solver in solver sample solver sample efficient sample efficient feature efficient feature based feature based reinforcement based reinforcement learning',\n",
              " 'learning physical graph physical graph representations graph representations visual representations visual scenes',\n",
              " 'deep graph pose graph pose semi pose semi supervised semi supervised deep supervised deep graphical deep graphical model graphical model improved model improved animal improved animal pose animal pose tracking',\n",
              " 'meta learning tasks learning tasks heterogeneous tasks heterogeneous attribute heterogeneous attribute spaces',\n",
              " 'estimating decision tree decision tree learnability tree learnability polylogarithmic learnability polylogarithmic sample polylogarithmic sample complexity',\n",
              " 'sparse symplectically integrated symplectically integrated neural integrated neural networks',\n",
              " 'continuous object representation object representation networks representation networks novel networks novel view novel view synthesis view synthesis without synthesis without target without target view target view supervision',\n",
              " 'multimodal generative learning generative learning utilizing learning utilizing jensen utilizing jensen shannon jensen shannon divergence',\n",
              " 'solver in the in the loop the loop learning loop learning differentiable learning differentiable physics differentiable physics interact physics interact iterative interact iterative pde iterative pde solvers',\n",
              " 'reinforcement learning general learning general value general value function value function approximation function approximation provably approximation provably efficient provably efficient approach efficient approach via approach via bounded via bounded eluder bounded eluder dimension',\n",
              " 'predicting training time training time without time without training',\n",
              " 'interaction affect interpretable affect interpretable attribution interpretable attribution feature attribution feature interactions',\n",
              " 'optimal adaptive electrode adaptive electrode selection electrode selection maximize selection maximize simultaneously maximize simultaneously recorded simultaneously recorded neuron recorded neuron yield',\n",
              " 'neurosymbolic reinforcement learning reinforcement learning formally learning formally verified formally verified exploration',\n",
              " 'wavelet flow fast flow fast training fast training high training high resolution high resolution normalizing resolution normalizing flows',\n",
              " 'multi task batch task batch reinforcement batch reinforcement learning reinforcement learning metric learning metric learning',\n",
              " '1 n neural n neural representation neural representation robustness',\n",
              " 'boundary thickness robustness thickness robustness learning robustness learning models',\n",
              " 'demixed shared component shared component analysis component analysis neural analysis neural population neural population data population data multiple data multiple brain multiple brain areas',\n",
              " 'learning kernel tests kernel tests without tests without data without data splitting',\n",
              " 'unsupervised data augmentation data augmentation consistency augmentation consistency training',\n",
              " 'subgroup based rank based rank 1 rank 1 lattice 1 lattice quasi lattice quasi monte quasi monte carlo',\n",
              " 'minibatch vs local vs local sgd local sgd heterogeneous sgd heterogeneous distributed heterogeneous distributed learning',\n",
              " 'multi task causal task causal learning causal learning gaussian learning gaussian processes',\n",
              " 'proximity operator matrix operator matrix perspective matrix perspective function perspective function applications',\n",
              " 'generative 3d part 3d part assembly part assembly via assembly via dynamic via dynamic graph dynamic graph learning',\n",
              " 'improving natural language natural language processing language processing tasks processing tasks human tasks human gaze human gaze guided gaze guided neural guided neural attention',\n",
              " 'power comparisons actively comparisons actively learning actively learning linear learning linear classifiers',\n",
              " 'boltzmann machines neural machines neural networks neural networks back',\n",
              " 'crush optimism pessimism optimism pessimism structured pessimism structured bandits structured bandits beyond bandits beyond asymptotic beyond asymptotic optimality',\n",
              " 'pruning neural networks neural networks without networks without data without data iteratively data iteratively conserving iteratively conserving synaptic conserving synaptic flow',\n",
              " 'detecting interactions neural interactions neural networks neural networks via networks via topological via topological analysis',\n",
              " 'neural bridge sampling bridge sampling evaluating sampling evaluating safety evaluating safety critical safety critical autonomous critical autonomous systems',\n",
              " 'interpretable personalized apprenticeship personalized apprenticeship scheduling apprenticeship scheduling learning scheduling learning interpretable learning interpretable scheduling interpretable scheduling policies scheduling policies heterogeneous policies heterogeneous user heterogeneous user demonstrations',\n",
              " 'task agnostic online agnostic online reinforcement online reinforcement learning reinforcement learning infinite learning infinite mixture infinite mixture gaussian mixture gaussian processes',\n",
              " 'benchmarking deep learning deep learning interpretability learning interpretability time interpretability time series time series predictions',\n",
              " 'federated principal component principal component analysis',\n",
              " 'de randomized smoothing randomized smoothing certifiable smoothing certifiable defense certifiable defense patch defense patch attacks',\n",
              " 'smyrf efficient attention efficient attention using attention using asymmetric using asymmetric clustering',\n",
              " 'introducing routing uncertainty routing uncertainty capsule uncertainty capsule networks',\n",
              " 'simple efficient smoothing efficient smoothing method smoothing method faster method faster optimization faster optimization local optimization local exploration',\n",
              " 'hyperparameter ensembles robustness ensembles robustness uncertainty robustness uncertainty quantification',\n",
              " 'neutralizing self selection self selection bias selection bias sampling bias sampling sortition',\n",
              " 'convergence smooth regularized smooth regularized approximate regularized approximate value approximate value iteration value iteration schemes',\n",
              " 'off policy evaluation policy evaluation via evaluation via regularized via regularized lagrangian',\n",
              " 'loca regret consistent regret consistent metric consistent metric evaluate metric evaluate model evaluate model based model based behavior based behavior reinforcement behavior reinforcement learning',\n",
              " 'neural power units',\n",
              " 'towards scalable bayesian scalable bayesian learning bayesian learning causal learning causal dags',\n",
              " 'dictionary approach domain approach domain invariant domain invariant learning invariant learning deep learning deep networks',\n",
              " 'bootstrapping neural processes',\n",
              " 'large scale adversarial scale adversarial training adversarial training vision training vision and vision and language and language representation language representation learning',\n",
              " 'relu networks suffer networks suffer ell suffer ell 2 ell 2 adversarial 2 adversarial perturbations',\n",
              " 'compositional visual generation visual generation energy generation energy based energy based models',\n",
              " 'factor graph grammars',\n",
              " 'erdos goes neural goes neural unsupervised neural unsupervised learning unsupervised learning framework learning framework combinatorial framework combinatorial optimization combinatorial optimization graphs',\n",
              " 'autoregressive score matching',\n",
              " 'debiasing distributed second distributed second order second order optimization order optimization surrogate optimization surrogate sketching surrogate sketching scaled sketching scaled regularization',\n",
              " 'neural controlled differential controlled differential equations differential equations irregular equations irregular time irregular time series',\n",
              " 'efficiency hierarchical reinforcement hierarchical reinforcement learning',\n",
              " 'correctness automatic differentiation automatic differentiation non differentiation non differentiable non differentiable functions',\n",
              " 'probabilistic linear solvers linear solvers machine solvers machine learning',\n",
              " 'dynamic regret policy regret policy optimization policy optimization non optimization non stationary non stationary environments',\n",
              " 'multipole graph neural graph neural operator neural operator parametric operator parametric partial parametric partial differential partial differential equations',\n",
              " 'blockgan learning 3d learning 3d object 3d object aware object aware scene aware scene representations scene representations unlabelled representations unlabelled images',\n",
              " 'online structured meta structured meta learning',\n",
              " 'learning strategic network strategic network emergence network emergence games',\n",
              " 'towards interpretable natural interpretable natural language natural language understanding language understanding explanations understanding explanations latent explanations latent variables',\n",
              " 'mean squared error squared error double error double q double q learning',\n",
              " 'makes good views good views contrastive views contrastive learning',\n",
              " 'denoising diffusion probabilistic diffusion probabilistic models',\n",
              " 'barking right tree right tree approach tree approach search approach search molecule search molecule synthesis molecule synthesis dags',\n",
              " 'uniform convergence low convergence low norm low norm interpolation norm interpolation learning',\n",
              " 'bandit samplers training samplers training graph training graph neural graph neural networks',\n",
              " 'sampling k dpp k dpp without dpp without looking without looking items',\n",
              " 'uncovering topology time topology time varying time varying fmri varying fmri data fmri data using data using cubical using cubical persistence',\n",
              " 'hierarchical poset decoding poset decoding compositional decoding compositional generalization compositional generalization language',\n",
              " 'evaluating rewarding teamwork rewarding teamwork using teamwork using cooperative using cooperative game cooperative game abstractions',\n",
              " 'exchangeable neural ode neural ode set ode set modeling',\n",
              " 'profile entropy fundamental entropy fundamental measure fundamental measure learnability measure learnability compressibility learnability compressibility distributions',\n",
              " 'coadnet collaborative aggregation collaborative aggregation and aggregation and distribution and distribution networks distribution networks co networks co salient co salient object salient object detection',\n",
              " 'regularized linear autoencoders linear autoencoders recover autoencoders recover principal recover principal components principal components eventually',\n",
              " 'semi supervised partial supervised partial label partial label learning label learning via learning via confidence via confidence rated confidence rated margin rated margin maximization',\n",
              " 'gramgan deep 3d deep 3d texture 3d texture synthesis texture synthesis 2d synthesis 2d exemplars',\n",
              " 'uwsod toward fully toward fully supervised fully supervised level supervised level capacity level capacity weakly capacity weakly supervised weakly supervised object supervised object detection',\n",
              " 'learning restricted boltzmann restricted boltzmann machines boltzmann machines sparse machines sparse latent sparse latent variables',\n",
              " 'sample complexity asynchronous complexity asynchronous q asynchronous q learning q learning sharper learning sharper analysis sharper analysis variance analysis variance reduction',\n",
              " 'curriculum learning multilevel learning multilevel budgeted multilevel budgeted combinatorial budgeted combinatorial problems',\n",
              " 'fedsplit algorithmic framework algorithmic framework fast framework fast federated fast federated optimization',\n",
              " 'estimation imputation probabilistic imputation probabilistic principal probabilistic principal component principal component analysis component analysis missing analysis missing random missing random data',\n",
              " 'correlation robust influence robust influence maximization',\n",
              " 'neuronal gaussian process gaussian process regression',\n",
              " 'nonconvex sparse graph sparse graph learning graph learning laplacian learning laplacian constrained laplacian constrained graphical constrained graphical model',\n",
              " 'synthetic data generators data generators sequential generators sequential private',\n",
              " 'uncertainty quantification inferring quantification inferring hawkes inferring hawkes networks',\n",
              " 'implicit distributional reinforcement distributional reinforcement learning',\n",
              " 'auxiliary task reweighting task reweighting minimum reweighting minimum data minimum data learning',\n",
              " 'small nash equilibrium nash equilibrium certificates equilibrium certificates large certificates large games',\n",
              " 'training linear finite linear finite state finite state machines',\n",
              " 'efficient active learning active learning sparse learning sparse halfspaces sparse halfspaces arbitrary halfspaces arbitrary bounded arbitrary bounded noise',\n",
              " 'swapping autoencoder deep autoencoder deep image deep image manipulation',\n",
              " 'self supervised few supervised few shot few shot learning shot learning point learning point clouds',\n",
              " 'faster differentially private differentially private samplers private samplers via samplers via r via r nyi r nyi divergence nyi divergence analysis divergence analysis discretized analysis discretized langevin discretized langevin mcmc',\n",
              " 'learning identifiable interpretable identifiable interpretable latent interpretable latent models latent models high models high dimensional high dimensional neural dimensional neural activity neural activity using activity using pi using pi vae',\n",
              " 'rl unplugged suite unplugged suite benchmarks suite benchmarks offline benchmarks offline reinforcement offline reinforcement learning',\n",
              " 'dual reducing estimation reducing estimation error estimation error transition error transition matrix transition matrix label matrix label noise label noise learning',\n",
              " 'interior point solving point solving lp solving lp based lp based prediction based prediction optimisation',\n",
              " 'simple normative network normative network approximates network approximates local approximates local non local non hebbian non hebbian learning hebbian learning cortex',\n",
              " 'kernelized information bottleneck information bottleneck leads bottleneck leads biologically leads biologically plausible biologically plausible 3 plausible 3 factor 3 factor hebbian factor hebbian learning hebbian learning deep learning deep networks',\n",
              " 'understanding role training role training regimes training regimes continual regimes continual learning',\n",
              " 'fair regression wasserstein regression wasserstein barycenters',\n",
              " 'training stronger baselines stronger baselines learning baselines learning optimize',\n",
              " 'exactly computing local computing local lipschitz local lipschitz constant lipschitz constant relu constant relu networks',\n",
              " 'strictly batch imitation batch imitation learning imitation learning energy learning energy based energy based distribution based distribution matching',\n",
              " 'ergodicity bias asymptotic bias asymptotic normality asymptotic normality randomized normality randomized midpoint randomized midpoint sampling midpoint sampling method',\n",
              " 'single loop smoothed loop smoothed gradient smoothed gradient descent gradient descent ascent descent ascent algorithm ascent algorithm nonconvex algorithm nonconvex concave nonconvex concave min concave min max min max problems',\n",
              " 'generating correct answers correct answers progressive answers progressive matrices progressive matrices intelligence matrices intelligence tests',\n",
              " 'hynet learning local learning local descriptor local descriptor hybrid descriptor hybrid similarity hybrid similarity measure similarity measure triplet measure triplet loss',\n",
              " 'preference learning along learning along multiple along multiple criteria multiple criteria game criteria game theoretic game theoretic perspective',\n",
              " 'multi plane program plane program induction program induction 3d induction 3d box 3d box priors',\n",
              " 'online neural connectivity neural connectivity estimation connectivity estimation noisy estimation noisy group noisy group testing',\n",
              " 'once for all for all adversarial all adversarial training adversarial training in training in situ in situ tradeoff situ tradeoff robustness tradeoff robustness accuracy robustness accuracy free',\n",
              " 'implicit neural representations neural representations periodic representations periodic activation periodic activation functions',\n",
              " 'rotated binary neural binary neural network',\n",
              " 'community detection sparse detection sparse time sparse time evolving time evolving graphs evolving graphs dynamical graphs dynamical bethe dynamical bethe hessian',\n",
              " 'simple principled uncertainty principled uncertainty estimation uncertainty estimation deterministic estimation deterministic deep deterministic deep learning deep learning via learning via distance via distance awareness',\n",
              " 'adaptive learning rank learning rank one rank one models one models efficient models efficient pairwise efficient pairwise sequence pairwise sequence alignment',\n",
              " 'hierarchical nucleation deep nucleation deep neural deep neural networks',\n",
              " 'fourier features let features let networks let networks learn networks learn high learn high frequency high frequency functions frequency functions low functions low dimensional low dimensional domains',\n",
              " 'graph geometry interaction geometry interaction learning',\n",
              " 'differentiable augmentation data augmentation data efficient data efficient gan efficient gan training',\n",
              " 'heuristic domain adaptation',\n",
              " 'learning certified individually certified individually fair individually fair representations',\n",
              " 'part dependent label dependent label noise label noise towards noise towards instance towards instance dependent instance dependent label dependent label noise',\n",
              " 'tackling objective inconsistency objective inconsistency problem inconsistency problem heterogeneous problem heterogeneous federated heterogeneous federated optimization',\n",
              " 'improved analysis variance analysis variance reduced variance reduced policy reduced policy gradient policy gradient natural gradient natural policy natural policy gradient policy gradient methods',\n",
              " 'geometric exploration online exploration online control',\n",
              " 'automatic curriculum learning curriculum learning value learning value disagreement',\n",
              " 'mri banding removal banding removal via removal via adversarial via adversarial training',\n",
              " 'nethack learning environment',\n",
              " 'language visual entity visual entity relationship entity relationship graph relationship graph agent graph agent navigation',\n",
              " 'icam interpretable classification interpretable classification via classification via disentangled via disentangled representations disentangled representations feature representations feature attribution feature attribution mapping',\n",
              " 'spectra conjugate kernel conjugate kernel neural kernel neural tangent neural tangent kernel tangent kernel linear kernel linear width linear width neural width neural networks',\n",
              " 'no regret learning regret learning dynamics learning dynamics extensive dynamics extensive form extensive form correlated form correlated equilibrium',\n",
              " 'estimating weighted areas weighted areas roc areas roc curve',\n",
              " 'implicit bias explain bias explain generalization explain generalization stochastic generalization stochastic convex stochastic convex optimization convex optimization case optimization case study',\n",
              " 'generalized hindsight reinforcement hindsight reinforcement learning',\n",
              " 'critic regularized regression',\n",
              " 'boosting adversarial training adversarial training hypersphere training hypersphere embedding',\n",
              " 'beyond homophily graph homophily graph neural graph neural networks neural networks current networks current limitations current limitations effective limitations effective designs',\n",
              " 'modeling continuous stochastic continuous stochastic processes stochastic processes dynamic processes dynamic normalizing dynamic normalizing flows',\n",
              " 'efficient online learning online learning optimal learning optimal rankings optimal rankings dimensionality rankings dimensionality reduction dimensionality reduction via reduction via gradient via gradient descent',\n",
              " 'training normalizing flows normalizing flows information flows information bottleneck information bottleneck competitive bottleneck competitive generative competitive generative classification',\n",
              " 'detecting hands recognizing hands recognizing physical recognizing physical contact physical contact wild',\n",
              " 'theory transfer learning transfer learning importance learning importance task importance task diversity',\n",
              " 'finite time analysis time analysis round analysis round robin round robin kullback robin kullback leibler kullback leibler upper leibler upper confidence upper confidence bounds confidence bounds optimal bounds optimal adaptive optimal adaptive allocation adaptive allocation multiple allocation multiple plays multiple plays markovian plays markovian rewards',\n",
              " 'neural star domain star domain primitive domain primitive representation',\n",
              " 'off policy interval policy interval estimation interval estimation lipschitz estimation lipschitz value lipschitz value iteration',\n",
              " 'inverse rational control rational control partially control partially observable partially observable continuous observable continuous nonlinear continuous nonlinear dynamics',\n",
              " 'deep statistical solvers',\n",
              " 'distributionally robust parametric robust parametric maximum parametric maximum likelihood maximum likelihood estimation',\n",
              " 'secretary online matching online matching problems matching problems machine problems machine learned machine learned advice',\n",
              " 'deep transformation invariant transformation invariant clustering',\n",
              " 'overfitting harmless basis harmless basis pursuit basis pursuit degree',\n",
              " 'improving generalization reinforcement generalization reinforcement learning reinforcement learning mixture learning mixture regularization',\n",
              " 'pontryagin differentiable programming differentiable programming end programming end to end to end to end learning end learning control learning control framework',\n",
              " 'learning aggregate observations',\n",
              " 'devil detail framework detail framework macroscopic framework macroscopic prediction macroscopic prediction via prediction via microscopic via microscopic models',\n",
              " 'subgraph neural networks',\n",
              " 'demystifying orthogonal monte orthogonal monte carlo monte carlo beyond',\n",
              " 'optimal robustness consistency robustness consistency trade consistency trade offs trade offs learning offs learning augmented learning augmented online augmented online algorithms',\n",
              " 'scalable approach privacy approach privacy preserving privacy preserving collaborative preserving collaborative machine collaborative machine learning',\n",
              " 'glow tts generative tts generative flow generative flow text flow text to text to speech to speech via speech via monotonic via monotonic alignment monotonic alignment search',\n",
              " 'towards learning convolutions learning convolutions scratch',\n",
              " 'cycle contrast self contrast self supervised self supervised video supervised video representation video representation learning',\n",
              " 'posterior re calibration re calibration imbalanced calibration imbalanced datasets',\n",
              " 'novelty search representational search representational space representational space sample space sample efficient sample efficient exploration',\n",
              " 'robust reinforcement learning reinforcement learning via learning via adversarial via adversarial training adversarial training langevin training langevin dynamics',\n",
              " 'adversarial blocking bandits',\n",
              " 'online algorithms multi algorithms multi shop multi shop ski shop ski rental ski rental machine rental machine learned machine learned advice',\n",
              " 'multi label contrastive label contrastive predictive contrastive predictive coding',\n",
              " 'rotation invariant local invariant local to local to global to global representation global representation learning representation learning 3d learning 3d point 3d point cloud',\n",
              " 'learning invariants soft invariants soft unification',\n",
              " 'one solution need solution need few need few shot few shot extrapolation shot extrapolation via extrapolation via structured via structured maxent structured maxent rl',\n",
              " 'variational bayesian monte bayesian monte carlo monte carlo noisy carlo noisy likelihoods',\n",
              " 'finite sample analysis sample analysis contractive analysis contractive stochastic contractive stochastic approximation stochastic approximation using approximation using smooth using smooth convex smooth convex envelopes',\n",
              " 'self supervised generative supervised generative adversarial generative adversarial compression',\n",
              " 'efficient nonconvex reformulation nonconvex reformulation stagewise reformulation stagewise convex stagewise convex optimization convex optimization problems',\n",
              " 'finite countable armed countable armed bandits',\n",
              " 'adversarial distributional training distributional training robust training robust deep robust deep learning',\n",
              " 'meta learning stationary learning stationary stochastic stationary stochastic process stochastic process prediction process prediction convolutional prediction convolutional neural convolutional neural processes',\n",
              " 'theory inspired path inspired path regularized path regularized differential regularized differential network differential network architecture network architecture search',\n",
              " 'conic descent application descent application memory application memory efficient memory efficient optimization efficient optimization positive optimization positive semidefinite positive semidefinite matrices',\n",
              " 'learning geometry wave geometry wave based wave based imaging',\n",
              " 'greedy inference structure inference structure exploiting structure exploiting lazy exploiting lazy maps',\n",
              " 'nimble lightweight parallel lightweight parallel gpu parallel gpu task gpu task scheduling task scheduling deep scheduling deep learning',\n",
              " 'finding homology decision homology decision boundaries decision boundaries active boundaries active learning',\n",
              " 'reinforced molecular optimization molecular optimization neighborhood optimization neighborhood controlled neighborhood controlled grammars',\n",
              " 'natural policy gradient policy gradient primal gradient primal dual primal dual method dual method constrained method constrained markov constrained markov decision markov decision processes',\n",
              " 'classification misspecification halfspaces misspecification halfspaces generalized halfspaces generalized linear generalized linear models linear models evolvability',\n",
              " 'certified defense image defense image transformations image transformations via transformations via randomized via randomized smoothing',\n",
              " 'estimation skill distribution skill distribution tournament',\n",
              " 'reparameterizing mirror descent mirror descent gradient descent gradient descent',\n",
              " 'general control functions control functions causal functions causal effect causal effect estimation effect estimation ivs',\n",
              " 'optimal algorithms stochastic algorithms stochastic multi stochastic multi armed multi armed bandits armed bandits heavy bandits heavy tailed heavy tailed rewards',\n",
              " 'certified robustness graph robustness graph convolution graph convolution networks convolution networks graph networks graph classification graph classification topological classification topological attacks',\n",
              " 'zero resource knowledge resource knowledge grounded knowledge grounded dialogue grounded dialogue generation',\n",
              " 'targeted adversarial perturbations adversarial perturbations monocular perturbations monocular depth monocular depth prediction',\n",
              " 'beyond mean field mean field structured field structured deep structured deep gaussian deep gaussian processes gaussian processes improve processes improve predictive improve predictive uncertainties',\n",
              " 'offline imitation learning imitation learning misspecified learning misspecified simulator',\n",
              " 'multi fidelity bayesian fidelity bayesian optimization bayesian optimization via optimization via deep via deep neural deep neural networks',\n",
              " 'plangan model based model based planning based planning sparse planning sparse rewards sparse rewards multiple rewards multiple goals',\n",
              " 'bad global minima global minima exist minima exist sgd exist sgd reach',\n",
              " 'optimal prediction number prediction number unseen number unseen species unseen species multiplicity',\n",
              " 'characterizing optimal mixed optimal mixed policies mixed policies intervene policies intervene observe',\n",
              " 'factor graph neural graph neural networks',\n",
              " 'closer look accuracy look accuracy vs accuracy vs robustness',\n",
              " 'curriculum learning dynamic learning dynamic instance dynamic instance hardness',\n",
              " 'spin weighted spherical weighted spherical cnns',\n",
              " 'learning execute programs execute programs instruction programs instruction pointer instruction pointer attention pointer attention graph attention graph neural graph neural networks',\n",
              " 'autoprivacy automated layer automated layer wise layer wise parameter wise parameter selection parameter selection secure selection secure neural secure neural network neural network inference',\n",
              " 'baxter permutation process',\n",
              " 'characterizing emergent representations emergent representations space representations space candidate space candidate learning candidate learning rules learning rules deep rules deep networks',\n",
              " 'fast accurate simple accurate simple models simple models tabular models tabular data tabular data via data via augmented via augmented distillation',\n",
              " 'adaptive probing policies probing policies shortest policies shortest path shortest path routing',\n",
              " 'approximate heavily constrained heavily constrained learning constrained learning lagrange learning lagrange multiplier lagrange multiplier models',\n",
              " 'faster randomized infeasible randomized infeasible interior infeasible interior point interior point methods point methods tall methods tall wide tall wide linear wide linear programs',\n",
              " 'sliding window algorithms window algorithms k algorithms k clustering k clustering problems',\n",
              " 'adashare learning share learning share efficient share efficient deep efficient deep multi deep multi task multi task learning',\n",
              " 'approximate cross validation cross validation structured validation structured models',\n",
              " 'exemplar vae linking vae linking generative linking generative models generative models nearest models nearest neighbor nearest neighbor retrieval neighbor retrieval data retrieval data augmentation',\n",
              " 'debiased contrastive learning',\n",
              " 'ucsg net unsupervised net unsupervised discovering unsupervised discovering constructive discovering constructive solid constructive solid geometry solid geometry tree',\n",
              " '',\n",
              " 'cot gan generating gan generating sequential generating sequential data sequential data via data via causal via causal optimal causal optimal transport',\n",
              " 'impossibility results grammar results grammar compressed grammar compressed linear compressed linear algebra',\n",
              " 'understanding spiking networks spiking networks convex networks convex optimization',\n",
              " 'better full matrix full matrix regret matrix regret via regret via parameter via parameter free parameter free online free online learning',\n",
              " 'large scale methods scale methods distributionally methods distributionally robust distributionally robust optimization',\n",
              " 'analysis design thompson design thompson sampling thompson sampling stochastic sampling stochastic partial stochastic partial monitoring',\n",
              " 'bandit linear control',\n",
              " 'refactoring policy compositional policy compositional generalizability compositional generalizability using generalizability using self using self supervised self supervised object supervised object proposals',\n",
              " 'pep parameter ensembling parameter ensembling perturbation',\n",
              " 'theoretical insights multiclass insights multiclass classification multiclass classification high classification high dimensional high dimensional asymptotic dimensional asymptotic view',\n",
              " 'adversarial example games',\n",
              " 'residual distillation towards distillation towards portable towards portable deep portable deep neural deep neural networks neural networks without networks without shortcuts',\n",
              " 'provably efficient neural efficient neural estimation neural estimation structural estimation structural equation structural equation models equation models adversarial models adversarial approach',\n",
              " 'security analysis safe analysis safe seldonian safe seldonian reinforcement seldonian reinforcement learning reinforcement learning algorithms',\n",
              " 'learning play sequential play sequential games sequential games versus games versus unknown versus unknown opponents',\n",
              " 'analysis outlier detection outlier detection deep detection deep generative deep generative models',\n",
              " 'bridging imagination reality imagination reality model reality model based model based deep based deep reinforcement deep reinforcement learning',\n",
              " 'neural networks learning networks learning memorization learning memorization almost memorization almost over almost over parameterization',\n",
              " 'exploiting higher order higher order smoothness order smoothness derivative smoothness derivative free derivative free optimization free optimization continuous optimization continuous bandits',\n",
              " 'towards combinatorial characterization combinatorial characterization bounded characterization bounded memory bounded memory learning',\n",
              " 'chaos extremism optimism extremism optimism volume optimism volume analysis volume analysis learning analysis learning games',\n",
              " 'regret multiple best multiple best arms',\n",
              " 'matrix completion hierarchical completion hierarchical graph hierarchical graph side graph side information',\n",
              " 'long horizon rl horizon rl difficult rl difficult short difficult short horizon short horizon rl',\n",
              " 'hamiltonian monte carlo monte carlo using carlo using adjoint using adjoint differentiated adjoint differentiated laplace differentiated laplace approximation laplace approximation bayesian approximation bayesian inference bayesian inference latent inference latent gaussian latent gaussian models gaussian models beyond',\n",
              " 'adversarial learning robust learning robust deep robust deep clustering',\n",
              " 'learning mutational semantics',\n",
              " 'learning learn variational learn variational semantic variational semantic memory',\n",
              " '',\n",
              " 'learnability indirect supervision indirect supervision signals',\n",
              " 'towards safe policy safe policy improvement policy improvement non improvement non stationary non stationary mdps',\n",
              " 'finer metagenomic reconstruction metagenomic reconstruction via reconstruction via biodiversity via biodiversity optimization',\n",
              " 'causal discovery physical discovery physical systems physical systems videos',\n",
              " 'glyph fast accurately fast accurately training accurately training deep training deep neural deep neural networks neural networks encrypted networks encrypted data',\n",
              " 'smoothed analysis online analysis online differentially online differentially private differentially private learning',\n",
              " 'self paced deep paced deep reinforcement deep reinforcement learning',\n",
              " 'kalman filtering attention filtering attention user attention user behavior user behavior modeling behavior modeling ctr modeling ctr prediction',\n",
              " 'towards maximizing representation maximizing representation gap representation gap in gap in domain in domain out domain out of out of distribution of distribution examples',\n",
              " 'fully convolutional mesh convolutional mesh autoencoder mesh autoencoder using autoencoder using efficient using efficient spatially efficient spatially varying spatially varying kernels',\n",
              " 'gnnguard defending graph defending graph neural graph neural networks neural networks adversarial networks adversarial attacks',\n",
              " 'geo pifu geometry pifu geometry pixel geometry pixel aligned pixel aligned implicit aligned implicit functions implicit functions single functions single view single view human view human reconstruction',\n",
              " 'optimal visual search visual search based search based model based model target model target detectability target detectability natural detectability natural images',\n",
              " 'towards convergence rate convergence rate analysis rate analysis random analysis random forests random forests classification',\n",
              " 'list decodable mean decodable mean estimation mean estimation via estimation via iterative via iterative multi iterative multi filtering',\n",
              " 'exact recovery mangled recovery mangled clusters mangled clusters same clusters same cluster same cluster queries',\n",
              " 'steady state analysis state analysis episodic analysis episodic reinforcement episodic reinforcement learning',\n",
              " 'direct feedback alignment feedback alignment scales alignment scales modern scales modern deep modern deep learning deep learning tasks learning tasks architectures',\n",
              " 'bayesian optimization iterative optimization iterative learning',\n",
              " 'minimax bounds generalized bounds generalized linear generalized linear models',\n",
              " 'projection robust wasserstein robust wasserstein distance wasserstein distance riemannian distance riemannian optimization',\n",
              " 'coindice off policy off policy confidence policy confidence interval confidence interval estimation',\n",
              " 'simple fast algorithm fast algorithm binary algorithm binary integer binary integer online integer online linear online linear programming',\n",
              " 'learning diverse discriminative diverse discriminative representations discriminative representations via representations via principle via principle maximal principle maximal coding maximal coding rate coding rate reduction',\n",
              " 'learning rich rankings',\n",
              " 'color visual illusions visual illusions statistics illusions statistics based statistics based computational based computational model',\n",
              " 'retrieval augmented generation augmented generation knowledge generation knowledge intensive knowledge intensive nlp intensive nlp tasks',\n",
              " 'universal guarantees decision guarantees decision tree decision tree induction tree induction via induction via higher via higher order higher order splitting order splitting criterion',\n",
              " 'trade offs guarantees offs guarantees adversarial guarantees adversarial representation adversarial representation learning representation learning information learning information obfuscation',\n",
              " 'boolean task algebra task algebra reinforcement algebra reinforcement learning',\n",
              " 'learning differentiable pertubed differentiable pertubed optimizers',\n",
              " 'optimal learning verified learning verified training verified training data',\n",
              " 'online linear optimization linear optimization many optimization many hints',\n",
              " 'dynamical mean field mean field theory field theory stochastic theory stochastic gradient stochastic gradient descent gradient descent gaussian descent gaussian mixture gaussian mixture classification',\n",
              " 'causal discovery soft discovery soft interventions soft interventions unknown interventions unknown targets unknown targets characterization targets characterization learning',\n",
              " 'exploiting surrogate gap surrogate gap online gap online multiclass online multiclass classification',\n",
              " 'pitfalls simplicity bias simplicity bias neural bias neural networks',\n",
              " 'automatically learning compact learning compact quality compact quality aware quality aware surrogates aware surrogates optimization surrogates optimization problems',\n",
              " 'empirical likelihood contextual likelihood contextual bandits',\n",
              " 'q learning graph learning graph networks graph networks learn networks learn generalizable learn generalizable branching generalizable branching heuristic branching heuristic sat heuristic sat solver',\n",
              " 'non reversible gaussian reversible gaussian processes gaussian processes identifying processes identifying latent identifying latent dynamical latent dynamical structure dynamical structure neural structure neural data',\n",
              " 'listening sounds silence sounds silence speech silence speech denoising',\n",
              " 'boxe box embedding box embedding model embedding model knowledge model knowledge base knowledge base completion',\n",
              " 'coherent hierarchical multi hierarchical multi label multi label classification label classification networks',\n",
              " 'walsh hadamard variational hadamard variational inference variational inference bayesian inference bayesian deep bayesian deep learning',\n",
              " 'federated bayesian optimization bayesian optimization via optimization via thompson via thompson sampling',\n",
              " 'multion benchmarking semantic benchmarking semantic map semantic map memory map memory using memory using multi using multi object multi object navigation',\n",
              " 'neural complexity measures',\n",
              " 'optimal iterative sketching iterative sketching methods sketching methods subsampled methods subsampled randomized subsampled randomized hadamard randomized hadamard transform',\n",
              " 'provably adaptive reinforcement adaptive reinforcement learning reinforcement learning metric learning metric spaces',\n",
              " 'shapeflow learnable deformation learnable deformation flows deformation flows among flows among 3d among 3d shapes',\n",
              " 'self supervised learning supervised learning cross learning cross modal cross modal audio modal audio video audio video clustering',\n",
              " 'optimal query complexity query complexity secure complexity secure stochastic secure stochastic convex stochastic convex optimization',\n",
              " 'dynabert dynamic bert dynamic bert adaptive bert adaptive width adaptive width depth',\n",
              " 'generalization bound gradient bound gradient descent gradient descent non descent non convex non convex metric convex metric learning',\n",
              " 'dynamic submodular maximization',\n",
              " 'inference batched bandits',\n",
              " 'approximate cross validation cross validation low validation low rank low rank data rank data high data high dimensions',\n",
              " 'ganspace discovering interpretable discovering interpretable gan interpretable gan controls',\n",
              " 'differentiable expected hypervolume expected hypervolume improvement hypervolume improvement parallel improvement parallel multi parallel multi objective multi objective bayesian objective bayesian optimization',\n",
              " 'neuron level structured level structured pruning structured pruning using pruning using polarization using polarization regularizer',\n",
              " 'limits testing structural testing structural changes structural changes ising changes ising models',\n",
              " 'field wise learning wise learning multi learning multi field multi field categorical field categorical data',\n",
              " 'continual learning low learning low rank low rank orthogonal rank orthogonal subspaces',\n",
              " 'unsupervised learning visual learning visual features visual features contrasting features contrasting cluster contrasting cluster assignments',\n",
              " 'sharpened generalization bounds generalization bounds based bounds based conditional based conditional mutual conditional mutual information mutual information application information application noisy application noisy iterative noisy iterative algorithms',\n",
              " 'learning deformable tetrahedral deformable tetrahedral meshes tetrahedral meshes 3d meshes 3d reconstruction',\n",
              " 'information theoretic limits theoretic limits learning limits learning sparse learning sparse rule',\n",
              " 'self supervised learning supervised learning eyes learning eyes child',\n",
              " 'unsupervised semantic aggregation semantic aggregation deformable aggregation deformable template deformable template matching template matching semi matching semi supervised semi supervised learning',\n",
              " 'game theoretic analysis theoretic analysis networked analysis networked system networked system control system control common control common pool common pool resource pool resource management resource management using management using multi using multi agent multi agent reinforcement agent reinforcement learning',\n",
              " 'shapes feature representations feature representations exploring representations exploring datasets exploring datasets architectures datasets architectures training',\n",
              " 'optimal best arm best arm identification arm identification linear identification linear bandits',\n",
              " 'data diversification simple diversification simple strategy simple strategy neural strategy neural machine neural machine translation',\n",
              " 'interstellar searching recurrent searching recurrent architecture recurrent architecture knowledge architecture knowledge graph knowledge graph embedding',\n",
              " 'cose compositional stroke compositional stroke embeddings',\n",
              " 'learning multi agent multi agent coordination agent coordination enhancing coordination enhancing target enhancing target coverage target coverage directional coverage directional sensor directional sensor networks',\n",
              " 'biological credit assignment credit assignment dynamic assignment dynamic inversion dynamic inversion feedforward inversion feedforward networks',\n",
              " 'discriminative sounding objects sounding objects localization objects localization via localization via self via self supervised self supervised audiovisual supervised audiovisual matching',\n",
              " 'learning multi agent multi agent communication agent communication structured communication structured attentive structured attentive reasoning',\n",
              " 'private identity testing identity testing high testing high dimensional high dimensional distributions',\n",
              " 'optimal weighted ell weighted ell 2 ell 2 regularization 2 regularization overparameterized regularization overparameterized linear overparameterized linear regression',\n",
              " 'efficient asynchronous method asynchronous method integrating method integrating evolutionary integrating evolutionary gradient evolutionary gradient based gradient based policy based policy search',\n",
              " 'metasdf meta learning meta learning signed learning signed distance signed distance functions',\n",
              " 'simple scalable sparse scalable sparse k sparse k means k means clustering means clustering via clustering via feature via feature ranking',\n",
              " 'model based adversarial based adversarial meta adversarial meta reinforcement meta reinforcement learning',\n",
              " 'graph policy network policy network transferable network transferable active transferable active learning active learning graphs',\n",
              " 'towards better global better global loss global loss landscape loss landscape gans',\n",
              " 'weighted qmix expanding qmix expanding monotonic expanding monotonic value monotonic value function value function factorisation function factorisation deep factorisation deep multi deep multi agent multi agent reinforcement agent reinforcement learning',\n",
              " 'banditpam almost linear almost linear time linear time k time k medoids k medoids clustering medoids clustering via clustering via multi via multi armed multi armed bandits',\n",
              " 'udh universal deep universal deep hiding deep hiding steganography hiding steganography watermarking steganography watermarking light watermarking light field light field messaging',\n",
              " 'evidential sparsification multimodal sparsification multimodal latent multimodal latent spaces latent spaces conditional spaces conditional variational conditional variational autoencoders',\n",
              " 'unbiased risk estimator risk estimator learning estimator learning augmented learning augmented classes',\n",
              " 'autobss efficient algorithm efficient algorithm block algorithm block stacking block stacking style stacking style search',\n",
              " 'pushing limits narrow limits narrow precision narrow precision inferencing precision inferencing cloud inferencing cloud scale cloud scale microsoft scale microsoft floating microsoft floating point',\n",
              " 'stochastic optimization laggard optimization laggard data laggard data pipelines',\n",
              " 'self supervised auxiliary supervised auxiliary learning auxiliary learning meta learning meta paths meta paths heterogeneous paths heterogeneous graphs',\n",
              " 'gps net graph net graph based graph based photometric based photometric stereo photometric stereo network',\n",
              " 'consistent structural relation structural relation learning relation learning zero learning zero shot zero shot segmentation',\n",
              " 'model selection contextual selection contextual stochastic contextual stochastic bandit stochastic bandit problems',\n",
              " 'truncated linear regression linear regression high regression high dimensions',\n",
              " 'incorporating pragmatic reasoning pragmatic reasoning communication reasoning communication emergent communication emergent language',\n",
              " 'deep subspace clustering subspace clustering data clustering data augmentation',\n",
              " 'empirical process approach process approach union approach union bound union bound practical bound practical algorithms practical algorithms combinatorial algorithms combinatorial linear combinatorial linear bandits',\n",
              " 'graph neural networks neural networks count networks count substructures',\n",
              " 'bayesian perspective training perspective training speed training speed model speed model selection',\n",
              " '',\n",
              " 'doubly robust off robust off policy off policy value policy value gradient value gradient estimation gradient estimation deterministic estimation deterministic policies',\n",
              " 'provably efficient neural efficient neural gtd neural gtd off gtd off policy off policy learning',\n",
              " 'learning discrete energy discrete energy based energy based models based models via models via auxiliary via auxiliary variable auxiliary variable local variable local exploration',\n",
              " 'stable expressive recurrent expressive recurrent vision recurrent vision models',\n",
              " 'entropic optimal transport optimal transport unbalanced transport unbalanced gaussian unbalanced gaussian measures gaussian measures closed measures closed form',\n",
              " 'brp nas prediction nas prediction based prediction based nas based nas using nas using gcns',\n",
              " 'deep shells unsupervised shells unsupervised shape unsupervised shape correspondence shape correspondence optimal correspondence optimal transport',\n",
              " 'ista nas efficient nas efficient consistent efficient consistent neural consistent neural architecture neural architecture search architecture search sparse search sparse coding',\n",
              " 'rel3d minimally contrastive minimally contrastive benchmark contrastive benchmark grounding benchmark grounding spatial grounding spatial relations spatial relations 3d',\n",
              " 'regularizing black box black box models box models improved models improved interpretability',\n",
              " 'trust model confident model confident masked confident masked model masked model based model based actor based actor critic',\n",
              " 'semi supervised neural supervised neural architecture neural architecture search',\n",
              " 'consistency regularization certified regularization certified robustness certified robustness smoothed robustness smoothed classifiers',\n",
              " 'robust multi agent multi agent reinforcement agent reinforcement learning reinforcement learning model learning model uncertainty',\n",
              " 'siri spatial relation spatial relation induced relation induced network induced network spatial network spatial description spatial description resolution',\n",
              " 'adaptive shrinkage estimation shrinkage estimation streaming estimation streaming graphs',\n",
              " 'make one shot one shot video shot video object video object segmentation object segmentation efficient',\n",
              " 'depth uncertainty neural uncertainty neural networks',\n",
              " 'non euclidean universal euclidean universal approximation',\n",
              " 'constraining variational inference variational inference geometric inference geometric jensen geometric jensen shannon jensen shannon divergence',\n",
              " 'gibbs sampling people',\n",
              " 'hm ann efficient ann efficient billion efficient billion point billion point nearest point nearest neighbor nearest neighbor search neighbor search heterogeneous search heterogeneous memory',\n",
              " 'frugalml use ml use ml prediction ml prediction apis prediction apis accurately apis accurately cheaply',\n",
              " 'sharp representation theorems representation theorems relu theorems relu networks relu networks precise networks precise dependence precise dependence depth',\n",
              " 'shared experience actor experience actor critic actor critic multi critic multi agent multi agent reinforcement agent reinforcement learning',\n",
              " 'monotone operator equilibrium operator equilibrium networks',\n",
              " 'lift lockdown global lockdown global covid global covid 19 covid 19 scenario 19 scenario analysis scenario analysis policy analysis policy assessment policy assessment using assessment using compartmental using compartmental gaussian compartmental gaussian processes',\n",
              " 'unsupervised learning lagrangian learning lagrangian dynamics lagrangian dynamics images dynamics images prediction images prediction control',\n",
              " 'high dimensional sparse dimensional sparse linear sparse linear bandits',\n",
              " 'non stochastic control stochastic control bandit control bandit feedback',\n",
              " 'generalized leverage score leverage score sampling score sampling neural sampling neural networks',\n",
              " 'optimal elimination algorithm elimination algorithm learning algorithm learning best learning best arm',\n",
              " 'efficient projection free projection free algorithms free algorithms saddle algorithms saddle point saddle point problems',\n",
              " 'mathematical model automatic model automatic differentiation automatic differentiation machine differentiation machine learning',\n",
              " 'unsupervised text generation text generation learning generation learning search',\n",
              " 'learning compositional rules compositional rules via rules via neural via neural program neural program synthesis',\n",
              " 'incorporating bert parallel bert parallel sequence parallel sequence decoding sequence decoding adapters',\n",
              " 'estimating fluctuations neural fluctuations neural representations neural representations uncertain representations uncertain environments',\n",
              " 'discover hallucinate adapt hallucinate adapt open adapt open compound open compound domain compound domain adaptation domain adaptation semantic adaptation semantic segmentation',\n",
              " 'surf simple universal simple universal robust universal robust fast robust fast distribution fast distribution learning distribution learning algorithm',\n",
              " 'understanding approximate fisher approximate fisher information fisher information fast information fast convergence fast convergence natural convergence natural gradient natural gradient descent gradient descent wide descent wide neural wide neural networks',\n",
              " 'general transportability soft transportability soft interventions soft interventions completeness interventions completeness results',\n",
              " 'gait prop biologically prop biologically plausible biologically plausible learning plausible learning rule learning rule derived rule derived backpropagation derived backpropagation error',\n",
              " 'lipschitz bounds provably bounds provably robust provably robust training robust training laplacian training laplacian smoothing',\n",
              " 'scop scientific control scientific control reliable control reliable neural reliable neural network neural network pruning',\n",
              " 'provably consistent partial consistent partial label partial label learning',\n",
              " 'robust accurate stochastic accurate stochastic optimization stochastic optimization variational optimization variational inference',\n",
              " 'discovering conflicting groups conflicting groups signed groups signed networks',\n",
              " 'learning popular gaussian popular gaussian graphical gaussian graphical models graphical models without models without condition without condition number condition number bounds',\n",
              " 'sense sensitivity analysis sensitivity analysis simple analysis simple post simple post hoc post hoc analysis hoc analysis bias analysis bias due bias due unobserved due unobserved confounding',\n",
              " 'mix match optimistic match optimistic tree optimistic tree search tree search approach search approach learning approach learning models learning models mixture models mixture distributions',\n",
              " 'understanding double descent double descent requires descent requires fine requires fine grained fine grained bias grained bias variance bias variance decomposition',\n",
              " 'vime extending success extending success self success self semi self semi supervised semi supervised learning supervised learning tabular learning tabular domain',\n",
              " 'smoothed possibility social possibility social choice',\n",
              " 'decentralized parallel algorithm parallel algorithm training algorithm training generative training generative adversarial generative adversarial nets',\n",
              " 'phase retrieval high retrieval high dimensions high dimensions statistical dimensions statistical computational statistical computational phase computational phase transitions',\n",
              " 'fair performance metric performance metric elicitation',\n",
              " 'hybrid variance reduced variance reduced sgd reduced sgd algorithms sgd algorithms minimax algorithms minimax problems minimax problems nonconvex problems nonconvex linear nonconvex linear function',\n",
              " 'belief dependent macro dependent macro action macro action discovery action discovery pomdps discovery pomdps using pomdps using value using value information',\n",
              " 'soft contrastive learning contrastive learning visual learning visual localization',\n",
              " 'fine grained dynamic grained dynamic head dynamic head object head object detection',\n",
              " 'loco local contrastive local contrastive representation contrastive representation learning',\n",
              " 'modeling optimization trade optimization trade off trade off meta off meta learning',\n",
              " 'snapboost heterogeneous boosting heterogeneous boosting machine',\n",
              " 'adaptive distance estimation',\n",
              " 'stage wise conservative wise conservative linear conservative linear bandits',\n",
              " 'relate physically plausible physically plausible multi plausible multi object multi object scene object scene synthesis scene synthesis using synthesis using structured using structured latent structured latent spaces',\n",
              " 'metric free individual free individual fairness individual fairness online fairness online learning',\n",
              " 'greedyfool distortion aware distortion aware sparse aware sparse adversarial sparse adversarial attack',\n",
              " 'vaem deep generative deep generative model generative model heterogeneous model heterogeneous mixed heterogeneous mixed type mixed type data',\n",
              " 'retroxpert decompose retrosynthesis decompose retrosynthesis prediction retrosynthesis prediction like prediction like chemist',\n",
              " 'sample efficient optimization efficient optimization latent optimization latent space latent space deep space deep generative deep generative models generative models via models via weighted via weighted retraining',\n",
              " 'improved sample complexity sample complexity incremental complexity incremental autonomous incremental autonomous exploration autonomous exploration mdps',\n",
              " 'tinytl reduce memory reduce memory parameters memory parameters efficient parameters efficient on efficient on device on device learning',\n",
              " 'rd 2 reward 2 reward decomposition reward decomposition representation decomposition representation decomposition',\n",
              " 'self paced contrastive paced contrastive learning contrastive learning hybrid learning hybrid memory hybrid memory domain memory domain adaptive domain adaptive object adaptive object re object re id',\n",
              " 'fairness constraints help constraints help exact help exact inference exact inference structured inference structured prediction',\n",
              " 'instance based generalization based generalization reinforcement generalization reinforcement learning',\n",
              " 'smooth consistent probabilistic consistent probabilistic regression probabilistic regression trees',\n",
              " 'computing valid p valid p value p value optimal value optimal changepoint optimal changepoint selective changepoint selective inference selective inference using inference using dynamic using dynamic programming',\n",
              " 'factorized neural processes neural processes neural processes neural processes neural processes k processes k shot k shot prediction shot prediction neural prediction neural responses',\n",
              " 'winning lottery continuous lottery continuous sparsification',\n",
              " 'adversarial robustness via robustness via robust via robust low robust low rank low rank representations',\n",
              " 'joints random forests',\n",
              " 'compositional generalization learning generalization learning analytical learning analytical expressions',\n",
              " 'jax md framework md framework differentiable framework differentiable physics',\n",
              " 'implicit function learning function learning approach learning approach parametric approach parametric modal parametric modal regression',\n",
              " 'sdf srn learning srn learning signed learning signed distance signed distance 3d distance 3d object 3d object reconstruction object reconstruction static reconstruction static images',\n",
              " 'coresets robust training robust training deep training deep neural deep neural networks neural networks noisy networks noisy labels',\n",
              " 'adapting misspecification contextual misspecification contextual bandits',\n",
              " 'convergence meta learning meta learning task learning task specific task specific adaptation specific adaptation partial adaptation partial parameters',\n",
              " 'metaperturb transferable regularizer transferable regularizer heterogeneous regularizer heterogeneous tasks heterogeneous tasks architectures',\n",
              " 'learning solve tv solve tv regularised tv regularised problems regularised problems unrolled problems unrolled algorithms',\n",
              " 'object centric learning centric learning slot learning slot attention',\n",
              " 'improving robustness common robustness common corruptions common corruptions covariate corruptions covariate shift covariate shift adaptation',\n",
              " 'deep smoothing implied smoothing implied volatility implied volatility surface',\n",
              " 'probabilistic inference algebraic inference algebraic constraints algebraic constraints theoretical constraints theoretical limits theoretical limits practical limits practical approximations',\n",
              " 'provable online cp online cp parafac cp parafac decomposition parafac decomposition structured decomposition structured tensor structured tensor via tensor via dictionary via dictionary learning',\n",
              " 'look ahead meta ahead meta learning meta learning continual learning continual learning',\n",
              " 'polynomial time algorithm time algorithm learning algorithm learning nonparametric learning nonparametric causal nonparametric causal graphs',\n",
              " 'sparse learning cart',\n",
              " 'proximal mapping deep mapping deep regularization',\n",
              " 'identifying causal effect causal effect inference effect inference failure inference failure uncertainty failure uncertainty aware uncertainty aware models',\n",
              " 'hierarchical granularity transfer granularity transfer learning',\n",
              " 'deep active inference active inference agents inference agents using agents using monte using monte carlo monte carlo methods',\n",
              " 'consistent estimation identifiable estimation identifiable nonparametric identifiable nonparametric mixture nonparametric mixture models mixture models grouped models grouped observations',\n",
              " 'manifold structure graph structure graph embeddings',\n",
              " 'adaptive learned bloom learned bloom filter bloom filter ada filter ada bf ada bf efficient bf efficient utilization efficient utilization classifier utilization classifier application classifier application real application real time real time information time information filtering information filtering web',\n",
              " 'mcunet tiny deep tiny deep learning deep learning iot learning iot devices',\n",
              " 'search robust measures robust measures generalization',\n",
              " 'task agnostic exploration agnostic exploration reinforcement exploration reinforcement learning',\n",
              " 'multi task additive task additive models additive models robust models robust estimation robust estimation automatic estimation automatic structure automatic structure discovery',\n",
              " 'provably efficient reward efficient reward agnostic reward agnostic navigation agnostic navigation linear navigation linear value linear value iteration',\n",
              " 'softmax deep double deep double deterministic double deterministic policy deterministic policy gradients',\n",
              " 'online decision based decision based visual based visual tracking visual tracking via tracking via reinforcement via reinforcement learning',\n",
              " 'efficient marginalization discrete marginalization discrete structured discrete structured latent structured latent variables latent variables via variables via sparsity',\n",
              " 'deepi2i enabling deep enabling deep hierarchical deep hierarchical image hierarchical image to image to image to image translation image translation transferring translation transferring gans',\n",
              " 'distributional robustness ipms robustness ipms links ipms links regularization links regularization gans',\n",
              " 'shooting formulation deep formulation deep learning',\n",
              " 'csi novelty detection novelty detection via detection via contrastive via contrastive learning contrastive learning distributionally learning distributionally shifted distributionally shifted instances',\n",
              " 'learning implicit credit implicit credit assignment credit assignment cooperative assignment cooperative multi cooperative multi agent multi agent reinforcement agent reinforcement learning',\n",
              " 'mate plugging model plugging model awareness model awareness task awareness task embedding task embedding meta embedding meta learning',\n",
              " 'restless ucb efficient ucb efficient low efficient low complexity low complexity algorithm complexity algorithm online algorithm online restless online restless bandits',\n",
              " 'predictive information accelerates information accelerates learning accelerates learning rl',\n",
              " 'robust heavy tailed heavy tailed mean tailed mean estimation mean estimation made estimation made simple made simple via simple via regret via regret minimization',\n",
              " 'high fidelity generative fidelity generative image generative image compression',\n",
              " 'statistical mechanics framework mechanics framework task framework task agnostic task agnostic sample agnostic sample design sample design machine design machine learning',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRN9P98zRXU-"
      },
      "source": [
        "#### Remove Redundant Word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2KOSbo-RWng"
      },
      "source": [
        "# Program without using any external library\n",
        "s = 'neural methods point methods point wise point wise dependency wise dependency estimation'\n",
        "\n",
        "def remove_duplicate_word(s):\n",
        "  l = s.split()\n",
        "  k = []\n",
        "  for i in l:\n",
        "      # If condition is used to store unique string \n",
        "      # in another list 'k' \n",
        "      if (s.count(i)>1 and (i not in k) or s.count(i)==1):\n",
        "          k.append(i)\n",
        "  #print(' '.join(k))\n",
        "  return ' '.join(k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgn5QwNFS-we"
      },
      "source": [
        "for i in range(len(topic_list)):\n",
        "  topic_list[i] = remove_duplicate_word(topic_list[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoewYEHRTUCh",
        "outputId": "b8cc1c41-4994-4e57-9910-f5b6a9e30056"
      },
      "source": [
        "topic_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['graph similarity deep learning',\n",
              " 'unsupervised information theoretic perceptual quality metric',\n",
              " 'self supervised multimodal versatile networks',\n",
              " 'benchmarking deep inverse models time neural adjoint method',\n",
              " 'off policy evaluation learning external validity covariate shift',\n",
              " 'neural methods point wise dependency estimation',\n",
              " 'fast flexible temporal point processes triangular maps',\n",
              " 'backpropagating linearly improves transferability adversarial examples',\n",
              " 'pyglove symbolic programming automated machine learning',\n",
              " 'fourier sparse leverage scores approximate kernel learning',\n",
              " 'improved algorithms online submodular maximization via first order regret bounds',\n",
              " 'synbols probing learning algorithms synthetic datasets',\n",
              " 'adversarially robust streaming algorithms via differential privacy',\n",
              " 'trading personalization accuracy data debugging collaborative filtering',\n",
              " 'cascaded text generation markov transformers',\n",
              " 'improving local identifiability probabilistic box embeddings',\n",
              " 'permute and flip new mechanism differentially private selection',\n",
              " 'deep reconstruction strange attractors time series',\n",
              " 'reciprocal adversarial learning via characteristic functions',\n",
              " 'statistical guarantees distributed nearest neighbor classification',\n",
              " 'stein self repulsive dynamics benefits past samples',\n",
              " 'statistical complexity early stopped mirror descent',\n",
              " 'algorithmic recourse imperfect causal knowledge probabilistic approach',\n",
              " 'quantitative propagation chaos sgd wide neural networks',\n",
              " 'causal view robustness neural networks',\n",
              " 'minimax classification 0 1 loss performance guarantees',\n",
              " 'learn useful critic model based action gradient estimator policy optimization',\n",
              " 'coresets regressions panel data',\n",
              " 'learning composable energy surrogates pde order reduction',\n",
              " 'efficient contextual bandits continuous actions',\n",
              " 'achieving equalized odds resampling sensitive attributes',\n",
              " 'multi robot collision avoidance uncertainty probabilistic safety barrier certificates',\n",
              " 'hard shape constrained kernel machines',\n",
              " 'closer look training strategy modern meta learning',\n",
              " 'value out of distribution testing example goodhart s law',\n",
              " 'generalised bayesian filtering via sequential monte carlo',\n",
              " 'deterministic approximation submodular maximization matroid nearly linear time',\n",
              " 'flows simultaneous manifold learning density estimation',\n",
              " 'simultaneous preference metric learning paired comparisons',\n",
              " 'efficient variational inference sparse deep learning theoretical guarantee',\n",
              " 'learning manifold implicitly via explicit heat kernel',\n",
              " 'deep relational topic modeling via graph poisson gamma belief network',\n",
              " 'one bit supervision image classification',\n",
              " 'transferred transfer learning',\n",
              " 'submodular maximization barrier functions',\n",
              " 'neural networks recurrent generative feedback',\n",
              " 'learning extrapolate knowledge transductive few shot out of graph link prediction',\n",
              " 'exploiting weakly supervised visual patterns learn partial annotations',\n",
              " 'improving inference neural image compression',\n",
              " 'neuron merging compensating pruned neurons',\n",
              " 'fixmatch simplifying semi supervised learning consistency confidence',\n",
              " 'reinforcement learning combinatorial actions application vehicle routing',\n",
              " 'towards playing full moba games deep reinforcement learning',\n",
              " 'rankmax adaptive projection alternative softmax function',\n",
              " 'online agnostic boosting via regret minimization',\n",
              " 'causal intervention weakly supervised semantic segmentation',\n",
              " 'belief propagation neural networks',\n",
              " 'over parameterized adversarial training analysis overcoming curse dimensionality',\n",
              " 'post training iterative hierarchical data augmentation deep networks',\n",
              " 'debugging tests model explanations',\n",
              " 'robust compressed sensing using generative models',\n",
              " 'fairness without demographics adversarially reweighted learning',\n",
              " 'stochastic latent actor critic deep reinforcement learning variable model',\n",
              " 'ridge rider finding diverse solutions following eigenvectors hessian',\n",
              " 'route chaos routing games price anarchy optimistic',\n",
              " 'online algorithm unsupervised sequential selection contextual information',\n",
              " 'adapting neural architectures domains',\n",
              " 'went wrong instance wise feature importance time series black box models',\n",
              " 'towards better generalization adaptive gradient methods',\n",
              " 'learning guidance rewards trajectory space smoothing',\n",
              " 'variance reduction via accelerated dual averaging finite sum optimization',\n",
              " 'tree low dimensional hyperbolic embedding',\n",
              " 'deep structural causal models tractable counterfactual inference',\n",
              " 'convolutional generation textured 3d meshes',\n",
              " 'statistical framework low bitwidth training deep neural networks',\n",
              " 'better set representations relational reasoning',\n",
              " 'autosync learning synchronize data parallel distributed deep',\n",
              " 'combinatorial perspective transfer learning',\n",
              " 'hardness learning neural networks natural weights',\n",
              " 'higher order spectral clustering directed graphs',\n",
              " 'primal dual mesh convolutional neural networks',\n",
              " 'advantage conditional meta learning biased regularization fine tuning',\n",
              " 'watch motion blurring vision deep neural networks',\n",
              " 'sinkhorn barycenter via functional gradient descent',\n",
              " 'coresets near convex functions',\n",
              " 'bayesian deep ensembles via neural tangent kernel',\n",
              " 'improved schemes episodic memory based lifelong learning',\n",
              " 'adaptive sampling stochastic risk averse learning',\n",
              " 'deep wiener deconvolution meets learning image deblurring',\n",
              " 'discovering reinforcement learning algorithms',\n",
              " 'taming discrete integration via boon dimensionality',\n",
              " 'blind video temporal consistency via deep prior',\n",
              " 'simplify robustify negative sampling implicit collaborative filtering',\n",
              " 'model selection production system via automated online experiments',\n",
              " 'almost sure convergence stochastic gradient descent non convex problems',\n",
              " 'automatic perturbation analysis scalable certified robustness beyond',\n",
              " 'adaptation properties allow identification optimized neural codes',\n",
              " 'global convergence variance reduction class nonconvex nonconcave minimax problems',\n",
              " 'model based multi agent rl zero sum markov games near optimal sample complexity',\n",
              " 'conservative q learning offline reinforcement',\n",
              " 'online influence maximization linear threshold model',\n",
              " 'ensembling geophysical models bayesian neural networks',\n",
              " 'delving cyclic mechanism semi supervised video object segmentation',\n",
              " 'asymmetric shapley values incorporating causal knowledge model agnostic explainability',\n",
              " 'understanding deep architecture reasoning layer',\n",
              " 'planning markov decision processes gap dependent sample complexity',\n",
              " 'provably good batch off policy reinforcement learning without great exploration',\n",
              " 'detection regression certified object median smoothing',\n",
              " 'contextual reserve price optimization auctions via mixed integer programming',\n",
              " 'expandnets linear over parameterization train compact convolutional networks',\n",
              " 'flexor trainable fractional quantization',\n",
              " 'implications local correlation learning deep functions',\n",
              " 'learning search efficiently causally near optimal treatments',\n",
              " 'game theoretic analysis additive adversarial attacks defenses',\n",
              " 'posterior network uncertainty estimation without ood samples via density based pseudo counts',\n",
              " 'recurrent quantum neural networks',\n",
              " 'no regret learning mixed nash equilibria mix',\n",
              " 'unifying view optimism episodic reinforcement learning',\n",
              " 'continuous submodular maximization beyond dr submodularity',\n",
              " 'asymptotically optimal primal dual incremental algorithm contextual linear bandits',\n",
              " 'assessing satnet s ability solve symbol grounding problem',\n",
              " 'bayesian nonparametrics view deep representations',\n",
              " 'similarity laplace neural tangent kernels',\n",
              " 'causal view compositional zero shot recognition',\n",
              " 'hippo recurrent memory optimal polynomial projections',\n",
              " 'auto learning attention',\n",
              " 'castle regularization via auxiliary causal graph discovery',\n",
              " 'long tailed classification keeping good removing bad momentum causal effect',\n",
              " '',\n",
              " 'deep archimedean copulas',\n",
              " 're examining linear embeddings high dimensional bayesian optimization',\n",
              " 'unmodnet learning unwrap modulo image high dynamic range imaging',\n",
              " 'thunder fast coordinate selection solver sparse learning',\n",
              " 'neural networks fail learn periodic functions fix',\n",
              " 'distribution matching crowd counting',\n",
              " 'correspondence learning via linearly invariant embedding',\n",
              " 'learning dispatch job shop scheduling via deep reinforcement',\n",
              " 'adaptive attacks adversarial example defenses',\n",
              " 'sinkhorn natural gradient generative models',\n",
              " 'online sinkhorn optimal transport distances sample streams',\n",
              " 'ultrahyperbolic representation learning',\n",
              " 'locally adaptive nonparametric online learning',\n",
              " 'compositional generalization via neural symbolic stack machines',\n",
              " 'graphon neural networks transferability graph',\n",
              " 'unreasonable effectiveness greedy algorithms multi armed bandit many arms',\n",
              " 'gamma models generative temporal difference learning infinite horizon prediction',\n",
              " 'deep transformers latent depth',\n",
              " 'neural mesh flow 3d manifold generation via diffeomorphic flows',\n",
              " 'statistical control spatio temporal meg eeg source imaging desparsified mutli task lasso',\n",
              " 'scalable mip based method learning optimal multivariate decision trees',\n",
              " 'efficient exact verification binarized neural networks',\n",
              " 'ultra low precision 4 bit training deep neural networks',\n",
              " 'bridging gap sample based one shot neural architecture search bonas',\n",
              " 'numerosity deep neural networks',\n",
              " 'outlier robust mean estimation subgaussian rates via stability',\n",
              " 'self supervised relationship probing',\n",
              " 'information theoretic counterfactual learning missing not at random feedback',\n",
              " 'prophet attention predicting future',\n",
              " 'language models few shot learners',\n",
              " 'margins insufficient explaining gradient boosting',\n",
              " 'fourier transform based attribution priors improve interpretability stability deep learning models genomics',\n",
              " 'momentumrnn integrating momentum recurrent neural networks',\n",
              " 'marginal utility planning continuous large discrete action spaces',\n",
              " 'projected stein variational gradient descent',\n",
              " 'minimax lower bounds transfer learning linear one hidden layer neural networks',\n",
              " 'se 3 transformers 3d roto translation equivariant attention networks',\n",
              " 'equivalence molecular graph convolution wave function poor basis set',\n",
              " 'power predictions online control',\n",
              " 'learning affordance landscapes interaction exploration 3d environments',\n",
              " 'cooperative multi player bandit optimization',\n",
              " 'tight first second order regret bounds adversarial linear bandits',\n",
              " 'pick sign optimizing deep multitask models gradient dropout',\n",
              " 'loss function generative neural networks based watson perceptual model',\n",
              " 'dynamic fusion eye movement data verbal narrations knowledge rich domains',\n",
              " 'scalable multi agent reinforcement learning networked systems average reward',\n",
              " 'optimizing neural networks via koopman operator theory',\n",
              " 'svgd kernelized wasserstein gradient flow chi squared divergence',\n",
              " 'adversarial robustness supervised sparse coding',\n",
              " 'differentiable meta learning bandit policies',\n",
              " 'biologically inspired mechanisms adversarial robustness',\n",
              " 'statistical query lower bounds via functional gradients',\n",
              " 'near optimal reinforcement learning self play',\n",
              " 'network diffusions via neural mean field dynamics',\n",
              " 'self distillation instance specific label smoothing',\n",
              " 'towards problem dependent optimal learning rates',\n",
              " 'cross lingual retrieval iterative self supervised training',\n",
              " 'rethinking pooling graph neural networks',\n",
              " 'pointer graph networks',\n",
              " 'gradient regularized v learning dynamic treatment regimes',\n",
              " 'faster wasserstein distance estimation sinkhorn divergence',\n",
              " 'forethought hindsight credit assignment',\n",
              " 'robust recursive partitioning heterogeneous treatment effects uncertainty quantification',\n",
              " 'rescuing neural spike train models bad mle',\n",
              " 'lower bounds optimal algorithms personalized federated learning',\n",
              " 'black box certification randomized smoothing functional optimization based framework',\n",
              " 'deep imitation learning bimanual robotic manipulation',\n",
              " 'stationary activations uncertainty calibration deep learning',\n",
              " 'ensemble distillation robust model fusion federated learning',\n",
              " 'falcon fast spectral inference encrypted data',\n",
              " 'power laws deep ensembles',\n",
              " 'practical quasi newton methods training deep neural networks',\n",
              " 'approximation based variance reduction reparameterization gradients',\n",
              " 'inference stage optimization cross scenario 3d human pose estimation',\n",
              " 'consistent feature selection analytic deep neural networks',\n",
              " 'glance focus dynamic approach reducing spatial redundancy image classification',\n",
              " 'information maximization few shot learning',\n",
              " 'inverse reinforcement learning gradient based learner',\n",
              " 'bayesian multi type mean field agent imitation learning',\n",
              " 'bayesian robust optimization imitation learning',\n",
              " 'multiview neural surface reconstruction disentangling geometry appearance',\n",
              " 'riemannian continuous normalizing flows',\n",
              " 'attention gated brain propagation implement reward based error backpropagation',\n",
              " 'asymptotic guarantees generative modeling based smooth wasserstein distance',\n",
              " 'online robust regression via sgd l1 loss',\n",
              " 'prank motion prediction based ranking',\n",
              " 'fighting copycat agents behavioral cloning observation histories',\n",
              " 'tight nonparametric convergence rates stochastic gradient descent noiseless linear model',\n",
              " 'structured prediction conditional meta learning',\n",
              " 'optimal lottery tickets via subset sum logarithmic over parameterization sufficient',\n",
              " 'hateful memes challenge detecting hate speech multimodal',\n",
              " 'stochasticity deterministic gradient descent large learning rate multiscale objective function',\n",
              " 'identifying learning rules neural network observables',\n",
              " 'optimal approximation smoothness tradeoffs soft max functions',\n",
              " 'weakly supervised reinforcement learning controllable behavior',\n",
              " 'improving policy constrained kidney exchange via pre screening',\n",
              " 'learning abstract structure drawing efficient motor program induction',\n",
              " 'deep residual networks generalize better feedforward neural tangent kernel perspective',\n",
              " 'dual instrumental variable regression',\n",
              " 'stochastic gradient descent correlated settings study gaussian processes',\n",
              " 'interventional few shot learning',\n",
              " 'minimax value interval off policy evaluation optimization',\n",
              " 'biased stochastic first order methods conditional optimization applications meta learning',\n",
              " 'shiftaddnet hardware inspired deep network',\n",
              " 'network to translation conditional invertible neural networks',\n",
              " 'intra processing methods debiasing neural networks',\n",
              " 'finding second order stationary points efficiently smooth nonconvex linearly constrained optimization problems',\n",
              " 'model based policy optimization unsupervised adaptation',\n",
              " 'implicit regularization convergence weight normalization',\n",
              " 'geometric all way boolean tensor decomposition',\n",
              " 'modular meta learning shrinkage',\n",
              " 'a b testing dense large scale networks design inference',\n",
              " 'neural networks memorize discovering long tail via influence estimation',\n",
              " 'partially view aligned clustering',\n",
              " 'partial optimal tranport applications positive unlabeled learning',\n",
              " 'toward fundamental limits imitation learning',\n",
              " 'logarithmic pruning need',\n",
              " 'hold tight influence discriminative features deep network boundaries',\n",
              " 'learning mixtures private public populations',\n",
              " 'adversarial weight perturbation helps robust generalization',\n",
              " 'stateful posted pricing vanishing regret via dynamic deterministic markov decision processes',\n",
              " 'adversarial self supervised contrastive learning',\n",
              " 'normalizing kalman filters multivariate time series analysis',\n",
              " 'learning summarize human feedback',\n",
              " 'fourier spectrum discrepancies deep network generated images',\n",
              " 'lamina specific neuronal properties promote robust stable signal propagation feedforward networks',\n",
              " 'learning dynamic belief graphs generalize text based games',\n",
              " 'triple descent two kinds overfitting appear',\n",
              " 'multimodal graph networks compositional generalization visual question answering',\n",
              " 'learning graph structure finite state automaton layer',\n",
              " 'universal approximation theorem deep neural networks expressing probability distributions',\n",
              " 'unsupervised object centric video generation decomposition 3d',\n",
              " 'domain generalization medical imaging classification linear dependency regularization',\n",
              " 'multi label classification hamming loss subset accuracy really conflict',\n",
              " 'novel automated curriculum strategy solve hard sokoban planning instances',\n",
              " 'causal analysis covid 19 spread germany',\n",
              " 'locally private non asymptotic testing discrete distributions faster using interactive mechanisms',\n",
              " 'adaptive gradient quantization data parallel sgd',\n",
              " 'finite continuum armed bandits',\n",
              " 'removing bias multi modal classifiers regularization maximizing functional entropies',\n",
              " 'compact task representations normative model higher order brain activity',\n",
              " 'robust adaptive control linear systems beyond quadratic costs',\n",
              " 'co exposure maximization online social networks',\n",
              " 'uclid net single view reconstruction object space',\n",
              " 'reinforcement learning control multiple frequencies',\n",
              " 'complex dynamics simple neural networks understanding gradient flow phase retrieval',\n",
              " 'neural message passing multi relational ordered recursive hypergraphs',\n",
              " 'unified view label shift estimation',\n",
              " 'optimal private median estimation minimal distributional assumptions',\n",
              " 'breaking communication privacy accuracy trilemma',\n",
              " 'audeo audio generation silent performance video',\n",
              " '',\n",
              " 'self distillation amplifies regularization hilbert space',\n",
              " 'coupling based invertible neural networks universal diffeomorphism approximators',\n",
              " 'community detection using fast low cardinality semidefinite programming',\n",
              " 'modeling noisy annotations crowd counting',\n",
              " 'operator view policy gradient methods',\n",
              " 'demystifying contrastive self supervised learning invariances augmentations dataset biases',\n",
              " 'online map inference determinantal point processes',\n",
              " 'video object segmentation adaptive feature bank uncertain region refinement',\n",
              " 'inferring learning rules animal decision making',\n",
              " 'input aware dynamic backdoor attack',\n",
              " 'hard distinguish graphs graph neural networks',\n",
              " 'minimax regret switching constrained online convex optimization phase transition',\n",
              " 'dual manifold adversarial robustness defense lp non attacks',\n",
              " 'cross scale internal graph neural network image super resolution',\n",
              " 'unsupervised representation learning invariance propagation',\n",
              " 'restoring negative information few shot object detection',\n",
              " 'adversarially robust imagenet models transfer better',\n",
              " 'robust correction sampling bias using cumulative distribution functions',\n",
              " 'personalized federated learning theoretical guarantees model agnostic meta approach',\n",
              " 'pixel level cycle association new perspective domain adaptive semantic segmentation',\n",
              " 'classification valid adaptive coverage',\n",
              " 'learning global transparent models consistent local contrastive explanations',\n",
              " 'learning approximate bregman divergence',\n",
              " 'diverse image captioning context object split latent spaces',\n",
              " 'learning disentangled representations videos missing data',\n",
              " 'natural graph networks',\n",
              " 'continual learning node importance based adaptive group sparse regularization',\n",
              " 'towards crowdsourced training large neural networks using decentralized mixture of experts',\n",
              " 'bidirectional convolutional poisson gamma dynamical systems',\n",
              " 'deep reinforcement infomax learning',\n",
              " 'ranking via sorting estimated expected utility',\n",
              " 'distribution free binary classification prediction sets confidence intervals calibration',\n",
              " 'closing dequantization gap pixelcnn single layer flow',\n",
              " 'sequence multi learning via conditional chain mapping mixture signals',\n",
              " 'variance reduction random coordinate descent langevin monte carlo',\n",
              " 'language cognitive tool imagine goals curiosity driven exploration',\n",
              " 'word embeddings one embedding',\n",
              " 'primal dual interpretation proximal stochastic gradient langevin algorithm',\n",
              " 'characterize landscape overparameterized convolutional neural networks',\n",
              " 'tightness semidefinite relaxations certifying robustness adversarial examples',\n",
              " 'submodular meta learning',\n",
              " 'rethinking pre training self',\n",
              " 'unsupervised sound separation using mixture invariant training',\n",
              " 'adaptive discretization model based reinforcement learning',\n",
              " 'codecmr cross modal retrieval function level binary source code matching',\n",
              " 'warm starting neural network training',\n",
              " 'dags fears closer look continuous optimization learning bayesian networks',\n",
              " 'ood maml meta learning few shot out of distribution detection classification',\n",
              " 'imitation observation approach transfer learning dynamics mismatch',\n",
              " 'learning objects interact',\n",
              " 'learning discrete distributions infinite support',\n",
              " 'dissecting neural odes',\n",
              " 'teaching gan learn',\n",
              " 'counterfactual data augmentation using locally factored dynamics',\n",
              " 'rethinking learnable tree filter generic feature transform',\n",
              " 'self supervised relational reasoning representation learning',\n",
              " 'sufficient dimension reduction classification using principal optimal transport direction',\n",
              " 'fast epigraphical projection based incremental algorithms wasserstein distributionally robust support vector machine',\n",
              " 'differentially private clustering tight approximation ratios',\n",
              " 'power louvain stochastic block model',\n",
              " 'fairness overlapping groups probabilistic perspective',\n",
              " 'attendlight universal attention based reinforcement learning model traffic signal control',\n",
              " 'searching low bit weights quantized neural networks',\n",
              " 'adaptive reduced rank regression',\n",
              " 'predictions decisions using lookahead regularization',\n",
              " 'sequential bayesian experimental design variable cost structure',\n",
              " 'predictive inference free jackknife after bootstrap',\n",
              " 'counterfactual predictions runtime confounding',\n",
              " 'learning loss test time augmentation',\n",
              " 'balanced meta softmax long tailed visual recognition',\n",
              " 'efficient exploration reward functions inverse reinforcement learning via bayesian optimization',\n",
              " 'mdp homomorphic networks group symmetries reinforcement learning',\n",
              " 'explain empirical study deep neural network explanation methods',\n",
              " 'error resistance hinge loss minimization',\n",
              " 'munchausen reinforcement learning',\n",
              " 'object goal navigation using oriented semantic exploration',\n",
              " 'efficient semidefinite programming based inference binary multi class mrfs',\n",
              " 'funnel transformer filtering sequential redundancy efficient language processing',\n",
              " 'semantic visual navigation watching youtube videos',\n",
              " 'heavy tailed representations text polarity classification data augmentation',\n",
              " 'superloss generic loss robust curriculum learning',\n",
              " 'cogmol target specific selective drug design covid 19 using deep generative models',\n",
              " 'memory based trajectory conditioned policies learning sparse rewards',\n",
              " 'liberty depth deep bayesian neural nets need complex weight posterior approximations',\n",
              " 'improving sample complexity bounds natural actor critic algorithms',\n",
              " 'learning differential equations easy solve',\n",
              " 'stability stochastic gradient descent nonsmooth convex losses',\n",
              " 'influence augmented online planning complex environments',\n",
              " 'pac bayes learning bounds sample dependent priors',\n",
              " 'reward rational implicit choice unifying formalism learning',\n",
              " 'probabilistic time series forecasting shape temporal diversity',\n",
              " 'low distortion block resampling spatially stochastic networks',\n",
              " 'continual deep learning functional regularisation memorable past',\n",
              " 'distance encoding design provably powerful neural networks graph representation learning',\n",
              " 'fast fourier convolution',\n",
              " 'unsupervised learning dense visual representations',\n",
              " 'higher order certification randomized smoothing',\n",
              " 'learning structured distributions untrusted batches faster simpler',\n",
              " 'hierarchical quantized autoencoders',\n",
              " 'diversity transferred output diversification white black box attacks',\n",
              " 'poly hoot monte carlo planning continuous space mdps non asymptotic analysis',\n",
              " 'ave assistance via empowerment',\n",
              " 'variational policy gradient method reinforcement learning general utilities',\n",
              " 'reverse engineering recurrent neural network solutions hierarchical inference task mice',\n",
              " 'temporal positive unlabeled learning biomedical hypothesis generation via risk estimation',\n",
              " 'efficient low rank gaussian variational inference neural networks',\n",
              " 'privacy amplification via random check ins',\n",
              " 'probabilistic circuits variational inference discrete graphical models',\n",
              " 'classifier secretly suffice multi source domain adaptation',\n",
              " 'labelling unlabelled videos scratch multi modal self supervision',\n",
              " 'non asymptotic analysis stein variational gradient descent',\n",
              " 'robust meta learning mixed linear regression small batches',\n",
              " 'bayesian deep learning probabilistic perspective generalization',\n",
              " 'unsupervised learning object landmarks via self training correspondence',\n",
              " 'randomized tests high dimensional regression efficient powerful solution',\n",
              " 'learning representations audio visual spatial alignment',\n",
              " 'generative view synthesis single semantics novel images',\n",
              " 'towards practical adversarial attacks graph neural networks',\n",
              " 'multi task reinforcement learning soft modularization',\n",
              " 'causal shapley values exploiting knowledge explain individual predictions complex models',\n",
              " 'training dynamics deep networks l 2 regularization',\n",
              " 'improved algorithms convex concave minimax optimization',\n",
              " 'deep variational instance segmentation',\n",
              " 'learning implicit functions topology varying dense 3d shape correspondence',\n",
              " 'deep multimodal fusion channel exchanging',\n",
              " 'hierarchically organized latent modules exploratory search morphogenetic systems',\n",
              " 'ai feynman 2 0 pareto optimal symbolic regression exploiting graph modularity',\n",
              " 'delay cooperation nonstochastic linear bandits',\n",
              " 'probabilistic orientation estimation matrix fisher distributions',\n",
              " 'minimax dynamics optimally balanced spiking networks excitatory inhibitory neurons',\n",
              " 'telescoping density ratio estimation',\n",
              " 'towards deeper graph neural networks differentiable group normalization',\n",
              " 'stochastic optimization performative prediction',\n",
              " 'learning differentiable programs admissible neural heuristics',\n",
              " 'improved guarantees multiple descent curve column subset selection nystrom method',\n",
              " 'domain adaptation problem inference graphical models',\n",
              " 'network size weights memorization two layers neural networks',\n",
              " 'certifying strategyproof auction networks',\n",
              " 'continual learning control primitives skill discovery via reset games',\n",
              " 'hoi analysis integrating decomposing human object interaction',\n",
              " 'strongly local p norm cut algorithms semi supervised learning graph clustering',\n",
              " 'deep direct likelihood knockoffs',\n",
              " '',\n",
              " 'neural dynamic policies end to sensorimotor learning',\n",
              " 'new inference approach training shallow deep generalized linear models noisy interacting neurons',\n",
              " 'decision making auto encoding variational bayes',\n",
              " 'attribution preservation network compression reliable interpretation',\n",
              " 'feature importance ranking deep learning',\n",
              " 'causal estimation functional confounders',\n",
              " 'model inversion networks based optimization',\n",
              " 'hausdorff dimension heavy tails generalization neural networks',\n",
              " 'exact expressions double descent implicit regularization via surrogate random design',\n",
              " 'certifying confidence via randomized smoothing',\n",
              " 'learning physical constraints neural projections',\n",
              " 'robust optimization fairness noisy protected groups',\n",
              " 'noise contrastive estimation multivariate point processes',\n",
              " 'game theoretic analysis empirical revenue maximization algorithm endogenous sampling',\n",
              " 'neural path features kernel understanding role gates deep learning',\n",
              " 'multiscale deep equilibrium models',\n",
              " 'sparse graphical memory robust planning',\n",
              " 'second order pac bayesian bounds weighted majority vote',\n",
              " 'dirichlet graph variational autoencoder',\n",
              " 'modeling task effects meaning representation brain via zero shot meg prediction',\n",
              " 'counterfactual vision and language navigation unravelling unseen',\n",
              " 'robust quantization one model rule',\n",
              " 'enabling certification verification agnostic networks via memory efficient semidefinite programming',\n",
              " 'federated accelerated stochastic gradient descent',\n",
              " 'robust density estimation besov ipm losses',\n",
              " 'analytic theory shallow networks dynamics hinge loss classification',\n",
              " 'fixed support wasserstein barycenters computational hardness fast algorithm',\n",
              " 'learning orient surfaces self supervised spherical cnns',\n",
              " 'adam bandit sampling deep learning',\n",
              " 'parabolic approximation line search dnns',\n",
              " 'agnostic learning single neuron gradient descent',\n",
              " 'statistical efficiency thompson sampling combinatorial semi bandits',\n",
              " 'analytic characterization hessian shallow relu models tale symmetry',\n",
              " 'generative causal explanations black box classifiers',\n",
              " 'sub sampling efficient non parametric bandit exploration',\n",
              " 'learning model misspecification applications variational ensemble methods',\n",
              " 'language prism spectral approach multiscale representations',\n",
              " 'dverge diversifying vulnerabilities enhanced robust generation ensembles',\n",
              " 'towards practical differentially private causal graph discovery',\n",
              " 'independent policy gradient methods competitive reinforcement learning',\n",
              " 'value equivalence principle model based reinforcement learning',\n",
              " 'structured convolutions efficient neural network design',\n",
              " 'latent world models intrinsically motivated exploration',\n",
              " 'estimating rank one spikes heavy tailed noise via self avoiding walks',\n",
              " 'policy improvement via imitation multiple oracles',\n",
              " 'training generative adversarial networks solving ordinary differential equations',\n",
              " 'learning discrete graphical models neural networks',\n",
              " 'reppoints v2 verification meets regression object detection',\n",
              " 'unfolding alternating optimization blind super resolution',\n",
              " 'entrywise convergence iterative methods eigenproblems',\n",
              " 'learning object centric representations multi scenes multiple views',\n",
              " 'catalyst framework minimax optimization',\n",
              " 'self supervised co training video representation learning',\n",
              " 'gradient estimation stochastic softmax tricks',\n",
              " 'meta learning requires augmentation',\n",
              " 'slip learning predict unknown dynamical systems long term memory',\n",
              " 'improving gan training probability ratio clipping sample reweighting',\n",
              " 'bayesian bits unifying quantization pruning',\n",
              " '',\n",
              " 'gaussian process bandit optimization thermodynamic variational objective',\n",
              " 'minilm deep self attention distillation task agnostic compression pre trained transformers',\n",
              " 'optimal epoch stochastic gradient descent ascent methods min max optimization',\n",
              " 'woodbury transformations deep generative flows',\n",
              " 'graph contrastive learning augmentations',\n",
              " 'gradient surgery multi task learning',\n",
              " 'bayesian probabilistic numerical integration tree based models',\n",
              " 'deep learning versus kernel empirical study loss landscape geometry time evolution neural tangent',\n",
              " 'graph meta learning via local subgraphs',\n",
              " 'stochastic deep gaussian processes graphs',\n",
              " 'bayesian causal structural learning zero inflated poisson networks',\n",
              " 'evaluating attribution graph neural networks',\n",
              " 'second order behaviour augmented neural odes',\n",
              " 'neuron shapley discovering responsible neurons',\n",
              " 'stochastic normalizing flows',\n",
              " 'gpu accelerated primal learning extremely fast large scale classification',\n",
              " 'random reshuffling always better',\n",
              " 'model agnostic multilevel explanations',\n",
              " 'neumiss networks differentiable programming supervised learning missing values',\n",
              " 'revisiting parameter sharing automatic neural channel number search',\n",
              " 'differentially private federated linear bandits',\n",
              " 'plug in solver sample efficient feature based reinforcement learning',\n",
              " 'learning physical graph representations visual scenes',\n",
              " 'deep graph pose semi supervised graphical model improved animal tracking',\n",
              " 'meta learning tasks heterogeneous attribute spaces',\n",
              " 'estimating decision tree learnability polylogarithmic sample complexity',\n",
              " 'sparse symplectically integrated neural networks',\n",
              " 'continuous object representation networks novel view synthesis without target supervision',\n",
              " 'multimodal generative learning utilizing jensen shannon divergence',\n",
              " 'solver in the loop learning differentiable physics interact iterative pde solvers',\n",
              " 'reinforcement learning general value function approximation provably efficient approach via bounded eluder dimension',\n",
              " 'predicting training time without',\n",
              " 'interaction affect interpretable attribution feature interactions',\n",
              " 'optimal adaptive electrode selection maximize simultaneously recorded neuron yield',\n",
              " 'neurosymbolic reinforcement learning formally verified exploration',\n",
              " 'wavelet flow fast training high resolution normalizing flows',\n",
              " 'multi task batch reinforcement learning metric',\n",
              " '1 n neural representation robustness',\n",
              " 'boundary thickness robustness learning models',\n",
              " 'demixed shared component analysis neural population data multiple brain areas',\n",
              " 'learning kernel tests without data splitting',\n",
              " 'unsupervised data augmentation consistency training',\n",
              " 'subgroup based rank 1 lattice quasi monte carlo',\n",
              " 'minibatch vs local sgd heterogeneous distributed learning',\n",
              " 'multi task causal learning gaussian processes',\n",
              " 'proximity operator matrix perspective function applications',\n",
              " 'generative 3d part assembly via dynamic graph learning',\n",
              " 'improving natural language processing tasks human gaze guided neural attention',\n",
              " 'power comparisons actively learning linear classifiers',\n",
              " 'boltzmann machines neural networks back',\n",
              " 'crush optimism pessimism structured bandits beyond asymptotic optimality',\n",
              " 'pruning neural networks without data iteratively conserving synaptic flow',\n",
              " 'detecting interactions neural networks via topological analysis',\n",
              " 'neural bridge sampling evaluating safety critical autonomous systems',\n",
              " 'interpretable personalized apprenticeship scheduling learning policies heterogeneous user demonstrations',\n",
              " 'task agnostic online reinforcement learning infinite mixture gaussian processes',\n",
              " 'benchmarking deep learning interpretability time series predictions',\n",
              " 'federated principal component analysis',\n",
              " 'de randomized smoothing certifiable defense patch attacks',\n",
              " 'smyrf efficient attention using asymmetric clustering',\n",
              " 'introducing routing uncertainty capsule networks',\n",
              " 'simple efficient smoothing method faster optimization local exploration',\n",
              " 'hyperparameter ensembles robustness uncertainty quantification',\n",
              " 'neutralizing self selection bias sampling sortition',\n",
              " 'convergence smooth regularized approximate value iteration schemes',\n",
              " 'off policy evaluation via regularized lagrangian',\n",
              " 'loca regret consistent metric evaluate model based behavior reinforcement learning',\n",
              " 'neural power units',\n",
              " 'towards scalable bayesian learning causal dags',\n",
              " 'dictionary approach domain invariant learning deep networks',\n",
              " 'bootstrapping neural processes',\n",
              " 'large scale adversarial training vision and language representation learning',\n",
              " 'relu networks suffer ell 2 adversarial perturbations',\n",
              " 'compositional visual generation energy based models',\n",
              " 'factor graph grammars',\n",
              " 'erdos goes neural unsupervised learning framework combinatorial optimization graphs',\n",
              " 'autoregressive score matching',\n",
              " 'debiasing distributed second order optimization surrogate sketching scaled regularization',\n",
              " 'neural controlled differential equations irregular time series',\n",
              " 'efficiency hierarchical reinforcement learning',\n",
              " 'correctness automatic differentiation non differentiable functions',\n",
              " 'probabilistic linear solvers machine learning',\n",
              " 'dynamic regret policy optimization non stationary environments',\n",
              " 'multipole graph neural operator parametric partial differential equations',\n",
              " 'blockgan learning 3d object aware scene representations unlabelled images',\n",
              " 'online structured meta learning',\n",
              " 'learning strategic network emergence games',\n",
              " 'towards interpretable natural language understanding explanations latent variables',\n",
              " 'mean squared error double q learning',\n",
              " 'makes good views contrastive learning',\n",
              " 'denoising diffusion probabilistic models',\n",
              " 'barking right tree approach search molecule synthesis dags',\n",
              " 'uniform convergence low norm interpolation learning',\n",
              " 'bandit samplers training graph neural networks',\n",
              " 'sampling k dpp without looking items',\n",
              " 'uncovering topology time varying fmri data using cubical persistence',\n",
              " 'hierarchical poset decoding compositional generalization language',\n",
              " 'evaluating rewarding teamwork using cooperative game abstractions',\n",
              " 'exchangeable neural ode set modeling',\n",
              " 'profile entropy fundamental measure learnability compressibility distributions',\n",
              " 'coadnet collaborative aggregation and distribution networks co salient object detection',\n",
              " 'regularized linear autoencoders recover principal components eventually',\n",
              " 'semi supervised partial label learning via confidence rated margin maximization',\n",
              " 'gramgan deep 3d texture synthesis 2d exemplars',\n",
              " 'uwsod toward fully supervised level capacity weakly object detection',\n",
              " 'learning restricted boltzmann machines sparse latent variables',\n",
              " 'sample complexity asynchronous q learning sharper analysis variance reduction',\n",
              " 'curriculum learning multilevel budgeted combinatorial problems',\n",
              " 'fedsplit algorithmic framework fast federated optimization',\n",
              " 'estimation imputation probabilistic principal component analysis missing random data',\n",
              " 'correlation robust influence maximization',\n",
              " 'neuronal gaussian process regression',\n",
              " 'nonconvex sparse graph learning laplacian constrained graphical model',\n",
              " 'synthetic data generators sequential private',\n",
              " 'uncertainty quantification inferring hawkes networks',\n",
              " 'implicit distributional reinforcement learning',\n",
              " 'auxiliary task reweighting minimum data learning',\n",
              " 'small nash equilibrium certificates large games',\n",
              " 'training linear finite state machines',\n",
              " 'efficient active learning sparse halfspaces arbitrary bounded noise',\n",
              " 'swapping autoencoder deep image manipulation',\n",
              " 'self supervised few shot learning point clouds',\n",
              " 'faster differentially private samplers via r nyi divergence analysis discretized langevin mcmc',\n",
              " 'learning identifiable interpretable latent models high dimensional neural activity using pi vae',\n",
              " 'rl unplugged suite benchmarks offline reinforcement learning',\n",
              " 'dual reducing estimation error transition matrix label noise learning',\n",
              " 'interior point solving lp based prediction optimisation',\n",
              " 'simple normative network approximates local non hebbian learning cortex',\n",
              " 'kernelized information bottleneck leads biologically plausible 3 factor hebbian learning deep networks',\n",
              " 'understanding role training regimes continual learning',\n",
              " 'fair regression wasserstein barycenters',\n",
              " 'training stronger baselines learning optimize',\n",
              " 'exactly computing local lipschitz constant relu networks',\n",
              " 'strictly batch imitation learning energy based distribution matching',\n",
              " 'ergodicity bias asymptotic normality randomized midpoint sampling method',\n",
              " 'single loop smoothed gradient descent ascent algorithm nonconvex concave min max problems',\n",
              " 'generating correct answers progressive matrices intelligence tests',\n",
              " 'hynet learning local descriptor hybrid similarity measure triplet loss',\n",
              " 'preference learning along multiple criteria game theoretic perspective',\n",
              " 'multi plane program induction 3d box priors',\n",
              " 'online neural connectivity estimation noisy group testing',\n",
              " 'once for all adversarial training in situ tradeoff robustness accuracy free',\n",
              " 'implicit neural representations periodic activation functions',\n",
              " 'rotated binary neural network',\n",
              " 'community detection sparse time evolving graphs dynamical bethe hessian',\n",
              " 'simple principled uncertainty estimation deterministic deep learning via distance awareness',\n",
              " 'adaptive learning rank one models efficient pairwise sequence alignment',\n",
              " 'hierarchical nucleation deep neural networks',\n",
              " 'fourier features let networks learn high frequency functions low dimensional domains',\n",
              " 'graph geometry interaction learning',\n",
              " 'differentiable augmentation data efficient gan training',\n",
              " 'heuristic domain adaptation',\n",
              " 'learning certified individually fair representations',\n",
              " 'part dependent label noise towards instance',\n",
              " 'tackling objective inconsistency problem heterogeneous federated optimization',\n",
              " 'improved analysis variance reduced policy gradient natural methods',\n",
              " 'geometric exploration online control',\n",
              " 'automatic curriculum learning value disagreement',\n",
              " 'mri banding removal via adversarial training',\n",
              " 'nethack learning environment',\n",
              " 'language visual entity relationship graph agent navigation',\n",
              " 'icam interpretable classification via disentangled representations feature attribution mapping',\n",
              " 'spectra conjugate kernel neural tangent linear width networks',\n",
              " 'no regret learning dynamics extensive form correlated equilibrium',\n",
              " 'estimating weighted areas roc curve',\n",
              " 'implicit bias explain generalization stochastic convex optimization case study',\n",
              " 'generalized hindsight reinforcement learning',\n",
              " 'critic regularized regression',\n",
              " 'boosting adversarial training hypersphere embedding',\n",
              " 'beyond homophily graph neural networks current limitations effective designs',\n",
              " 'modeling continuous stochastic processes dynamic normalizing flows',\n",
              " 'efficient online learning optimal rankings dimensionality reduction via gradient descent',\n",
              " 'training normalizing flows information bottleneck competitive generative classification',\n",
              " 'detecting hands recognizing physical contact wild',\n",
              " 'theory transfer learning importance task diversity',\n",
              " 'finite time analysis round robin kullback leibler upper confidence bounds optimal adaptive allocation multiple plays markovian rewards',\n",
              " 'neural star domain primitive representation',\n",
              " 'off policy interval estimation lipschitz value iteration',\n",
              " 'inverse rational control partially observable continuous nonlinear dynamics',\n",
              " 'deep statistical solvers',\n",
              " 'distributionally robust parametric maximum likelihood estimation',\n",
              " 'secretary online matching problems machine learned advice',\n",
              " 'deep transformation invariant clustering',\n",
              " 'overfitting harmless basis pursuit degree',\n",
              " 'improving generalization reinforcement learning mixture regularization',\n",
              " 'pontryagin differentiable programming end to learning control framework',\n",
              " 'learning aggregate observations',\n",
              " 'devil detail framework macroscopic prediction via microscopic models',\n",
              " 'subgraph neural networks',\n",
              " 'demystifying orthogonal monte carlo beyond',\n",
              " 'optimal robustness consistency trade offs learning augmented online algorithms',\n",
              " 'scalable approach privacy preserving collaborative machine learning',\n",
              " 'glow tts generative flow text to speech via monotonic alignment search',\n",
              " 'towards learning convolutions scratch',\n",
              " 'cycle contrast self supervised video representation learning',\n",
              " 'posterior re calibration imbalanced datasets',\n",
              " 'novelty search representational space sample efficient exploration',\n",
              " 'robust reinforcement learning via adversarial training langevin dynamics',\n",
              " 'adversarial blocking bandits',\n",
              " 'online algorithms multi shop ski rental machine learned advice',\n",
              " 'multi label contrastive predictive coding',\n",
              " 'rotation invariant local to global representation learning 3d point cloud',\n",
              " 'learning invariants soft unification',\n",
              " 'one solution need few shot extrapolation via structured maxent rl',\n",
              " 'variational bayesian monte carlo noisy likelihoods',\n",
              " 'finite sample analysis contractive stochastic approximation using smooth convex envelopes',\n",
              " 'self supervised generative adversarial compression',\n",
              " 'efficient nonconvex reformulation stagewise convex optimization problems',\n",
              " 'finite countable armed bandits',\n",
              " 'adversarial distributional training robust deep learning',\n",
              " 'meta learning stationary stochastic process prediction convolutional neural processes',\n",
              " 'theory inspired path regularized differential network architecture search',\n",
              " 'conic descent application memory efficient optimization positive semidefinite matrices',\n",
              " 'learning geometry wave based imaging',\n",
              " 'greedy inference structure exploiting lazy maps',\n",
              " 'nimble lightweight parallel gpu task scheduling deep learning',\n",
              " 'finding homology decision boundaries active learning',\n",
              " 'reinforced molecular optimization neighborhood controlled grammars',\n",
              " 'natural policy gradient primal dual method constrained markov decision processes',\n",
              " 'classification misspecification halfspaces generalized linear models evolvability',\n",
              " 'certified defense image transformations via randomized smoothing',\n",
              " 'estimation skill distribution tournament',\n",
              " 'reparameterizing mirror descent gradient',\n",
              " 'general control functions causal effect estimation ivs',\n",
              " 'optimal algorithms stochastic multi armed bandits heavy tailed rewards',\n",
              " 'certified robustness graph convolution networks classification topological attacks',\n",
              " 'zero resource knowledge grounded dialogue generation',\n",
              " 'targeted adversarial perturbations monocular depth prediction',\n",
              " 'beyond mean field structured deep gaussian processes improve predictive uncertainties',\n",
              " 'offline imitation learning misspecified simulator',\n",
              " 'multi fidelity bayesian optimization via deep neural networks',\n",
              " 'plangan model based planning sparse rewards multiple goals',\n",
              " 'bad global minima exist sgd reach',\n",
              " 'optimal prediction number unseen species multiplicity',\n",
              " 'characterizing optimal mixed policies intervene observe',\n",
              " 'factor graph neural networks',\n",
              " 'closer look accuracy vs robustness',\n",
              " 'curriculum learning dynamic instance hardness',\n",
              " 'spin weighted spherical cnns',\n",
              " 'learning execute programs instruction pointer attention graph neural networks',\n",
              " 'autoprivacy automated layer wise parameter selection secure neural network inference',\n",
              " 'baxter permutation process',\n",
              " 'characterizing emergent representations space candidate learning rules deep networks',\n",
              " 'fast accurate simple models tabular data via augmented distillation',\n",
              " 'adaptive probing policies shortest path routing',\n",
              " 'approximate heavily constrained learning lagrange multiplier models',\n",
              " 'faster randomized infeasible interior point methods tall wide linear programs',\n",
              " 'sliding window algorithms k clustering problems',\n",
              " 'adashare learning share efficient deep multi task',\n",
              " 'approximate cross validation structured models',\n",
              " 'exemplar vae linking generative models nearest neighbor retrieval data augmentation',\n",
              " 'debiased contrastive learning',\n",
              " 'ucsg net unsupervised discovering constructive solid geometry tree',\n",
              " '',\n",
              " 'cot gan generating sequential data via causal optimal transport',\n",
              " 'impossibility results grammar compressed linear algebra',\n",
              " 'understanding spiking networks convex optimization',\n",
              " 'better full matrix regret via parameter free online learning',\n",
              " 'large scale methods distributionally robust optimization',\n",
              " 'analysis design thompson sampling stochastic partial monitoring',\n",
              " 'bandit linear control',\n",
              " 'refactoring policy compositional generalizability using self supervised object proposals',\n",
              " 'pep parameter ensembling perturbation',\n",
              " 'theoretical insights multiclass classification high dimensional asymptotic view',\n",
              " 'adversarial example games',\n",
              " 'residual distillation towards portable deep neural networks without shortcuts',\n",
              " 'provably efficient neural estimation structural equation models adversarial approach',\n",
              " 'security analysis safe seldonian reinforcement learning algorithms',\n",
              " 'learning play sequential games versus unknown opponents',\n",
              " 'analysis outlier detection deep generative models',\n",
              " 'bridging imagination reality model based deep reinforcement learning',\n",
              " 'neural networks learning memorization almost over parameterization',\n",
              " 'exploiting higher order smoothness derivative free optimization continuous bandits',\n",
              " 'towards combinatorial characterization bounded memory learning',\n",
              " 'chaos extremism optimism volume analysis learning games',\n",
              " 'regret multiple best arms',\n",
              " 'matrix completion hierarchical graph side information',\n",
              " 'long horizon rl difficult short',\n",
              " 'hamiltonian monte carlo using adjoint differentiated laplace approximation bayesian inference latent gaussian models beyond',\n",
              " 'adversarial learning robust deep clustering',\n",
              " 'learning mutational semantics',\n",
              " 'learning learn variational semantic memory',\n",
              " '',\n",
              " 'learnability indirect supervision signals',\n",
              " 'towards safe policy improvement non stationary mdps',\n",
              " 'finer metagenomic reconstruction via biodiversity optimization',\n",
              " 'causal discovery physical systems videos',\n",
              " 'glyph fast accurately training deep neural networks encrypted data',\n",
              " 'smoothed analysis online differentially private learning',\n",
              " 'self paced deep reinforcement learning',\n",
              " 'kalman filtering attention user behavior modeling ctr prediction',\n",
              " 'towards maximizing representation gap in domain out of distribution examples',\n",
              " 'fully convolutional mesh autoencoder using efficient spatially varying kernels',\n",
              " 'gnnguard defending graph neural networks adversarial attacks',\n",
              " 'geo pifu geometry pixel aligned implicit functions single view human reconstruction',\n",
              " 'optimal visual search based model target detectability natural images',\n",
              " 'towards convergence rate analysis random forests classification',\n",
              " 'list decodable mean estimation via iterative multi filtering',\n",
              " 'exact recovery mangled clusters same cluster queries',\n",
              " 'steady state analysis episodic reinforcement learning',\n",
              " 'direct feedback alignment scales modern deep learning tasks architectures',\n",
              " 'bayesian optimization iterative learning',\n",
              " 'minimax bounds generalized linear models',\n",
              " 'projection robust wasserstein distance riemannian optimization',\n",
              " 'coindice off policy confidence interval estimation',\n",
              " 'simple fast algorithm binary integer online linear programming',\n",
              " 'learning diverse discriminative representations via principle maximal coding rate reduction',\n",
              " 'learning rich rankings',\n",
              " 'color visual illusions statistics based computational model',\n",
              " 'retrieval augmented generation knowledge intensive nlp tasks',\n",
              " 'universal guarantees decision tree induction via higher order splitting criterion',\n",
              " 'trade offs guarantees adversarial representation learning information obfuscation',\n",
              " 'boolean task algebra reinforcement learning',\n",
              " 'learning differentiable pertubed optimizers',\n",
              " 'optimal learning verified training data',\n",
              " 'online linear optimization many hints',\n",
              " 'dynamical mean field theory stochastic gradient descent gaussian mixture classification',\n",
              " 'causal discovery soft interventions unknown targets characterization learning',\n",
              " 'exploiting surrogate gap online multiclass classification',\n",
              " 'pitfalls simplicity bias neural networks',\n",
              " 'automatically learning compact quality aware surrogates optimization problems',\n",
              " 'empirical likelihood contextual bandits',\n",
              " 'q learning graph networks learn generalizable branching heuristic sat solver',\n",
              " 'non reversible gaussian processes identifying latent dynamical structure neural data',\n",
              " 'listening sounds silence speech denoising',\n",
              " 'boxe box embedding model knowledge base completion',\n",
              " 'coherent hierarchical multi label classification networks',\n",
              " 'walsh hadamard variational inference bayesian deep learning',\n",
              " 'federated bayesian optimization via thompson sampling',\n",
              " 'multion benchmarking semantic map memory using multi object navigation',\n",
              " 'neural complexity measures',\n",
              " 'optimal iterative sketching methods subsampled randomized hadamard transform',\n",
              " 'provably adaptive reinforcement learning metric spaces',\n",
              " 'shapeflow learnable deformation flows among 3d shapes',\n",
              " 'self supervised learning cross modal audio video clustering',\n",
              " 'optimal query complexity secure stochastic convex optimization',\n",
              " 'dynabert dynamic bert adaptive width depth',\n",
              " 'generalization bound gradient descent non convex metric learning',\n",
              " 'dynamic submodular maximization',\n",
              " 'inference batched bandits',\n",
              " 'approximate cross validation low rank data high dimensions',\n",
              " 'ganspace discovering interpretable gan controls',\n",
              " 'differentiable expected hypervolume improvement parallel multi objective bayesian optimization',\n",
              " 'neuron level structured pruning using polarization regularizer',\n",
              " 'limits testing structural changes ising models',\n",
              " 'field wise learning multi categorical data',\n",
              " 'continual learning low rank orthogonal subspaces',\n",
              " 'unsupervised learning visual features contrasting cluster assignments',\n",
              " 'sharpened generalization bounds based conditional mutual information application noisy iterative algorithms',\n",
              " 'learning deformable tetrahedral meshes 3d reconstruction',\n",
              " 'information theoretic limits learning sparse rule',\n",
              " 'self supervised learning eyes child',\n",
              " 'unsupervised semantic aggregation deformable template matching semi supervised learning',\n",
              " 'game theoretic analysis networked system control common pool resource management using multi agent reinforcement learning',\n",
              " 'shapes feature representations exploring datasets architectures training',\n",
              " 'optimal best arm identification linear bandits',\n",
              " 'data diversification simple strategy neural machine translation',\n",
              " 'interstellar searching recurrent architecture knowledge graph embedding',\n",
              " 'cose compositional stroke embeddings',\n",
              " 'learning multi agent coordination enhancing target coverage directional sensor networks',\n",
              " 'biological credit assignment dynamic inversion feedforward networks',\n",
              " 'discriminative sounding objects localization via self supervised audiovisual matching',\n",
              " 'learning multi agent communication structured attentive reasoning',\n",
              " 'private identity testing high dimensional distributions',\n",
              " 'optimal weighted ell 2 regularization overparameterized linear regression',\n",
              " 'efficient asynchronous method integrating evolutionary gradient based policy search',\n",
              " 'metasdf meta learning signed distance functions',\n",
              " 'simple scalable sparse k means clustering via feature ranking',\n",
              " 'model based adversarial meta reinforcement learning',\n",
              " 'graph policy network transferable active learning graphs',\n",
              " 'towards better global loss landscape gans',\n",
              " 'weighted qmix expanding monotonic value function factorisation deep multi agent reinforcement learning',\n",
              " 'banditpam almost linear time k medoids clustering via multi armed bandits',\n",
              " 'udh universal deep hiding steganography watermarking light field messaging',\n",
              " 'evidential sparsification multimodal latent spaces conditional variational autoencoders',\n",
              " 'unbiased risk estimator learning augmented classes',\n",
              " 'autobss efficient algorithm block stacking style search',\n",
              " 'pushing limits narrow precision inferencing cloud scale microsoft floating point',\n",
              " 'stochastic optimization laggard data pipelines',\n",
              " 'self supervised auxiliary learning meta paths heterogeneous graphs',\n",
              " 'gps net graph based photometric stereo network',\n",
              " 'consistent structural relation learning zero shot segmentation',\n",
              " 'model selection contextual stochastic bandit problems',\n",
              " 'truncated linear regression high dimensions',\n",
              " 'incorporating pragmatic reasoning communication emergent language',\n",
              " 'deep subspace clustering data augmentation',\n",
              " 'empirical process approach union bound practical algorithms combinatorial linear bandits',\n",
              " 'graph neural networks count substructures',\n",
              " 'bayesian perspective training speed model selection',\n",
              " '',\n",
              " 'doubly robust off policy value gradient estimation deterministic policies',\n",
              " 'provably efficient neural gtd off policy learning',\n",
              " 'learning discrete energy based models via auxiliary variable local exploration',\n",
              " 'stable expressive recurrent vision models',\n",
              " 'entropic optimal transport unbalanced gaussian measures closed form',\n",
              " 'brp nas prediction based using gcns',\n",
              " 'deep shells unsupervised shape correspondence optimal transport',\n",
              " 'ista nas efficient consistent neural architecture search sparse coding',\n",
              " 'rel3d minimally contrastive benchmark grounding spatial relations 3d',\n",
              " 'regularizing black box models improved interpretability',\n",
              " 'trust model confident masked based actor critic',\n",
              " 'semi supervised neural architecture search',\n",
              " 'consistency regularization certified robustness smoothed classifiers',\n",
              " 'robust multi agent reinforcement learning model uncertainty',\n",
              " 'siri spatial relation induced network description resolution',\n",
              " 'adaptive shrinkage estimation streaming graphs',\n",
              " 'make one shot video object segmentation efficient',\n",
              " 'depth uncertainty neural networks',\n",
              " 'non euclidean universal approximation',\n",
              " 'constraining variational inference geometric jensen shannon divergence',\n",
              " 'gibbs sampling people',\n",
              " 'hm ann efficient billion point nearest neighbor search heterogeneous memory',\n",
              " 'frugalml use ml prediction apis accurately cheaply',\n",
              " 'sharp representation theorems relu networks precise dependence depth',\n",
              " 'shared experience actor critic multi agent reinforcement learning',\n",
              " 'monotone operator equilibrium networks',\n",
              " 'lift lockdown global covid 19 scenario analysis policy assessment using compartmental gaussian processes',\n",
              " 'unsupervised learning lagrangian dynamics images prediction control',\n",
              " 'high dimensional sparse linear bandits',\n",
              " 'non stochastic control bandit feedback',\n",
              " 'generalized leverage score sampling neural networks',\n",
              " 'optimal elimination algorithm learning best arm',\n",
              " 'efficient projection free algorithms saddle point problems',\n",
              " 'mathematical model automatic differentiation machine learning',\n",
              " 'unsupervised text generation learning search',\n",
              " 'learning compositional rules via neural program synthesis',\n",
              " 'incorporating bert parallel sequence decoding adapters',\n",
              " 'estimating fluctuations neural representations uncertain environments',\n",
              " 'discover hallucinate adapt open compound domain adaptation semantic segmentation',\n",
              " 'surf simple universal robust fast distribution learning algorithm',\n",
              " 'understanding approximate fisher information fast convergence natural gradient descent wide neural networks',\n",
              " 'general transportability soft interventions completeness results',\n",
              " 'gait prop biologically plausible learning rule derived backpropagation error',\n",
              " 'lipschitz bounds provably robust training laplacian smoothing',\n",
              " 'scop scientific control reliable neural network pruning',\n",
              " 'provably consistent partial label learning',\n",
              " 'robust accurate stochastic optimization variational inference',\n",
              " 'discovering conflicting groups signed networks',\n",
              " 'learning popular gaussian graphical models without condition number bounds',\n",
              " 'sense sensitivity analysis simple post hoc bias due unobserved confounding',\n",
              " 'mix match optimistic tree search approach learning models mixture distributions',\n",
              " 'understanding double descent requires fine grained bias variance decomposition',\n",
              " 'vime extending success self semi supervised learning tabular domain',\n",
              " 'smoothed possibility social choice',\n",
              " 'decentralized parallel algorithm training generative adversarial nets',\n",
              " 'phase retrieval high dimensions statistical computational transitions',\n",
              " 'fair performance metric elicitation',\n",
              " 'hybrid variance reduced sgd algorithms minimax problems nonconvex linear function',\n",
              " 'belief dependent macro action discovery pomdps using value information',\n",
              " 'soft contrastive learning visual localization',\n",
              " 'fine grained dynamic head object detection',\n",
              " 'loco local contrastive representation learning',\n",
              " 'modeling optimization trade off meta learning',\n",
              " 'snapboost heterogeneous boosting machine',\n",
              " 'adaptive distance estimation',\n",
              " 'stage wise conservative linear bandits',\n",
              " 'relate physically plausible multi object scene synthesis using structured latent spaces',\n",
              " 'metric free individual fairness online learning',\n",
              " 'greedyfool distortion aware sparse adversarial attack',\n",
              " 'vaem deep generative model heterogeneous mixed type data',\n",
              " 'retroxpert decompose retrosynthesis prediction like chemist',\n",
              " 'sample efficient optimization latent space deep generative models via weighted retraining',\n",
              " 'improved sample complexity incremental autonomous exploration mdps',\n",
              " 'tinytl reduce memory parameters efficient on device learning',\n",
              " 'rd 2 reward decomposition representation',\n",
              " 'self paced contrastive learning hybrid memory domain adaptive object re id',\n",
              " 'fairness constraints help exact inference structured prediction',\n",
              " 'instance based generalization reinforcement learning',\n",
              " 'smooth consistent probabilistic regression trees',\n",
              " 'computing valid p value optimal changepoint selective inference using dynamic programming',\n",
              " 'factorized neural processes k shot prediction responses',\n",
              " 'winning lottery continuous sparsification',\n",
              " 'adversarial robustness via robust low rank representations',\n",
              " 'joints random forests',\n",
              " 'compositional generalization learning analytical expressions',\n",
              " 'jax md framework differentiable physics',\n",
              " 'implicit function learning approach parametric modal regression',\n",
              " 'sdf srn learning signed distance 3d object reconstruction static images',\n",
              " 'coresets robust training deep neural networks noisy labels',\n",
              " 'adapting misspecification contextual bandits',\n",
              " 'convergence meta learning task specific adaptation partial parameters',\n",
              " 'metaperturb transferable regularizer heterogeneous tasks architectures',\n",
              " 'learning solve tv regularised problems unrolled algorithms',\n",
              " 'object centric learning slot attention',\n",
              " 'improving robustness common corruptions covariate shift adaptation',\n",
              " 'deep smoothing implied volatility surface',\n",
              " 'probabilistic inference algebraic constraints theoretical limits practical approximations',\n",
              " 'provable online cp parafac decomposition structured tensor via dictionary learning',\n",
              " 'look ahead meta learning continual',\n",
              " 'polynomial time algorithm learning nonparametric causal graphs',\n",
              " 'sparse learning cart',\n",
              " 'proximal mapping deep regularization',\n",
              " 'identifying causal effect inference failure uncertainty aware models',\n",
              " 'hierarchical granularity transfer learning',\n",
              " 'deep active inference agents using monte carlo methods',\n",
              " 'consistent estimation identifiable nonparametric mixture models grouped observations',\n",
              " 'manifold structure graph embeddings',\n",
              " 'adaptive learned bloom filter ada bf efficient utilization classifier application real time information filtering web',\n",
              " 'mcunet tiny deep learning iot devices',\n",
              " 'search robust measures generalization',\n",
              " 'task agnostic exploration reinforcement learning',\n",
              " 'multi task additive models robust estimation automatic structure discovery',\n",
              " 'provably efficient reward agnostic navigation linear value iteration',\n",
              " 'softmax deep double deterministic policy gradients',\n",
              " 'online decision based visual tracking via reinforcement learning',\n",
              " 'efficient marginalization discrete structured latent variables via sparsity',\n",
              " 'deepi2i enabling deep hierarchical image to translation transferring gans',\n",
              " 'distributional robustness ipms links regularization gans',\n",
              " 'shooting formulation deep learning',\n",
              " 'csi novelty detection via contrastive learning distributionally shifted instances',\n",
              " 'learning implicit credit assignment cooperative multi agent reinforcement',\n",
              " 'mate plugging model awareness task embedding meta learning',\n",
              " 'restless ucb efficient low complexity algorithm online bandits',\n",
              " 'predictive information accelerates learning rl',\n",
              " 'robust heavy tailed mean estimation made simple via regret minimization',\n",
              " 'high fidelity generative image compression',\n",
              " 'statistical mechanics framework task agnostic sample design machine learning',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeYyWvkyTpFF"
      },
      "source": [
        "#### Store Data- Topics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "8uBeBb5eTrcd",
        "outputId": "29949cef-1f40-48de-9c40-d3ce831f4f6b"
      },
      "source": [
        "#Create a new dataFrame \n",
        "data = pd.DataFrame(columns = ['topic']) \n",
        "data['topic'] = topic_list\n",
        "\n",
        "#Show the data set\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>graph similarity deep learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>unsupervised information theoretic perceptual ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>self supervised multimodal versatile networks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>benchmarking deep inverse models time neural a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>off policy evaluation learning external validi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1893</th>\n",
              "      <td>distributed distillation on device learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1894</th>\n",
              "      <td>coot cooperative hierarchical transformer vide...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1895</th>\n",
              "      <td>passport aware normalization deep model protec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1896</th>\n",
              "      <td>sampling decomposable generative adversarial r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1897</th>\n",
              "      <td>limits depth efficiencies self attention</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1898 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  topic\n",
              "0                        graph similarity deep learning\n",
              "1     unsupervised information theoretic perceptual ...\n",
              "2         self supervised multimodal versatile networks\n",
              "3     benchmarking deep inverse models time neural a...\n",
              "4     off policy evaluation learning external validi...\n",
              "...                                                 ...\n",
              "1893        distributed distillation on device learning\n",
              "1894  coot cooperative hierarchical transformer vide...\n",
              "1895  passport aware normalization deep model protec...\n",
              "1896  sampling decomposable generative adversarial r...\n",
              "1897           limits depth efficiencies self attention\n",
              "\n",
              "[1898 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-gG02snUV_m"
      },
      "source": [
        "file_path = '/content/drive/Shared drives/1DeepContextGraph/1DeepContextGraph/code/data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWxP2vL_UZzd"
      },
      "source": [
        "data.to_csv(file_path+topic_file_name+str(ngramsCount)+'grams.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Sug89X_RnOR"
      },
      "source": [
        "### Topic Count Param Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBvxFt0dRqTL"
      },
      "source": [
        "topic_count = data.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXj_1vCiPvKQ"
      },
      "source": [
        "## 4.Topic Related Paper Search [.getRelatedPaper()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rahs7nD9y1Yd"
      },
      "source": [
        "### Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPq79bidTnH4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "424f0703-3e1d-4b6d-a9d3-36b2103792ab"
      },
      "source": [
        "!pip install newspaper3k"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting newspaper3k\n",
            "  Downloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▌                              | 10 kB 16.9 MB/s eta 0:00:01\r\u001b[K     |███                             | 20 kB 21.8 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 30 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 40 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 51 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 61 kB 32.9 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 71 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 81 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 92 kB 35.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 102 kB 35.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 112 kB 35.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 122 kB 35.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 133 kB 35.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 143 kB 35.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 153 kB 35.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 163 kB 35.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 174 kB 35.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 184 kB 35.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 194 kB 35.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 204 kB 35.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 211 kB 35.6 MB/s \n",
            "\u001b[?25hCollecting tinysegmenter==0.3\n",
            "  Downloading tinysegmenter-0.3.tar.gz (16 kB)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (7.1.2)\n",
            "Collecting tldextract>=2.0.1\n",
            "  Downloading tldextract-3.1.0-py2.py3-none-any.whl (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 5.5 MB/s \n",
            "\u001b[?25hCollecting feedfinder2>=0.0.4\n",
            "  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (5.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (2.8.1)\n",
            "Collecting cssselect>=0.9.2\n",
            "  Downloading cssselect-1.1.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (3.6.2)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (2.23.0)\n",
            "Collecting feedparser>=5.2.1\n",
            "  Downloading feedparser-6.0.8-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 8.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (4.6.3)\n",
            "Collecting jieba3k>=0.35.1\n",
            "  Downloading jieba3k-0.35.1.zip (7.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4 MB 32.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (4.2.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.15.0)\n",
            "Collecting sgmllib3k\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk>=3.2.1->newspaper3k) (4.41.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from nltk>=3.2.1->newspaper3k) (2019.8.19)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.2.1->newspaper3k) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk>=3.2.1->newspaper3k) (1.0.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k) (2021.5.30)\n",
            "Collecting requests-file>=1.4\n",
            "  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.0.12)\n",
            "Building wheels for collected packages: tinysegmenter, feedfinder2, jieba3k, sgmllib3k\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13551 sha256=1f85303fcd70923c1f269d373eef762c2b72d3ec772441c5f9c466285e79890f\n",
            "  Stored in directory: /root/.cache/pip/wheels/df/67/41/faca10fa501ca010be41b49d40360c2959e1c4f09bcbfa37fa\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3354 sha256=533524ae8880c29fd246f0b20aa412eb929b9b21f09acf2a7a22bf27bc477af0\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/d4/8f/6e2ca54744c9d7292d88ddb8d42876bcdab5e6d84a21c10346\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398404 sha256=e9e3fe3c1edb27dcec7959932d59d3392f8743334b9b9b8f90653a62787eaf32\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/91/46/3c208287b726df325a5979574324878b679116e4baae1af3c3\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6065 sha256=84fa26077befcd942b99243b3ba1730d96c82a61219a2ba40f96868af8e5092a\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/ad/a4/0dff4a6ef231fc0dfa12ffbac2a36cebfdddfe059f50e019aa\n",
            "Successfully built tinysegmenter feedfinder2 jieba3k sgmllib3k\n",
            "Installing collected packages: sgmllib3k, requests-file, tldextract, tinysegmenter, jieba3k, feedparser, feedfinder2, cssselect, newspaper3k\n",
            "Successfully installed cssselect-1.1.0 feedfinder2-0.0.4 feedparser-6.0.8 jieba3k-0.35.1 newspaper3k-0.2.8 requests-file-1.5.1 sgmllib3k-1.0.0 tinysegmenter-0.3 tldextract-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DGjgrtrVNfv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac7d3c55-5b9d-46d9-c1b9-63a4d02847c4"
      },
      "source": [
        "!pip install sent2vec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sent2vec\n",
            "  Downloading sent2vec-0.2.0-py3-none-any.whl (5.2 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from sent2vec) (1.9.0+cu102)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sent2vec) (1.19.5)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (from sent2vec) (2.3.4)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (from sent2vec) (4.9.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from sent2vec) (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->sent2vec) (5.1.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim->sent2vec) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim->sent2vec) (1.15.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy->sent2vec) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->sent2vec) (2.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy->sent2vec) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy->sent2vec) (2.23.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->sent2vec) (0.4.1)\n",
            "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy->sent2vec) (7.4.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy->sent2vec) (57.2.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->sent2vec) (3.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->sent2vec) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->sent2vec) (0.8.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy->sent2vec) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy->sent2vec) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->sent2vec) (4.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy->sent2vec) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy->sent2vec) (3.5.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->sent2vec) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->sent2vec) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->sent2vec) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->sent2vec) (2.10)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->sent2vec) (2019.8.19)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers->sent2vec) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers->sent2vec) (21.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers->sent2vec) (5.4.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers->sent2vec) (0.0.13)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers->sent2vec) (0.10.3)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers->sent2vec) (0.0.12)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers->sent2vec) (2.4.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->sent2vec) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->sent2vec) (7.1.2)\n",
            "Installing collected packages: sent2vec\n",
            "Successfully installed sent2vec-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIpGURz6ZkHi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3059b1d4-516d-482b-ef43-7111f98619c7"
      },
      "source": [
        "import json\n",
        "import os\n",
        "# For caculating approximate time to process notebook (IGNORE)\n",
        "import datetime\n",
        "datetime.datetime.now()\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import operator\n",
        "import pickle as pkl \n",
        "import matplotlib.pyplot as plt\n",
        "import nltk as nl\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "import statistics\n",
        "import random\n",
        "import warnings\n",
        "from string import punctuation\n",
        "from matplotlib import pyplot\n",
        "from pandas import Series, datetime\n",
        "from pandas.plotting import scatter_matrix, autocorrelation_plot\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV, TimeSeriesSplit\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, mean_squared_error\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "import nltk\n",
        "import re\n",
        "import io\n",
        "import requests\n",
        "import time\n",
        "import gensim\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "import nltk.sentiment\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('vader_lexicon')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYX-M6bRTqcF"
      },
      "source": [
        "from newspaper import fulltext\n",
        "import requests"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XscK1daMVQo8"
      },
      "source": [
        "from scipy import spatial\n",
        "from sent2vec.vectorizer import Vectorizer\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFu-NFDKAY1b"
      },
      "source": [
        "#### LDA setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vabu7Te_AbFD",
        "outputId": "5df60c68-73f0-454a-c18a-26223ec2024b"
      },
      "source": [
        "!pip install sentence-transformers\n",
        "!pip install LexRank\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "\n",
        "from lexrank import STOPWORDS, LexRank\n",
        "from path import Path\n",
        "import json\n",
        "import os\n",
        "# For caculating approximate time to process notebook (IGNORE)\n",
        "import datetime\n",
        "datetime.datetime.now()\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import operator\n",
        "import pickle as pkl \n",
        "import matplotlib.pyplot as plt\n",
        "import nltk as nl\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "import statistics\n",
        "import random\n",
        "import warnings\n",
        "from string import punctuation\n",
        "from matplotlib import pyplot\n",
        "from pandas import Series, datetime\n",
        "from pandas.plotting import scatter_matrix, autocorrelation_plot\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV, TimeSeriesSplit\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, mean_squared_error\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from spacy import displacy \n",
        "import nltk\n",
        "import re\n",
        "import io\n",
        "import requests\n",
        "import time\n",
        "import gensim\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "import nltk.sentiment\n",
        "#from sentence_transformers import SentenceTransformer, util\n",
        "import numpy as np\n",
        "import spacy\n",
        "from spacy.lang.en import English\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('brown')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.7/dist-packages (2.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.9.0+cu102)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.9.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.0.12)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.10.0+cu102)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.1.96)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.41.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.6.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.23.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (5.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.10.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (4.6.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.0.13)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2019.8.19)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.5.30)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: LexRank in /usr/local/lib/python3.7/dist-packages (0.1.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from LexRank) (1.19.5)\n",
            "Requirement already satisfied: urlextract>=0.7 in /usr/local/lib/python3.7/dist-packages (from LexRank) (1.3.0)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from LexRank) (0.18.0)\n",
            "Requirement already satisfied: regex>=2017.11.9 in /usr/local/lib/python3.7/dist-packages (from LexRank) (2019.8.19)\n",
            "Requirement already satisfied: path.py>=10.5 in /usr/local/lib/python3.7/dist-packages (from LexRank) (12.5.0)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from LexRank) (1.4.1)\n",
            "Requirement already satisfied: path in /usr/local/lib/python3.7/dist-packages (from path.py>=10.5->LexRank) (16.2.0)\n",
            "Requirement already satisfied: uritools in /usr/local/lib/python3.7/dist-packages (from urlextract>=0.7->LexRank) (3.0.2)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from urlextract>=0.7->LexRank) (1.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from urlextract>=0.7->LexRank) (2.10)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from urlextract>=0.7->LexRank) (3.0.12)\n",
            "Collecting en_core_web_sm==2.3.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 27.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<2.4.0,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.3.1) (2.3.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.19.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n",
            "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (57.2.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.24.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StXkVX4FQBDK"
      },
      "source": [
        "### Data Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1nZLsfSQC-H"
      },
      "source": [
        "df = data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bb7TyZj6f2K"
      },
      "source": [
        "### Google Custom Search API\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw0vW6TDH0e5"
      },
      "source": [
        "* Ref:  https://www.simplifiedpython.net/google-custom-search-api-python/#:~:text=The%20Custom%20Search%20JSON%20API,search%20results%20in%20JSON%20format.\n",
        "\n",
        "* CSE link: https://cse.google.com/cse/setup/basic?cx=d0515d2f05012bdbc\n",
        "\n",
        "* Google Search API: https://console.cloud.google.com/apis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSl5t_lKIH2i"
      },
      "source": [
        "#### Information\n",
        "\n",
        "projectname: deepcontext\n",
        "api key name: APIkey1\n",
        "api key= AIzaSyBDX5Zv8L1Pk-XuTNQ0qd2uPXpf_-xFIhE\n",
        "custom search engine name: custom_search_engine\n",
        "search engine id: d0515d2f05012bdbc\n",
        "Public URL= https://cse.google.com/cse?cx=d0515d2f05012bdbc "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waXPXuuoILfa"
      },
      "source": [
        "#### Env Set-up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RRSjqQ4G2wz",
        "outputId": "7a17d34c-781e-46f9-beb0-9d46f2d81b4b"
      },
      "source": [
        "pip install google-api-python-client"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.7/dist-packages (1.12.8)\n",
            "Requirement already satisfied: six<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client) (1.15.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client) (0.0.4)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client) (1.26.3)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client) (3.0.1)\n",
            "Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client) (1.32.1)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client) (0.17.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client) (1.53.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client) (2018.9)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client) (3.17.3)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client) (57.2.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client) (21.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client) (2.23.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client) (4.7.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.21.0->google-api-python-client) (2.4.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.16.0->google-api-python-client) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "st_3KZq4pmge"
      },
      "source": [
        "from googleapiclient.discovery import build\n",
        "import pprint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcpfXuTRIeCb"
      },
      "source": [
        "####  Custom Search Engine Key Set-up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75Ttz_nMG7Ki"
      },
      "source": [
        "#define key\n",
        "api_key = \"AIzaSyBbL96aJjiBbDkqGj8qB-cTfzd3Pq6XBLs\"#\"AIzaSyBDX5Zv8L1Pk-XuTNQ0qd2uPXpf_-xFIhE\"\n",
        "cse_key = \"4fb333d2d04344b4c\" #\"d0515d2f05012bdbc\"\n",
        " \n",
        "resource = build(\"customsearch\", 'v1', developerKey=api_key).cse()\n",
        "\n",
        " \n",
        "#pprint.pprint(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5BuIUfZ1X5g"
      },
      "source": [
        "### Text Distillation Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9zg6DzVyV1Q"
      },
      "source": [
        "#### Lemmatization\n",
        "  \n",
        "First, the raw words must be converted to root forms.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qs9YyZ8WygUo"
      },
      "source": [
        "def lemmatize(tokenized_words):\n",
        "  text = [nltk.WordNetLemmatizer().lemmatize(word) for word in tokenized_words]\n",
        "  return text\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRnq7Orw5sSW"
      },
      "source": [
        "#### Removing Stop words\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7axUBcsp5yXD"
      },
      "source": [
        "english_stopwords = set(stopwords.words('english') + list(punctuation) + [''])\n",
        "\n",
        "def remove_stopwords(tokenized_words):\n",
        "  text = [word for word in tokenized_words if word not in english_stopwords]\n",
        "  return text\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejCglovYHwyb"
      },
      "source": [
        "#### Custom Filtering\n",
        "\n",
        "Some of the one or two-letter words from the tokenized words are also removed to further cleanse the raw text. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9ujoC42HwGM"
      },
      "source": [
        "whitelist = set(['ai', 'ax', 'ca', 'eu', 'go', 'io', 'la', 'ox', 'us', 'uk', \n",
        "                 'al', 'ak', 'az', 'ar', 'ca', 'co', 'ct', 'de', 'fl', 'ga', 'hi', \n",
        "                 'id', 'il', 'in', 'ia', 'ks', 'ky', 'la', 'me', 'md', 'ma', 'mi',\n",
        "                 'mn', 'ms', 'mo', 'mt', 'ne', 'nv', 'nh', 'nj', 'nm', 'ny',\n",
        "                 'nc', 'nd', 'oh', 'ok', 'or', 'pa', 'ri', 'sc', 'sd', 'tn',\n",
        "                 'tx', 'ut', 'vt', 'va', 'wa', 'wv', 'wi', 'wy' ])\n",
        "def remove_too_short(tokenized_words):\n",
        "  text = [word for word in tokenized_words if (len(word) >= 3 or word not in whitelist) ]\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGmEhyrkC0e5"
      },
      "source": [
        "#### LDA Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7Fdvch1EjQ4"
      },
      "source": [
        "from gensim.models.ldamodel import LdaModel\n",
        "from gensim.corpora import Dictionary\n",
        "\n",
        "def topics(tokenized_words):\n",
        "    d = Dictionary([tokenized_words])\n",
        "    c = [d.doc2bow(tokenized_words)]\n",
        "    m = LdaModel(c, num_topics=1, id2word=d)\n",
        "    return list(m.print_topics(num_words=2))\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ze4YTpBLultl"
      },
      "source": [
        "#### Topics as Simple List of Words\n",
        "\n",
        "A list of topic terms is compiled as show below. The coefficients in front of each word are dropped as part of simplification. The assumption is that the top two words comprising the topic, are both significant enough to be treated equally. It is important that the goal is to build a reliable prediction model. While there is a risk of oversimplification, if the final model results in a poor accuracy score, the coefficient can always be reintroduced here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1fxmdcyuqoB"
      },
      "source": [
        "def parseTopics(topics):\n",
        "   output = []\n",
        "   words = topics[0][1].split( '+' )\n",
        "   for word in words:\n",
        "       output.append( word.split('*')[1].replace( '\"', '' ) )\n",
        "   return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCwJ0YL7WMEX"
      },
      "source": [
        "#### similarity computation method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txrkD2BxFgUQ"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def method_3_with_sentence_sim_avg(topic,data_2,column_name):\n",
        "  similarity_list = []\n",
        "  i = 0\n",
        "  j= 0\n",
        "\n",
        "  #id = row['most_similar'][0][0]\n",
        "  max_sim = (-math.inf)\n",
        "  max_index = -1\n",
        "  #print(\"\\njoin(row1['text_distilled']=\" , text1)\n",
        "\n",
        "  #vectorize for bert\n",
        "  vectorizer.bert(data_1.iloc[0]['topic'])\n",
        "  vectors_bert1 = vectorizer.vectors\n",
        "  for index2, row2 in data_2.iterrows():\n",
        "    text2 = \"\".join(row2[column_name])\n",
        "\n",
        "    #vectorize for bert\n",
        "    vectorizer.bert(row2[column_name])\n",
        "    vectors_bert2 = vectorizer.vectors\n",
        "\n",
        "    x = vectors_bert1.reshape(1,-1)\n",
        "    y = vectors_bert2.reshape(1,-1)\n",
        "    sim = cosine_similarity(vectors_bert1, vectors_bert2)\n",
        "    sim_reshape = sim.reshape(1,-1)\n",
        "    sim_avg = np.mean(sim_reshape)\n",
        "    #print(sim_avg)\n",
        "        \n",
        "    max_sim = sim_avg\n",
        "    max_index = index2\n",
        "    j= 1\n",
        "    similarity_list.append((max_index,max_sim))\n",
        "      \n",
        "  return similarity_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4zKGRhV97up"
      },
      "source": [
        "#### LDA Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etoUCdfO-ACD",
        "outputId": "8095b827-0b5a-40a1-8812-626acebdfa94"
      },
      "source": [
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stopwords = stopwords.words('english')\n",
        "\n",
        "def join_tokens(list_of_tokens):\n",
        "    outstr = TreebankWordDetokenizer().detokenize(list_of_tokens)\n",
        "    return outstr\n",
        "\n",
        "def filter_stopwords_from_list(titles):\n",
        "    word_list = titles\n",
        "    title_list = []\n",
        "    new_word_list = []\n",
        "    new_title_list= []\n",
        "    for title in titles:\n",
        "            #print (title)\n",
        "            title_list =  nltk.word_tokenize(title)\n",
        "            #print (words)\n",
        "            for word in title_list:\n",
        "                print (word)\n",
        "                if word.lower() not in stopwords:\n",
        "                    new_word_list.append(word)\n",
        "                    #print(\"joined {} :\".format(word))\n",
        "            #print (\"new title list :\",new_word_list)\n",
        "            new_title = join_tokens(new_word_list)\n",
        "            #print (\"\\n New title : \", new_title)\n",
        "            new_word_list =[]\n",
        "            # print (\"old : {}  \\n -----> new : {}\\n\\n\".format(title, new_title))\n",
        "            new_title_list.append(new_title)\n",
        "    # print (\"========================\\n\")\n",
        "    # print (\"new list of titles: \\n: ===> \",new_title_list )\n",
        "    return new_title_list\n",
        "        #print (new_line)\n",
        "        #filtered_words = [word for word in words if word.lower() not in stopwords]\n",
        "        #print (words)\n",
        "\n",
        "# receives a list of texts and creates n-grams for each of the text as well as for the entire corpus\n",
        "def getNGramsConcat(lstText, ngramsCount):\n",
        "  import re\n",
        "  from nltk.util import ngrams\n",
        "  s = \" \".join(lstText) # this may be needed to crea\n",
        "  s = s.lower()\n",
        "  s = re.sub(r'[^a-zA-Z0-9\\s]', ' ', s)\n",
        "  tokens = [token for token in s.split(\" \") if token != \"\"]\n",
        "  corpusNGrams = list(ngrams(tokens, ngramsCount))\n",
        "  corpusNGramsConcat = [\"-\".join(e) for e in corpusNGrams]\n",
        "\n",
        "  txtNGrams = []\n",
        "  txtNGramsConcat = []\n",
        "  for t in lstText:\n",
        "    t2 = t.lower()\n",
        "    t2 = re.sub(r'[^a-zA-Z0-9\\s]', ' ', t2)\n",
        "    tokens2 = [token2 for token2 in t2.split(\" \") if token2 != \"\"]\n",
        "    ng = list(ngrams(tokens2, ngramsCount))\n",
        "    txtNGrams.append(ng)\n",
        "    txtNGramsConcat.append( [\"-\".join(e) for e in ng])\n",
        "\n",
        "  return (txtNGramsConcat, corpusNGramsConcat)\n",
        "\n",
        "# titles = dfEvents[\"title\"]\n",
        "# filteredTitles = filter_stopwords_from_list(titles)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gp86D59E_Aod"
      },
      "source": [
        "import numpy as np\n",
        "from gensim import corpora, models\n",
        "def runLDA(doc_set, numOfTopics): # source: https://rstudio-pubs-static.s3.amazonaws.com/79360_850b2a69980c4488b1db95987a24867a.html  (modified by Renato)\n",
        "    \n",
        "    np.random.seed(1) # LDA uses randomness in its calculation. Setting fixed seed to make sure we always get the same result\n",
        "    \n",
        "    from nltk.tokenize import RegexpTokenizer\n",
        "    from stop_words import get_stop_words\n",
        "    from nltk.stem.porter import PorterStemmer\n",
        "    from gensim import corpora, models\n",
        "    import gensim\n",
        "\n",
        "\n",
        "    tokenizer = RegexpTokenizer(r'[\\w-]+')\n",
        "\n",
        "    # create English stop words list\n",
        "    en_stop = get_stop_words('en')\n",
        "\n",
        "    # Create p_stemmer of class PorterStemmer\n",
        "    # p_stemmer = PorterStemmer()\n",
        "\n",
        "   \n",
        "    # list for tokenized documents in loop\n",
        "    texts = []\n",
        "\n",
        "    # loop through document list\n",
        "    for d in doc_set:\n",
        "        d = \" \".join(d)\n",
        "        # # removing \"'\"\n",
        "        # d = d.replace(\"'\", \"\")\n",
        "           \n",
        "        # clean and tokenize document string\n",
        "        raw = d.lower()\n",
        "        tokens = tokenizer.tokenize(raw)\n",
        "\n",
        "        # remove stop words from tokens\n",
        "        # stopped_tokens = [i for i in tokens if not i in en_stop]\n",
        "\n",
        "        # stem tokens\n",
        "        # stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
        "     \n",
        "        # add tokens to list\n",
        "        # texts.append(stemmed_tokens)\n",
        "        texts.append(tokens)\n",
        "\n",
        "    # turn our tokenized documents into a id <-> term dictionary\n",
        "    dictionary = corpora.Dictionary(texts)\n",
        "    \n",
        "    # TODO: removing high frequency words\n",
        "    #dictionary.filter_extremes(no_below=1, no_above=0.6, keep_n=1)\n",
        "\n",
        "    # convert tokenized documents into a document-term matrix\n",
        "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
        "\n",
        "    # generate LDA model\n",
        "    ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=numOfTopics, id2word = dictionary, passes=20)\n",
        "    \n",
        "    return ldamodel, texts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdFgH0eeB2ob"
      },
      "source": [
        "def topic_build(topn_words):\n",
        "  topic_list = []\n",
        "  for key in topn_words.keys():\n",
        "    temp_str = ''\n",
        "    j_len = len(topn_words[key])\n",
        "    #print(topn_words[key])\n",
        "    for j in range(j_len):\n",
        "      temp_str = temp_str +' ' +topn_words[key][j].replace('-', ' ')\n",
        "    #print(temp_str)\n",
        "    topic_list.append(temp_str.strip())\n",
        "  return topic_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvHMZbYBBtdT"
      },
      "source": [
        "#remove duplicate\n",
        "def remove_duplicate_word(s):\n",
        "  l = s.split()\n",
        "  k = []\n",
        "  for i in l:\n",
        "      # If condition is used to store unique string \n",
        "      # in another list 'k' \n",
        "      if (s.count(i)>1 and (i not in k) or s.count(i)==1):\n",
        "          k.append(i)\n",
        "  #print(' '.join(k))\n",
        "  return ' '.join(k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IF2j7Um7jp_z"
      },
      "source": [
        "#### Scrape from PDF Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUolm2M3kMCm",
        "outputId": "bbe01044-0270-4de6-9072-ee7af2086011"
      },
      "source": [
        "!pip install pdfminer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pdfminer\n",
            "  Downloading pdfminer-20191125.tar.gz (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 27.5 MB/s \n",
            "\u001b[?25hCollecting pycryptodome\n",
            "  Downloading pycryptodome-3.10.1-cp35-abi3-manylinux2010_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 45.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pdfminer\n",
            "  Building wheel for pdfminer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pdfminer: filename=pdfminer-20191125-py3-none-any.whl size=6140084 sha256=48885234c8c9a2c0d4dfbac8fea5c0abb6dea1fa80d67a6675792ccc5354c3d4\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/5e/f4/d210b46e9e4a28229ea070ed5b3efa92c3c29d1a7918dd4b97\n",
            "Successfully built pdfminer\n",
            "Installing collected packages: pycryptodome, pdfminer\n",
            "Successfully installed pdfminer-20191125 pycryptodome-3.10.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StMBMMy-j1Os"
      },
      "source": [
        "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
        "from pdfminer.converter import TextConverter\n",
        "from pdfminer.layout import LAParams\n",
        "from pdfminer.pdfpage import PDFPage\n",
        "from io import StringIO\n",
        "\n",
        "class PdfConverter:\n",
        "\n",
        "   def __init__(self, file_path):\n",
        "       self.file_path = file_path\n",
        "# convert pdf file to a string which has space among words \n",
        "   def convert_pdf_to_txt(self):\n",
        "       rsrcmgr = PDFResourceManager()\n",
        "       retstr = StringIO()\n",
        "       codec = 'utf-8'  # 'utf16','utf-8'\n",
        "       laparams = LAParams()\n",
        "       device = TextConverter(rsrcmgr, retstr,  laparams=laparams) #codec=codec,\n",
        "       fp = open(self.file_path, 'rb')\n",
        "       interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
        "       password = \"\"\n",
        "       maxpages = 0\n",
        "       caching = True\n",
        "       pagenos = set()\n",
        "       for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages, password=password, caching=caching, check_extractable=True):\n",
        "           interpreter.process_page(page)\n",
        "       fp.close()\n",
        "       device.close()\n",
        "       str = retstr.getvalue()\n",
        "       retstr.close()\n",
        "       \n",
        "       text =str\n",
        "       word1 = 'Abstract'\n",
        "       word2 = 'Introduction'\n",
        "       abstract_text = \"\"\n",
        "       #print(text.index(word1))\n",
        "       #print(text.index(word2))\n",
        "       try:\n",
        "          abstract_text = text[text.index(word1):text.index(word2)]\n",
        "          return abstract_text\n",
        "       #print(abstract_text)\n",
        "       except:\n",
        "          abstract_text = \"No Text\"\n",
        "          return abstract_text\n",
        "# convert pdf file text to string and save as a text_pdf.txt file\n",
        "   def save_convert_pdf_to_txt(self):\n",
        "       content = self.convert_pdf_to_txt()\n",
        "       txt_pdf = open('./example.txt', 'wb')\n",
        "       txt_pdf.write(content.encode('utf-8'))\n",
        "       txt_pdf.close()\n",
        "# if __name__ == '__main__':\n",
        "#     pdfConverter = PdfConverter(file_path='./example.pdf')\n",
        "#     print(pdfConverter.convert_pdf_to_txt())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKRO18actPQg"
      },
      "source": [
        "### Loop to find the topic related paper with rank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "5gHeQlTumLDt",
        "outputId": "1d980f68-450c-4b66-d547-dff15da4ac98"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>graph similarity deep learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>unsupervised information theoretic perceptual ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>self supervised multimodal versatile networks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>benchmarking deep inverse models time neural a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>off policy evaluation learning external validi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1893</th>\n",
              "      <td>distributed distillation on device learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1894</th>\n",
              "      <td>coot cooperative hierarchical transformer vide...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1895</th>\n",
              "      <td>passport aware normalization deep model protec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1896</th>\n",
              "      <td>sampling decomposable generative adversarial r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1897</th>\n",
              "      <td>limits depth efficiencies self attention</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1898 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  topic\n",
              "0                        graph similarity deep learning\n",
              "1     unsupervised information theoretic perceptual ...\n",
              "2         self supervised multimodal versatile networks\n",
              "3     benchmarking deep inverse models time neural a...\n",
              "4     off policy evaluation learning external validi...\n",
              "...                                                 ...\n",
              "1893        distributed distillation on device learning\n",
              "1894  coot cooperative hierarchical transformer vide...\n",
              "1895  passport aware normalization deep model protec...\n",
              "1896  sampling decomposable generative adversarial r...\n",
              "1897           limits depth efficiencies self attention\n",
              "\n",
              "[1898 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKLOcws6mPBb"
      },
      "source": [
        "#topic_count =2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2QTSH1rXSjx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "159f4b7c-4f2c-443c-d7ae-35acfd3c7171"
      },
      "source": [
        "cols = ['topic', 'title', 'text','url',  'similarity_score','rank',\n",
        "        'similarity_score_lda',\t'rank_lda']\n",
        "df_output = pd.DataFrame(columns=cols)\n",
        "df_output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>topic</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>url</th>\n",
              "      <th>similarity_score</th>\n",
              "      <th>rank</th>\n",
              "      <th>similarity_score_lda</th>\n",
              "      <th>rank_lda</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [topic, title, text, url, similarity_score, rank, similarity_score_lda, rank_lda]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3wdijWKnuD9"
      },
      "source": [
        "from joblib import Memory\n",
        "from pathlib import Path\n",
        "# !pip install requests\n",
        "import requests"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21LubTeWprxH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d51b511c737b41ab846a167d5e934f34",
            "c22662fda94f4efd92ae372e39a71687",
            "4e5202df885444e6b3126703b8140348",
            "f3d891c0ac3347a69785c86c716b1f1b",
            "5b9188ac63634b9dae09fba87c866254",
            "8966ddf543f8496eb11b96acf7ca83a6",
            "4fa7e53049d9418e97dee36155893f33",
            "4d54004f9bec42bf8386c72509d61fde",
            "72778c0f871d46ae8beb512a91b98c38",
            "c3446589739e4ae2828d1b11ae28cd9f",
            "a129ae5021364fc684759fbb7479e44e",
            "fd5da834d2da45a5bfb4af01bde800ed",
            "3eb0fa2c12474cc18b50c7cf70953916",
            "6af320a038b04e728a11fa4fd674f55a",
            "8821650883e245018bce02b7ff4f3ed8",
            "c159eea4fa90426a921df7d3c3d718e2",
            "4fc8279aadd94c07aa910a675a7bc1b9",
            "77819468aa694b05b5dd25b0ae852ed4",
            "10bc6b2da9ad44239f2b9edad12d7031",
            "0b39a048235a419d9626d2aed8a9addd",
            "164be9b1b41b422aa788fdbe8965f68c",
            "0b03595f6c594725ac159d2034114c3e",
            "1c1affee94054a63a6c43be9f48bd355",
            "167b764c57a54841823f8c163939b4f6",
            "a7e37c4e13d14672b930d61a86650299",
            "32a132887f5f427ebd89d39bd2ddc56c",
            "5e12f9cfc8a343ddb60f50c6de3275ed",
            "6faee1983f564d5993aee157c9deccc6",
            "0728253c9a0c44959e491c5d59061a72",
            "d96cf7785c304b2d97aed740e9a0dffe",
            "70769eb544f84c5fb688859594f2c635",
            "2ef86a3bd09143d897b6aed270c9f4bc",
            "bbeeed0f42b44431b2ae60f49526f4cc",
            "daf66f65ae614e3b8883b36ed0a2dce2",
            "502ed2954ecd4b4e8716749994f80a26",
            "ad5a760951964a1caa1a9ebdb5382df5",
            "62aa5006f8ac4876a918f2e7bd34d234",
            "a0db0184f95a426eac7b42d5d1654208",
            "d47392e81951406495627a879bc16911",
            "8d69df1e63804d55965233b99a2ffdf4"
          ]
        },
        "outputId": "831fbbea-46f2-45dd-8016-fdea2a097059"
      },
      "source": [
        "for id_ in range(topic_count):\n",
        "  topic = df['topic'][id_] + ' '+conf_name \n",
        "  print(\"topic: \", topic, \"id_=\", id_)\n",
        "  result = resource.list(q=topic, cx=cse_key).execute()\n",
        "  #print(len(result))\n",
        "  #print(result)\n",
        "\n",
        "  ## print the links\n",
        "  # i = 1\n",
        "  # for item in result['items']:\n",
        "  #   if 'pdf' not in item['link'] and '.pptx' not in item['link']:\n",
        "  #     print(i, \".\",item['title'], item['link'])\n",
        "  #     i+= 1\n",
        "  ##text extract\n",
        "  i = 1\n",
        "  topics = []\n",
        "  text = []\n",
        "  title = []\n",
        "  url = []\n",
        "  for item in result['items']:\n",
        "    if 'pdf' not in item['link'] and 'pptx' not in item['link'] and 'info' not in item['link'] and 'tfhub' not in item['link']:\n",
        "        print(i, \".\",item['title'], item['link'])\n",
        "        try:\n",
        "            article = fulltext(requests.get(item['link']).text)\n",
        "            #print(abstract_text)\n",
        "        except:\n",
        "            article = \"No Text\"\n",
        "        \n",
        "        #print(article)\n",
        "\n",
        "        topics.append(topic)\n",
        "        title.append(item['title'])\n",
        "        url.append(item['link'])\n",
        "        text.append(article)\n",
        "        i+= 1\n",
        "        print(\"**********************************************\")\n",
        "\n",
        "    if 'pdf' in item['link']:\n",
        "      print(i, \".\",item['title'], item['link'])\n",
        "\n",
        "      path = Path('.')\n",
        "      CACHE_DIR =  path / '.jupyter_cache'\n",
        "      memory = Memory(CACHE_DIR, verbose=0)\n",
        "\n",
        "      @memory.cache\n",
        "      def download(url, dst):\n",
        "        response = requests.get(url, allow_redirects=True)\n",
        "        with open(dst, 'wb') as f:\n",
        "          f.write(response.content)\n",
        "\n",
        "      pdf_link = item['link']\n",
        "      fn = path / 'example.pdf'\n",
        "      download(pdf_link, fn)\n",
        "      print(fn)\n",
        "\n",
        "      #get pdf text\n",
        "      pdfConverter = PdfConverter(file_path='./example.pdf')\n",
        "      print(pdfConverter.convert_pdf_to_txt())\n",
        "      abstract_text = pdfConverter.convert_pdf_to_txt()\n",
        "\n",
        "      if abstract_text == \"No Text\":\n",
        "        continue\n",
        "      topics.append(topic)\n",
        "      title.append(item['title'])\n",
        "      url.append(item['link'])\n",
        "      text.append(abstract_text)\n",
        "      i+= 1\n",
        "      print(\"**********************************************\")\n",
        "\n",
        "  ## create new dataframe\n",
        "  #Create a new dataFrame \n",
        "  data = pd.DataFrame(columns = ['topic','title', 'text', 'url']) \n",
        "  data['topic'] = topics\n",
        "  data['title'] = title\n",
        "  data['text'] = text\n",
        "  data['url'] = url\n",
        "\n",
        "\n",
        "  #Show the data set\n",
        "  print(\"data:\", data)\n",
        "  print(\"**********************************************\")\n",
        "  ##distillation\n",
        "  data_all_news = data\n",
        "  data_all_news['text_distilled'] = data_all_news['text'].apply(lambda x : re.split('\\W+', str(x).lower()))\n",
        "  data_all_news['topic_distilled'] = data_all_news['title'].apply(lambda x : re.split('\\W+', str(x).lower()))\n",
        "  data_all_news['text_distilled'] = data_all_news['text_distilled'].apply(lemmatize)\n",
        "  data_all_news['topic_distilled'] = data_all_news['topic_distilled'].apply(lemmatize)\n",
        "  data_all_news['text_distilled'] = data_all_news['text_distilled'].apply(remove_stopwords)\n",
        "  data_all_news['topic_distilled'] = data_all_news['topic_distilled'].apply(remove_stopwords)\n",
        "  data_all_news['text_distilled'] = data_all_news['text_distilled'].apply(remove_too_short)\n",
        "  data_all_news['topic_distilled'] = data_all_news['topic_distilled'].apply(remove_too_short)\n",
        "\n",
        "\n",
        "  ## similarity computation \n",
        "  vectorizer = Vectorizer()\n",
        "  data_1 = data_all_news\n",
        "  data_2 = data_all_news\n",
        "  #print(\"data_2-------------\", data_all_news['text_distilled'])\n",
        "  similarity_list = method_3_with_sentence_sim_avg(topic,data_2, 'text_distilled')\n",
        "  data_1['most_similar'] = similarity_list\n",
        "\n",
        "  lst1 = []\n",
        "  for sim in similarity_list:\n",
        "    lst2 = []\n",
        "    id = sim[0]\n",
        "    score = sim[1]\n",
        "    lst1.append([data_1.iloc[id]['topic'], data_1.iloc[id]['title'], data_1.iloc[id]['text'], data_1.iloc[id]['url'],  score])\n",
        "\n",
        "  ##build a df\n",
        "  cols = ['topic', 'title', 'text','url',  'similarity_score']\n",
        "  df_final = pd.DataFrame(lst1, columns=cols)\n",
        "  print(df_final)\n",
        "\n",
        "  ##rank computation\n",
        "  df_final['rank'] = df_final['similarity_score'].rank(method='max' , ascending=False)\n",
        "  print(\"df_final after rank=\", df_final)\n",
        "\n",
        "  ##LDA text ranking\n",
        "  texts = data_all_news[\"text\"] \n",
        "  print(texts)\n",
        "  filteredTexts = filter_stopwords_from_list(texts)\n",
        "  (lstNGrams, corpusNGrams) = getNGramsConcat(filteredTexts, ngramsCount = 3)\n",
        "\n",
        "  ###LDA computing\n",
        "  numTopics = len(df_final)\n",
        "  (ldamodel, corpus) = runLDA(lstNGrams, numTopics) #(mid_grams, numTopics) #(lstNGrams, numTopics)\n",
        "  # print(f\"Top {numTopics} TOPICS:\")\n",
        "  # ldamodel.print_topics(num_topics=numTopics, num_words=5)\n",
        "  topn_words = {'Topic_' + str(i): [word for word, prob in ldamodel.show_topic(i, topn=10)] for i in range(0, ldamodel.num_topics)}\n",
        "  topic_list = topic_build(topn_words)\n",
        "  for i in range(len(topic_list)):\n",
        "    topic_list[i] = remove_duplicate_word(topic_list[i])\n",
        "  #adding lda distilled topic\n",
        "  data_all_news['lda_topic_distilled'] = topic_list\n",
        "\n",
        "  ##LDA-similarity computation\n",
        "  vectorizer = Vectorizer()\n",
        "  data_1 = data_all_news\n",
        "  data_2 = data_all_news\n",
        "  similarity_list = method_3_with_sentence_sim_avg(topic,data_2, 'lda_topic_distilled')\n",
        "  data_1['most_similar_lda'] = similarity_list\n",
        "  #similarity\n",
        "  lst1 = []\n",
        "  for sim in similarity_list:\n",
        "    lst2 = []\n",
        "    id = sim[0]\n",
        "    score = sim[1]\n",
        "    lst1.append(score)\n",
        "  df_final['similarity_score_lda'] = lst1\n",
        "  ##rank after lda\n",
        "  df_final['rank_lda'] = df_final['similarity_score_lda'].rank(method='max' , ascending=False)\n",
        "\n",
        "  ##append with result data drame\n",
        "  df_output = df_output.append(df_final)\n",
        "  print(\"df_output\", df_output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "topic:  graph similarity deep learning neurips id_= 0\n",
            "1 . A graph similarity for deep learning https://papers.nips.cc/paper/2020/hash/0004d0b59e19461ff126e3a08a814c33-Abstract.html\n",
            "**********************************************\n",
            "2 . A Graph Similarity for Deep Learning https://papers.nips.cc/paper/2020/file/0004d0b59e19461ff126e3a08a814c33-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Graph neural networks (GNNs) have been successful in learning representations\n",
            "from graphs. Many popular GNNs follow the pattern of aggregate-transform:\n",
            "they aggregate the neighbors’ attributes and then transform the results of aggre-\n",
            "gation with a learnable function. Analyses of these GNNs explain which pairs of\n",
            "non-identical graphs have different representations. However, we still lack an un-\n",
            "derstanding of how similar these representations will be. We adopt kernel distance\n",
            "and propose transform-sum-cat as an alternative to aggregate-transform to reﬂect\n",
            "the continuous similarity between the node neighborhoods in the neighborhood ag-\n",
            "gregation. The idea leads to a simple and efﬁcient graph similarity, which we name\n",
            "Weisfeiler–Leman similarity (WLS). In contrast to existing graph kernels, WLS is\n",
            "easy to implement with common deep learning frameworks. In graph classiﬁca-\n",
            "tion experiments, transform-sum-cat signiﬁcantly outperforms other neighborhood\n",
            "aggregation methods from popular GNN models. We also develop a simple and\n",
            "fast GNN model based on transform-sum-cat, which obtains, in comparison with\n",
            "widely used GNN models, (1) a higher accuracy in node classiﬁcation, (2) a lower\n",
            "absolute error in graph regression, and (3) greater stability in adversarial training\n",
            "of graph generation.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "3 . A graph similarity for deep learning - Review for NeurIPS paper https://papers.nips.cc/paper/2020/file/0004d0b59e19461ff126e3a08a814c33-Review.html\n",
            "**********************************************\n",
            "4 . A graph similarity for deep learning - Review for NeurIPS paper https://papers.nips.cc/paper/2020/file/0004d0b59e19461ff126e3a08a814c33-MetaReview.html\n",
            "**********************************************\n",
            "5 . Advances in Neural Information Processing Systems 33 (NeurIPS ... https://papers.nips.cc/paper/2020\n",
            "**********************************************\n",
            "6 . Adversarial Attacks on Deep Graph Matching https://papers.nips.cc/paper/2020/hash/ef126722e64e98d1c33933783e52eafc-Abstract.html\n",
            "**********************************************\n",
            "7 . Adversarial Attacks on Deep Graph Matching https://papers.nips.cc/paper/2020/file/ef126722e64e98d1c33933783e52eafc-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Despite achieving remarkable performance, deep graph learning models, such\n",
            "as node classiﬁcation and network embedding, suffer from harassment caused\n",
            "by small adversarial perturbations. However, the vulnerability analysis of graph\n",
            "matching under adversarial attacks has not been fully investigated yet. This paper\n",
            "proposes an adversarial attack model with two novel attack techniques to perturb\n",
            "the graph structure and degrade the quality of deep graph matching: (1) a kernel\n",
            "density estimation approach is utilized to estimate and maximize node densities to\n",
            "derive imperceptible perturbations, by pushing attacked nodes to dense regions in\n",
            "two graphs, such that they are indistinguishable from many neighbors; and (2) a\n",
            "meta learning-based projected gradient descent method is developed to well choose\n",
            "attack starting points and to improve the search performance for producing effective\n",
            "perturbations. We evaluate the effectiveness of the attack model on real datasets\n",
            "and validate that the attacks can be transferable to other graph learning models.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "8 . Iterative Deep Graph Learning for Graph ... - Review for NeurIPS paper https://papers.nips.cc/paper/2020/file/e05c7ba4e087beea9410929698dc41a6-Review.html\n",
            "**********************************************\n",
            "9 . Random Walk Graph Neural Networks https://papers.nips.cc/paper/2020/file/ba95d78a7c942571185308775a97a3a0-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "In recent years, graph neural networks (GNNs) have become the de facto tool\n",
            "for performing machine learning tasks on graphs. Most GNNs belong to the\n",
            "family of message passing neural networks (MPNNs). These models employ an\n",
            "iterative neighborhood aggregation scheme to update vertex representations. Then,\n",
            "to compute vector representations of graphs, they aggregate the representations\n",
            "of the vertices using some permutation invariant function. One would expect\n",
            "the hidden layers of a GNN to be composed of parameters that take the form of\n",
            "graphs. However, this is not the case for MPNNs since their update procedure is\n",
            "parameterized by fully-connected layers. In this paper, we propose a more intuitive\n",
            "and transparent architecture for graph-structured data, so-called Random Walk\n",
            "Graph Neural Network (RWNN). The ﬁrst layer of the model consists of a number\n",
            "of trainable “hidden graphs” which are compared against the input graphs using a\n",
            "random walk kernel to produce graph representations. These representations are\n",
            "then passed on to a fully-connected neural network which produces the output. The\n",
            "employed random walk kernel is differentiable, and therefore, the proposed model\n",
            "is end-to-end trainable. We demonstrate the model’s transparency on synthetic\n",
            "datasets. Furthermore, we empirically evaluate the model on graph classiﬁcation\n",
            "datasets and show that it achieves competitive performance.\n",
            "\n",
            "\n",
            "**********************************************\n",
            "10 . Adversarial Attacks on Deep Graph ... - Review for NeurIPS paper https://papers.nips.cc/paper/2020/file/ef126722e64e98d1c33933783e52eafc-Review.html\n",
            "**********************************************\n",
            "data:                                     topic  ...                                                url\n",
            "0  graph similarity deep learning neurips  ...  https://papers.nips.cc/paper/2020/hash/0004d0b...\n",
            "1  graph similarity deep learning neurips  ...  https://papers.nips.cc/paper/2020/file/0004d0b...\n",
            "2  graph similarity deep learning neurips  ...  https://papers.nips.cc/paper/2020/file/0004d0b...\n",
            "3  graph similarity deep learning neurips  ...  https://papers.nips.cc/paper/2020/file/0004d0b...\n",
            "4  graph similarity deep learning neurips  ...                  https://papers.nips.cc/paper/2020\n",
            "5  graph similarity deep learning neurips  ...  https://papers.nips.cc/paper/2020/hash/ef12672...\n",
            "6  graph similarity deep learning neurips  ...  https://papers.nips.cc/paper/2020/file/ef12672...\n",
            "7  graph similarity deep learning neurips  ...  https://papers.nips.cc/paper/2020/file/e05c7ba...\n",
            "8  graph similarity deep learning neurips  ...  https://papers.nips.cc/paper/2020/file/ba95d78...\n",
            "9  graph similarity deep learning neurips  ...  https://papers.nips.cc/paper/2020/file/ef12672...\n",
            "\n",
            "[10 rows x 4 columns]\n",
            "**********************************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d51b511c737b41ab846a167d5e934f34",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72778c0f871d46ae8beb512a91b98c38",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4fc8279aadd94c07aa910a675a7bc1b9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a7e37c4e13d14672b930d61a86650299",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bbeeed0f42b44431b2ae60f49526f4cc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=267967963.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "The\n",
            "same\n",
            "way\n",
            "that\n",
            "linear\n",
            "SVMs\n",
            "sometimes\n",
            "generalized\n",
            "better\n",
            "than\n",
            "RBF\n",
            "kernels\n",
            "in\n",
            "the\n",
            "SVM\n",
            "era\n",
            ".\n",
            "I\n",
            "suppose\n",
            "in\n",
            "that\n",
            "case\n",
            "a\n",
            "linear\n",
            "kernel\n",
            "for\n",
            "the\n",
            "transform\n",
            "part\n",
            "would\n",
            "take\n",
            "the\n",
            "part\n",
            "of\n",
            "the\n",
            "aggregate\n",
            ",\n",
            "and\n",
            "then\n",
            "it\n",
            "should\n",
            "perform\n",
            "similarly\n",
            "to\n",
            "the\n",
            "aggregate\n",
            "first\n",
            "methods\n",
            ".\n",
            "You\n",
            "can\n",
            "sort\n",
            "of\n",
            "see\n",
            "the\n",
            "effect\n",
            "in\n",
            "Table\n",
            "1\n",
            "on\n",
            "the\n",
            "BZR\n",
            "and\n",
            "COX2\n",
            "data\n",
            "set\n",
            "where\n",
            "WLSIn\n",
            "has\n",
            "a\n",
            "lower\n",
            "variance\n",
            "than\n",
            "WLS\n",
            ".\n",
            "Maybe\n",
            "a\n",
            "linear\n",
            "kernel\n",
            "baseline\n",
            "would\n",
            "help\n",
            "as\n",
            "well\n",
            "to\n",
            "convince\n",
            "the\n",
            "reader\n",
            ".\n",
            "Also\n",
            "since\n",
            "in\n",
            "line\n",
            "235\n",
            "the\n",
            "hyperparameters\n",
            "were\n",
            "tuned\n",
            "for\n",
            "each\n",
            "split\n",
            ",\n",
            "it\n",
            "'s\n",
            "hard\n",
            "to\n",
            "tell\n",
            "if\n",
            "the\n",
            "method\n",
            "generalizes\n",
            "to\n",
            "an\n",
            "unseen\n",
            "split\n",
            "that\n",
            "was\n",
            "n't\n",
            "tuned\n",
            "against\n",
            ".\n",
            "Correctness\n",
            ":\n",
            "I\n",
            "'m\n",
            "a\n",
            "bit\n",
            "concerned\n",
            "about\n",
            "tuning\n",
            "each\n",
            "split\n",
            "individually\n",
            "as\n",
            "in\n",
            "line\n",
            "235\n",
            ".\n",
            "It\n",
            "could\n",
            "lead\n",
            "to\n",
            "false\n",
            "security\n",
            "about\n",
            "generalization\n",
            "performance\n",
            ".\n",
            "In\n",
            "production\n",
            "system\n",
            "there\n",
            "is\n",
            "usually\n",
            "a\n",
            "secret\n",
            "test\n",
            "set\n",
            "that\n",
            "is\n",
            "not\n",
            "tuned\n",
            "against\n",
            "by\n",
            "the\n",
            "hyperparameter\n",
            "tuner\n",
            "to\n",
            "check\n",
            "for\n",
            "overfitting\n",
            "via\n",
            "the\n",
            "hyperparameter\n",
            "tuning\n",
            "process\n",
            ".\n",
            "Clarity\n",
            ":\n",
            "Yes\n",
            ",\n",
            "although\n",
            "I\n",
            "am\n",
            "not\n",
            "familiar\n",
            "with\n",
            "the\n",
            "particular\n",
            "approach\n",
            ",\n",
            "the\n",
            "toy\n",
            "diagrams\n",
            "and\n",
            "clear\n",
            "explanations\n",
            "worked\n",
            "for\n",
            "me\n",
            ".\n",
            "Relation\n",
            "to\n",
            "Prior\n",
            "Work\n",
            ":\n",
            "Yes\n",
            ",\n",
            "the\n",
            "idea\n",
            "of\n",
            "moving\n",
            "aggregation\n",
            "outside\n",
            "of\n",
            "the\n",
            "learning\n",
            "loop\n",
            "made\n",
            "sense\n",
            "to\n",
            "me\n",
            ".\n",
            "Reproducibility\n",
            ":\n",
            "Yes\n",
            "NeurIPS\n",
            "2020\n",
            "A\n",
            "graph\n",
            "similarity\n",
            "for\n",
            "deep\n",
            "learning\n",
            "Meta\n",
            "Review\n",
            "The\n",
            "reviewers\n",
            "liked\n",
            "the\n",
            "motivation\n",
            "and\n",
            "presentation\n",
            "of\n",
            "this\n",
            "new\n",
            "WL\n",
            "kernel-inspired\n",
            "GNN\n",
            "architecture\n",
            ",\n",
            "despite\n",
            "the\n",
            "actual\n",
            "architectural\n",
            "change\n",
            "to\n",
            "existing\n",
            "GNNs\n",
            "is\n",
            "relatively\n",
            "incremental\n",
            ".\n",
            "I\n",
            "hope\n",
            "the\n",
            "authors\n",
            "can\n",
            "revise\n",
            "their\n",
            "paper\n",
            "to\n",
            "address\n",
            "the\n",
            "reviewers\n",
            "’\n",
            "comments\n",
            "in\n",
            "the\n",
            "camera\n",
            "ready\n",
            "version\n",
            ",\n",
            "and\n",
            "give\n",
            "proper\n",
            "credit\n",
            "to\n",
            "prior\n",
            "work\n",
            ".\n",
            "Book\n",
            "Do\n",
            "not\n",
            "remove\n",
            ":\n",
            "This\n",
            "comment\n",
            "is\n",
            "monitored\n",
            "to\n",
            "verify\n",
            "that\n",
            "the\n",
            "site\n",
            "is\n",
            "working\n",
            "properly\n",
            "Adversarial\n",
            "Attacks\n",
            "on\n",
            "Deep\n",
            "Graph\n",
            "Matching\n",
            "Part\n",
            "of\n",
            "Advances\n",
            "in\n",
            "Neural\n",
            "Information\n",
            "Processing\n",
            "Systems\n",
            "33\n",
            "(\n",
            "NeurIPS\n",
            "2020\n",
            ")\n",
            "Authors\n",
            "Zijie\n",
            "Zhang\n",
            ",\n",
            "Zeru\n",
            "Zhang\n",
            ",\n",
            "Yang\n",
            "Zhou\n",
            ",\n",
            "Yelong\n",
            "Shen\n",
            ",\n",
            "Ruoming\n",
            "Jin\n",
            ",\n",
            "Dejing\n",
            "Dou\n",
            "Abstract\n",
            "Despite\n",
            "achieving\n",
            "remarkable\n",
            "performance\n",
            ",\n",
            "deep\n",
            "graph\n",
            "learning\n",
            "models\n",
            ",\n",
            "such\n",
            "as\n",
            "node\n",
            "classification\n",
            "and\n",
            "network\n",
            "embedding\n",
            ",\n",
            "suffer\n",
            "from\n",
            "harassment\n",
            "caused\n",
            "by\n",
            "small\n",
            "adversarial\n",
            "perturbations\n",
            ".\n",
            "However\n",
            ",\n",
            "the\n",
            "vulnerability\n",
            "analysis\n",
            "of\n",
            "graph\n",
            "matching\n",
            "under\n",
            "adversarial\n",
            "attacks\n",
            "has\n",
            "not\n",
            "been\n",
            "fully\n",
            "investigated\n",
            "yet\n",
            ".\n",
            "This\n",
            "paper\n",
            "proposes\n",
            "an\n",
            "adversarial\n",
            "attack\n",
            "model\n",
            "with\n",
            "two\n",
            "novel\n",
            "attack\n",
            "techniques\n",
            "to\n",
            "perturb\n",
            "the\n",
            "graph\n",
            "structure\n",
            "and\n",
            "degrade\n",
            "the\n",
            "quality\n",
            "of\n",
            "deep\n",
            "graph\n",
            "matching\n",
            ":\n",
            "(\n",
            "1\n",
            ")\n",
            "a\n",
            "kernel\n",
            "density\n",
            "estimation\n",
            "approach\n",
            "is\n",
            "utilized\n",
            "to\n",
            "estimate\n",
            "and\n",
            "maximize\n",
            "node\n",
            "densities\n",
            "to\n",
            "derive\n",
            "imperceptible\n",
            "perturbations\n",
            ",\n",
            "by\n",
            "pushing\n",
            "attacked\n",
            "nodes\n",
            "to\n",
            "dense\n",
            "regions\n",
            "in\n",
            "two\n",
            "graphs\n",
            ",\n",
            "such\n",
            "that\n",
            "they\n",
            "are\n",
            "indistinguishable\n",
            "from\n",
            "many\n",
            "neighbors\n",
            ";\n",
            "and\n",
            "(\n",
            "2\n",
            ")\n",
            "a\n",
            "meta\n",
            "learning-based\n",
            "projected\n",
            "gradient\n",
            "descent\n",
            "method\n",
            "is\n",
            "developed\n",
            "to\n",
            "well\n",
            "choose\n",
            "attack\n",
            "starting\n",
            "points\n",
            "and\n",
            "to\n",
            "improve\n",
            "the\n",
            "search\n",
            "performance\n",
            "for\n",
            "producing\n",
            "effective\n",
            "perturbations\n",
            ".\n",
            "We\n",
            "evaluate\n",
            "the\n",
            "effectiveness\n",
            "of\n",
            "the\n",
            "attack\n",
            "model\n",
            "on\n",
            "real\n",
            "datasets\n",
            "and\n",
            "validate\n",
            "that\n",
            "the\n",
            "attacks\n",
            "can\n",
            "be\n",
            "transferable\n",
            "to\n",
            "other\n",
            "graph\n",
            "learning\n",
            "models\n",
            ".\n",
            "Abstract\n",
            "Despite\n",
            "achieving\n",
            "remarkable\n",
            "performance\n",
            ",\n",
            "deep\n",
            "graph\n",
            "learning\n",
            "models\n",
            ",\n",
            "such\n",
            "as\n",
            "node\n",
            "classiﬁcation\n",
            "and\n",
            "network\n",
            "embedding\n",
            ",\n",
            "suffer\n",
            "from\n",
            "harassment\n",
            "caused\n",
            "by\n",
            "small\n",
            "adversarial\n",
            "perturbations\n",
            ".\n",
            "However\n",
            ",\n",
            "the\n",
            "vulnerability\n",
            "analysis\n",
            "of\n",
            "graph\n",
            "matching\n",
            "under\n",
            "adversarial\n",
            "attacks\n",
            "has\n",
            "not\n",
            "been\n",
            "fully\n",
            "investigated\n",
            "yet\n",
            ".\n",
            "This\n",
            "paper\n",
            "proposes\n",
            "an\n",
            "adversarial\n",
            "attack\n",
            "model\n",
            "with\n",
            "two\n",
            "novel\n",
            "attack\n",
            "techniques\n",
            "to\n",
            "perturb\n",
            "the\n",
            "graph\n",
            "structure\n",
            "and\n",
            "degrade\n",
            "the\n",
            "quality\n",
            "of\n",
            "deep\n",
            "graph\n",
            "matching\n",
            ":\n",
            "(\n",
            "1\n",
            ")\n",
            "a\n",
            "kernel\n",
            "density\n",
            "estimation\n",
            "approach\n",
            "is\n",
            "utilized\n",
            "to\n",
            "estimate\n",
            "and\n",
            "maximize\n",
            "node\n",
            "densities\n",
            "to\n",
            "derive\n",
            "imperceptible\n",
            "perturbations\n",
            ",\n",
            "by\n",
            "pushing\n",
            "attacked\n",
            "nodes\n",
            "to\n",
            "dense\n",
            "regions\n",
            "in\n",
            "two\n",
            "graphs\n",
            ",\n",
            "such\n",
            "that\n",
            "they\n",
            "are\n",
            "indistinguishable\n",
            "from\n",
            "many\n",
            "neighbors\n",
            ";\n",
            "and\n",
            "(\n",
            "2\n",
            ")\n",
            "a\n",
            "meta\n",
            "learning-based\n",
            "projected\n",
            "gradient\n",
            "descent\n",
            "method\n",
            "is\n",
            "developed\n",
            "to\n",
            "well\n",
            "choose\n",
            "attack\n",
            "starting\n",
            "points\n",
            "and\n",
            "to\n",
            "improve\n",
            "the\n",
            "search\n",
            "performance\n",
            "for\n",
            "producing\n",
            "effective\n",
            "perturbations\n",
            ".\n",
            "We\n",
            "evaluate\n",
            "the\n",
            "effectiveness\n",
            "of\n",
            "the\n",
            "attack\n",
            "model\n",
            "on\n",
            "real\n",
            "datasets\n",
            "and\n",
            "validate\n",
            "that\n",
            "the\n",
            "attacks\n",
            "can\n",
            "be\n",
            "transferable\n",
            "to\n",
            "other\n",
            "graph\n",
            "learning\n",
            "models\n",
            ".\n",
            "1\n",
            "NeurIPS\n",
            "2020\n",
            "Iterative\n",
            "Deep\n",
            "Graph\n",
            "Learning\n",
            "for\n",
            "Graph\n",
            "Neural\n",
            "Networks\n",
            ":\n",
            "Better\n",
            "and\n",
            "Robust\n",
            "Node\n",
            "Embeddings\n",
            "Review\n",
            "1\n",
            "Summary\n",
            "and\n",
            "Contributions\n",
            ":\n",
            "This\n",
            "manuscript\n",
            "proposes\n",
            "a\n",
            "new\n",
            "deep\n",
            "graph\n",
            "learning\n",
            "framework\n",
            "which\n",
            "integrates\n",
            "feature\n",
            "learning\n",
            "and\n",
            "graph\n",
            "structure\n",
            "learning\n",
            "for\n",
            "a\n",
            "link\n",
            "prediction\n",
            "task\n",
            ".\n",
            "Based\n",
            "on\n",
            "anchor-based\n",
            "metric\n",
            "learning\n",
            ",\n",
            "a\n",
            "scalable\n",
            "method\n",
            "is\n",
            "also\n",
            "proposed\n",
            "to\n",
            "accelerate\n",
            "the\n",
            "computation\n",
            "of\n",
            "the\n",
            "original\n",
            "model\n",
            ".\n",
            "The\n",
            "proposed\n",
            "method\n",
            "slightly\n",
            "outperforms\n",
            "other\n",
            "state-of-the-art\n",
            "models\n",
            ".\n",
            "Strengths\n",
            ":\n",
            "1\n",
            ".\n",
            "The\n",
            "manuscript\n",
            "is\n",
            "readable\n",
            ".\n",
            "2\n",
            ".\n",
            "The\n",
            "idea\n",
            "of\n",
            "alternatively\n",
            "optimizing\n",
            "the\n",
            "node\n",
            "embedding\n",
            "vectors\n",
            "and\n",
            "revising\n",
            "the\n",
            "graph\n",
            "structure\n",
            "seems\n",
            "to\n",
            "be\n",
            "reasonable\n",
            "even\n",
            "though\n",
            "the\n",
            "effect\n",
            "of\n",
            "this\n",
            "integration\n",
            "is\n",
            "somewhat\n",
            "limitedly\n",
            "observed\n",
            "in\n",
            "the\n",
            "experimental\n",
            "results\n",
            ".\n",
            "3\n",
            ".\n",
            "The\n",
            "anchor-based\n",
            "metric\n",
            "learning\n",
            "effectively\n",
            "reduces\n",
            "the\n",
            "model\n",
            "complexity\n",
            "while\n",
            "not\n",
            "losing\n",
            "much\n",
            "accuracy\n",
            ".\n",
            "Weaknesses\n",
            ":\n",
            "The\n",
            "main\n",
            "algorithm\n",
            "(\n",
            "Algorithm\n",
            "1\n",
            ")\n",
            "should\n",
            "be\n",
            "described\n",
            "in\n",
            "the\n",
            "main\n",
            "text\n",
            "instead\n",
            "of\n",
            "Appendix\n",
            ".\n",
            "I\n",
            "was\n",
            "able\n",
            "to\n",
            "understand\n",
            "the\n",
            "overall\n",
            "flow\n",
            "of\n",
            "the\n",
            "algorithm\n",
            "only\n",
            "after\n",
            "reading\n",
            "Algorithm\n",
            "1\n",
            "in\n",
            "Appendix\n",
            ".\n",
            "In\n",
            "Table\n",
            "1\n",
            ",\n",
            "it\n",
            "is\n",
            "kind\n",
            "of\n",
            "disappointing\n",
            "to\n",
            "see\n",
            "that\n",
            "the\n",
            "performance\n",
            "gap\n",
            "between\n",
            "the\n",
            "proposed\n",
            "method\n",
            "and\n",
            "the\n",
            "best\n",
            "baseline\n",
            "method\n",
            "is\n",
            "so\n",
            "little\n",
            "on\n",
            "all\n",
            "the\n",
            "datasets\n",
            ".\n",
            "Since\n",
            "the\n",
            "proposed\n",
            "method\n",
            "is\n",
            "a\n",
            "more\n",
            "expensive\n",
            "method\n",
            "than\n",
            "other\n",
            "methods\n",
            "as\n",
            "shown\n",
            "in\n",
            "Table\n",
            "4\n",
            ",\n",
            "one\n",
            "might\n",
            "expect\n",
            "to\n",
            "see\n",
            "this\n",
            "cost\n",
            "is\n",
            "payed\n",
            "off\n",
            "by\n",
            "a\n",
            "large\n",
            "performance\n",
            "increase\n",
            ".\n",
            "However\n",
            ",\n",
            "I\n",
            "'m\n",
            "afraid\n",
            "that\n",
            "Table\n",
            "1\n",
            "does\n",
            "not\n",
            "support\n",
            "this\n",
            ".\n",
            "Also\n",
            ",\n",
            "it\n",
            "would\n",
            "be\n",
            "better\n",
            "to\n",
            "show\n",
            "the\n",
            "performance\n",
            "of\n",
            "all\n",
            "the\n",
            "graph-based\n",
            "models\n",
            "(\n",
            "GCN\n",
            ",\n",
            "GAT\n",
            ",\n",
            "GraphSage\n",
            ",\n",
            "and\n",
            "so\n",
            "on\n",
            ")\n",
            "on\n",
            "the\n",
            "Wine\n",
            ",\n",
            "Cancer\n",
            ",\n",
            "Digits\n",
            "datasets\n",
            "by\n",
            "generating\n",
            "a\n",
            "simple\n",
            "kNN\n",
            "graph\n",
            "based\n",
            "on\n",
            "the\n",
            "features\n",
            ".\n",
            "(\n",
            "Currently\n",
            ",\n",
            "only\n",
            "GCN_\n",
            "{\n",
            "kNN\n",
            "}\n",
            "is\n",
            "presented\n",
            ".\n",
            ")\n",
            "It\n",
            "would\n",
            "be\n",
            "informative\n",
            "if\n",
            "we\n",
            "can\n",
            "check\n",
            "the\n",
            "performances\n",
            "of\n",
            "all\n",
            "the\n",
            "graph-based\n",
            "models\n",
            "in\n",
            "the\n",
            "kNN\n",
            "graph\n",
            ".\n",
            "In\n",
            "the\n",
            "experiments\n",
            ",\n",
            "it\n",
            "would\n",
            "be\n",
            "better\n",
            "to\n",
            "include\n",
            "more\n",
            "'link\n",
            "prediction\n",
            "'\n",
            "tasks\n",
            "and\n",
            "include\n",
            "more\n",
            "datasets\n",
            "related\n",
            "to\n",
            "the\n",
            "link\n",
            "prediction\n",
            "task\n",
            "because\n",
            "the\n",
            "main\n",
            "goal\n",
            "of\n",
            "the\n",
            "proposed\n",
            "method\n",
            "is\n",
            "to\n",
            "increase\n",
            "the\n",
            "accuracy\n",
            "in\n",
            "link\n",
            "prediction\n",
            ".\n",
            "Correctness\n",
            ":\n",
            "Overall\n",
            ",\n",
            "the\n",
            "reasoning\n",
            "of\n",
            "the\n",
            "main\n",
            "idea\n",
            "and\n",
            "the\n",
            "proposed\n",
            "algorithm\n",
            "seem\n",
            "to\n",
            "be\n",
            "reasonable\n",
            "even\n",
            "though\n",
            "I\n",
            "did\n",
            "not\n",
            "check\n",
            "all\n",
            "the\n",
            "details\n",
            ".\n",
            "The\n",
            "experiments\n",
            "use\n",
            "benchmark\n",
            "datasets\n",
            "and\n",
            "standard\n",
            "metrics\n",
            "to\n",
            "compare\n",
            "the\n",
            "performances\n",
            "of\n",
            "the\n",
            "methods\n",
            ".\n",
            "Clarity\n",
            ":\n",
            "Algorithm\n",
            "1\n",
            "should\n",
            "be\n",
            "presented\n",
            "in\n",
            "the\n",
            "main\n",
            "text\n",
            ",\n",
            "or\n",
            "there\n",
            "should\n",
            "be\n",
            "some\n",
            "high-level\n",
            "description\n",
            "about\n",
            "the\n",
            "overall\n",
            "algorithm\n",
            "somewhere\n",
            "in\n",
            "the\n",
            "main\n",
            "text\n",
            ".\n",
            "In\n",
            "the\n",
            "experiments\n",
            ",\n",
            "how\n",
            "the\n",
            "training\n",
            "set\n",
            "and\n",
            "the\n",
            "test\n",
            "set\n",
            "is\n",
            "divided\n",
            "should\n",
            "be\n",
            "described\n",
            "in\n",
            "the\n",
            "manuscript\n",
            ".\n",
            "Relation\n",
            "to\n",
            "Prior\n",
            "Work\n",
            ":\n",
            "It\n",
            "seems\n",
            "that\n",
            "the\n",
            "proposed\n",
            "method\n",
            "is\n",
            "properly\n",
            "compared\n",
            "with\n",
            "other\n",
            "related\n",
            "methods\n",
            ".\n",
            "Reproducibility\n",
            ":\n",
            "No\n",
            "Additional\n",
            "Feedback\n",
            ":\n",
            "Review\n",
            "2\n",
            "Summary\n",
            "and\n",
            "Contributions\n",
            ":\n",
            "In\n",
            "this\n",
            "paper\n",
            ",\n",
            "the\n",
            "author\n",
            "presented\n",
            "a\n",
            "new\n",
            "graph\n",
            "learning\n",
            "method\n",
            "for\n",
            "graph\n",
            "neural\n",
            "networks\n",
            ".\n",
            "The\n",
            "authors\n",
            "started\n",
            "to\n",
            "analyze\n",
            "the\n",
            "significant\n",
            "drawbacks\n",
            "of\n",
            "existing\n",
            "GNNs\n",
            "methods\n",
            ":\n",
            "1.\n",
            "work\n",
            "only\n",
            "when\n",
            "the\n",
            "graph\n",
            "data\n",
            "input\n",
            "is\n",
            "given\n",
            ";\n",
            "2.\n",
            "ignore\n",
            "potentially\n",
            "imperfect\n",
            "graph\n",
            "inputs\n",
            "(\n",
            "due\n",
            "to\n",
            "the\n",
            "noise\n",
            "and\n",
            "can\n",
            "not\n",
            "reflect\n",
            "true\n",
            "graph\n",
            "topology\n",
            ")\n",
            ";\n",
            "3.\n",
            "completely\n",
            "fail\n",
            "when\n",
            "inputs\n",
            "like\n",
            "texts\n",
            "are\n",
            "not\n",
            "given\n",
            "in\n",
            "graph\n",
            "format\n",
            ".\n",
            "To\n",
            "solve\n",
            "these\n",
            "problems\n",
            ",\n",
            "this\n",
            "paper\n",
            "proposed\n",
            "a\n",
            "new\n",
            "deep\n",
            "graph\n",
            "learning\n",
            "framework\n",
            "for\n",
            "learning\n",
            "the\n",
            "graph\n",
            "embedding\n",
            "and\n",
            "graph\n",
            "structure\n",
            "at\n",
            "the\n",
            "same\n",
            "time\n",
            ".\n",
            "Specifically\n",
            ",\n",
            "this\n",
            "paper\n",
            "introduced\n",
            "an\n",
            "iterative\n",
            "deep\n",
            "graph\n",
            "learning\n",
            "approach\n",
            ",\n",
            "where\n",
            "the\n",
            "key\n",
            "idea\n",
            "is\n",
            "to\n",
            "alternatively\n",
            "produce\n",
            "a\n",
            "better\n",
            "and\n",
            "more\n",
            "robust\n",
            "graph\n",
            "node\n",
            "embedding\n",
            "with\n",
            "a\n",
            "better\n",
            "learned\n",
            "graph\n",
            "structure\n",
            "and\n",
            "then\n",
            "learn\n",
            "a\n",
            "better\n",
            "graph\n",
            "structure\n",
            "based\n",
            "on\n",
            "better\n",
            "graph\n",
            "node\n",
            "embeddings\n",
            ".\n",
            "They\n",
            "further\n",
            "proposed\n",
            "a\n",
            "scalable\n",
            "version\n",
            "of\n",
            "the\n",
            "proposed\n",
            "method\n",
            "IDGL\n",
            "by\n",
            "leveraging\n",
            "the\n",
            "anchor-based\n",
            "approximation\n",
            "method\n",
            ".\n",
            "Graph\n",
            "similarity\n",
            "learning\n",
            "and\n",
            "graph\n",
            "regularization\n",
            "are\n",
            "also\n",
            "proposed\n",
            "to\n",
            "learn\n",
            "a\n",
            "graph\n",
            "structure\n",
            "with\n",
            "controlled\n",
            "quality\n",
            ",\n",
            "instead\n",
            "of\n",
            "learning\n",
            "a\n",
            "fully\n",
            "connected\n",
            "graph\n",
            "in\n",
            "existing\n",
            "methods\n",
            ".\n",
            "Authors\n",
            "show\n",
            "the\n",
            "experimental\n",
            "comparisons\n",
            "with\n",
            "other\n",
            "state-of-the-art\n",
            "GNNs\n",
            "methods\n",
            ".\n",
            "The\n",
            "proposed\n",
            "method\n",
            "showed\n",
            "better\n",
            "performance\n",
            "on\n",
            "accuracy\n",
            "and\n",
            "computational\n",
            "time\n",
            ".\n",
            "In\n",
            "addition\n",
            ",\n",
            "the\n",
            "presented\n",
            "method\n",
            "showed\n",
            "good\n",
            "scalability\n",
            "even\n",
            "on\n",
            "relatively\n",
            "large\n",
            "dataset\n",
            "without\n",
            "compromising\n",
            "the\n",
            "accuracy\n",
            ",\n",
            "owning\n",
            "to\n",
            "the\n",
            "use\n",
            "of\n",
            "anchor-based\n",
            "approximation\n",
            "technique\n",
            ".\n",
            "Strengths\n",
            ":\n",
            "(\n",
            "1\n",
            ")\n",
            "The\n",
            "idea\n",
            "of\n",
            "using\n",
            "iterative\n",
            "method\n",
            "for\n",
            "constructing\n",
            "a\n",
            "graph\n",
            "and\n",
            "learning\n",
            "graph\n",
            "node\n",
            "embeddings\n",
            "in\n",
            "a\n",
            "joint\n",
            "fashion\n",
            "seems\n",
            "very\n",
            "novel\n",
            ",\n",
            "to\n",
            "the\n",
            "best\n",
            "of\n",
            "my\n",
            "knowledge\n",
            ".\n",
            "Authors\n",
            "further\n",
            "presented\n",
            "improved\n",
            "version\n",
            "of\n",
            "IDGL\n",
            "in\n",
            "order\n",
            "to\n",
            "overcome\n",
            "the\n",
            "scalability\n",
            "issue\n",
            "of\n",
            "original\n",
            "IDGL\n",
            "for\n",
            "dealing\n",
            "with\n",
            "large\n",
            "graphs\n",
            ".\n",
            "Authors\n",
            "also\n",
            "provided\n",
            "theoretical\n",
            "analysis\n",
            "of\n",
            "the\n",
            "convergence\n",
            "of\n",
            "Anchor\n",
            "graphs\n",
            "to\n",
            "the\n",
            "exact\n",
            "similarity\n",
            "graph\n",
            ",\n",
            "making\n",
            "the\n",
            "proposed\n",
            "method\n",
            "more\n",
            "principled\n",
            ".\n",
            "(\n",
            "2\n",
            ")\n",
            "Instead\n",
            "of\n",
            "using\n",
            "fully\n",
            "connected\n",
            "graph\n",
            "(\n",
            "e.g\n",
            ".\n",
            "employing\n",
            "self-attention/transformer-like\n",
            "techniques\n",
            ")\n",
            ",\n",
            "authors\n",
            "tend\n",
            "to\n",
            "use\n",
            "sparsified\n",
            "graph\n",
            "over\n",
            "the\n",
            "fully\n",
            "connected\n",
            "graph\n",
            "by\n",
            "performing\n",
            "epsilon-neighborhood\n",
            "and\n",
            "adaptive\n",
            "graph\n",
            "regularization\n",
            "and\n",
            "showed\n",
            "better\n",
            "performance\n",
            "in\n",
            "the\n",
            "experiments\n",
            ".\n",
            "I\n",
            "found\n",
            "this\n",
            "insight\n",
            "is\n",
            "very\n",
            "interesting\n",
            "and\n",
            "could\n",
            "be\n",
            "transferred\n",
            "to\n",
            "other\n",
            "domain\n",
            "as\n",
            "well\n",
            ".\n",
            "(\n",
            "3\n",
            ")\n",
            "The\n",
            "paper\n",
            "is\n",
            "very\n",
            "well\n",
            "written\n",
            "and\n",
            "clearly\n",
            "motivated\n",
            ".\n",
            "For\n",
            "instance\n",
            ",\n",
            "the\n",
            "paper\n",
            "started\n",
            "to\n",
            "discuss\n",
            "the\n",
            "issues\n",
            "of\n",
            "existing\n",
            "methods\n",
            "(\n",
            "assuming\n",
            "graph\n",
            "is\n",
            "perfect\n",
            ",\n",
            "LDS\n",
            "only\n",
            "dealt\n",
            "with\n",
            "transductive\n",
            "setting\n",
            "and\n",
            "has\n",
            "scalability\n",
            "issue\n",
            ")\n",
            "and\n",
            "they\n",
            "proposed\n",
            "their\n",
            "solutions\n",
            ".\n",
            "These\n",
            "issues\n",
            "are\n",
            "well\n",
            "explained\n",
            "in\n",
            "the\n",
            "paper\n",
            "and\n",
            "the\n",
            "authors\n",
            "do\n",
            "a\n",
            "good\n",
            "job\n",
            "at\n",
            "explaining\n",
            "how\n",
            "their\n",
            "proposed\n",
            "method\n",
            "addresses\n",
            "these\n",
            "issues\n",
            ".\n",
            "(\n",
            "4\n",
            ")\n",
            "The\n",
            "overall\n",
            "experimental\n",
            "and\n",
            "ablation\n",
            "study\n",
            "results\n",
            "well\n",
            "investigated\n",
            "several\n",
            "advantages\n",
            "of\n",
            "the\n",
            "method\n",
            "in\n",
            "terms\n",
            "of\n",
            "both\n",
            "accuracy\n",
            "and\n",
            "scalability\n",
            "compared\n",
            "to\n",
            "existing\n",
            "GNNs\n",
            "methods\n",
            ".\n",
            "Weaknesses\n",
            ":\n",
            "(\n",
            "1\n",
            ")\n",
            "Authors\n",
            "discussed\n",
            "anchor-based\n",
            "metric\n",
            "learning\n",
            "and\n",
            "showed\n",
            "how\n",
            "it\n",
            "can\n",
            "use\n",
            "affinity\n",
            "matrix\n",
            "between\n",
            "graphs\n",
            "nodes\n",
            "and\n",
            "anchor\n",
            "nodes\n",
            "to\n",
            "reduce\n",
            "both\n",
            "runtimes\n",
            "and\n",
            "memory\n",
            "consumption\n",
            ".\n",
            "I\n",
            "think\n",
            "this\n",
            "is\n",
            "very\n",
            "interesting\n",
            "direction\n",
            "for\n",
            "dealing\n",
            "with\n",
            "large-scale\n",
            "graphs\n",
            ".\n",
            "However\n",
            ",\n",
            "I\n",
            "did\n",
            "not\n",
            "see\n",
            "any\n",
            "experiments\n",
            "how\n",
            "the\n",
            "convergence\n",
            "of\n",
            "performance\n",
            "when\n",
            "increasing\n",
            "the\n",
            "number\n",
            "of\n",
            "anchor\n",
            "points\n",
            ".\n",
            "More\n",
            "detailed\n",
            "discussion\n",
            "on\n",
            "the\n",
            "sensitivity\n",
            "of\n",
            "the\n",
            "number\n",
            "of\n",
            "anchor\n",
            "nodes\n",
            "should\n",
            "be\n",
            "given\n",
            ".\n",
            "(\n",
            "2\n",
            ")\n",
            "Authors\n",
            "did\n",
            "not\n",
            "provide\n",
            "the\n",
            "full\n",
            "algorithm\n",
            "1\n",
            "in\n",
            "the\n",
            "main\n",
            "section\n",
            ",\n",
            "which\n",
            "I\n",
            "found\n",
            "it\n",
            "is\n",
            "very\n",
            "inconvenient\n",
            "to\n",
            "digest\n",
            "the\n",
            "whole\n",
            "framework\n",
            ".\n",
            "I\n",
            "would\n",
            "suggest\n",
            "authors\n",
            "to\n",
            "move\n",
            "it\n",
            "in\n",
            "the\n",
            "main\n",
            "section\n",
            "in\n",
            "order\n",
            "to\n",
            "better\n",
            "discuss\n",
            "them\n",
            "in\n",
            "details\n",
            ".\n",
            "(\n",
            "3\n",
            ")\n",
            "It\n",
            "seems\n",
            "like\n",
            "this\n",
            "work\n",
            "is\n",
            "also\n",
            "related\n",
            "to\n",
            "adversarial\n",
            "robustness\n",
            "of\n",
            "graph\n",
            "neural\n",
            "networks\n",
            ".\n",
            "I\n",
            "would\n",
            "like\n",
            "to\n",
            "see\n",
            "more\n",
            "discussions\n",
            "regarding\n",
            "the\n",
            "connection\n",
            "and\n",
            "difference\n",
            "between\n",
            "this\n",
            "work\n",
            "and\n",
            "adversarial\n",
            "examples\n",
            "in\n",
            "GNN\n",
            "domain\n",
            ".\n",
            "Correctness\n",
            ":\n",
            "Yes\n",
            "Clarity\n",
            ":\n",
            "Yes\n",
            "Relation\n",
            "to\n",
            "Prior\n",
            "Work\n",
            ":\n",
            "Yes\n",
            "Reproducibility\n",
            ":\n",
            "Yes\n",
            "Additional\n",
            "Feedback\n",
            ":\n",
            "Review\n",
            "3\n",
            "Summary\n",
            "and\n",
            "Contributions\n",
            ":\n",
            "This\n",
            "paper\n",
            "focus\n",
            "on\n",
            "the\n",
            "problem\n",
            "of\n",
            "how\n",
            "to\n",
            "develop\n",
            "a\n",
            "(\n",
            "scalable\n",
            ")\n",
            "graph\n",
            "learning\n",
            "technique\n",
            ",\n",
            "which\n",
            "has\n",
            "been\n",
            "underexplored\n",
            "in\n",
            "the\n",
            "domain\n",
            ".\n",
            "Existing\n",
            "popular\n",
            "methods\n",
            "still\n",
            "have\n",
            "some\n",
            "limitations\n",
            ":\n",
            "first\n",
            ",\n",
            "GNNs\n",
            "can\n",
            "be\n",
            "only\n",
            "used\n",
            "when\n",
            "graph-structured\n",
            "data\n",
            "is\n",
            "provided\n",
            ";\n",
            "second\n",
            ",\n",
            "the\n",
            "intrinsic\n",
            "graph\n",
            "inputs\n",
            "are\n",
            "often\n",
            "noisy\n",
            "(\n",
            "not\n",
            "optimal\n",
            ")\n",
            "or\n",
            "incomplete\n",
            ";\n",
            "third\n",
            ",\n",
            "many\n",
            "applications\n",
            "may\n",
            "even\n",
            "only\n",
            "have\n",
            "sequence\n",
            "data\n",
            "or\n",
            "data\n",
            "matrix\n",
            "and\n",
            "lack\n",
            "of\n",
            "graph\n",
            "structured\n",
            "data\n",
            ".\n",
            "To\n",
            "overcome\n",
            "such\n",
            "issues\n",
            ",\n",
            "this\n",
            "paper\n",
            "presented\n",
            "a\n",
            "novel\n",
            "end-to-end\n",
            "graph\n",
            "learning\n",
            "framework\n",
            ",\n",
            "called\n",
            "Iterative\n",
            "Deep\n",
            "Graph\n",
            "Learning\n",
            "(\n",
            "IDGL\n",
            ")\n",
            ",\n",
            "to\n",
            "joint\n",
            "learn\n",
            "graph\n",
            "structure\n",
            "and\n",
            "graph\n",
            "embeddings\n",
            ".\n",
            "The\n",
            "model\n",
            "can\n",
            "generate\n",
            "more\n",
            "robust\n",
            "and\n",
            "better\n",
            "node\n",
            "embedding\n",
            "when\n",
            "learning\n",
            "graph\n",
            "structure\n",
            "through\n",
            "an\n",
            "iterative\n",
            "learning\n",
            "framework\n",
            ".\n",
            "It\n",
            "also\n",
            "has\n",
            "lower\n",
            "computational\n",
            "complexity\n",
            "(\n",
            "IDGL-ANCH\n",
            ")\n",
            "with\n",
            "the\n",
            "anchor-based\n",
            "approximation\n",
            ".\n",
            "The\n",
            "model\n",
            "can\n",
            "cope\n",
            "with\n",
            "both\n",
            "transductive\n",
            "and\n",
            "inductive\n",
            "settings\n",
            ",\n",
            "where\n",
            "the\n",
            "learned\n",
            "embeddings\n",
            "can\n",
            "be\n",
            "applied\n",
            "for\n",
            "many\n",
            "tasks\n",
            ".\n",
            "Besides\n",
            ",\n",
            "the\n",
            "key\n",
            "ideas\n",
            "of\n",
            "the\n",
            "paper\n",
            ",\n",
            "i.e.\n",
            ",\n",
            "iterative\n",
            "graph\n",
            "learning\n",
            "and\n",
            "anchor\n",
            "approximation\n",
            ",\n",
            "seem\n",
            "generally\n",
            "useful\n",
            "for\n",
            "other\n",
            "machine\n",
            "learning\n",
            "tasks\n",
            "and\n",
            "problems\n",
            ".\n",
            "The\n",
            "author\n",
            "also\n",
            "performed\n",
            "extensive\n",
            "set\n",
            "of\n",
            "experiments\n",
            "to\n",
            "study\n",
            "the\n",
            "properties\n",
            "of\n",
            "the\n",
            "proposed\n",
            "methods\n",
            "and\n",
            "demonstrated\n",
            "the\n",
            "effectiveness\n",
            "and\n",
            "efficiency\n",
            "compared\n",
            "to\n",
            "other\n",
            "popular\n",
            "GNN\n",
            "and\n",
            "graph\n",
            "learning\n",
            "methods\n",
            ".\n",
            "Strengths\n",
            ":\n",
            "(\n",
            "1\n",
            ")\n",
            "This\n",
            "paper\n",
            "studies\n",
            "an\n",
            "important\n",
            "problem\n",
            "and\n",
            "I\n",
            "like\n",
            "the\n",
            "overall\n",
            "idea\n",
            "behind\n",
            "the\n",
            "work\n",
            ".\n",
            "A\n",
            "simple\n",
            "and\n",
            "elegant\n",
            "solution\n",
            "is\n",
            "proposed\n",
            "to\n",
            "develop\n",
            "robust\n",
            "and\n",
            "better\n",
            "node\n",
            "embeddings\n",
            ",\n",
            "and\n",
            "at\n",
            "the\n",
            "same\n",
            "time\n",
            ",\n",
            "learn\n",
            "graph\n",
            "structure\n",
            "using\n",
            "a\n",
            "novel\n",
            "iterative\n",
            "approach\n",
            ".\n",
            "(\n",
            "2\n",
            ")\n",
            "The\n",
            "model\n",
            "has\n",
            "several\n",
            "key\n",
            "components\n",
            "including\n",
            "graph\n",
            "similarity\n",
            "learning\n",
            ",\n",
            "graph\n",
            "regularization\n",
            ",\n",
            "joint\n",
            "learning\n",
            ",\n",
            "and\n",
            "particular\n",
            "anchor-based\n",
            "graph\n",
            "approximation\n",
            ".\n",
            "They\n",
            "are\n",
            "designed\n",
            "and\n",
            "combined\n",
            "in\n",
            "a\n",
            "nice\n",
            "architecture\n",
            "for\n",
            "fulfilling\n",
            "the\n",
            "above\n",
            "mentioned\n",
            "properties\n",
            ",\n",
            "although\n",
            "some\n",
            "of\n",
            "them\n",
            "are\n",
            "not\n",
            "completely\n",
            "new\n",
            "in\n",
            "the\n",
            "vast\n",
            "of\n",
            "literature\n",
            ".\n",
            "(\n",
            "3\n",
            ")\n",
            "A\n",
            "good\n",
            "set\n",
            "of\n",
            "baselines\n",
            "and\n",
            "datasets\n",
            "are\n",
            "chosen\n",
            "in\n",
            "the\n",
            "experiments\n",
            "and\n",
            "an\n",
            "appropriate\n",
            "set\n",
            "of\n",
            "experiments\n",
            "are\n",
            "performed\n",
            "to\n",
            "show\n",
            "the\n",
            "strong\n",
            "empirical\n",
            "performance\n",
            "of\n",
            "the\n",
            "IDGL\n",
            "and\n",
            "IDGL-ANCH\n",
            "in\n",
            "comparison\n",
            "to\n",
            "other\n",
            "state-of-the-art\n",
            "baselines\n",
            ".\n",
            "In\n",
            "fact\n",
            ",\n",
            "the\n",
            "ablation\n",
            "study\n",
            "and\n",
            "model\n",
            "analyses\n",
            "help\n",
            "me\n",
            "better\n",
            "understand\n",
            "the\n",
            "roles\n",
            "of\n",
            "each\n",
            "important\n",
            "component\n",
            ",\n",
            "which\n",
            "brings\n",
            "me\n",
            "good\n",
            "points\n",
            ".\n",
            "Weaknesses\n",
            ":\n",
            "(\n",
            "1\n",
            ")\n",
            "In\n",
            "lines\n",
            "139-143\n",
            ",\n",
            "the\n",
            "authors\n",
            "mentioned\n",
            "the\n",
            "final\n",
            "graph\n",
            "is\n",
            "the\n",
            "combination\n",
            "of\n",
            "the\n",
            "initial\n",
            "graph\n",
            "topology\n",
            "and\n",
            "learned\n",
            "graph\n",
            "topology\n",
            ".\n",
            "However\n",
            ",\n",
            "it\n",
            "is\n",
            "unclear\n",
            "to\n",
            "me\n",
            "why\n",
            "we\n",
            "also\n",
            "have\n",
            "the\n",
            "combination\n",
            "of\n",
            "A\n",
            "(\n",
            "t\n",
            ")\n",
            "and\n",
            "A\n",
            "(\n",
            "1\n",
            ")\n",
            "in\n",
            "Eq\n",
            ".\n",
            "(\n",
            "3\n",
            ")\n",
            ".\n",
            "I\n",
            "suggest\n",
            "that\n",
            "elaborating\n",
            "more\n",
            "on\n",
            "this\n",
            "part\n",
            ".\n",
            "(\n",
            "2\n",
            ")\n",
            "It\n",
            "seems\n",
            "like\n",
            "the\n",
            "graph\n",
            "embedding\n",
            "component\n",
            "is\n",
            "fixed\n",
            "to\n",
            "GCN\n",
            "in\n",
            "the\n",
            "paper\n",
            ".\n",
            "But\n",
            "it\n",
            "seems\n",
            "to\n",
            "me\n",
            "that\n",
            "it\n",
            "can\n",
            "be\n",
            "any\n",
            "existing\n",
            "variant\n",
            "of\n",
            "GNNs\n",
            ".\n",
            "Could\n",
            "you\n",
            "elaborate\n",
            "more\n",
            "on\n",
            "it\n",
            "?\n",
            "Also\n",
            ",\n",
            "have\n",
            "you\n",
            "tried\n",
            "to\n",
            "use\n",
            "different\n",
            "variants\n",
            "of\n",
            "GNNs\n",
            "to\n",
            "combine\n",
            "with\n",
            "your\n",
            "IDGL\n",
            "framework\n",
            "?\n",
            "I\n",
            "suggest\n",
            "adding\n",
            "some\n",
            "analyses\n",
            "about\n",
            "this\n",
            "point\n",
            ".\n",
            "(\n",
            "3\n",
            ")\n",
            "Minors\n",
            ":\n",
            "Some\n",
            "hyper\n",
            "parameters\n",
            "need\n",
            "better\n",
            "explanations\n",
            "(\n",
            "such\n",
            "as\n",
            "lamda\n",
            ",\n",
            "gamma\n",
            ",\n",
            "beta\n",
            "and\n",
            "eta\n",
            ")\n",
            "and\n",
            "the\n",
            "paper\n",
            "needs\n",
            "some\n",
            "editing\n",
            "to\n",
            "fix\n",
            "a\n",
            "few\n",
            "grammar\n",
            "issues\n",
            ".\n",
            "Correctness\n",
            ":\n",
            "Yes\n",
            ",\n",
            "The\n",
            "model\n",
            "is\n",
            "in\n",
            "a\n",
            "nice\n",
            "architecture\n",
            "and\n",
            "the\n",
            "experiments\n",
            "have\n",
            "shown\n",
            "the\n",
            "effectiveness\n",
            "of\n",
            "each\n",
            "part\n",
            ".\n",
            "Clarity\n",
            ":\n",
            "Yes\n",
            ",\n",
            "the\n",
            "paper\n",
            "is\n",
            "well\n",
            "written\n",
            ",\n",
            "which\n",
            "is\n",
            "easy\n",
            "to\n",
            "follow\n",
            ",\n",
            "although\n",
            "some\n",
            "hyper\n",
            "parameters\n",
            "needs\n",
            "better\n",
            "explanations\n",
            ".\n",
            "Relation\n",
            "to\n",
            "Prior\n",
            "Work\n",
            ":\n",
            "Yes\n",
            ",\n",
            "The\n",
            "paper\n",
            "has\n",
            "pointed\n",
            "out\n",
            "the\n",
            "differences\n",
            "between\n",
            "the\n",
            "proposed\n",
            "model\n",
            "and\n",
            "existing\n",
            "works\n",
            "and\n",
            "highlighted\n",
            "the\n",
            "contributions\n",
            ".\n",
            "Reproducibility\n",
            ":\n",
            "Yes\n",
            "Additional\n",
            "Feedback\n",
            ":\n",
            "Thanks\n",
            "for\n",
            "the\n",
            "authors\n",
            "'\n",
            "response\n",
            ".\n",
            "I\n",
            "hope\n",
            "my\n",
            "suggestions\n",
            "would\n",
            "be\n",
            "helpful\n",
            ".\n",
            "Review\n",
            "4\n",
            "Summary\n",
            "and\n",
            "Contributions\n",
            ":\n",
            "Many\n",
            "real-world\n",
            "applications\n",
            "naturally\n",
            "admit\n",
            "network-structured\n",
            "data\n",
            "(\n",
            "e.g.\n",
            ",\n",
            "social\n",
            "networks\n",
            ")\n",
            ".\n",
            "However\n",
            ",\n",
            "these\n",
            "intrinsic\n",
            "graph-structures\n",
            "are\n",
            "not\n",
            "always\n",
            "optimal\n",
            "for\n",
            "the\n",
            "downstream\n",
            "tasks\n",
            ".\n",
            "To\n",
            "address\n",
            "this\n",
            "real-world\n",
            "issue\n",
            ",\n",
            "this\n",
            "paper\n",
            "presents\n",
            "an\n",
            "end-to-end\n",
            "graph\n",
            "learning\n",
            "framework\n",
            ",\n",
            "namely\n",
            "Iterative\n",
            "Deep\n",
            "Graph\n",
            "Learning\n",
            "(\n",
            "IDGL\n",
            ")\n",
            ",\n",
            "for\n",
            "jointly\n",
            "and\n",
            "iteratively\n",
            "learning\n",
            "the\n",
            "graph\n",
            "structure\n",
            "and\n",
            "the\n",
            "GNN\n",
            "parameters\n",
            "that\n",
            "are\n",
            "optimized\n",
            "towards\n",
            "the\n",
            "downstream\n",
            "prediction\n",
            "task\n",
            ".\n",
            "The\n",
            "performance\n",
            "of\n",
            "the\n",
            "proposed\n",
            "IDGL\n",
            "is\n",
            "consistently\n",
            "better\n",
            "than\n",
            "or\n",
            "close\n",
            "to\n",
            "that\n",
            "of\n",
            "SOTA\n",
            "baselines\n",
            ".\n",
            "The\n",
            "ablation\n",
            "study\n",
            "is\n",
            "provided\n",
            "to\n",
            "verify\n",
            "each\n",
            "component\n",
            "in\n",
            "IDGL\n",
            "is\n",
            "effective\n",
            ".\n",
            "In\n",
            "general\n",
            ",\n",
            "this\n",
            "paper\n",
            "is\n",
            "a\n",
            "good\n",
            "paper\n",
            "and\n",
            "should\n",
            "be\n",
            "presented\n",
            "in\n",
            "NeurIPS2020\n",
            ".\n",
            "Strengths\n",
            ":\n",
            "This\n",
            "paper\n",
            "addresses\n",
            "an\n",
            "important\n",
            "problem\n",
            "existed\n",
            "in\n",
            "GNNs\n",
            ".\n",
            "When\n",
            "training\n",
            "a\n",
            "GNN\n",
            ",\n",
            "many\n",
            "real-world\n",
            "applications\n",
            "naturally\n",
            "admit\n",
            "network-structured\n",
            "data\n",
            "(\n",
            "e.g.\n",
            ",\n",
            "social\n",
            "networks\n",
            ")\n",
            ".\n",
            "However\n",
            ",\n",
            "these\n",
            "intrinsic\n",
            "graph-structures\n",
            "are\n",
            "not\n",
            "always\n",
            "optimal\n",
            "for\n",
            "the\n",
            "downstream\n",
            "tasks\n",
            ".\n",
            "To\n",
            "address\n",
            "this\n",
            "real-world\n",
            "issue\n",
            ",\n",
            "this\n",
            "paper\n",
            "presents\n",
            "an\n",
            "end-to-end\n",
            "graph\n",
            "learning\n",
            "framework\n",
            ",\n",
            "namely\n",
            "Iterative\n",
            "Deep\n",
            "Graph\n",
            "Learning\n",
            "(\n",
            "IDGL\n",
            ")\n",
            ",\n",
            "for\n",
            "jointly\n",
            "and\n",
            "iteratively\n",
            "learning\n",
            "the\n",
            "graph\n",
            "structure\n",
            "and\n",
            "the\n",
            "GNN\n",
            "parameters\n",
            "that\n",
            "are\n",
            "optimized\n",
            "towards\n",
            "the\n",
            "downstream\n",
            "prediction\n",
            "task\n",
            ".\n",
            "The\n",
            "performance\n",
            "of\n",
            "the\n",
            "proposed\n",
            "IDGL\n",
            "is\n",
            "consistently\n",
            "better\n",
            "than\n",
            "or\n",
            "close\n",
            "to\n",
            "that\n",
            "of\n",
            "SOTA\n",
            "baselines\n",
            ".\n",
            "The\n",
            "ablation\n",
            "study\n",
            "is\n",
            "provided\n",
            "to\n",
            "verify\n",
            "each\n",
            "component\n",
            "in\n",
            "IDGL\n",
            "is\n",
            "effective\n",
            ".\n",
            "Weaknesses\n",
            ":\n",
            "I\n",
            "would\n",
            "be\n",
            "the\n",
            "best\n",
            "to\n",
            "provide\n",
            "an\n",
            "empirical\n",
            "evidence\n",
            "that\n",
            "intrinsic\n",
            "graph-structures\n",
            "are\n",
            "not\n",
            "always\n",
            "optimal\n",
            "for\n",
            "the\n",
            "downstream\n",
            "tasks\n",
            "in\n",
            "the\n",
            "introduction\n",
            "section\n",
            ".\n",
            "Correctness\n",
            ":\n",
            "Yes\n",
            ",\n",
            "all\n",
            "claims\n",
            "and\n",
            "methods\n",
            "are\n",
            "correct\n",
            ".\n",
            "The\n",
            "the\n",
            "empirical\n",
            "methodology\n",
            "is\n",
            "correct\n",
            ".\n",
            "Clarity\n",
            ":\n",
            "This\n",
            "paper\n",
            "is\n",
            "well\n",
            "written\n",
            ".\n",
            "Relation\n",
            "to\n",
            "Prior\n",
            "Work\n",
            ":\n",
            "Yes\n",
            ".\n",
            "it\n",
            "is\n",
            "clearly\n",
            "discussed\n",
            "how\n",
            "this\n",
            "work\n",
            "differs\n",
            "from\n",
            "previous\n",
            "contributions\n",
            ".\n",
            "Reproducibility\n",
            ":\n",
            "Yes\n",
            "Abstract\n",
            "In\n",
            "recent\n",
            "years\n",
            ",\n",
            "graph\n",
            "neural\n",
            "networks\n",
            "(\n",
            "GNNs\n",
            ")\n",
            "have\n",
            "become\n",
            "the\n",
            "de\n",
            "facto\n",
            "tool\n",
            "for\n",
            "performing\n",
            "machine\n",
            "learning\n",
            "tasks\n",
            "on\n",
            "graphs\n",
            ".\n",
            "Most\n",
            "GNNs\n",
            "belong\n",
            "to\n",
            "the\n",
            "family\n",
            "of\n",
            "message\n",
            "passing\n",
            "neural\n",
            "networks\n",
            "(\n",
            "MPNNs\n",
            ")\n",
            ".\n",
            "These\n",
            "models\n",
            "employ\n",
            "an\n",
            "iterative\n",
            "neighborhood\n",
            "aggregation\n",
            "scheme\n",
            "to\n",
            "update\n",
            "vertex\n",
            "representations\n",
            ".\n",
            "Then\n",
            ",\n",
            "to\n",
            "compute\n",
            "vector\n",
            "representations\n",
            "of\n",
            "graphs\n",
            ",\n",
            "they\n",
            "aggregate\n",
            "the\n",
            "representations\n",
            "of\n",
            "the\n",
            "vertices\n",
            "using\n",
            "some\n",
            "permutation\n",
            "invariant\n",
            "function\n",
            ".\n",
            "One\n",
            "would\n",
            "expect\n",
            "the\n",
            "hidden\n",
            "layers\n",
            "of\n",
            "a\n",
            "GNN\n",
            "to\n",
            "be\n",
            "composed\n",
            "of\n",
            "parameters\n",
            "that\n",
            "take\n",
            "the\n",
            "form\n",
            "of\n",
            "graphs\n",
            ".\n",
            "However\n",
            ",\n",
            "this\n",
            "is\n",
            "not\n",
            "the\n",
            "case\n",
            "for\n",
            "MPNNs\n",
            "since\n",
            "their\n",
            "update\n",
            "procedure\n",
            "is\n",
            "parameterized\n",
            "by\n",
            "fully-connected\n",
            "layers\n",
            ".\n",
            "In\n",
            "this\n",
            "paper\n",
            ",\n",
            "we\n",
            "propose\n",
            "a\n",
            "more\n",
            "intuitive\n",
            "and\n",
            "transparent\n",
            "architecture\n",
            "for\n",
            "graph-structured\n",
            "data\n",
            ",\n",
            "so-called\n",
            "Random\n",
            "Walk\n",
            "Graph\n",
            "Neural\n",
            "Network\n",
            "(\n",
            "RWNN\n",
            ")\n",
            ".\n",
            "The\n",
            "ﬁrst\n",
            "layer\n",
            "of\n",
            "the\n",
            "model\n",
            "consists\n",
            "of\n",
            "a\n",
            "number\n",
            "of\n",
            "trainable\n",
            "“\n",
            "hidden\n",
            "graphs\n",
            "”\n",
            "which\n",
            "are\n",
            "compared\n",
            "against\n",
            "the\n",
            "input\n",
            "graphs\n",
            "using\n",
            "a\n",
            "random\n",
            "walk\n",
            "kernel\n",
            "to\n",
            "produce\n",
            "graph\n",
            "representations\n",
            ".\n",
            "These\n",
            "representations\n",
            "are\n",
            "then\n",
            "passed\n",
            "on\n",
            "to\n",
            "a\n",
            "fully-connected\n",
            "neural\n",
            "network\n",
            "which\n",
            "produces\n",
            "the\n",
            "output\n",
            ".\n",
            "The\n",
            "employed\n",
            "random\n",
            "walk\n",
            "kernel\n",
            "is\n",
            "differentiable\n",
            ",\n",
            "and\n",
            "therefore\n",
            ",\n",
            "the\n",
            "proposed\n",
            "model\n",
            "is\n",
            "end-to-end\n",
            "trainable\n",
            ".\n",
            "We\n",
            "demonstrate\n",
            "the\n",
            "model\n",
            "’\n",
            "s\n",
            "transparency\n",
            "on\n",
            "synthetic\n",
            "datasets\n",
            ".\n",
            "Furthermore\n",
            ",\n",
            "we\n",
            "empirically\n",
            "evaluate\n",
            "the\n",
            "model\n",
            "on\n",
            "graph\n",
            "classiﬁcation\n",
            "datasets\n",
            "and\n",
            "show\n",
            "that\n",
            "it\n",
            "achieves\n",
            "competitive\n",
            "performance\n",
            ".\n",
            "NeurIPS\n",
            "2020\n",
            "Adversarial\n",
            "Attacks\n",
            "on\n",
            "Deep\n",
            "Graph\n",
            "Matching\n",
            "Review\n",
            "1\n",
            "Summary\n",
            "and\n",
            "Contributions\n",
            ":\n",
            "The\n",
            "author\n",
            "proposed\n",
            "a\n",
            "model-agnostic\n",
            "method\n",
            "for\n",
            "generating\n",
            "the\n",
            "graph\n",
            "node\n",
            "adversarial\n",
            "samples\n",
            "and\n",
            "attacking\n",
            "some\n",
            "graph\n",
            "matching\n",
            "models\n",
            ".\n",
            "Specifically\n",
            ",\n",
            "a\n",
            "kernel\n",
            "density\n",
            "estimation\n",
            "function\n",
            "is\n",
            "proposed\n",
            "for\n",
            "pushing\n",
            "attacked\n",
            "nodes\n",
            "(\n",
            "around\n",
            "the\n",
            "target\n",
            "node\n",
            ")\n",
            "to\n",
            "aggregate\n",
            "together\n",
            ".\n",
            "Hence\n",
            ",\n",
            "the\n",
            "attacked\n",
            "node\n",
            "can\n",
            "confuse\n",
            "the\n",
            "graph\n",
            "model\n",
            "to\n",
            "make\n",
            "a\n",
            "wrong\n",
            "decision\n",
            "when\n",
            "matching\n",
            "the\n",
            "pairwise\n",
            "nodes\n",
            ".\n",
            "Also\n",
            ",\n",
            "a\n",
            "meta\n",
            "learning\n",
            "projected\n",
            "gradient\n",
            "method\n",
            "is\n",
            "proposed\n",
            "to\n",
            "select\n",
            "the\n",
            "attack\n",
            "start\n",
            "nodes\n",
            ".\n",
            "Strengths\n",
            ":\n",
            "The\n",
            "author\n",
            "conducts\n",
            "a\n",
            "solid\n",
            "analysis\n",
            "of\n",
            "their\n",
            "proposed\n",
            "methods\n",
            "and\n",
            "also\n",
            "evaluate\n",
            "their\n",
            "attack\n",
            "methods\n",
            "on\n",
            "multiple\n",
            "graph\n",
            "models\n",
            ".\n",
            "Besides\n",
            ",\n",
            "the\n",
            "comparison\n",
            "baseline\n",
            "models\n",
            "are\n",
            "also\n",
            "solid\n",
            ".\n",
            "Weaknesses\n",
            ":\n",
            "In\n",
            "the\n",
            "experiment\n",
            "part\n",
            ",\n",
            "the\n",
            "author\n",
            "should\n",
            "show\n",
            "some\n",
            "evidence\n",
            "of\n",
            "the\n",
            "unnoticeable\n",
            "perturbations\n",
            "on\n",
            "the\n",
            "graph\n",
            ".\n",
            "Also\n",
            ",\n",
            "could\n",
            "the\n",
            "author\n",
            "shortly\n",
            "explain\n",
            "why\n",
            "you\n",
            "chose\n",
            "the\n",
            "Gaussian\n",
            "model\n",
            "on\n",
            "parameter\n",
            "estimation\n",
            "?\n",
            "Correctness\n",
            ":\n",
            "The\n",
            "whole\n",
            "method\n",
            "is\n",
            "valid\n",
            ",\n",
            "and\n",
            "the\n",
            "author\n",
            "showed\n",
            "enough\n",
            "analysis\n",
            "on\n",
            "their\n",
            "methodology\n",
            "description\n",
            ".\n",
            "Clarity\n",
            ":\n",
            "The\n",
            "paper\n",
            "is\n",
            "well\n",
            "organized\n",
            "and\n",
            "written\n",
            "except\n",
            "for\n",
            "some\n",
            "little\n",
            "flaws\n",
            ".\n",
            "(\n",
            "E.g\n",
            ".\n",
            "equation\n",
            "5\n",
            "is\n",
            "somehow\n",
            "unexpected\n",
            ",\n",
            "the\n",
            "author\n",
            "should\n",
            "better\n",
            "introduce\n",
            "the\n",
            "equation\n",
            "before\n",
            "the\n",
            "equation\n",
            ".\n",
            ")\n",
            "Relation\n",
            "to\n",
            "Prior\n",
            "Work\n",
            ":\n",
            "The\n",
            "paper\n",
            "firstly\n",
            "introduces\n",
            "the\n",
            "kernel\n",
            "density\n",
            "estimation\n",
            "method\n",
            "(\n",
            "KDE\n",
            ")\n",
            "into\n",
            "graph\n",
            "adversarial\n",
            "attack\n",
            "task\n",
            ".\n",
            "Also\n",
            ",\n",
            "few\n",
            "work\n",
            "are\n",
            "conducted\n",
            "on\n",
            "adversarial\n",
            "attack\n",
            "to\n",
            "graph\n",
            "matching\n",
            "model\n",
            ",\n",
            "which\n",
            "is\n",
            "an\n",
            "important\n",
            "work\n",
            "to\n",
            "evaluate\n",
            "the\n",
            "robustness\n",
            "of\n",
            "the\n",
            "graph\n",
            "matching\n",
            "models\n",
            "Reproducibility\n",
            ":\n",
            "Yes\n",
            "Additional\n",
            "Feedback\n",
            ":\n",
            "The\n",
            "rebuttal\n",
            "indeed\n",
            "improved\n",
            "the\n",
            "paper\n",
            ",\n",
            "and\n",
            "I\n",
            "will\n",
            "increase\n",
            "the\n",
            "score\n",
            ".\n",
            "Review\n",
            "2\n",
            "Summary\n",
            "and\n",
            "Contributions\n",
            ":\n",
            "The\n",
            "paper\n",
            "proposed\n",
            "an\n",
            "attack\n",
            "method\n",
            "on\n",
            "GNN\n",
            ".\n",
            "They\n",
            "utilize\n",
            "a\n",
            "kernel\n",
            "density\n",
            "estimation\n",
            "function\n",
            "to\n",
            "estimate\n",
            "the\n",
            "densities\n",
            "of\n",
            "nodes\n",
            "and\n",
            "generate\n",
            "perturbations\n",
            "under\n",
            "a\n",
            "specific\n",
            "budget\n",
            "by\n",
            "pushing\n",
            "attacked\n",
            "nodes\n",
            "to\n",
            "dense\n",
            "regions\n",
            "in\n",
            "two\n",
            "graphs\n",
            ".\n",
            "Moreover\n",
            ",\n",
            "they\n",
            "developed\n",
            "meta\n",
            "learning\n",
            "based\n",
            "projected\n",
            "gradient\n",
            "descent\n",
            "method\n",
            "to\n",
            "optimize\n",
            "the\n",
            "objective\n",
            "function\n",
            ".\n",
            "Strengths\n",
            ":\n",
            "1\n",
            ".\n",
            "The\n",
            "method\n",
            "is\n",
            "novel\n",
            "and\n",
            "sound\n",
            ".\n",
            "The\n",
            "theoretical\n",
            "analysis\n",
            "is\n",
            "comprehensive\n",
            "and\n",
            "convincing\n",
            ".\n",
            "2\n",
            ".\n",
            "The\n",
            "meta-learning\n",
            "helps\n",
            "in\n",
            "finding\n",
            "good\n",
            "attack\n",
            "starting\n",
            "points\n",
            "that\n",
            "alleviate\n",
            "the\n",
            "overlarge\n",
            "search\n",
            "domain\n",
            "on\n",
            "large\n",
            "graphs\n",
            ".\n",
            "2\n",
            ".\n",
            "The\n",
            "experimental\n",
            "results\n",
            "demonstrated\n",
            "the\n",
            "proposed\n",
            "method\n",
            ".\n",
            "Weaknesses\n",
            ":\n",
            "1\n",
            ".\n",
            "What\n",
            "'s\n",
            "the\n",
            "time\n",
            "complexity\n",
            "of\n",
            "the\n",
            "attack\n",
            "method\n",
            "?\n",
            "Since\n",
            "the\n",
            "meta-learning\n",
            "involved\n",
            "in\n",
            "a\n",
            "repeatedly\n",
            "training/attacking\n",
            "procedure\n",
            ",\n",
            "I\n",
            "'m\n",
            "wondering\n",
            "the\n",
            "time\n",
            "cost\n",
            "could\n",
            "be\n",
            "very\n",
            "high\n",
            "to\n",
            "find\n",
            "the\n",
            "adversarial\n",
            "nodes\n",
            "especially\n",
            "compare\n",
            "with\n",
            "existing\n",
            "methods\n",
            ".\n",
            "2\n",
            ".\n",
            "Recently\n",
            ",\n",
            "a\n",
            "lot\n",
            "of\n",
            "defense\n",
            "methods\n",
            "against\n",
            "adversarial\n",
            "attacks\n",
            "on\n",
            "GNN\n",
            "have\n",
            "been\n",
            "proposed\n",
            ",\n",
            "such\n",
            "as\n",
            "[\n",
            "1-4\n",
            "]\n",
            ".\n",
            "I\n",
            "think\n",
            "the\n",
            "authors\n",
            "should\n",
            "at\n",
            "least\n",
            "choose\n",
            "one\n",
            "to\n",
            "demonstrate\n",
            "attack\n",
            "is\n",
            "still\n",
            "useful\n",
            "even\n",
            "under\n",
            "such\n",
            "defenses\n",
            ".\n",
            "3\n",
            ".\n",
            "The\n",
            "related\n",
            "work\n",
            "part\n",
            "is\n",
            "missing\n",
            ",\n",
            "so\n",
            "I\n",
            "yield\n",
            "a\n",
            "question\n",
            "that\n",
            "by\n",
            "leverage\n",
            "meta-learning\n",
            "to\n",
            "help\n",
            "generate\n",
            "adversarial\n",
            "attacks\n",
            "is\n",
            "shown\n",
            "in\n",
            "[\n",
            "5\n",
            "]\n",
            ".\n",
            "So\n",
            "the\n",
            "difference\n",
            "should\n",
            "be\n",
            "clarified\n",
            ".\n",
            "Minor\n",
            "question\n",
            ":\n",
            "It\n",
            "seems\n",
            "that\n",
            "the\n",
            "proposed\n",
            "method\n",
            "is\n",
            "getting\n",
            "more\n",
            "powerful\n",
            "as\n",
            "the\n",
            "dataset\n",
            "comes\n",
            "larger\n",
            "from\n",
            "Table\n",
            "2\n",
            ".\n",
            "Any\n",
            "insight\n",
            "can\n",
            "be\n",
            "obtained\n",
            "from\n",
            "this\n",
            "?\n",
            "[\n",
            "1\n",
            "]\n",
            "Certifiable\n",
            "Robustness\n",
            "and\n",
            "Robust\n",
            "Training\n",
            "for\n",
            "Graph\n",
            "Convolutional\n",
            "Networks\n",
            "[\n",
            "2\n",
            "]\n",
            "Adversarial\n",
            "Examples\n",
            "on\n",
            "Graph\n",
            "Data\n",
            ":\n",
            "Deep\n",
            "Insights\n",
            "into\n",
            "Attack\n",
            "and\n",
            "Defense\n",
            "[\n",
            "3\n",
            "]\n",
            "Topology\n",
            "Attack\n",
            "and\n",
            "Defense\n",
            "for\n",
            "Graph\n",
            "Neural\n",
            "Networks\n",
            ":\n",
            "An\n",
            "Optimization\n",
            "Perspective\n",
            "[\n",
            "4\n",
            "]\n",
            "All\n",
            "You\n",
            "Need\n",
            "is\n",
            "Low\n",
            "(\n",
            "Rank\n",
            ")\n",
            ":\n",
            "Defending\n",
            "Against\n",
            "Adversarial\n",
            "Attacks\n",
            "on\n",
            "Graphs\n",
            "[\n",
            "5\n",
            "]\n",
            "Adversarial\n",
            "Attacks\n",
            "on\n",
            "Graph\n",
            "Neural\n",
            "Networks\n",
            "via\n",
            "Meta\n",
            "Learning\n",
            "Correctness\n",
            ":\n",
            "The\n",
            "claims\n",
            "are\n",
            "proofed\n",
            "in\n",
            "the\n",
            "paper\n",
            "and\n",
            "maybe\n",
            "correct\n",
            ".\n",
            "Clarity\n",
            ":\n",
            "The\n",
            "paper\n",
            "is\n",
            "well\n",
            "written\n",
            "and\n",
            "many\n",
            "experimental\n",
            "details\n",
            "are\n",
            "stated\n",
            "in\n",
            "the\n",
            "appendix\n",
            ".\n",
            "Relation\n",
            "to\n",
            "Prior\n",
            "Work\n",
            ":\n",
            "Not\n",
            "very\n",
            "comprehensive\n",
            ".\n",
            "Reproducibility\n",
            ":\n",
            "Yes\n",
            "Additional\n",
            "Feedback\n",
            ":\n",
            "Overall\n",
            ",\n",
            "I\n",
            "agree\n",
            "the\n",
            "novelty\n",
            "of\n",
            "this\n",
            "paper\n",
            ",\n",
            "I\n",
            "'d\n",
            "like\n",
            "to\n",
            "change\n",
            "my\n",
            "score\n",
            "if\n",
            "the\n",
            "authors\n",
            "can\n",
            "answer\n",
            "my\n",
            "questions\n",
            "in\n",
            "[\n",
            "Weaknesses\n",
            "]\n",
            "part\n",
            ".\n",
            "===================================\n",
            "After\n",
            "read\n",
            "the\n",
            "rebutall\n",
            ",\n",
            "the\n",
            "author\n",
            "addressed\n",
            "my\n",
            "question\n",
            "well\n",
            "and\n",
            "I\n",
            "decided\n",
            "to\n",
            "rasie\n",
            "my\n",
            "score\n",
            "to\n",
            "6\n",
            ".\n",
            "The\n",
            "contribution\n",
            "needs\n",
            "to\n",
            "be\n",
            "clarified\n",
            "in\n",
            "the\n",
            "revision\n",
            ".\n",
            "Review\n",
            "3\n",
            "Summary\n",
            "and\n",
            "Contributions\n",
            ":\n",
            "In\n",
            "this\n",
            "paper\n",
            ",\n",
            "the\n",
            "authors\n",
            "propose\n",
            "a\n",
            "method\n",
            "for\n",
            "adversarial\n",
            "attacking\n",
            "graph\n",
            "matching\n",
            "methods\n",
            "based\n",
            "on\n",
            "a\n",
            "kernel\n",
            "density\n",
            "estimation\n",
            "approach\n",
            "and\n",
            "a\n",
            "meta-learning\n",
            "based\n",
            "gradient\n",
            "descent\n",
            "method\n",
            ".\n",
            "Theoretical\n",
            "results\n",
            "are\n",
            "provided\n",
            "in\n",
            "deriving\n",
            "the\n",
            "KDE\n",
            "and\n",
            "experiments\n",
            "demonstrate\n",
            "the\n",
            "effectiveness\n",
            "of\n",
            "the\n",
            "proposed\n",
            "method\n",
            "in\n",
            "successfully\n",
            "downgrading\n",
            "a\n",
            "range\n",
            "of\n",
            "recent\n",
            "deep\n",
            "graph\n",
            "matching\n",
            "methods\n",
            ".\n",
            "In\n",
            "the\n",
            "supplementary\n",
            "material\n",
            ",\n",
            "the\n",
            "authors\n",
            "also\n",
            "generalize\n",
            "their\n",
            "method\n",
            "in\n",
            "node\n",
            "classification\n",
            "and\n",
            "link\n",
            "prediction\n",
            "tasks\n",
            ".\n",
            "Strengths\n",
            ":\n",
            "(\n",
            "+\n",
            ")\n",
            ":\n",
            "The\n",
            "authors\n",
            "study\n",
            "a\n",
            "novel\n",
            "problem\n",
            ",\n",
            "i.e.\n",
            ",\n",
            "adversarial\n",
            "attacks\n",
            "of\n",
            "graph\n",
            "matching\n",
            ".\n",
            "(\n",
            "+\n",
            ")\n",
            ":\n",
            "The\n",
            "literature\n",
            "survey\n",
            "is\n",
            "quite\n",
            "comprehensive\n",
            ".\n",
            "(\n",
            "+\n",
            ")\n",
            ":\n",
            "Experiments\n",
            "demonstrate\n",
            "the\n",
            "effectiveness\n",
            "of\n",
            "the\n",
            "proposed\n",
            "method\n",
            ".\n",
            "(\n",
            "+\n",
            ")\n",
            ":\n",
            "The\n",
            "proposed\n",
            "method\n",
            "may\n",
            "be\n",
            "generalized\n",
            "to\n",
            "other\n",
            "settings\n",
            "such\n",
            "as\n",
            "node\n",
            "classification\n",
            ".\n",
            "Weaknesses\n",
            ":\n",
            "(\n",
            "-\n",
            ")\n",
            ":\n",
            "The\n",
            "proposed\n",
            "method\n",
            "does\n",
            "not\n",
            "precisely\n",
            "correspond\n",
            "to\n",
            "the\n",
            "motivation\n",
            ".\n",
            "(\n",
            "-\n",
            ")\n",
            ":\n",
            "Some\n",
            "technical\n",
            "details\n",
            "and\n",
            "experimental\n",
            "settings\n",
            "are\n",
            "not\n",
            "clear\n",
            ".\n",
            "The\n",
            "negative\n",
            "points\n",
            "are\n",
            "explained\n",
            "more\n",
            "specifically\n",
            "as\n",
            "follows\n",
            ".\n",
            "(\n",
            "1\n",
            ")\n",
            "The\n",
            "authors\n",
            "claimed\n",
            "the\n",
            "main\n",
            "attack\n",
            "strategy\n",
            "as\n",
            "“\n",
            "a\n",
            "kernel\n",
            "density\n",
            "estimation\n",
            "approach\n",
            "to\n",
            "push\n",
            "attacked\n",
            "nodes\n",
            "to\n",
            "dense\n",
            "regions\n",
            "in\n",
            "two\n",
            "graphs\n",
            ",\n",
            "such\n",
            "that\n",
            "they\n",
            "are\n",
            "indistinguishable\n",
            "from\n",
            "many\n",
            "neighbors\n",
            "”\n",
            "and\n",
            "focus\n",
            "on\n",
            "deriving\n",
            "the\n",
            "KDE\n",
            "in\n",
            "Section\n",
            "3\n",
            ".\n",
            "However\n",
            ",\n",
            "in\n",
            "the\n",
            "objective\n",
            "function\n",
            "Eq\n",
            ".\n",
            "9\n",
            ",\n",
            "KDE\n",
            "is\n",
            "only\n",
            "adopted\n",
            "as\n",
            "a\n",
            "sort\n",
            "of\n",
            "regularization\n",
            ".\n",
            "I\n",
            "feel\n",
            "it\n",
            "is\n",
            "the\n",
            "first\n",
            "term\n",
            ",\n",
            "which\n",
            "explicitly\n",
            "pushes\n",
            "away\n",
            "ground-truth\n",
            "matching\n",
            "points\n",
            ",\n",
            "that\n",
            "really\n",
            "matters\n",
            "and\n",
            "it\n",
            "does\n",
            "not\n",
            "depend\n",
            "on\n",
            "the\n",
            "sophisticated\n",
            "KDE\n",
            ".\n",
            "The\n",
            "authors\n",
            "should\n",
            "prove\n",
            "that\n",
            "the\n",
            "KDE\n",
            "term\n",
            "is\n",
            "indeed\n",
            "helpful\n",
            ",\n",
            "e.g.\n",
            ",\n",
            "by\n",
            "an\n",
            "explicit\n",
            "theorem\n",
            "or\n",
            "conducting\n",
            "an\n",
            "ablation\n",
            "study\n",
            ".\n",
            "(\n",
            "2\n",
            ")\n",
            "I\n",
            "am\n",
            "also\n",
            "not\n",
            "sure\n",
            "why\n",
            "the\n",
            "authors\n",
            "claimed\n",
            "using\n",
            "KDE\n",
            "“\n",
            "reduces\n",
            "the\n",
            "possibility\n",
            "of\n",
            "perturbation\n",
            "detection\n",
            "by\n",
            "humans\n",
            "or\n",
            "defender\n",
            "programs\n",
            "”\n",
            "since\n",
            "the\n",
            "level\n",
            "of\n",
            "attack\n",
            ",\n",
            "i.e.\n",
            ",\n",
            "whether\n",
            "the\n",
            "permutation\n",
            "is\n",
            "perceptible\n",
            "or\n",
            "not\n",
            ",\n",
            "is\n",
            "only\n",
            "determined\n",
            "by\n",
            "the\n",
            "budget\n",
            ".\n",
            "(\n",
            "3\n",
            ")\n",
            "As\n",
            "for\n",
            "the\n",
            "experimental\n",
            "setting\n",
            ",\n",
            "it\n",
            "seems\n",
            "that\n",
            "most\n",
            "baselines\n",
            "are\n",
            "designed\n",
            "for\n",
            "GNN-based\n",
            "node\n",
            "classification\n",
            "tasks\n",
            "and\n",
            "how\n",
            "to\n",
            "adapt\n",
            "them\n",
            "in\n",
            "the\n",
            "graph\n",
            "matching\n",
            "problem\n",
            "remains\n",
            "unexplained\n",
            "(\n",
            "e.g.\n",
            ",\n",
            "do\n",
            "you\n",
            "still\n",
            "use\n",
            "misclassifying\n",
            "node\n",
            "labels\n",
            "as\n",
            "the\n",
            "objective\n",
            "function\n",
            "?\n",
            ")\n",
            ".\n",
            "In\n",
            "addition\n",
            ",\n",
            "following\n",
            "(\n",
            "1\n",
            ")\n",
            ",\n",
            "I\n",
            "think\n",
            "the\n",
            "authors\n",
            "should\n",
            "also\n",
            "compare\n",
            "with\n",
            "the\n",
            "most\n",
            "intuitive\n",
            "method\n",
            "of\n",
            "directly\n",
            "maximizing\n",
            "the\n",
            "first\n",
            "term\n",
            "in\n",
            "Eq\n",
            ".\n",
            "9\n",
            ".\n",
            "(\n",
            "4\n",
            ")\n",
            "Also\n",
            ",\n",
            "what\n",
            "’\n",
            "s\n",
            "the\n",
            "adopted\n",
            "projection\n",
            "M\n",
            "function\n",
            "?\n",
            "Do\n",
            "you\n",
            "use\n",
            "a\n",
            "surrogate\n",
            "model\n",
            "as\n",
            "[\n",
            "98\n",
            "]\n",
            "or\n",
            "do\n",
            "you\n",
            "need\n",
            "the\n",
            "actual\n",
            "graph\n",
            "matching\n",
            "model\n",
            "?\n",
            "Correctness\n",
            ":\n",
            "Yes\n",
            ",\n",
            "as\n",
            "far\n",
            "as\n",
            "I\n",
            "can\n",
            "tell\n",
            ".\n",
            "Clarity\n",
            ":\n",
            "Yes\n",
            "Relation\n",
            "to\n",
            "Prior\n",
            "Work\n",
            ":\n",
            "Yes\n",
            "Reproducibility\n",
            ":\n",
            "Yes\n",
            "Additional\n",
            "Feedback\n",
            ":\n",
            "(\n",
            "1\n",
            ")\n",
            "I\n",
            "suggest\n",
            "using\n",
            "a\n",
            "consistent\n",
            "metric\n",
            ",\n",
            "i.e.\n",
            ",\n",
            "either\n",
            "mismatching\n",
            "rate\n",
            "or\n",
            "precision\n",
            ",\n",
            "in\n",
            "all\n",
            "the\n",
            "figures\n",
            ",\n",
            "since\n",
            "they\n",
            "show\n",
            "explicitly\n",
            "the\n",
            "opposite\n",
            "trends\n",
            "and\n",
            "mixing\n",
            "them\n",
            "is\n",
            "confusing\n",
            ".\n",
            "(\n",
            "2\n",
            ")\n",
            "I\n",
            "also\n",
            "suggest\n",
            "the\n",
            "authors\n",
            "trying/extending\n",
            "their\n",
            "method\n",
            "to\n",
            "an\n",
            "“\n",
            "unsupervised\n",
            "”\n",
            "setting\n",
            ",\n",
            "e.g.\n",
            ",\n",
            "not\n",
            "using\n",
            "ground-truth\n",
            "matching\n",
            "pairs\n",
            ",\n",
            "which\n",
            "will\n",
            "make\n",
            "the\n",
            "proposed\n",
            "model\n",
            "more\n",
            "practical\n",
            ",\n",
            "e.g.\n",
            ",\n",
            "for\n",
            "a\n",
            "social\n",
            "network\n",
            "to\n",
            "anonymize\n",
            ",\n",
            "since\n",
            "it\n",
            "may\n",
            "not\n",
            "be\n",
            "feasible\n",
            "to\n",
            "collect\n",
            "such\n",
            "ground-truths\n",
            "in\n",
            "the\n",
            "first\n",
            "place\n",
            ".\n",
            "(\n",
            "3\n",
            ")\n",
            "A\n",
            "brief\n",
            "discussion\n",
            "of\n",
            "how\n",
            "KDE\n",
            "can\n",
            "be\n",
            "utilized\n",
            "to\n",
            "other\n",
            "graph\n",
            "tasks\n",
            "beyond\n",
            "attacking\n",
            "graph\n",
            "matching\n",
            "may\n",
            "also\n",
            "be\n",
            "interesting\n",
            ".\n",
            "===Updates===\n",
            "(\n",
            "1\n",
            ")\n",
            "I\n",
            "appreciate\n",
            "the\n",
            "ablation\n",
            "study\n",
            "in\n",
            "Figure\n",
            "5\n",
            "about\n",
            "KDE\n",
            "and\n",
            "MLPGD\n",
            ",\n",
            "but\n",
            "this\n",
            "is\n",
            "not\n",
            "what\n",
            "I\n",
            "asked\n",
            ".\n",
            "Let\n",
            "me\n",
            "rephrase\n",
            "to\n",
            "see\n",
            "whether\n",
            "I\n",
            "understand\n",
            "this\n",
            "correctly\n",
            ":\n",
            "the\n",
            "authors\n",
            "termed\n",
            "all\n",
            "Eq.5\n",
            "as\n",
            "the\n",
            "KDE\n",
            ",\n",
            "and\n",
            "I\n",
            "am\n",
            "curious\n",
            "in\n",
            "this\n",
            "equation\n",
            ",\n",
            "whether\n",
            "the\n",
            "first\n",
            "part\n",
            ",\n",
            "i.e\n",
            ".\n",
            "pushing\n",
            "away\n",
            "matching\n",
            "nodes\n",
            ",\n",
            "or\n",
            "the\n",
            "second\n",
            "part\n",
            ",\n",
            "i.e.\n",
            ",\n",
            "maximizing\n",
            "density\n",
            ",\n",
            "actually\n",
            "matters\n",
            ".\n",
            "I\n",
            "believe\n",
            "this\n",
            "is\n",
            "important\n",
            "since\n",
            "only\n",
            "the\n",
            "second\n",
            "term\n",
            "is\n",
            "the\n",
            "actual\n",
            "KDE\n",
            "(\n",
            "we\n",
            "can\n",
            "push\n",
            "away\n",
            "matching\n",
            "nodes\n",
            "even\n",
            "we\n",
            "do\n",
            "not\n",
            "know\n",
            "KDE\n",
            ")\n",
            ".\n",
            "(\n",
            "2\n",
            ")\n",
            "I\n",
            "agree\n",
            "with\n",
            "the\n",
            "authors\n",
            "that\n",
            "“\n",
            "small\n",
            "attack\n",
            "budget\n",
            "is\n",
            "not\n",
            "enough\n",
            "for\n",
            "imperceptible\n",
            "attacks\n",
            "”\n",
            ".\n",
            "However\n",
            ",\n",
            "the\n",
            "examples\n",
            "in\n",
            "the\n",
            "rebuttal\n",
            "slightly\n",
            "improve\n",
            "the\n",
            "motivation\n",
            "but\n",
            "do\n",
            "not\n",
            "entirely\n",
            "clarify\n",
            "it\n",
            "since\n",
            "what\n",
            "the\n",
            "authors\n",
            "suggested\n",
            "seems\n",
            "to\n",
            "be\n",
            "a\n",
            "degree-related\n",
            "attack\n",
            "budget\n",
            ".\n",
            "Using\n",
            "the\n",
            "authors\n",
            "’\n",
            "example\n",
            ",\n",
            "for\n",
            "a\n",
            "node\n",
            "with\n",
            "two\n",
            "edges\n",
            ",\n",
            "how\n",
            "KDE\n",
            "can\n",
            "make\n",
            "the\n",
            "attack\n",
            "imperceptible\n",
            "since\n",
            "changing\n",
            "one\n",
            "edge\n",
            "is\n",
            "inevitably\n",
            "obvious\n",
            "?\n",
            "The\n",
            "square\n",
            "example\n",
            "seems\n",
            "reasonable\n",
            "at\n",
            "first\n",
            ",\n",
            "but\n",
            "raises\n",
            "questions\n",
            "at\n",
            "second\n",
            "thoughts\n",
            "since\n",
            "this\n",
            "is\n",
            "not\n",
            "how\n",
            "humans/most\n",
            "machine\n",
            "learning\n",
            "models\n",
            "analyze\n",
            "graphs\n",
            "(\n",
            "since\n",
            "we\n",
            "can\n",
            "not\n",
            "assess\n",
            "the\n",
            "graph\n",
            "density\n",
            "easily\n",
            "as\n",
            "in\n",
            "assessing\n",
            "crowd\n",
            "density\n",
            ")\n",
            ".\n",
            "More\n",
            "appropriate\n",
            "examples\n",
            "are\n",
            "needed\n",
            "(\n",
            "e.g.\n",
            ",\n",
            "a\n",
            "synthesis\n",
            "graph\n",
            "example\n",
            "?\n",
            ")\n",
            ".\n",
            "(\n",
            "3\n",
            ")\n",
            "Baseline\n",
            "setting\n",
            ":\n",
            "I\n",
            "appreciate\n",
            "the\n",
            "clarification\n",
            "and\n",
            "believe\n",
            "it\n",
            "’\n",
            "s\n",
            "important\n",
            "to\n",
            "add\n",
            "these\n",
            "details\n",
            "in\n",
            "an\n",
            "updated\n",
            "version\n",
            ".\n",
            "Considering\n",
            "that\n",
            "the\n",
            "rebuttal\n",
            "addressed\n",
            "some\n",
            "of\n",
            "my\n",
            "concerns\n",
            "(\n",
            "though\n",
            "not\n",
            "entirely\n",
            ")\n",
            "and\n",
            "this\n",
            "paper\n",
            "studies\n",
            "a\n",
            "new\n",
            "question\n",
            ",\n",
            "I\n",
            "have\n",
            "raised\n",
            "my\n",
            "rating\n",
            "to\n",
            "6.\n",
            "Review\n",
            "4\n",
            "Summary\n",
            "and\n",
            "Contributions\n",
            ":\n",
            "The\n",
            "paper\n",
            "studies\n",
            "the\n",
            "problem\n",
            "of\n",
            "attacking\n",
            "the\n",
            "graph\n",
            "matching\n",
            "models\n",
            ".\n",
            "The\n",
            "authors\n",
            "propose\n",
            "an\n",
            "adversarial\n",
            "attack\n",
            "model\n",
            "to\n",
            "perturb\n",
            "the\n",
            "structure\n",
            "and\n",
            "degrade\n",
            "the\n",
            "quality\n",
            "of\n",
            "graph\n",
            "matching\n",
            ".\n",
            "First\n",
            ",\n",
            "a\n",
            "kernel\n",
            "density\n",
            "estimation\n",
            "is\n",
            "used\n",
            "to\n",
            "maximize\n",
            "node\n",
            "densities\n",
            "to\n",
            "derive\n",
            "imperceptible\n",
            "perturbation\n",
            ".\n",
            "Then\n",
            "a\n",
            "meta-learning-based\n",
            "PGD\n",
            "method\n",
            "is\n",
            "utilized\n",
            "to\n",
            "choose\n",
            "the\n",
            "attack\n",
            "starting\n",
            "points\n",
            "to\n",
            "improve\n",
            "the\n",
            "search\n",
            "performance\n",
            ".\n",
            "The\n",
            "experimental\n",
            "results\n",
            "show\n",
            "the\n",
            "effectiveness\n",
            "of\n",
            "their\n",
            "approach\n",
            ".\n",
            "Strengths\n",
            ":\n",
            "The\n",
            "paper\n",
            "is\n",
            "well\n",
            "motivated\n",
            ",\n",
            "and\n",
            "the\n",
            "idea\n",
            "is\n",
            "very\n",
            "interesting\n",
            ".\n",
            "The\n",
            "paper\n",
            "is\n",
            "the\n",
            "first\n",
            "work\n",
            "to\n",
            "design\n",
            "the\n",
            "strategy\n",
            "to\n",
            "attack\n",
            "the\n",
            "graph\n",
            "matching\n",
            "model\n",
            ".\n",
            "The\n",
            "theoretical\n",
            "analysis\n",
            "is\n",
            "detailed\n",
            ".\n",
            "The\n",
            "empirical\n",
            "evaluation\n",
            "setting\n",
            "is\n",
            "reasonable\n",
            ",\n",
            "the\n",
            "experiment\n",
            "is\n",
            "complete\n",
            ",\n",
            "and\n",
            "the\n",
            "results\n",
            "look\n",
            "great\n",
            ".\n",
            "Weaknesses\n",
            ":\n",
            "The\n",
            "authors\n",
            "assume\n",
            "that\n",
            "the\n",
            "graph\n",
            "data\n",
            "follow\n",
            "the\n",
            "Gaussian\n",
            "distribution\n",
            ",\n",
            "but\n",
            "I\n",
            "can\n",
            "not\n",
            "find\n",
            "any\n",
            "evidence\n",
            "to\n",
            "support\n",
            "the\n",
            "assumption\n",
            ".\n",
            "The\n",
            "empirical\n",
            "analysis\n",
            "or\n",
            "reference\n",
            "should\n",
            "be\n",
            "provided\n",
            ".\n",
            "Correctness\n",
            ":\n",
            "In\n",
            "my\n",
            "opinion\n",
            ",\n",
            "the\n",
            "method\n",
            "and\n",
            "claims\n",
            "are\n",
            "correct\n",
            ".\n",
            "Also\n",
            ",\n",
            "the\n",
            "empirical\n",
            "methodology\n",
            "is\n",
            "correct\n",
            ".\n",
            "Clarity\n",
            ":\n",
            "The\n",
            "motivation\n",
            "for\n",
            "the\n",
            "paper\n",
            "is\n",
            "clear\n",
            ".\n",
            "Also\n",
            "the\n",
            "motivations\n",
            "for\n",
            "using\n",
            "the\n",
            "kernel\n",
            "density\n",
            "estimation\n",
            "and\n",
            "the\n",
            "meta-learning-based\n",
            "PGD\n",
            "are\n",
            "provided\n",
            ".\n",
            "But\n",
            "the\n",
            "methodology\n",
            "part\n",
            "is\n",
            "not\n",
            "very\n",
            "easy\n",
            "to\n",
            "follow\n",
            ".\n",
            "Relation\n",
            "to\n",
            "Prior\n",
            "Work\n",
            ":\n",
            "Yes\n",
            "Reproducibility\n",
            ":\n",
            "No\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "df_output                                     topic  ... rank_lda\n",
            "0  graph similarity deep learning neurips  ...      6.0\n",
            "1  graph similarity deep learning neurips  ...     10.0\n",
            "2  graph similarity deep learning neurips  ...      2.0\n",
            "3  graph similarity deep learning neurips  ...      5.0\n",
            "4  graph similarity deep learning neurips  ...      1.0\n",
            "5  graph similarity deep learning neurips  ...      8.0\n",
            "6  graph similarity deep learning neurips  ...      4.0\n",
            "7  graph similarity deep learning neurips  ...      3.0\n",
            "8  graph similarity deep learning neurips  ...      7.0\n",
            "9  graph similarity deep learning neurips  ...      9.0\n",
            "\n",
            "[10 rows x 8 columns]\n",
            "topic:  unsupervised information theoretic perceptual quality metric neurips id_= 1\n",
            "1 . An Unsupervised Information-Theoretic Perceptual Quality Metric https://papers.nips.cc/paper/2020/hash/00482b9bed15a272730fcb590ffebddd-Abstract.html\n",
            "**********************************************\n",
            "2 . Review for NeurIPS paper: An Unsupervised Information-Theoretic ... https://papers.nips.cc/paper/2020/file/00482b9bed15a272730fcb590ffebddd-Review.html\n",
            "**********************************************\n",
            "3 . Advances in Neural Information Processing Systems 33 (NeurIPS ... https://papers.nips.cc/paper/2020\n",
            "**********************************************\n",
            "4 . Neural FFTs for Universal Texture Image Synthesis https://papers.nips.cc/paper/2020/file/a23156abfd4a114c35b930b836064e8b-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Synthesizing larger texture images from a smaller exemplar is an important task\n",
            "in graphics and vision. The conventional CNNs, recently adopted for synthesis,\n",
            "require to train and test on the same set of images and fail to generalize to unseen\n",
            "images. This is mainly because those CNNs fully rely on convolutional and\n",
            "upsampling layers that operate locally and not suitable for a task as global as texture\n",
            "synthesis. In this work, inspired by the repetitive nature of texture patterns, we\n",
            "ﬁnd that texture synthesis can be viewed as (local) upsampling in the Fast Fourier\n",
            "Transform (FFT) domain. However, FFT of natural images exhibits high dynamic\n",
            "range and lacks local correlations. Therefore, to train CNNs we design a framework\n",
            "to perform FFT upsampling in feature space using deformable convolutions. Such\n",
            "design allows our framework to generalize to unseen images, and synthesize\n",
            "textures in a single pass. Extensive evaluations conﬁrm that our method achieves\n",
            "state-of-the-art performance both quantitatively and qualitatively.\n",
            "\n",
            "\n",
            "**********************************************\n",
            "5 . Swapping Autoencoder for Deep Image Manipulation https://papers.nips.cc/paper/2020/file/50905d7b2216bfeccb5b41016357176b-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Deep generative models have become increasingly effective at producing realistic\n",
            "images from randomly sampled seeds, but using such models for controllable\n",
            "manipulation of existing images remains challenging. We propose the Swapping\n",
            "Autoencoder, a deep model designed speciﬁcally for image manipulation, rather\n",
            "than random sampling. The key idea is to encode an image into two independent\n",
            "components and enforce that any swapped combination maps to a realistic image.\n",
            "In particular, we encourage the components to represent structure and texture, by\n",
            "enforcing one component to encode co-occurrent patch statistics across different\n",
            "parts of the image. As our method is trained with an encoder, ﬁnding the latent codes\n",
            "for a new input image becomes trivial, rather than cumbersome. As a result, our\n",
            "method enables us to manipulate real input images in various ways, including texture\n",
            "swapping, local and global editing, and latent code vector arithmetic. Experiments\n",
            "on multiple datasets show that our model produces better results and is substantially\n",
            "more efﬁcient compared to recent generative models.\n",
            "\n",
            "Figure 1: Our Swapping Autoencoder learns to disentangle texture from structure for image editing tasks. One\n",
            "such task is texture swapping, shown here. Please see our project webpage for a demo video of our editing method.\n",
            "\n",
            "\n",
            "**********************************************\n",
            "6 . Object-Centric Learning with Slot Attention https://papers.nips.cc/paper/2020/file/8511df98c02ab60aea1b2356c013bc0f-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Learning object-centric representations of complex scenes is a promising step\n",
            "towards enabling efﬁcient abstract reasoning from low-level perceptual features.\n",
            "Yet, most deep learning approaches learn distributed representations that do\n",
            "not capture the compositional properties of natural scenes.\n",
            "In this paper, we\n",
            "present the Slot Attention module, an architectural component that interfaces with\n",
            "perceptual representations such as the output of a convolutional neural network\n",
            "and produces a set of task-dependent abstract representations which we call slots.\n",
            "These slots are exchangeable and can bind to any object in the input by specializing\n",
            "through a competitive procedure over multiple rounds of attention. We empirically\n",
            "demonstrate that Slot Attention can extract object-centric representations that\n",
            "enable generalization to unseen compositions when trained on unsupervised object\n",
            "discovery and supervised property prediction tasks.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "7 . Self-supervised learning through the eyes of a child https://papers.nips.cc/paper/2020/file/7183145a2a3e0ce2b68cd3735186b1d5-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Within months of birth, children develop meaningful expectations about the world\n",
            "around them. How much of this early knowledge can be explained through generic\n",
            "learning mechanisms applied to sensory data, and how much of it requires more\n",
            "substantive innate inductive biases? Addressing this fundamental question in its full\n",
            "generality is currently infeasible, but we can hope to make real progress in more\n",
            "narrowly deﬁned domains, such as the development of high-level visual categories,\n",
            "thanks to improvements in data collecting technology and recent progress in deep\n",
            "learning. In this paper, our goal is precisely to achieve such progress by utilizing\n",
            "modern self-supervised deep learning methods and a recent longitudinal, egocentric\n",
            "video dataset recorded from the perspective of three young children (Sullivan et\n",
            "al., 2020). Our results demonstrate the emergence of powerful, high-level visual\n",
            "representations from developmentally realistic natural videos using generic self-\n",
            "supervised learning objectives.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "8 . Robust Compressed Sensing using Generative Models https://papers.nips.cc/paper/2020/file/07cb5f86508f146774a2fac4373a8e50-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "The goal of compressed sensing is to estimate a high dimensional vector from\n",
            "an underdetermined system of noisy linear equations. In analogy to classical\n",
            "compressed sensing, here we assume a generative model as a prior, that is, we\n",
            "assume the vector is represented by a deep generative model G : Rk → Rn.\n",
            "Classical recovery approaches such as empirical risk minimization (ERM) are\n",
            "guaranteed to succeed when the measurement matrix is sub-Gaussian. However,\n",
            "when the measurement matrix and measurements are heavy-tailed or have outliers,\n",
            "recovery may fail dramatically. In this paper we propose an algorithm inspired by\n",
            "the Median-of-Means (MOM). Our algorithm guarantees recovery for heavy-tailed\n",
            "data, even in the presence of outliers. Theoretically, our results show our novel\n",
            "MOM-based algorithm enjoys the same sample complexity guarantees as ERM\n",
            "under sub-Gaussian assumptions. Our experiments validate both aspects of our\n",
            "claims: other algorithms are indeed fragile and fail under heavy-tailed and/or\n",
            "corrupted data, while our approach exhibits the predicted robustness.\n",
            "\n",
            "\n",
            "**********************************************\n",
            "9 . Functional Regularization for Representation Learning: A Unified ... https://papers.nips.cc/paper/2020/file/c793b3be8f18731f2a4c627fb3c6c63d-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Unsupervised and self-supervised learning approaches have become a crucial tool\n",
            "to learn representations for downstream prediction tasks. While these approaches\n",
            "are widely used in practice and achieve impressive empirical gains, their theoret-\n",
            "ical understanding largely lags behind. Towards bridging this gap, we present a\n",
            "unifying perspective where several such approaches can be viewed as imposing\n",
            "a regularization on the representation via a learnable function using unlabeled\n",
            "data. We propose a discriminative theoretical framework for analyzing the sam-\n",
            "ple complexity of these approaches, which generalizes the framework of [3] to\n",
            "allow learnable regularization functions. Our sample complexity bounds show\n",
            "that, with carefully chosen hypothesis classes to exploit the structure in the data,\n",
            "these learnable regularization functions can prune the hypothesis space, and help\n",
            "reduce the amount of labeled data needed. We then provide two concrete examples\n",
            "of functional regularization, one using auto-encoders and the other using masked\n",
            "self-supervision, and apply our framework to quantify the reduction in the sample\n",
            "complexity bound of labeled data. We also provide complementary empirical\n",
            "results to support our analysis.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "10 . Network-to-Network Translation with Conditional Invertible Neural ... https://papers.nips.cc/paper/2020/file/1cfa81af29c6f2d8cacb44921722e753-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Given the ever-increasing computational costs of modern machine learning mod-\n",
            "els, we need to ﬁnd new ways to reuse such expert models and thus tap into the\n",
            "resources that have been invested in their creation. Recent work suggests that the\n",
            "power of these massive models is captured by the representations they learn. There-\n",
            "fore, we seek a model that can relate between different existing representations and\n",
            "propose to solve this task with a conditionally invertible network. This network\n",
            "demonstrates its capability by (i) providing generic transfer between diverse do-\n",
            "mains, (ii) enabling controlled content synthesis by allowing modiﬁcation in other\n",
            "domains, and (iii) facilitating diagnosis of existing representations by translating\n",
            "them into interpretable domains such as images. Our domain transfer network\n",
            "can translate between ﬁxed representations without having to learn or ﬁnetune\n",
            "them. This allows users to utilize various existing domain-speciﬁc expert models\n",
            "from the literature that had been trained with extensive computational resources.\n",
            "Experiments on diverse conditional image synthesis tasks, competitive image mod-\n",
            "iﬁcation results and experiments on image-to-image and text-to-image generation\n",
            "demonstrate the generic applicability of our approach. For example, we translate\n",
            "between BERT and BigGAN, state-of-the-art text and image models to provide\n",
            "text-to-image generation, which neither of both experts can perform on their own.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "data:                                                topic  ...                                                url\n",
            "0  unsupervised information theoretic perceptual ...  ...  https://papers.nips.cc/paper/2020/hash/00482b9...\n",
            "1  unsupervised information theoretic perceptual ...  ...  https://papers.nips.cc/paper/2020/file/00482b9...\n",
            "2  unsupervised information theoretic perceptual ...  ...                  https://papers.nips.cc/paper/2020\n",
            "3  unsupervised information theoretic perceptual ...  ...  https://papers.nips.cc/paper/2020/file/a23156a...\n",
            "4  unsupervised information theoretic perceptual ...  ...  https://papers.nips.cc/paper/2020/file/50905d7...\n",
            "5  unsupervised information theoretic perceptual ...  ...  https://papers.nips.cc/paper/2020/file/8511df9...\n",
            "6  unsupervised information theoretic perceptual ...  ...  https://papers.nips.cc/paper/2020/file/7183145...\n",
            "7  unsupervised information theoretic perceptual ...  ...  https://papers.nips.cc/paper/2020/file/07cb5f8...\n",
            "8  unsupervised information theoretic perceptual ...  ...  https://papers.nips.cc/paper/2020/file/c793b3b...\n",
            "9  unsupervised information theoretic perceptual ...  ...  https://papers.nips.cc/paper/2020/file/1cfa81a...\n",
            "\n",
            "[10 rows x 4 columns]\n",
            "**********************************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                                               topic  ... similarity_score\n",
            "0  unsupervised information theoretic perceptual ...  ...         0.960361\n",
            "1  unsupervised information theoretic perceptual ...  ...         0.940551\n",
            "2  unsupervised information theoretic perceptual ...  ...         0.964870\n",
            "3  unsupervised information theoretic perceptual ...  ...         0.960257\n",
            "4  unsupervised information theoretic perceptual ...  ...         0.960770\n",
            "5  unsupervised information theoretic perceptual ...  ...         0.959921\n",
            "6  unsupervised information theoretic perceptual ...  ...         0.964294\n",
            "7  unsupervised information theoretic perceptual ...  ...         0.963900\n",
            "8  unsupervised information theoretic perceptual ...  ...         0.961062\n",
            "9  unsupervised information theoretic perceptual ...  ...         0.963835\n",
            "\n",
            "[10 rows x 5 columns]\n",
            "df_final after rank=                                                topic  ...  rank\n",
            "0  unsupervised information theoretic perceptual ...  ...   7.0\n",
            "1  unsupervised information theoretic perceptual ...  ...  10.0\n",
            "2  unsupervised information theoretic perceptual ...  ...   1.0\n",
            "3  unsupervised information theoretic perceptual ...  ...   8.0\n",
            "4  unsupervised information theoretic perceptual ...  ...   6.0\n",
            "5  unsupervised information theoretic perceptual ...  ...   9.0\n",
            "6  unsupervised information theoretic perceptual ...  ...   2.0\n",
            "7  unsupervised information theoretic perceptual ...  ...   3.0\n",
            "8  unsupervised information theoretic perceptual ...  ...   5.0\n",
            "9  unsupervised information theoretic perceptual ...  ...   4.0\n",
            "\n",
            "[10 rows x 6 columns]\n",
            "0    An Unsupervised Information-Theoretic Perceptu...\n",
            "1    NeurIPS 2020\\n\\nAn Unsupervised Information-Th...\n",
            "2    Book\\n\\nDo not remove: This comment is monitor...\n",
            "3    Abstract\\n\\nSynthesizing larger texture images...\n",
            "4    Abstract\\n\\nDeep generative models have become...\n",
            "5    Abstract\\n\\nLearning object-centric representa...\n",
            "6    Abstract\\n\\nWithin months of birth, children d...\n",
            "7    Abstract\\n\\nThe goal of compressed sensing is ...\n",
            "8    Abstract\\n\\nUnsupervised and self-supervised l...\n",
            "9    Abstract\\n\\nGiven the ever-increasing computat...\n",
            "Name: text, dtype: object\n",
            "An\n",
            "Unsupervised\n",
            "Information-Theoretic\n",
            "Perceptual\n",
            "Quality\n",
            "Metric\n",
            "Part\n",
            "of\n",
            "Advances\n",
            "in\n",
            "Neural\n",
            "Information\n",
            "Processing\n",
            "Systems\n",
            "33\n",
            "(\n",
            "NeurIPS\n",
            "2020\n",
            ")\n",
            "Authors\n",
            "Sangnie\n",
            "Bhardwaj\n",
            ",\n",
            "Ian\n",
            "Fischer\n",
            ",\n",
            "Johannes\n",
            "Ballé\n",
            ",\n",
            "Troy\n",
            "Chinen\n",
            "Abstract\n",
            "Tractable\n",
            "models\n",
            "of\n",
            "human\n",
            "perception\n",
            "have\n",
            "proved\n",
            "to\n",
            "be\n",
            "challenging\n",
            "to\n",
            "build\n",
            ".\n",
            "Hand-designed\n",
            "models\n",
            "such\n",
            "as\n",
            "MS-SSIM\n",
            "remain\n",
            "popular\n",
            "predictors\n",
            "of\n",
            "human\n",
            "image\n",
            "quality\n",
            "judgements\n",
            "due\n",
            "to\n",
            "their\n",
            "simplicity\n",
            "and\n",
            "speed\n",
            ".\n",
            "Recent\n",
            "modern\n",
            "deep\n",
            "learning\n",
            "approaches\n",
            "can\n",
            "perform\n",
            "better\n",
            ",\n",
            "but\n",
            "they\n",
            "rely\n",
            "on\n",
            "supervised\n",
            "data\n",
            "which\n",
            "can\n",
            "be\n",
            "costly\n",
            "to\n",
            "gather\n",
            ":\n",
            "large\n",
            "sets\n",
            "of\n",
            "class\n",
            "labels\n",
            "such\n",
            "as\n",
            "ImageNet\n",
            ",\n",
            "image\n",
            "quality\n",
            "ratings\n",
            ",\n",
            "or\n",
            "both\n",
            ".\n",
            "We\n",
            "combine\n",
            "recent\n",
            "advances\n",
            "in\n",
            "information-theoretic\n",
            "objective\n",
            "functions\n",
            "with\n",
            "a\n",
            "computational\n",
            "architecture\n",
            "informed\n",
            "by\n",
            "the\n",
            "physiology\n",
            "of\n",
            "the\n",
            "human\n",
            "visual\n",
            "system\n",
            "and\n",
            "unsupervised\n",
            "training\n",
            "on\n",
            "pairs\n",
            "of\n",
            "video\n",
            "frames\n",
            ",\n",
            "yielding\n",
            "our\n",
            "Perceptual\n",
            "Information\n",
            "Metric\n",
            "(\n",
            "PIM\n",
            ")\n",
            ".\n",
            "We\n",
            "show\n",
            "that\n",
            "PIM\n",
            "is\n",
            "competitive\n",
            "with\n",
            "supervised\n",
            "metrics\n",
            "on\n",
            "the\n",
            "recent\n",
            "and\n",
            "challenging\n",
            "BAPPS\n",
            "image\n",
            "quality\n",
            "assessment\n",
            "dataset\n",
            "and\n",
            "outperforms\n",
            "them\n",
            "in\n",
            "predicting\n",
            "the\n",
            "ranking\n",
            "of\n",
            "image\n",
            "compression\n",
            "methods\n",
            "in\n",
            "CLIC\n",
            "2020\n",
            ".\n",
            "We\n",
            "also\n",
            "perform\n",
            "qualitative\n",
            "experiments\n",
            "using\n",
            "the\n",
            "ImageNet-C\n",
            "dataset\n",
            ",\n",
            "and\n",
            "establish\n",
            "that\n",
            "PIM\n",
            "is\n",
            "robust\n",
            "with\n",
            "respect\n",
            "to\n",
            "architectural\n",
            "details\n",
            ".\n",
            "NeurIPS\n",
            "2020\n",
            "An\n",
            "Unsupervised\n",
            "Information-Theoretic\n",
            "Perceptual\n",
            "Quality\n",
            "Metric\n",
            "Review\n",
            "1\n",
            "Summary\n",
            "and\n",
            "Contributions\n",
            ":\n",
            "The\n",
            "authors\n",
            "propose\n",
            "an\n",
            "advanced\n",
            "perceptual\n",
            "quality\n",
            "metric\n",
            ",\n",
            "which\n",
            "is\n",
            "learned\n",
            "from\n",
            "adjacent\n",
            "video\n",
            "frames\n",
            "in\n",
            "an\n",
            "unsupervised\n",
            "manner\n",
            ".\n",
            "This\n",
            "learning\n",
            "scheme\n",
            "is\n",
            "well\n",
            "motivated\n",
            "by\n",
            "the\n",
            "observation\n",
            "of\n",
            "human\n",
            "visual\n",
            "system\n",
            ".\n",
            "Experiments\n",
            "on\n",
            "BAPPS\n",
            "and\n",
            "ImageNet-C\n",
            "datasets\n",
            "demonstrate\n",
            "the\n",
            "effectiveness\n",
            "of\n",
            "method\n",
            ".\n",
            "Strengths\n",
            ":\n",
            "-\n",
            "The\n",
            "proposed\n",
            "method\n",
            "is\n",
            "well\n",
            "motivated\n",
            "and\n",
            "backed\n",
            "up\n",
            "by\n",
            "solid\n",
            "theories\n",
            ".\n",
            "-\n",
            "Experiments\n",
            "are\n",
            "comprehensive\n",
            "and\n",
            "the\n",
            "overall\n",
            "performance\n",
            "is\n",
            "promising\n",
            ".\n",
            "-\n",
            "Paper\n",
            "is\n",
            "well\n",
            "organized\n",
            "and\n",
            "easy\n",
            "to\n",
            "follow\n",
            ".\n",
            "Weaknesses\n",
            ":\n",
            "A\n",
            "good\n",
            "quality\n",
            "metric\n",
            "should\n",
            "stand\n",
            "the\n",
            "test\n",
            "of\n",
            "time\n",
            ".\n",
            "Yet\n",
            "it\n",
            "seems\n",
            "that\n",
            "the\n",
            "authors\n",
            "have\n",
            "not\n",
            "preparation\n",
            "to\n",
            "make\n",
            "this\n",
            "project\n",
            "publicly\n",
            "available\n",
            ".\n",
            "Therefore\n",
            ",\n",
            "I\n",
            "encourage\n",
            "the\n",
            "authors\n",
            "to\n",
            "provide\n",
            "the\n",
            "code\n",
            "or\n",
            "executable\n",
            "files\n",
            "to\n",
            "ensure\n",
            "the\n",
            "reproducibility\n",
            ".\n",
            "Correctness\n",
            ":\n",
            "Technically\n",
            "sound\n",
            ",\n",
            "but\n",
            "not\n",
            "be\n",
            "carefully\n",
            "checked\n",
            ".\n",
            "Clarity\n",
            ":\n",
            "Yes\n",
            ".\n",
            "Relation\n",
            "to\n",
            "Prior\n",
            "Work\n",
            ":\n",
            "Yes\n",
            ".\n",
            "Reproducibility\n",
            ":\n",
            "No\n",
            "Additional\n",
            "Feedback\n",
            ":\n",
            "Review\n",
            "2\n",
            "Summary\n",
            "and\n",
            "Contributions\n",
            ":\n",
            "An\n",
            "unsupervised\n",
            "Information-Theoretic\n",
            "based\n",
            "image\n",
            "quality\n",
            "metric\n",
            "using\n",
            "deep\n",
            "learning\n",
            "is\n",
            "proposed\n",
            ".\n",
            "Some\n",
            "experiments\n",
            "were\n",
            "conducted\n",
            "and\n",
            "showed\n",
            "the\n",
            "competitive\n",
            "performance\n",
            ".\n",
            "Strengths\n",
            ":\n",
            "NOT\n",
            "CLEAR\n",
            ".\n",
            "Basically\n",
            ",\n",
            "I\n",
            "would\n",
            "not\n",
            "find\n",
            "the\n",
            "strengths\n",
            "of\n",
            "the\n",
            "work\n",
            ".\n",
            "Nothing\n",
            "could\n",
            "be\n",
            "got\n",
            "when\n",
            "reading\n",
            "the\n",
            "abstract\n",
            "several\n",
            "times\n",
            ".\n",
            "How\n",
            "this\n",
            "work\n",
            "is\n",
            "inspired\n",
            "by\n",
            "the\n",
            "physiology\n",
            "of\n",
            "the\n",
            "human\n",
            "visual\n",
            "system\n",
            "is\n",
            "not\n",
            "clear\n",
            "in\n",
            "the\n",
            "abstract\n",
            ".\n",
            "I\n",
            "do\n",
            "not\n",
            "think\n",
            "that\n",
            "using\n",
            "such\n",
            "words\n",
            "``\n",
            "our\n",
            "model\n",
            "is\n",
            "informed\n",
            "by\n",
            "the\n",
            "physiology\n",
            "of\n",
            "the\n",
            "human\n",
            "visual\n",
            "system\n",
            "''\n",
            "in\n",
            "the\n",
            "abstract\n",
            "means\n",
            "this\n",
            "work\n",
            "has\n",
            "new\n",
            "contributions\n",
            ".\n",
            "The\n",
            "key\n",
            "is\n",
            "to\n",
            "how\n",
            "to\n",
            "model\n",
            "the\n",
            "human\n",
            "visual\n",
            "system\n",
            "in\n",
            "your\n",
            "work\n",
            ".\n",
            "Unfortunately\n",
            ",\n",
            "this\n",
            "paper\n",
            "did\n",
            "n't\n",
            "describe\n",
            "it\n",
            "in\n",
            "details\n",
            ".\n",
            "There\n",
            "are\n",
            "too\n",
            "many\n",
            "DL\n",
            "based\n",
            "IQAs\n",
            ".\n",
            "What\n",
            "'s\n",
            "your\n",
            "new\n",
            "contribution\n",
            "?\n",
            "Weaknesses\n",
            ":\n",
            "This\n",
            "paper\n",
            "is\n",
            "not\n",
            "easy\n",
            "to\n",
            "follow\n",
            ".\n",
            "It\n",
            "is\n",
            "difficult\n",
            "to\n",
            "judge\n",
            "the\n",
            "novelty\n",
            ".\n",
            "Author\n",
            "claimed\n",
            "that\n",
            "their\n",
            "model\n",
            "is\n",
            "inspired\n",
            "by\n",
            "visual\n",
            "physiology\n",
            "such\n",
            "as\n",
            "efficient\n",
            "coding\n",
            "and\n",
            "slowness\n",
            ".\n",
            "However\n",
            ",\n",
            "there\n",
            "are\n",
            "no\n",
            "any\n",
            "introductions\n",
            "about\n",
            "them\n",
            "in\n",
            "details\n",
            ".\n",
            "Moreover\n",
            ",\n",
            "I\n",
            "did\n",
            "n't\n",
            "see\n",
            "where\n",
            "two\n",
            "biological\n",
            "mechanisms\n",
            "are\n",
            "imitated\n",
            "in\n",
            "the\n",
            "model\n",
            ".\n",
            "I\n",
            "only\n",
            "see\n",
            "a\n",
            "DL-based\n",
            "IQA\n",
            "method\n",
            "without\n",
            "clear\n",
            "contributions\n",
            ".\n",
            "Finally\n",
            ",\n",
            "there\n",
            "are\n",
            "no\n",
            "scientific\n",
            "contributions\n",
            "in\n",
            "this\n",
            "manuscript\n",
            "such\n",
            "as\n",
            "``\n",
            "perceptual\n",
            "similarity\n",
            "is\n",
            "an\n",
            "emergent\n",
            "property\n",
            "shared\n",
            "across\n",
            "deep\n",
            "visual\n",
            "representations\n",
            "''\n",
            "discovered\n",
            "in\n",
            "[\n",
            "35\n",
            "]\n",
            ".\n",
            "[\n",
            "35\n",
            "]\n",
            "Richard\n",
            "Zhang\n",
            "et\n",
            "al\n",
            ".\n",
            "“\n",
            "The\n",
            "Unreasonable\n",
            "Effectiveness\n",
            "of\n",
            "Deep\n",
            "Features\n",
            "as\n",
            "a\n",
            "Perceptual\n",
            "Metric\n",
            "”\n",
            ".\n",
            "In\n",
            ":\n",
            "(\n",
            "2018\n",
            ")\n",
            ".\n",
            "cite\n",
            "arxiv:1801.03924Comment\n",
            ":\n",
            "Code\n",
            "and\n",
            "data\n",
            "available\n",
            "https\n",
            ":\n",
            "//www.github.com/richzhang/PerceptualSimilarity\n",
            ".\n",
            "URL\n",
            ":\n",
            "http\n",
            ":\n",
            "//arxiv.org/abs/1801.03924\n",
            ".\n",
            "after\n",
            "response\n",
            ":\n",
            "Although\n",
            "some\n",
            "confusion\n",
            "may\n",
            "have\n",
            "been\n",
            "clarified\n",
            ",\n",
            "author\n",
            "did\n",
            "n't\n",
            "positively\n",
            "reply\n",
            "the\n",
            "key\n",
            "comments\n",
            "that\n",
            "their\n",
            "model\n",
            "is\n",
            "inspired\n",
            "by\n",
            "visual\n",
            "physiology\n",
            "such\n",
            "as\n",
            "efficient\n",
            "coding\n",
            "and\n",
            "slowness\n",
            ".\n",
            "However\n",
            ",\n",
            "there\n",
            "are\n",
            "no\n",
            "any\n",
            "introductions\n",
            "about\n",
            "them\n",
            "in\n",
            "details\n",
            ".\n",
            "``\n",
            "Moreover\n",
            ",\n",
            "where\n",
            "two\n",
            "biological\n",
            "mechanisms\n",
            "in\n",
            "details\n",
            "are\n",
            "imitated\n",
            "in\n",
            "the\n",
            "model\n",
            "is\n",
            "not\n",
            "clear\n",
            "''\n",
            ".\n",
            "Furthermore\n",
            ",\n",
            "the\n",
            "paper\n",
            "is\n",
            "lacking\n",
            "of\n",
            "scientific\n",
            "contributions\n",
            "considering\n",
            "that\n",
            "it\n",
            "is\n",
            "only\n",
            "built\n",
            "on\n",
            "previous\n",
            "work\n",
            ".\n",
            "Correctness\n",
            ":\n",
            "No\n",
            "Clarity\n",
            ":\n",
            "This\n",
            "paper\n",
            "is\n",
            "very\n",
            "difficult\n",
            "to\n",
            "follow\n",
            ".\n",
            "Relation\n",
            "to\n",
            "Prior\n",
            "Work\n",
            ":\n",
            "Maybe\n",
            "Reproducibility\n",
            ":\n",
            "No\n",
            "Additional\n",
            "Feedback\n",
            ":\n",
            "1\n",
            ".\n",
            "How\n",
            "this\n",
            "work\n",
            "is\n",
            "inspired\n",
            "by\n",
            "the\n",
            "physiology\n",
            "of\n",
            "the\n",
            "human\n",
            "visual\n",
            "system\n",
            "is\n",
            "not\n",
            "clear\n",
            "in\n",
            "the\n",
            "paper\n",
            ".\n",
            "I\n",
            "do\n",
            "not\n",
            "think\n",
            "that\n",
            "using\n",
            "such\n",
            "words\n",
            "``\n",
            "our\n",
            "model\n",
            "is\n",
            "informed\n",
            "by\n",
            "the\n",
            "physiology\n",
            "of\n",
            "the\n",
            "human\n",
            "visual\n",
            "system\n",
            "''\n",
            "in\n",
            "the\n",
            "abstract\n",
            "means\n",
            "this\n",
            "work\n",
            "has\n",
            "new\n",
            "contributions\n",
            ".\n",
            "The\n",
            "key\n",
            "is\n",
            "to\n",
            "how\n",
            "to\n",
            "model\n",
            "the\n",
            "human\n",
            "visual\n",
            "system\n",
            "in\n",
            "your\n",
            "work\n",
            "in\n",
            "details\n",
            "in\n",
            "order\n",
            "to\n",
            "improve\n",
            "the\n",
            "current\n",
            "IQA\n",
            ".\n",
            "Unfortunately\n",
            ",\n",
            "this\n",
            "paper\n",
            "did\n",
            "n't\n",
            "belong\n",
            "this\n",
            "one\n",
            ".\n",
            "2\n",
            ".\n",
            "Refer\n",
            "to\n",
            "[\n",
            "35\n",
            "]\n",
            "for\n",
            "improvement\n",
            "such\n",
            "as\n",
            "enhancing\n",
            "the\n",
            "scientific\n",
            "contributions\n",
            ".\n",
            "[\n",
            "35\n",
            "]\n",
            "Richard\n",
            "Zhang\n",
            "et\n",
            "al\n",
            ".\n",
            "“\n",
            "The\n",
            "Unreasonable\n",
            "Effectiveness\n",
            "of\n",
            "Deep\n",
            "Features\n",
            "as\n",
            "a\n",
            "Perceptual\n",
            "Metric\n",
            "”\n",
            ".\n",
            "In\n",
            ":\n",
            "(\n",
            "2018\n",
            ")\n",
            ".\n",
            "cite\n",
            "arxiv:1801.03924Comment\n",
            ":\n",
            "Code\n",
            "and\n",
            "data\n",
            "available\n",
            "https\n",
            ":\n",
            "//www.github.com/richzhang/PerceptualSimilarity\n",
            ".\n",
            "URL\n",
            ":\n",
            "http\n",
            ":\n",
            "//arxiv.org/abs/1801.03924\n",
            ".\n",
            "Review\n",
            "3\n",
            "Summary\n",
            "and\n",
            "Contributions\n",
            ":\n",
            "This\n",
            "paper\n",
            "proposed\n",
            "a\n",
            "new\n",
            "unsupervised\n",
            ",\n",
            "information-based\n",
            "perceptual\n",
            "quality\n",
            "metric\n",
            ",\n",
            "i.e\n",
            ".\n",
            "PIM\n",
            ".\n",
            "The\n",
            "method\n",
            "is\n",
            "based\n",
            "on\n",
            "optimization\n",
            "of\n",
            "a\n",
            "lower\n",
            "bound\n",
            "of\n",
            "the\n",
            "multivariate\n",
            "mutual\n",
            "information\n",
            ".\n",
            "This\n",
            "proposal\n",
            "has\n",
            "roots\n",
            "in\n",
            "two\n",
            "prominent\n",
            "ideas\n",
            "in\n",
            "neuroscience\n",
            ",\n",
            "efficient\n",
            "coding\n",
            "and\n",
            "slowness\n",
            ".\n",
            "The\n",
            "authors\n",
            "implemented\n",
            "the\n",
            "proposal\n",
            "in\n",
            "deep\n",
            "neural\n",
            "networks\n",
            ",\n",
            "and\n",
            "test\n",
            "it\n",
            "on\n",
            "BAPPS\n",
            "and\n",
            "ImageNet-C\n",
            ".\n",
            "They\n",
            "reported\n",
            "competitive\n",
            "performance\n",
            "of\n",
            "this\n",
            "method\n",
            "to\n",
            "the\n",
            "supervised\n",
            "methods\n",
            ".\n",
            "Strengths\n",
            ":\n",
            "I\n",
            "very\n",
            "much\n",
            "enjoyed\n",
            "reading\n",
            "this\n",
            "manuscript\n",
            ".\n",
            "The\n",
            "method\n",
            "is\n",
            "to\n",
            "my\n",
            "knowledge\n",
            "novel\n",
            "and\n",
            "principled\n",
            ".\n",
            "It\n",
            "is\n",
            "well\n",
            "founded\n",
            "in\n",
            "Information\n",
            "theory\n",
            ",\n",
            "and\n",
            "broadly\n",
            "inspired\n",
            "by\n",
            "a\n",
            "couple\n",
            "of\n",
            "core\n",
            "principles\n",
            "in\n",
            "neural\n",
            "information\n",
            "processing\n",
            ".\n",
            "The\n",
            "method\n",
            "is\n",
            "purely\n",
            "unsupervised\n",
            ",\n",
            "and\n",
            "does\n",
            "not\n",
            "need\n",
            "human\n",
            "psychophysical\n",
            "judgements\n",
            "to\n",
            "train\n",
            "the\n",
            "model\n",
            ".\n",
            "Yet\n",
            "the\n",
            "method\n",
            "show\n",
            "competitive\n",
            "performance\n",
            "with\n",
            "the\n",
            "fully\n",
            "supervised\n",
            "approach\n",
            "in\n",
            "ref\n",
            "[\n",
            "35\n",
            "]\n",
            ".\n",
            "I\n",
            "found\n",
            "this\n",
            "to\n",
            "be\n",
            "quite\n",
            "remarkable\n",
            "and\n",
            "potentially\n",
            "quite\n",
            "significant\n",
            ".\n",
            "The\n",
            "problem\n",
            "studied\n",
            "in\n",
            "the\n",
            "paper\n",
            "is\n",
            "also\n",
            "high\n",
            "relevant\n",
            "to\n",
            "the\n",
            "NeurIPS\n",
            "community\n",
            ".\n",
            "*\n",
            "*\n",
            "added\n",
            "after\n",
            "rebuttal\n",
            ":\n",
            "After\n",
            "reading\n",
            "through\n",
            "other\n",
            "reviewers\n",
            "'\n",
            "comments\n",
            "and\n",
            "the\n",
            "authors\n",
            "'\n",
            "feedback\n",
            ",\n",
            "I\n",
            "remain\n",
            "very\n",
            "positive\n",
            "of\n",
            "this\n",
            "paper\n",
            ".\n",
            "I\n",
            "think\n",
            "the\n",
            "idea\n",
            "in\n",
            "the\n",
            "paper\n",
            "is\n",
            "novel\n",
            ",\n",
            "the\n",
            "experiments\n",
            "were\n",
            "reasonable\n",
            "and\n",
            "the\n",
            "results\n",
            "are\n",
            "very\n",
            "promising\n",
            ".\n",
            "Weaknesses\n",
            ":\n",
            "My\n",
            "main\n",
            "concern\n",
            "is\n",
            "that\n",
            "the\n",
            "results\n",
            "are\n",
            "a\n",
            "bit\n",
            "preliminary\n",
            "(\n",
            "lacking\n",
            "more\n",
            "comprehensive\n",
            "comparison\n",
            "to\n",
            "some\n",
            "of\n",
            "the\n",
            "previous\n",
            "methods\n",
            ",\n",
            "such\n",
            "as\n",
            "ref\n",
            "[\n",
            "29\n",
            "]\n",
            "as\n",
            "the\n",
            "authors\n",
            "acknowledged\n",
            ")\n",
            ",\n",
            "although\n",
            "the\n",
            "results\n",
            "look\n",
            "very\n",
            "promising\n",
            "for\n",
            "sure\n",
            ".\n",
            "It\n",
            "is\n",
            "also\n",
            "not\n",
            "entirely\n",
            "clear\n",
            "whether\n",
            "the\n",
            "improvement\n",
            "of\n",
            "the\n",
            "performance\n",
            "mainlycomes\n",
            "from\n",
            "the\n",
            "generic\n",
            "advantage\n",
            "of\n",
            "the\n",
            "objective\n",
            "function\n",
            ",\n",
            "or\n",
            "the\n",
            "choice\n",
            "of\n",
            "the\n",
            "hyper-parameters\n",
            "or\n",
            "the\n",
            "model\n",
            "architecture\n",
            ".\n",
            "Correctness\n",
            ":\n",
            "The\n",
            "claims\n",
            "and\n",
            "method\n",
            "are\n",
            "sound\n",
            ".\n",
            "Clarity\n",
            ":\n",
            "The\n",
            "paper\n",
            "is\n",
            "well\n",
            "written\n",
            ".\n",
            "The\n",
            "presentation\n",
            "in\n",
            "Section\n",
            "3.4\n",
            "perhaps\n",
            "could\n",
            "be\n",
            "improved\n",
            ".\n",
            "Right\n",
            "now\n",
            ",\n",
            "it\n",
            "is\n",
            "a\n",
            "bit\n",
            "difficult\n",
            "to\n",
            "get\n",
            "the\n",
            "key\n",
            "message\n",
            ".\n",
            "Relation\n",
            "to\n",
            "Prior\n",
            "Work\n",
            ":\n",
            "The\n",
            "relation\n",
            "to\n",
            "prior\n",
            "work\n",
            "is\n",
            "generally\n",
            "well\n",
            "discussed\n",
            ".\n",
            "Reproducibility\n",
            ":\n",
            "Yes\n",
            "Additional\n",
            "Feedback\n",
            ":\n",
            "Fig\n",
            "2\n",
            "and\n",
            "Fig3\n",
            "could\n",
            "benefit\n",
            "by\n",
            "have\n",
            "a\n",
            "bit\n",
            "more\n",
            "detailed\n",
            "figure\n",
            "legends\n",
            ".\n",
            "Review\n",
            "4\n",
            "Summary\n",
            "and\n",
            "Contributions\n",
            ":\n",
            "The\n",
            "paper\n",
            "proposes\n",
            "PIM\n",
            "(\n",
            "Perceptual\n",
            "Information\n",
            "Metric\n",
            ")\n",
            "which\n",
            "is\n",
            "an\n",
            "image\n",
            "quality\n",
            "metric\n",
            "learned\n",
            "in\n",
            "an\n",
            "unsupervised\n",
            "manner\n",
            "by\n",
            "enforcing\n",
            "two\n",
            "loss\n",
            "functions\n",
            "-\n",
            "1\n",
            ".\n",
            "Compression\n",
            "and\n",
            "2\n",
            ".\n",
            "Consistency\n",
            "across\n",
            "time\n",
            ".\n",
            "The\n",
            "authors\n",
            "compare\n",
            "PIM\n",
            "to\n",
            "other\n",
            "proposed\n",
            "metrics\n",
            "on\n",
            "multiple\n",
            "datasets\n",
            "and\n",
            "show\n",
            "improvements\n",
            ".\n",
            "They\n",
            "also\n",
            "do\n",
            "ablation\n",
            "studies\n",
            "to\n",
            "show\n",
            "how\n",
            "each\n",
            "of\n",
            "the\n",
            "choices\n",
            "made\n",
            "in\n",
            "the\n",
            "paper\n",
            "yield\n",
            "various\n",
            "improvements\n",
            ".\n",
            "Strengths\n",
            ":\n",
            "Competitive\n",
            "results\n",
            "on\n",
            "multiple\n",
            "benchmarks\n",
            ",\n",
            "ablation\n",
            "studies\n",
            ",\n",
            "additional\n",
            "qualitative\n",
            "experiments\n",
            "on\n",
            "ImageNet-C\n",
            "Weaknesses\n",
            ":\n",
            "The\n",
            "paper\n",
            "is\n",
            "built\n",
            "on\n",
            "previous\n",
            "works\n",
            "and\n",
            "one\n",
            "of\n",
            "the\n",
            "main\n",
            "new\n",
            "directions\n",
            "proposed\n",
            "is\n",
            "the\n",
            "notion\n",
            "of\n",
            "consistency\n",
            "(\n",
            "perceptual\n",
            "metric\n",
            "not\n",
            "changing\n",
            "between\n",
            "immediate\n",
            "or\n",
            "nearby\n",
            "frames\n",
            "in\n",
            "a\n",
            "video\n",
            ")\n",
            ".\n",
            "While\n",
            "this\n",
            "intuition\n",
            "seems\n",
            "reasonable\n",
            "I\n",
            "worry\n",
            "that\n",
            "many\n",
            "artifacts\n",
            "like\n",
            "-\n",
            "motion\n",
            "blur\n",
            ",\n",
            "face\n",
            "blur\n",
            ",\n",
            "aliasing\n",
            "etc\n",
            ".\n",
            "are\n",
            "things\n",
            "that\n",
            "could\n",
            "change\n",
            "perceptual\n",
            "metric\n",
            "significantly\n",
            ".\n",
            "It\n",
            "would\n",
            "be\n",
            "great\n",
            "to\n",
            "hear\n",
            "from\n",
            "authors\n",
            "on\n",
            "whether\n",
            "they\n",
            "worked\n",
            "on\n",
            "uncompressed\n",
            "video\n",
            "and\n",
            "if\n",
            "not\n",
            "talk\n",
            "a\n",
            "little\n",
            "more\n",
            "about\n",
            "the\n",
            "importance\n",
            "of\n",
            "using\n",
            "consistency\n",
            "metric\n",
            ".\n",
            "Since\n",
            ",\n",
            "this\n",
            "is\n",
            "one\n",
            "of\n",
            "the\n",
            "main\n",
            "novelty\n",
            "of\n",
            "the\n",
            "paper\n",
            "I\n",
            "would\n",
            "like\n",
            "to\n",
            "make\n",
            "sure\n",
            "this\n",
            "part\n",
            "is\n",
            "well\n",
            "justified\n",
            ".\n",
            "Correctness\n",
            ":\n",
            "Yes\n",
            ",\n",
            "I\n",
            "did\n",
            "not\n",
            "see\n",
            "anything\n",
            "wrong\n",
            "in\n",
            "the\n",
            "setup\n",
            "and\n",
            "the\n",
            "claims\n",
            "made\n",
            "by\n",
            "the\n",
            "authors\n",
            ".\n",
            "Clarity\n",
            ":\n",
            "Yes\n",
            ",\n",
            "for\n",
            "most\n",
            "part\n",
            ".\n",
            "The\n",
            "results\n",
            "section\n",
            "can\n",
            "be\n",
            "improved\n",
            "further\n",
            ",\n",
            "especially\n",
            "maybe\n",
            "contrast\n",
            "where\n",
            "PIM\n",
            "performs\n",
            "better\n",
            "qualitatively\n",
            "and\n",
            "talk\n",
            "about\n",
            "why\n",
            ".\n",
            "Relation\n",
            "to\n",
            "Prior\n",
            "Work\n",
            ":\n",
            "Yes\n",
            ",\n",
            "a\n",
            "latest\n",
            "reference\n",
            "that\n",
            "might\n",
            "be\n",
            "related\n",
            "is\n",
            "shared\n",
            "below\n",
            ":\n",
            "From\n",
            "patches\n",
            "to\n",
            "pictures\n",
            "(\n",
            "PaQ-2-PiQ\n",
            ")\n",
            ":\n",
            "Mapping\n",
            "the\n",
            "perceptual\n",
            "space\n",
            "of\n",
            "picture\n",
            "quality\n",
            "Z\n",
            "Ying\n",
            ",\n",
            "H\n",
            "Niu\n",
            ",\n",
            "P\n",
            "Gupta\n",
            ",\n",
            "D\n",
            "Mahajan\n",
            ",\n",
            "D\n",
            "Ghadiyaram\n",
            ",\n",
            "A\n",
            "Bovik\n",
            "Reproducibility\n",
            ":\n",
            "Yes\n",
            "Book\n",
            "Do\n",
            "not\n",
            "remove\n",
            ":\n",
            "This\n",
            "comment\n",
            "is\n",
            "monitored\n",
            "to\n",
            "verify\n",
            "that\n",
            "the\n",
            "site\n",
            "is\n",
            "working\n",
            "properly\n",
            "Abstract\n",
            "Synthesizing\n",
            "larger\n",
            "texture\n",
            "images\n",
            "from\n",
            "a\n",
            "smaller\n",
            "exemplar\n",
            "is\n",
            "an\n",
            "important\n",
            "task\n",
            "in\n",
            "graphics\n",
            "and\n",
            "vision\n",
            ".\n",
            "The\n",
            "conventional\n",
            "CNNs\n",
            ",\n",
            "recently\n",
            "adopted\n",
            "for\n",
            "synthesis\n",
            ",\n",
            "require\n",
            "to\n",
            "train\n",
            "and\n",
            "test\n",
            "on\n",
            "the\n",
            "same\n",
            "set\n",
            "of\n",
            "images\n",
            "and\n",
            "fail\n",
            "to\n",
            "generalize\n",
            "to\n",
            "unseen\n",
            "images\n",
            ".\n",
            "This\n",
            "is\n",
            "mainly\n",
            "because\n",
            "those\n",
            "CNNs\n",
            "fully\n",
            "rely\n",
            "on\n",
            "convolutional\n",
            "and\n",
            "upsampling\n",
            "layers\n",
            "that\n",
            "operate\n",
            "locally\n",
            "and\n",
            "not\n",
            "suitable\n",
            "for\n",
            "a\n",
            "task\n",
            "as\n",
            "global\n",
            "as\n",
            "texture\n",
            "synthesis\n",
            ".\n",
            "In\n",
            "this\n",
            "work\n",
            ",\n",
            "inspired\n",
            "by\n",
            "the\n",
            "repetitive\n",
            "nature\n",
            "of\n",
            "texture\n",
            "patterns\n",
            ",\n",
            "we\n",
            "ﬁnd\n",
            "that\n",
            "texture\n",
            "synthesis\n",
            "can\n",
            "be\n",
            "viewed\n",
            "as\n",
            "(\n",
            "local\n",
            ")\n",
            "upsampling\n",
            "in\n",
            "the\n",
            "Fast\n",
            "Fourier\n",
            "Transform\n",
            "(\n",
            "FFT\n",
            ")\n",
            "domain\n",
            ".\n",
            "However\n",
            ",\n",
            "FFT\n",
            "of\n",
            "natural\n",
            "images\n",
            "exhibits\n",
            "high\n",
            "dynamic\n",
            "range\n",
            "and\n",
            "lacks\n",
            "local\n",
            "correlations\n",
            ".\n",
            "Therefore\n",
            ",\n",
            "to\n",
            "train\n",
            "CNNs\n",
            "we\n",
            "design\n",
            "a\n",
            "framework\n",
            "to\n",
            "perform\n",
            "FFT\n",
            "upsampling\n",
            "in\n",
            "feature\n",
            "space\n",
            "using\n",
            "deformable\n",
            "convolutions\n",
            ".\n",
            "Such\n",
            "design\n",
            "allows\n",
            "our\n",
            "framework\n",
            "to\n",
            "generalize\n",
            "to\n",
            "unseen\n",
            "images\n",
            ",\n",
            "and\n",
            "synthesize\n",
            "textures\n",
            "in\n",
            "a\n",
            "single\n",
            "pass\n",
            ".\n",
            "Extensive\n",
            "evaluations\n",
            "conﬁrm\n",
            "that\n",
            "our\n",
            "method\n",
            "achieves\n",
            "state-of-the-art\n",
            "performance\n",
            "both\n",
            "quantitatively\n",
            "and\n",
            "qualitatively\n",
            ".\n",
            "Abstract\n",
            "Deep\n",
            "generative\n",
            "models\n",
            "have\n",
            "become\n",
            "increasingly\n",
            "effective\n",
            "at\n",
            "producing\n",
            "realistic\n",
            "images\n",
            "from\n",
            "randomly\n",
            "sampled\n",
            "seeds\n",
            ",\n",
            "but\n",
            "using\n",
            "such\n",
            "models\n",
            "for\n",
            "controllable\n",
            "manipulation\n",
            "of\n",
            "existing\n",
            "images\n",
            "remains\n",
            "challenging\n",
            ".\n",
            "We\n",
            "propose\n",
            "the\n",
            "Swapping\n",
            "Autoencoder\n",
            ",\n",
            "a\n",
            "deep\n",
            "model\n",
            "designed\n",
            "speciﬁcally\n",
            "for\n",
            "image\n",
            "manipulation\n",
            ",\n",
            "rather\n",
            "than\n",
            "random\n",
            "sampling\n",
            ".\n",
            "The\n",
            "key\n",
            "idea\n",
            "is\n",
            "to\n",
            "encode\n",
            "an\n",
            "image\n",
            "into\n",
            "two\n",
            "independent\n",
            "components\n",
            "and\n",
            "enforce\n",
            "that\n",
            "any\n",
            "swapped\n",
            "combination\n",
            "maps\n",
            "to\n",
            "a\n",
            "realistic\n",
            "image\n",
            ".\n",
            "In\n",
            "particular\n",
            ",\n",
            "we\n",
            "encourage\n",
            "the\n",
            "components\n",
            "to\n",
            "represent\n",
            "structure\n",
            "and\n",
            "texture\n",
            ",\n",
            "by\n",
            "enforcing\n",
            "one\n",
            "component\n",
            "to\n",
            "encode\n",
            "co-occurrent\n",
            "patch\n",
            "statistics\n",
            "across\n",
            "different\n",
            "parts\n",
            "of\n",
            "the\n",
            "image\n",
            ".\n",
            "As\n",
            "our\n",
            "method\n",
            "is\n",
            "trained\n",
            "with\n",
            "an\n",
            "encoder\n",
            ",\n",
            "ﬁnding\n",
            "the\n",
            "latent\n",
            "codes\n",
            "for\n",
            "a\n",
            "new\n",
            "input\n",
            "image\n",
            "becomes\n",
            "trivial\n",
            ",\n",
            "rather\n",
            "than\n",
            "cumbersome\n",
            ".\n",
            "As\n",
            "a\n",
            "result\n",
            ",\n",
            "our\n",
            "method\n",
            "enables\n",
            "us\n",
            "to\n",
            "manipulate\n",
            "real\n",
            "input\n",
            "images\n",
            "in\n",
            "various\n",
            "ways\n",
            ",\n",
            "including\n",
            "texture\n",
            "swapping\n",
            ",\n",
            "local\n",
            "and\n",
            "global\n",
            "editing\n",
            ",\n",
            "and\n",
            "latent\n",
            "code\n",
            "vector\n",
            "arithmetic\n",
            ".\n",
            "Experiments\n",
            "on\n",
            "multiple\n",
            "datasets\n",
            "show\n",
            "that\n",
            "our\n",
            "model\n",
            "produces\n",
            "better\n",
            "results\n",
            "and\n",
            "is\n",
            "substantially\n",
            "more\n",
            "efﬁcient\n",
            "compared\n",
            "to\n",
            "recent\n",
            "generative\n",
            "models\n",
            ".\n",
            "Figure\n",
            "1\n",
            ":\n",
            "Our\n",
            "Swapping\n",
            "Autoencoder\n",
            "learns\n",
            "to\n",
            "disentangle\n",
            "texture\n",
            "from\n",
            "structure\n",
            "for\n",
            "image\n",
            "editing\n",
            "tasks\n",
            ".\n",
            "One\n",
            "such\n",
            "task\n",
            "is\n",
            "texture\n",
            "swapping\n",
            ",\n",
            "shown\n",
            "here\n",
            ".\n",
            "Please\n",
            "see\n",
            "our\n",
            "project\n",
            "webpage\n",
            "for\n",
            "a\n",
            "demo\n",
            "video\n",
            "of\n",
            "our\n",
            "editing\n",
            "method\n",
            ".\n",
            "Abstract\n",
            "Learning\n",
            "object-centric\n",
            "representations\n",
            "of\n",
            "complex\n",
            "scenes\n",
            "is\n",
            "a\n",
            "promising\n",
            "step\n",
            "towards\n",
            "enabling\n",
            "efﬁcient\n",
            "abstract\n",
            "reasoning\n",
            "from\n",
            "low-level\n",
            "perceptual\n",
            "features\n",
            ".\n",
            "Yet\n",
            ",\n",
            "most\n",
            "deep\n",
            "learning\n",
            "approaches\n",
            "learn\n",
            "distributed\n",
            "representations\n",
            "that\n",
            "do\n",
            "not\n",
            "capture\n",
            "the\n",
            "compositional\n",
            "properties\n",
            "of\n",
            "natural\n",
            "scenes\n",
            ".\n",
            "In\n",
            "this\n",
            "paper\n",
            ",\n",
            "we\n",
            "present\n",
            "the\n",
            "Slot\n",
            "Attention\n",
            "module\n",
            ",\n",
            "an\n",
            "architectural\n",
            "component\n",
            "that\n",
            "interfaces\n",
            "with\n",
            "perceptual\n",
            "representations\n",
            "such\n",
            "as\n",
            "the\n",
            "output\n",
            "of\n",
            "a\n",
            "convolutional\n",
            "neural\n",
            "network\n",
            "and\n",
            "produces\n",
            "a\n",
            "set\n",
            "of\n",
            "task-dependent\n",
            "abstract\n",
            "representations\n",
            "which\n",
            "we\n",
            "call\n",
            "slots\n",
            ".\n",
            "These\n",
            "slots\n",
            "are\n",
            "exchangeable\n",
            "and\n",
            "can\n",
            "bind\n",
            "to\n",
            "any\n",
            "object\n",
            "in\n",
            "the\n",
            "input\n",
            "by\n",
            "specializing\n",
            "through\n",
            "a\n",
            "competitive\n",
            "procedure\n",
            "over\n",
            "multiple\n",
            "rounds\n",
            "of\n",
            "attention\n",
            ".\n",
            "We\n",
            "empirically\n",
            "demonstrate\n",
            "that\n",
            "Slot\n",
            "Attention\n",
            "can\n",
            "extract\n",
            "object-centric\n",
            "representations\n",
            "that\n",
            "enable\n",
            "generalization\n",
            "to\n",
            "unseen\n",
            "compositions\n",
            "when\n",
            "trained\n",
            "on\n",
            "unsupervised\n",
            "object\n",
            "discovery\n",
            "and\n",
            "supervised\n",
            "property\n",
            "prediction\n",
            "tasks\n",
            ".\n",
            "1\n",
            "Abstract\n",
            "Within\n",
            "months\n",
            "of\n",
            "birth\n",
            ",\n",
            "children\n",
            "develop\n",
            "meaningful\n",
            "expectations\n",
            "about\n",
            "the\n",
            "world\n",
            "around\n",
            "them\n",
            ".\n",
            "How\n",
            "much\n",
            "of\n",
            "this\n",
            "early\n",
            "knowledge\n",
            "can\n",
            "be\n",
            "explained\n",
            "through\n",
            "generic\n",
            "learning\n",
            "mechanisms\n",
            "applied\n",
            "to\n",
            "sensory\n",
            "data\n",
            ",\n",
            "and\n",
            "how\n",
            "much\n",
            "of\n",
            "it\n",
            "requires\n",
            "more\n",
            "substantive\n",
            "innate\n",
            "inductive\n",
            "biases\n",
            "?\n",
            "Addressing\n",
            "this\n",
            "fundamental\n",
            "question\n",
            "in\n",
            "its\n",
            "full\n",
            "generality\n",
            "is\n",
            "currently\n",
            "infeasible\n",
            ",\n",
            "but\n",
            "we\n",
            "can\n",
            "hope\n",
            "to\n",
            "make\n",
            "real\n",
            "progress\n",
            "in\n",
            "more\n",
            "narrowly\n",
            "deﬁned\n",
            "domains\n",
            ",\n",
            "such\n",
            "as\n",
            "the\n",
            "development\n",
            "of\n",
            "high-level\n",
            "visual\n",
            "categories\n",
            ",\n",
            "thanks\n",
            "to\n",
            "improvements\n",
            "in\n",
            "data\n",
            "collecting\n",
            "technology\n",
            "and\n",
            "recent\n",
            "progress\n",
            "in\n",
            "deep\n",
            "learning\n",
            ".\n",
            "In\n",
            "this\n",
            "paper\n",
            ",\n",
            "our\n",
            "goal\n",
            "is\n",
            "precisely\n",
            "to\n",
            "achieve\n",
            "such\n",
            "progress\n",
            "by\n",
            "utilizing\n",
            "modern\n",
            "self-supervised\n",
            "deep\n",
            "learning\n",
            "methods\n",
            "and\n",
            "a\n",
            "recent\n",
            "longitudinal\n",
            ",\n",
            "egocentric\n",
            "video\n",
            "dataset\n",
            "recorded\n",
            "from\n",
            "the\n",
            "perspective\n",
            "of\n",
            "three\n",
            "young\n",
            "children\n",
            "(\n",
            "Sullivan\n",
            "et\n",
            "al.\n",
            ",\n",
            "2020\n",
            ")\n",
            ".\n",
            "Our\n",
            "results\n",
            "demonstrate\n",
            "the\n",
            "emergence\n",
            "of\n",
            "powerful\n",
            ",\n",
            "high-level\n",
            "visual\n",
            "representations\n",
            "from\n",
            "developmentally\n",
            "realistic\n",
            "natural\n",
            "videos\n",
            "using\n",
            "generic\n",
            "self-\n",
            "supervised\n",
            "learning\n",
            "objectives\n",
            ".\n",
            "1\n",
            "Abstract\n",
            "The\n",
            "goal\n",
            "of\n",
            "compressed\n",
            "sensing\n",
            "is\n",
            "to\n",
            "estimate\n",
            "a\n",
            "high\n",
            "dimensional\n",
            "vector\n",
            "from\n",
            "an\n",
            "underdetermined\n",
            "system\n",
            "of\n",
            "noisy\n",
            "linear\n",
            "equations\n",
            ".\n",
            "In\n",
            "analogy\n",
            "to\n",
            "classical\n",
            "compressed\n",
            "sensing\n",
            ",\n",
            "here\n",
            "we\n",
            "assume\n",
            "a\n",
            "generative\n",
            "model\n",
            "as\n",
            "a\n",
            "prior\n",
            ",\n",
            "that\n",
            "is\n",
            ",\n",
            "we\n",
            "assume\n",
            "the\n",
            "vector\n",
            "is\n",
            "represented\n",
            "by\n",
            "a\n",
            "deep\n",
            "generative\n",
            "model\n",
            "G\n",
            ":\n",
            "Rk\n",
            "→\n",
            "Rn\n",
            ".\n",
            "Classical\n",
            "recovery\n",
            "approaches\n",
            "such\n",
            "as\n",
            "empirical\n",
            "risk\n",
            "minimization\n",
            "(\n",
            "ERM\n",
            ")\n",
            "are\n",
            "guaranteed\n",
            "to\n",
            "succeed\n",
            "when\n",
            "the\n",
            "measurement\n",
            "matrix\n",
            "is\n",
            "sub-Gaussian\n",
            ".\n",
            "However\n",
            ",\n",
            "when\n",
            "the\n",
            "measurement\n",
            "matrix\n",
            "and\n",
            "measurements\n",
            "are\n",
            "heavy-tailed\n",
            "or\n",
            "have\n",
            "outliers\n",
            ",\n",
            "recovery\n",
            "may\n",
            "fail\n",
            "dramatically\n",
            ".\n",
            "In\n",
            "this\n",
            "paper\n",
            "we\n",
            "propose\n",
            "an\n",
            "algorithm\n",
            "inspired\n",
            "by\n",
            "the\n",
            "Median-of-Means\n",
            "(\n",
            "MOM\n",
            ")\n",
            ".\n",
            "Our\n",
            "algorithm\n",
            "guarantees\n",
            "recovery\n",
            "for\n",
            "heavy-tailed\n",
            "data\n",
            ",\n",
            "even\n",
            "in\n",
            "the\n",
            "presence\n",
            "of\n",
            "outliers\n",
            ".\n",
            "Theoretically\n",
            ",\n",
            "our\n",
            "results\n",
            "show\n",
            "our\n",
            "novel\n",
            "MOM-based\n",
            "algorithm\n",
            "enjoys\n",
            "the\n",
            "same\n",
            "sample\n",
            "complexity\n",
            "guarantees\n",
            "as\n",
            "ERM\n",
            "under\n",
            "sub-Gaussian\n",
            "assumptions\n",
            ".\n",
            "Our\n",
            "experiments\n",
            "validate\n",
            "both\n",
            "aspects\n",
            "of\n",
            "our\n",
            "claims\n",
            ":\n",
            "other\n",
            "algorithms\n",
            "are\n",
            "indeed\n",
            "fragile\n",
            "and\n",
            "fail\n",
            "under\n",
            "heavy-tailed\n",
            "and/or\n",
            "corrupted\n",
            "data\n",
            ",\n",
            "while\n",
            "our\n",
            "approach\n",
            "exhibits\n",
            "the\n",
            "predicted\n",
            "robustness\n",
            ".\n",
            "Abstract\n",
            "Unsupervised\n",
            "and\n",
            "self-supervised\n",
            "learning\n",
            "approaches\n",
            "have\n",
            "become\n",
            "a\n",
            "crucial\n",
            "tool\n",
            "to\n",
            "learn\n",
            "representations\n",
            "for\n",
            "downstream\n",
            "prediction\n",
            "tasks\n",
            ".\n",
            "While\n",
            "these\n",
            "approaches\n",
            "are\n",
            "widely\n",
            "used\n",
            "in\n",
            "practice\n",
            "and\n",
            "achieve\n",
            "impressive\n",
            "empirical\n",
            "gains\n",
            ",\n",
            "their\n",
            "theoret-\n",
            "ical\n",
            "understanding\n",
            "largely\n",
            "lags\n",
            "behind\n",
            ".\n",
            "Towards\n",
            "bridging\n",
            "this\n",
            "gap\n",
            ",\n",
            "we\n",
            "present\n",
            "a\n",
            "unifying\n",
            "perspective\n",
            "where\n",
            "several\n",
            "such\n",
            "approaches\n",
            "can\n",
            "be\n",
            "viewed\n",
            "as\n",
            "imposing\n",
            "a\n",
            "regularization\n",
            "on\n",
            "the\n",
            "representation\n",
            "via\n",
            "a\n",
            "learnable\n",
            "function\n",
            "using\n",
            "unlabeled\n",
            "data\n",
            ".\n",
            "We\n",
            "propose\n",
            "a\n",
            "discriminative\n",
            "theoretical\n",
            "framework\n",
            "for\n",
            "analyzing\n",
            "the\n",
            "sam-\n",
            "ple\n",
            "complexity\n",
            "of\n",
            "these\n",
            "approaches\n",
            ",\n",
            "which\n",
            "generalizes\n",
            "the\n",
            "framework\n",
            "of\n",
            "[\n",
            "3\n",
            "]\n",
            "to\n",
            "allow\n",
            "learnable\n",
            "regularization\n",
            "functions\n",
            ".\n",
            "Our\n",
            "sample\n",
            "complexity\n",
            "bounds\n",
            "show\n",
            "that\n",
            ",\n",
            "with\n",
            "carefully\n",
            "chosen\n",
            "hypothesis\n",
            "classes\n",
            "to\n",
            "exploit\n",
            "the\n",
            "structure\n",
            "in\n",
            "the\n",
            "data\n",
            ",\n",
            "these\n",
            "learnable\n",
            "regularization\n",
            "functions\n",
            "can\n",
            "prune\n",
            "the\n",
            "hypothesis\n",
            "space\n",
            ",\n",
            "and\n",
            "help\n",
            "reduce\n",
            "the\n",
            "amount\n",
            "of\n",
            "labeled\n",
            "data\n",
            "needed\n",
            ".\n",
            "We\n",
            "then\n",
            "provide\n",
            "two\n",
            "concrete\n",
            "examples\n",
            "of\n",
            "functional\n",
            "regularization\n",
            ",\n",
            "one\n",
            "using\n",
            "auto-encoders\n",
            "and\n",
            "the\n",
            "other\n",
            "using\n",
            "masked\n",
            "self-supervision\n",
            ",\n",
            "and\n",
            "apply\n",
            "our\n",
            "framework\n",
            "to\n",
            "quantify\n",
            "the\n",
            "reduction\n",
            "in\n",
            "the\n",
            "sample\n",
            "complexity\n",
            "bound\n",
            "of\n",
            "labeled\n",
            "data\n",
            ".\n",
            "We\n",
            "also\n",
            "provide\n",
            "complementary\n",
            "empirical\n",
            "results\n",
            "to\n",
            "support\n",
            "our\n",
            "analysis\n",
            ".\n",
            "1\n",
            "Abstract\n",
            "Given\n",
            "the\n",
            "ever-increasing\n",
            "computational\n",
            "costs\n",
            "of\n",
            "modern\n",
            "machine\n",
            "learning\n",
            "mod-\n",
            "els\n",
            ",\n",
            "we\n",
            "need\n",
            "to\n",
            "ﬁnd\n",
            "new\n",
            "ways\n",
            "to\n",
            "reuse\n",
            "such\n",
            "expert\n",
            "models\n",
            "and\n",
            "thus\n",
            "tap\n",
            "into\n",
            "the\n",
            "resources\n",
            "that\n",
            "have\n",
            "been\n",
            "invested\n",
            "in\n",
            "their\n",
            "creation\n",
            ".\n",
            "Recent\n",
            "work\n",
            "suggests\n",
            "that\n",
            "the\n",
            "power\n",
            "of\n",
            "these\n",
            "massive\n",
            "models\n",
            "is\n",
            "captured\n",
            "by\n",
            "the\n",
            "representations\n",
            "they\n",
            "learn\n",
            ".\n",
            "There-\n",
            "fore\n",
            ",\n",
            "we\n",
            "seek\n",
            "a\n",
            "model\n",
            "that\n",
            "can\n",
            "relate\n",
            "between\n",
            "different\n",
            "existing\n",
            "representations\n",
            "and\n",
            "propose\n",
            "to\n",
            "solve\n",
            "this\n",
            "task\n",
            "with\n",
            "a\n",
            "conditionally\n",
            "invertible\n",
            "network\n",
            ".\n",
            "This\n",
            "network\n",
            "demonstrates\n",
            "its\n",
            "capability\n",
            "by\n",
            "(\n",
            "i\n",
            ")\n",
            "providing\n",
            "generic\n",
            "transfer\n",
            "between\n",
            "diverse\n",
            "do-\n",
            "mains\n",
            ",\n",
            "(\n",
            "ii\n",
            ")\n",
            "enabling\n",
            "controlled\n",
            "content\n",
            "synthesis\n",
            "by\n",
            "allowing\n",
            "modiﬁcation\n",
            "in\n",
            "other\n",
            "domains\n",
            ",\n",
            "and\n",
            "(\n",
            "iii\n",
            ")\n",
            "facilitating\n",
            "diagnosis\n",
            "of\n",
            "existing\n",
            "representations\n",
            "by\n",
            "translating\n",
            "them\n",
            "into\n",
            "interpretable\n",
            "domains\n",
            "such\n",
            "as\n",
            "images\n",
            ".\n",
            "Our\n",
            "domain\n",
            "transfer\n",
            "network\n",
            "can\n",
            "translate\n",
            "between\n",
            "ﬁxed\n",
            "representations\n",
            "without\n",
            "having\n",
            "to\n",
            "learn\n",
            "or\n",
            "ﬁnetune\n",
            "them\n",
            ".\n",
            "This\n",
            "allows\n",
            "users\n",
            "to\n",
            "utilize\n",
            "various\n",
            "existing\n",
            "domain-speciﬁc\n",
            "expert\n",
            "models\n",
            "from\n",
            "the\n",
            "literature\n",
            "that\n",
            "had\n",
            "been\n",
            "trained\n",
            "with\n",
            "extensive\n",
            "computational\n",
            "resources\n",
            ".\n",
            "Experiments\n",
            "on\n",
            "diverse\n",
            "conditional\n",
            "image\n",
            "synthesis\n",
            "tasks\n",
            ",\n",
            "competitive\n",
            "image\n",
            "mod-\n",
            "iﬁcation\n",
            "results\n",
            "and\n",
            "experiments\n",
            "on\n",
            "image-to-image\n",
            "and\n",
            "text-to-image\n",
            "generation\n",
            "demonstrate\n",
            "the\n",
            "generic\n",
            "applicability\n",
            "of\n",
            "our\n",
            "approach\n",
            ".\n",
            "For\n",
            "example\n",
            ",\n",
            "we\n",
            "translate\n",
            "between\n",
            "BERT\n",
            "and\n",
            "BigGAN\n",
            ",\n",
            "state-of-the-art\n",
            "text\n",
            "and\n",
            "image\n",
            "models\n",
            "to\n",
            "provide\n",
            "text-to-image\n",
            "generation\n",
            ",\n",
            "which\n",
            "neither\n",
            "of\n",
            "both\n",
            "experts\n",
            "can\n",
            "perform\n",
            "on\n",
            "their\n",
            "own\n",
            ".\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "df_output                                                topic  ... rank_lda\n",
            "0             graph similarity deep learning neurips  ...      6.0\n",
            "1             graph similarity deep learning neurips  ...     10.0\n",
            "2             graph similarity deep learning neurips  ...      2.0\n",
            "3             graph similarity deep learning neurips  ...      5.0\n",
            "4             graph similarity deep learning neurips  ...      1.0\n",
            "5             graph similarity deep learning neurips  ...      8.0\n",
            "6             graph similarity deep learning neurips  ...      4.0\n",
            "7             graph similarity deep learning neurips  ...      3.0\n",
            "8             graph similarity deep learning neurips  ...      7.0\n",
            "9             graph similarity deep learning neurips  ...      9.0\n",
            "0  unsupervised information theoretic perceptual ...  ...     10.0\n",
            "1  unsupervised information theoretic perceptual ...  ...      9.0\n",
            "2  unsupervised information theoretic perceptual ...  ...      8.0\n",
            "3  unsupervised information theoretic perceptual ...  ...      2.0\n",
            "4  unsupervised information theoretic perceptual ...  ...      3.0\n",
            "5  unsupervised information theoretic perceptual ...  ...      5.0\n",
            "6  unsupervised information theoretic perceptual ...  ...      4.0\n",
            "7  unsupervised information theoretic perceptual ...  ...      7.0\n",
            "8  unsupervised information theoretic perceptual ...  ...      1.0\n",
            "9  unsupervised information theoretic perceptual ...  ...      6.0\n",
            "\n",
            "[20 rows x 8 columns]\n",
            "topic:  self supervised multimodal versatile networks neurips id_= 2\n",
            "1 . Self-Supervised MultiModal Versatile Networks https://papers.nips.cc/paper/2020/hash/0060ef47b12160b9198302ebdb144dcf-Abstract.html\n",
            "**********************************************\n",
            "2 . Advances in Neural Information Processing Systems 33 (NeurIPS ... https://papers.nips.cc/paper/2020\n",
            "**********************************************\n",
            "3 . Large-Scale Adversarial Training for Vision-and-Language ... https://papers.nips.cc/paper/2020/file/49562478de4c54fafd4ec46fdb297de5-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "We present VILLA, the ﬁrst known effort on large-scale adversarial training for\n",
            "vision-and-language (V+L) representation learning. VILLA consists of two training\n",
            "stages: (i) task-agnostic adversarial pre-training; followed by (ii) task-speciﬁc\n",
            "adversarial ﬁnetuning. Instead of adding adversarial perturbations on image pixels\n",
            "and textual tokens, we propose to perform adversarial training in the embedding\n",
            "space of each modality. To enable large-scale training, we adopt the “free” adver-\n",
            "sarial training strategy, and combine it with KL-divergence-based regularization to\n",
            "promote higher invariance in the embedding space. We apply VILLA to current\n",
            "best-performing V+L models, and achieve new state of the art on a wide range\n",
            "of tasks, including Visual Question Answering, Visual Commonsense Reasoning,\n",
            "Image-Text Retrieval, Referring Expression Comprehension, Visual Entailment,\n",
            "and NLVR2.1\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "4 . Training Generative Adversarial Networks with Limited Data https://papers.nips.cc/paper/2020/file/8d30aa96e72440759f74bd2306c1fa3d-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Training generative adversarial networks (GAN) using too little data typically leads\n",
            "to discriminator overﬁtting, causing training to diverge. We propose an adaptive\n",
            "discriminator augmentation mechanism that signiﬁcantly stabilizes training in\n",
            "limited data regimes. The approach does not require changes to loss functions\n",
            "or network architectures, and is applicable both when training from scratch and\n",
            "when ﬁne-tuning an existing GAN on another dataset. We demonstrate, on several\n",
            "datasets, that good results are now possible using only a few thousand training\n",
            "images, often matching StyleGAN2 results with an order of magnitude fewer\n",
            "images. We expect this to open up new application domains for GANs. We also\n",
            "ﬁnd that the widely used CIFAR-10 is, in fact, a limited data benchmark, and\n",
            "improve the record FID from 5.59 to 2.42.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "5 . Bayesian Attention Modules https://papers.nips.cc/paper/2020/file/bcff3f632fd16ff099a49c2f0932b47a-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Attention modules, as simple and effective tools, have not only enabled deep neural\n",
            "networks to achieve state-of-the-art results in many domains, but also enhanced\n",
            "their interpretability. Most current models use deterministic attention modules\n",
            "due to their simplicity and ease of optimization. Stochastic counterparts, on the\n",
            "other hand, are less popular despite their potential beneﬁts. The main reason is\n",
            "that stochastic attention often introduces optimization issues or requires signiﬁcant\n",
            "model changes. In this paper, we propose a scalable stochastic version of attention\n",
            "that is easy to implement and optimize. We construct simplex-constrained attention\n",
            "distributions by normalizing reparameterizable distributions, making the training\n",
            "process differentiable. We learn their parameters in a Bayesian framework where\n",
            "a data-dependent prior is introduced for regularization. We apply the proposed\n",
            "stochastic attention modules to various attention-based models, with applications\n",
            "to graph node classiﬁcation, visual question answering, image captioning, machine\n",
            "translation, and language understanding. Our experiments show the proposed\n",
            "method brings consistent improvements over the corresponding baselines.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "6 . Language-Conditioned Imitation Learning for Robot Manipulation ... https://papers.nips.cc/paper/2020/file/9909794d52985cbc5d95c26e31125d1a-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Imitation learning is a popular approach for teaching motor skills to robots. How-\n",
            "ever, most approaches focus on extracting policy parameters from execution traces\n",
            "alone (i.e., motion trajectories and perceptual data). No adequate communication\n",
            "channel exists between the human expert and the robot to describe critical aspects\n",
            "of the task, such as the properties of the target object or the intended shape of the\n",
            "motion. Motivated by insights into the human teaching process, we introduce a\n",
            "method for incorporating unstructured natural language into imitation learning. At\n",
            "training time, the expert can provide demonstrations along with verbal descriptions\n",
            "in order to describe the underlying intent (e.g., “go to the large green bowl”). The\n",
            "training process then interrelates these two modalities to encode the correlations\n",
            "between language, perception, and motion. The resulting language-conditioned\n",
            "visuomotor policies can be conditioned at runtime on new human commands and\n",
            "instructions, which allows for more ﬁne-grained control over the trained policies\n",
            "while also reducing situational ambiguity. We demonstrate in a set of simulation\n",
            "experiments how our approach can learn language-conditioned manipulation poli-\n",
            "cies for a seven-degree-of-freedom robot arm and compare the results to a variety\n",
            "of alternative methods.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "data:                                                topic  ...                                                url\n",
            "0  self supervised multimodal versatile networks ...  ...  https://papers.nips.cc/paper/2020/hash/0060ef4...\n",
            "1  self supervised multimodal versatile networks ...  ...                  https://papers.nips.cc/paper/2020\n",
            "2  self supervised multimodal versatile networks ...  ...  https://papers.nips.cc/paper/2020/file/4956247...\n",
            "3  self supervised multimodal versatile networks ...  ...  https://papers.nips.cc/paper/2020/file/8d30aa9...\n",
            "4  self supervised multimodal versatile networks ...  ...  https://papers.nips.cc/paper/2020/file/bcff3f6...\n",
            "5  self supervised multimodal versatile networks ...  ...  https://papers.nips.cc/paper/2020/file/9909794...\n",
            "\n",
            "[6 rows x 4 columns]\n",
            "**********************************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                                               topic  ... similarity_score\n",
            "0  self supervised multimodal versatile networks ...  ...         0.965593\n",
            "1  self supervised multimodal versatile networks ...  ...         0.966477\n",
            "2  self supervised multimodal versatile networks ...  ...         0.965714\n",
            "3  self supervised multimodal versatile networks ...  ...         0.963016\n",
            "4  self supervised multimodal versatile networks ...  ...         0.962894\n",
            "5  self supervised multimodal versatile networks ...  ...         0.966408\n",
            "\n",
            "[6 rows x 5 columns]\n",
            "df_final after rank=                                                topic  ... rank\n",
            "0  self supervised multimodal versatile networks ...  ...  4.0\n",
            "1  self supervised multimodal versatile networks ...  ...  1.0\n",
            "2  self supervised multimodal versatile networks ...  ...  3.0\n",
            "3  self supervised multimodal versatile networks ...  ...  5.0\n",
            "4  self supervised multimodal versatile networks ...  ...  6.0\n",
            "5  self supervised multimodal versatile networks ...  ...  2.0\n",
            "\n",
            "[6 rows x 6 columns]\n",
            "0    Self-Supervised MultiModal Versatile Networks\\...\n",
            "1    Book\\n\\nDo not remove: This comment is monitor...\n",
            "2    Abstract\\n\\nWe present VILLA, the ﬁrst known e...\n",
            "3    Abstract\\n\\nTraining generative adversarial ne...\n",
            "4    Abstract\\n\\nAttention modules, as simple and e...\n",
            "5    Abstract\\n\\nImitation learning is a popular ap...\n",
            "Name: text, dtype: object\n",
            "Self-Supervised\n",
            "MultiModal\n",
            "Versatile\n",
            "Networks\n",
            "Part\n",
            "of\n",
            "Advances\n",
            "in\n",
            "Neural\n",
            "Information\n",
            "Processing\n",
            "Systems\n",
            "33\n",
            "(\n",
            "NeurIPS\n",
            "2020\n",
            ")\n",
            "Authors\n",
            "Jean-Baptiste\n",
            "Alayrac\n",
            ",\n",
            "Adria\n",
            "Recasens\n",
            ",\n",
            "Rosalia\n",
            "Schneider\n",
            ",\n",
            "Relja\n",
            "Arandjelović\n",
            ",\n",
            "Jason\n",
            "Ramapuram\n",
            ",\n",
            "Jeffrey\n",
            "De\n",
            "Fauw\n",
            ",\n",
            "Lucas\n",
            "Smaira\n",
            ",\n",
            "Sander\n",
            "Dieleman\n",
            ",\n",
            "Andrew\n",
            "Zisserman\n",
            "Abstract\n",
            "Videos\n",
            "are\n",
            "a\n",
            "rich\n",
            "source\n",
            "of\n",
            "multi-modal\n",
            "supervision\n",
            ".\n",
            "In\n",
            "this\n",
            "work\n",
            ",\n",
            "we\n",
            "learn\n",
            "representations\n",
            "using\n",
            "self-supervision\n",
            "by\n",
            "leveraging\n",
            "three\n",
            "modalities\n",
            "naturally\n",
            "present\n",
            "in\n",
            "videos\n",
            ":\n",
            "visual\n",
            ",\n",
            "audio\n",
            "and\n",
            "language\n",
            "streams\n",
            ".\n",
            "To\n",
            "this\n",
            "end\n",
            ",\n",
            "we\n",
            "introduce\n",
            "the\n",
            "notion\n",
            "of\n",
            "a\n",
            "multimodal\n",
            "versatile\n",
            "network\n",
            "--\n",
            "a\n",
            "network\n",
            "that\n",
            "can\n",
            "ingest\n",
            "multiple\n",
            "modalities\n",
            "and\n",
            "whose\n",
            "representations\n",
            "enable\n",
            "downstream\n",
            "tasks\n",
            "in\n",
            "multiple\n",
            "modalities\n",
            ".\n",
            "In\n",
            "particular\n",
            ",\n",
            "we\n",
            "explore\n",
            "how\n",
            "best\n",
            "to\n",
            "combine\n",
            "the\n",
            "modalities\n",
            ",\n",
            "such\n",
            "that\n",
            "fine-grained\n",
            "representations\n",
            "of\n",
            "the\n",
            "visual\n",
            "and\n",
            "audio\n",
            "modalities\n",
            "can\n",
            "be\n",
            "maintained\n",
            ",\n",
            "whilst\n",
            "also\n",
            "integrating\n",
            "text\n",
            "into\n",
            "a\n",
            "common\n",
            "embedding\n",
            ".\n",
            "Driven\n",
            "by\n",
            "versatility\n",
            ",\n",
            "we\n",
            "also\n",
            "introduce\n",
            "a\n",
            "novel\n",
            "process\n",
            "of\n",
            "deflation\n",
            ",\n",
            "so\n",
            "that\n",
            "the\n",
            "networks\n",
            "can\n",
            "be\n",
            "effortlessly\n",
            "applied\n",
            "to\n",
            "the\n",
            "visual\n",
            "data\n",
            "in\n",
            "the\n",
            "form\n",
            "of\n",
            "video\n",
            "or\n",
            "a\n",
            "static\n",
            "image\n",
            ".\n",
            "We\n",
            "demonstrate\n",
            "how\n",
            "such\n",
            "networks\n",
            "trained\n",
            "on\n",
            "large\n",
            "collections\n",
            "of\n",
            "unlabelled\n",
            "video\n",
            "data\n",
            "can\n",
            "be\n",
            "applied\n",
            "on\n",
            "video\n",
            ",\n",
            "video-text\n",
            ",\n",
            "image\n",
            "and\n",
            "audio\n",
            "tasks\n",
            ".\n",
            "Equipped\n",
            "with\n",
            "these\n",
            "representations\n",
            ",\n",
            "we\n",
            "obtain\n",
            "state-of-the-art\n",
            "performance\n",
            "on\n",
            "multiple\n",
            "challenging\n",
            "benchmarks\n",
            "including\n",
            "UCF101\n",
            ",\n",
            "HMDB51\n",
            ",\n",
            "Kinetics600\n",
            ",\n",
            "AudioSet\n",
            "and\n",
            "ESC-50\n",
            "when\n",
            "compared\n",
            "to\n",
            "previous\n",
            "self-supervised\n",
            "work\n",
            ".\n",
            "Our\n",
            "models\n",
            "are\n",
            "publicly\n",
            "available\n",
            ".\n",
            "Book\n",
            "Do\n",
            "not\n",
            "remove\n",
            ":\n",
            "This\n",
            "comment\n",
            "is\n",
            "monitored\n",
            "to\n",
            "verify\n",
            "that\n",
            "the\n",
            "site\n",
            "is\n",
            "working\n",
            "properly\n",
            "Abstract\n",
            "We\n",
            "present\n",
            "VILLA\n",
            ",\n",
            "the\n",
            "ﬁrst\n",
            "known\n",
            "effort\n",
            "on\n",
            "large-scale\n",
            "adversarial\n",
            "training\n",
            "for\n",
            "vision-and-language\n",
            "(\n",
            "V+L\n",
            ")\n",
            "representation\n",
            "learning\n",
            ".\n",
            "VILLA\n",
            "consists\n",
            "of\n",
            "two\n",
            "training\n",
            "stages\n",
            ":\n",
            "(\n",
            "i\n",
            ")\n",
            "task-agnostic\n",
            "adversarial\n",
            "pre-training\n",
            ";\n",
            "followed\n",
            "by\n",
            "(\n",
            "ii\n",
            ")\n",
            "task-speciﬁc\n",
            "adversarial\n",
            "ﬁnetuning\n",
            ".\n",
            "Instead\n",
            "of\n",
            "adding\n",
            "adversarial\n",
            "perturbations\n",
            "on\n",
            "image\n",
            "pixels\n",
            "and\n",
            "textual\n",
            "tokens\n",
            ",\n",
            "we\n",
            "propose\n",
            "to\n",
            "perform\n",
            "adversarial\n",
            "training\n",
            "in\n",
            "the\n",
            "embedding\n",
            "space\n",
            "of\n",
            "each\n",
            "modality\n",
            ".\n",
            "To\n",
            "enable\n",
            "large-scale\n",
            "training\n",
            ",\n",
            "we\n",
            "adopt\n",
            "the\n",
            "“\n",
            "free\n",
            "”\n",
            "adver-\n",
            "sarial\n",
            "training\n",
            "strategy\n",
            ",\n",
            "and\n",
            "combine\n",
            "it\n",
            "with\n",
            "KL-divergence-based\n",
            "regularization\n",
            "to\n",
            "promote\n",
            "higher\n",
            "invariance\n",
            "in\n",
            "the\n",
            "embedding\n",
            "space\n",
            ".\n",
            "We\n",
            "apply\n",
            "VILLA\n",
            "to\n",
            "current\n",
            "best-performing\n",
            "V+L\n",
            "models\n",
            ",\n",
            "and\n",
            "achieve\n",
            "new\n",
            "state\n",
            "of\n",
            "the\n",
            "art\n",
            "on\n",
            "a\n",
            "wide\n",
            "range\n",
            "of\n",
            "tasks\n",
            ",\n",
            "including\n",
            "Visual\n",
            "Question\n",
            "Answering\n",
            ",\n",
            "Visual\n",
            "Commonsense\n",
            "Reasoning\n",
            ",\n",
            "Image-Text\n",
            "Retrieval\n",
            ",\n",
            "Referring\n",
            "Expression\n",
            "Comprehension\n",
            ",\n",
            "Visual\n",
            "Entailment\n",
            ",\n",
            "and\n",
            "NLVR2.1\n",
            "1\n",
            "Abstract\n",
            "Training\n",
            "generative\n",
            "adversarial\n",
            "networks\n",
            "(\n",
            "GAN\n",
            ")\n",
            "using\n",
            "too\n",
            "little\n",
            "data\n",
            "typically\n",
            "leads\n",
            "to\n",
            "discriminator\n",
            "overﬁtting\n",
            ",\n",
            "causing\n",
            "training\n",
            "to\n",
            "diverge\n",
            ".\n",
            "We\n",
            "propose\n",
            "an\n",
            "adaptive\n",
            "discriminator\n",
            "augmentation\n",
            "mechanism\n",
            "that\n",
            "signiﬁcantly\n",
            "stabilizes\n",
            "training\n",
            "in\n",
            "limited\n",
            "data\n",
            "regimes\n",
            ".\n",
            "The\n",
            "approach\n",
            "does\n",
            "not\n",
            "require\n",
            "changes\n",
            "to\n",
            "loss\n",
            "functions\n",
            "or\n",
            "network\n",
            "architectures\n",
            ",\n",
            "and\n",
            "is\n",
            "applicable\n",
            "both\n",
            "when\n",
            "training\n",
            "from\n",
            "scratch\n",
            "and\n",
            "when\n",
            "ﬁne-tuning\n",
            "an\n",
            "existing\n",
            "GAN\n",
            "on\n",
            "another\n",
            "dataset\n",
            ".\n",
            "We\n",
            "demonstrate\n",
            ",\n",
            "on\n",
            "several\n",
            "datasets\n",
            ",\n",
            "that\n",
            "good\n",
            "results\n",
            "are\n",
            "now\n",
            "possible\n",
            "using\n",
            "only\n",
            "a\n",
            "few\n",
            "thousand\n",
            "training\n",
            "images\n",
            ",\n",
            "often\n",
            "matching\n",
            "StyleGAN2\n",
            "results\n",
            "with\n",
            "an\n",
            "order\n",
            "of\n",
            "magnitude\n",
            "fewer\n",
            "images\n",
            ".\n",
            "We\n",
            "expect\n",
            "this\n",
            "to\n",
            "open\n",
            "up\n",
            "new\n",
            "application\n",
            "domains\n",
            "for\n",
            "GANs\n",
            ".\n",
            "We\n",
            "also\n",
            "ﬁnd\n",
            "that\n",
            "the\n",
            "widely\n",
            "used\n",
            "CIFAR-10\n",
            "is\n",
            ",\n",
            "in\n",
            "fact\n",
            ",\n",
            "a\n",
            "limited\n",
            "data\n",
            "benchmark\n",
            ",\n",
            "and\n",
            "improve\n",
            "the\n",
            "record\n",
            "FID\n",
            "from\n",
            "5.59\n",
            "to\n",
            "2.42\n",
            ".\n",
            "1\n",
            "Abstract\n",
            "Attention\n",
            "modules\n",
            ",\n",
            "as\n",
            "simple\n",
            "and\n",
            "effective\n",
            "tools\n",
            ",\n",
            "have\n",
            "not\n",
            "only\n",
            "enabled\n",
            "deep\n",
            "neural\n",
            "networks\n",
            "to\n",
            "achieve\n",
            "state-of-the-art\n",
            "results\n",
            "in\n",
            "many\n",
            "domains\n",
            ",\n",
            "but\n",
            "also\n",
            "enhanced\n",
            "their\n",
            "interpretability\n",
            ".\n",
            "Most\n",
            "current\n",
            "models\n",
            "use\n",
            "deterministic\n",
            "attention\n",
            "modules\n",
            "due\n",
            "to\n",
            "their\n",
            "simplicity\n",
            "and\n",
            "ease\n",
            "of\n",
            "optimization\n",
            ".\n",
            "Stochastic\n",
            "counterparts\n",
            ",\n",
            "on\n",
            "the\n",
            "other\n",
            "hand\n",
            ",\n",
            "are\n",
            "less\n",
            "popular\n",
            "despite\n",
            "their\n",
            "potential\n",
            "beneﬁts\n",
            ".\n",
            "The\n",
            "main\n",
            "reason\n",
            "is\n",
            "that\n",
            "stochastic\n",
            "attention\n",
            "often\n",
            "introduces\n",
            "optimization\n",
            "issues\n",
            "or\n",
            "requires\n",
            "signiﬁcant\n",
            "model\n",
            "changes\n",
            ".\n",
            "In\n",
            "this\n",
            "paper\n",
            ",\n",
            "we\n",
            "propose\n",
            "a\n",
            "scalable\n",
            "stochastic\n",
            "version\n",
            "of\n",
            "attention\n",
            "that\n",
            "is\n",
            "easy\n",
            "to\n",
            "implement\n",
            "and\n",
            "optimize\n",
            ".\n",
            "We\n",
            "construct\n",
            "simplex-constrained\n",
            "attention\n",
            "distributions\n",
            "by\n",
            "normalizing\n",
            "reparameterizable\n",
            "distributions\n",
            ",\n",
            "making\n",
            "the\n",
            "training\n",
            "process\n",
            "differentiable\n",
            ".\n",
            "We\n",
            "learn\n",
            "their\n",
            "parameters\n",
            "in\n",
            "a\n",
            "Bayesian\n",
            "framework\n",
            "where\n",
            "a\n",
            "data-dependent\n",
            "prior\n",
            "is\n",
            "introduced\n",
            "for\n",
            "regularization\n",
            ".\n",
            "We\n",
            "apply\n",
            "the\n",
            "proposed\n",
            "stochastic\n",
            "attention\n",
            "modules\n",
            "to\n",
            "various\n",
            "attention-based\n",
            "models\n",
            ",\n",
            "with\n",
            "applications\n",
            "to\n",
            "graph\n",
            "node\n",
            "classiﬁcation\n",
            ",\n",
            "visual\n",
            "question\n",
            "answering\n",
            ",\n",
            "image\n",
            "captioning\n",
            ",\n",
            "machine\n",
            "translation\n",
            ",\n",
            "and\n",
            "language\n",
            "understanding\n",
            ".\n",
            "Our\n",
            "experiments\n",
            "show\n",
            "the\n",
            "proposed\n",
            "method\n",
            "brings\n",
            "consistent\n",
            "improvements\n",
            "over\n",
            "the\n",
            "corresponding\n",
            "baselines\n",
            ".\n",
            "1\n",
            "Abstract\n",
            "Imitation\n",
            "learning\n",
            "is\n",
            "a\n",
            "popular\n",
            "approach\n",
            "for\n",
            "teaching\n",
            "motor\n",
            "skills\n",
            "to\n",
            "robots\n",
            ".\n",
            "How-\n",
            "ever\n",
            ",\n",
            "most\n",
            "approaches\n",
            "focus\n",
            "on\n",
            "extracting\n",
            "policy\n",
            "parameters\n",
            "from\n",
            "execution\n",
            "traces\n",
            "alone\n",
            "(\n",
            "i.e.\n",
            ",\n",
            "motion\n",
            "trajectories\n",
            "and\n",
            "perceptual\n",
            "data\n",
            ")\n",
            ".\n",
            "No\n",
            "adequate\n",
            "communication\n",
            "channel\n",
            "exists\n",
            "between\n",
            "the\n",
            "human\n",
            "expert\n",
            "and\n",
            "the\n",
            "robot\n",
            "to\n",
            "describe\n",
            "critical\n",
            "aspects\n",
            "of\n",
            "the\n",
            "task\n",
            ",\n",
            "such\n",
            "as\n",
            "the\n",
            "properties\n",
            "of\n",
            "the\n",
            "target\n",
            "object\n",
            "or\n",
            "the\n",
            "intended\n",
            "shape\n",
            "of\n",
            "the\n",
            "motion\n",
            ".\n",
            "Motivated\n",
            "by\n",
            "insights\n",
            "into\n",
            "the\n",
            "human\n",
            "teaching\n",
            "process\n",
            ",\n",
            "we\n",
            "introduce\n",
            "a\n",
            "method\n",
            "for\n",
            "incorporating\n",
            "unstructured\n",
            "natural\n",
            "language\n",
            "into\n",
            "imitation\n",
            "learning\n",
            ".\n",
            "At\n",
            "training\n",
            "time\n",
            ",\n",
            "the\n",
            "expert\n",
            "can\n",
            "provide\n",
            "demonstrations\n",
            "along\n",
            "with\n",
            "verbal\n",
            "descriptions\n",
            "in\n",
            "order\n",
            "to\n",
            "describe\n",
            "the\n",
            "underlying\n",
            "intent\n",
            "(\n",
            "e.g.\n",
            ",\n",
            "“\n",
            "go\n",
            "to\n",
            "the\n",
            "large\n",
            "green\n",
            "bowl\n",
            "”\n",
            ")\n",
            ".\n",
            "The\n",
            "training\n",
            "process\n",
            "then\n",
            "interrelates\n",
            "these\n",
            "two\n",
            "modalities\n",
            "to\n",
            "encode\n",
            "the\n",
            "correlations\n",
            "between\n",
            "language\n",
            ",\n",
            "perception\n",
            ",\n",
            "and\n",
            "motion\n",
            ".\n",
            "The\n",
            "resulting\n",
            "language-conditioned\n",
            "visuomotor\n",
            "policies\n",
            "can\n",
            "be\n",
            "conditioned\n",
            "at\n",
            "runtime\n",
            "on\n",
            "new\n",
            "human\n",
            "commands\n",
            "and\n",
            "instructions\n",
            ",\n",
            "which\n",
            "allows\n",
            "for\n",
            "more\n",
            "ﬁne-grained\n",
            "control\n",
            "over\n",
            "the\n",
            "trained\n",
            "policies\n",
            "while\n",
            "also\n",
            "reducing\n",
            "situational\n",
            "ambiguity\n",
            ".\n",
            "We\n",
            "demonstrate\n",
            "in\n",
            "a\n",
            "set\n",
            "of\n",
            "simulation\n",
            "experiments\n",
            "how\n",
            "our\n",
            "approach\n",
            "can\n",
            "learn\n",
            "language-conditioned\n",
            "manipulation\n",
            "poli-\n",
            "cies\n",
            "for\n",
            "a\n",
            "seven-degree-of-freedom\n",
            "robot\n",
            "arm\n",
            "and\n",
            "compare\n",
            "the\n",
            "results\n",
            "to\n",
            "a\n",
            "variety\n",
            "of\n",
            "alternative\n",
            "methods\n",
            ".\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "df_output                                                topic  ... rank_lda\n",
            "0             graph similarity deep learning neurips  ...      6.0\n",
            "1             graph similarity deep learning neurips  ...     10.0\n",
            "2             graph similarity deep learning neurips  ...      2.0\n",
            "3             graph similarity deep learning neurips  ...      5.0\n",
            "4             graph similarity deep learning neurips  ...      1.0\n",
            "5             graph similarity deep learning neurips  ...      8.0\n",
            "6             graph similarity deep learning neurips  ...      4.0\n",
            "7             graph similarity deep learning neurips  ...      3.0\n",
            "8             graph similarity deep learning neurips  ...      7.0\n",
            "9             graph similarity deep learning neurips  ...      9.0\n",
            "0  unsupervised information theoretic perceptual ...  ...     10.0\n",
            "1  unsupervised information theoretic perceptual ...  ...      9.0\n",
            "2  unsupervised information theoretic perceptual ...  ...      8.0\n",
            "3  unsupervised information theoretic perceptual ...  ...      2.0\n",
            "4  unsupervised information theoretic perceptual ...  ...      3.0\n",
            "5  unsupervised information theoretic perceptual ...  ...      5.0\n",
            "6  unsupervised information theoretic perceptual ...  ...      4.0\n",
            "7  unsupervised information theoretic perceptual ...  ...      7.0\n",
            "8  unsupervised information theoretic perceptual ...  ...      1.0\n",
            "9  unsupervised information theoretic perceptual ...  ...      6.0\n",
            "0  self supervised multimodal versatile networks ...  ...      6.0\n",
            "1  self supervised multimodal versatile networks ...  ...      1.0\n",
            "2  self supervised multimodal versatile networks ...  ...      4.0\n",
            "3  self supervised multimodal versatile networks ...  ...      5.0\n",
            "4  self supervised multimodal versatile networks ...  ...      2.0\n",
            "5  self supervised multimodal versatile networks ...  ...      3.0\n",
            "\n",
            "[26 rows x 8 columns]\n",
            "topic:  benchmarking deep inverse models time neural adjoint method neurips id_= 3\n",
            "1 . Benchmarking Deep Inverse Models over time, and the Neural ... https://papers.nips.cc/paper/2020/hash/007ff380ee5ac49ffc34442f5c2a2b86-Abstract.html\n",
            "**********************************************\n",
            "2 . Benchmarking Deep Inverse Models ... - Review for NeurIPS paper https://papers.nips.cc/paper/2020/file/007ff380ee5ac49ffc34442f5c2a2b86-Review.html\n",
            "**********************************************\n",
            "3 . Supplementary material: Benchmarking Deep Inverse Models over ... https://papers.nips.cc/paper/2020/file/007ff380ee5ac49ffc34442f5c2a2b86-Supplemental.pdf\n",
            "example.pdf\n",
            "\n",
            "3 . Benchmarking Deep Inverse Models ... - Review for NeurIPS paper https://papers.nips.cc/paper/2020/file/007ff380ee5ac49ffc34442f5c2a2b86-MetaReview.html\n",
            "**********************************************\n",
            "4 . Advances in Neural Information Processing Systems 33 (NeurIPS ... https://papers.nips.cc/paper/2020\n",
            "**********************************************\n",
            "5 . Author Response for Paper 6449 We thank the reviewers for their ... https://papers.nips.cc/paper/2020/file/007ff380ee5ac49ffc34442f5c2a2b86-AuthorFeedback.pdf\n",
            "example.pdf\n",
            "\n",
            "5 . On Second Order Behaviour in Augmented Neural ODEs https://papers.nips.cc/paper/2020/file/418db2ea5d227a9ea8db8e5357ca2084-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Neural Ordinary Differential Equations (NODEs) are a new class of models that\n",
            "transform data continuously through inﬁnite-depth architectures. The continuous\n",
            "nature of NODEs has made them particularly suitable for learning the dynamics\n",
            "of complex physical systems. While previous work has mostly been focused on\n",
            "ﬁrst order ODEs, the dynamics of many systems, especially in classical physics,\n",
            "are governed by second order laws. In this work, we consider Second Order\n",
            "Neural ODEs (SONODEs). We show how the adjoint sensitivity method can be\n",
            "extended to SONODEs and prove that the optimisation of a ﬁrst order coupled\n",
            "ODE is equivalent and computationally more efﬁcient. Furthermore, we extend the\n",
            "theoretical understanding of the broader class of Augmented NODEs (ANODEs)\n",
            "by showing they can also learn higher order dynamics with a minimal number\n",
            "of augmented dimensions, but at the cost of interpretability. This indicates that\n",
            "the advantages of ANODEs go beyond the extra space offered by the augmented\n",
            "dimensions, as originally thought. Finally, we compare SONODEs and ANODEs\n",
            "on synthetic and real dynamical systems and demonstrate that the inductive biases\n",
            "of the former generally result in faster training and better performance.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "6 . Supplemental https://papers.nips.cc/paper/2020/file/766d856ef1a6b02f93d894415e6bfa0e-Supplemental.pdf\n",
            "example.pdf\n",
            "\n",
            "6 . A Flexible Framework for Designing Trainable Priors with Adaptive ... https://papers.nips.cc/paper/2020/file/b4edda67f0f57e218a8e766927e3e5c5-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "We introduce a general framework for designing and training neural network\n",
            "layers whose forward passes can be interpreted as solving non-smooth convex\n",
            "optimization problems, and whose architectures are derived from an optimization\n",
            "algorithm. We focus on convex games, solved by local agents represented by the\n",
            "nodes of a graph and interacting through regularization functions. This approach\n",
            "is appealing for solving imaging problems, as it allows the use of classical image\n",
            "priors within deep models that are trainable end to end. The priors used in this\n",
            "presentation include variants of total variation, Laplacian regularization, bilateral\n",
            "ﬁltering, sparse coding on learned dictionaries, and non-local self similarities.\n",
            "Our models are fully interpretable as well as parameter and data efﬁcient. Our\n",
            "experiments demonstrate their effectiveness on a large diversity of tasks ranging\n",
            "from image denoising and compressed sensing for fMRI to dense stereo matching.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "7 . JAX, M.D. https://papers.nips.cc/paper/2020/file/83d3d4b6c9579515e1679aca8cbc8033-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "We introduce JAX MD, a software package for performing differentiable physics\n",
            "simulations with a focus on molecular dynamics. JAX MD includes a number\n",
            "of physics simulation environments, as well as interaction potentials and neural\n",
            "networks that can be integrated into these environments without writing any addi-\n",
            "tional code. Since the simulations themselves are differentiable functions, entire\n",
            "trajectories can be differentiated to perform meta-optimization. These features are\n",
            "built on primitive operations, such as spatial partitioning, that allow simulations to\n",
            "scale to hundreds-of-thousands of particles on a single GPU. These primitives are\n",
            "ﬂexible enough that they can be used to scale up workloads outside of molecular\n",
            "dynamics. We present several examples that highlight the features of JAX MD\n",
            "including: integration of graph neural networks into traditional simulations, meta-\n",
            "optimization through minimization of particle packings, and a multi-agent ﬂocking\n",
            "simulation. JAX MD is available at www.github.com/google/jax-md.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "data:                                                topic  ...                                                url\n",
            "0  benchmarking deep inverse models time neural a...  ...  https://papers.nips.cc/paper/2020/hash/007ff38...\n",
            "1  benchmarking deep inverse models time neural a...  ...  https://papers.nips.cc/paper/2020/file/007ff38...\n",
            "2  benchmarking deep inverse models time neural a...  ...  https://papers.nips.cc/paper/2020/file/007ff38...\n",
            "3  benchmarking deep inverse models time neural a...  ...                  https://papers.nips.cc/paper/2020\n",
            "4  benchmarking deep inverse models time neural a...  ...  https://papers.nips.cc/paper/2020/file/418db2e...\n",
            "5  benchmarking deep inverse models time neural a...  ...  https://papers.nips.cc/paper/2020/file/b4edda6...\n",
            "6  benchmarking deep inverse models time neural a...  ...  https://papers.nips.cc/paper/2020/file/83d3d4b...\n",
            "\n",
            "[7 rows x 4 columns]\n",
            "**********************************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                                               topic  ... similarity_score\n",
            "0  benchmarking deep inverse models time neural a...  ...         0.961588\n",
            "1  benchmarking deep inverse models time neural a...  ...         0.966438\n",
            "2  benchmarking deep inverse models time neural a...  ...         0.966165\n",
            "3  benchmarking deep inverse models time neural a...  ...         0.965975\n",
            "4  benchmarking deep inverse models time neural a...  ...         0.961224\n",
            "5  benchmarking deep inverse models time neural a...  ...         0.962293\n",
            "6  benchmarking deep inverse models time neural a...  ...         0.966740\n",
            "\n",
            "[7 rows x 5 columns]\n",
            "df_final after rank=                                                topic  ... rank\n",
            "0  benchmarking deep inverse models time neural a...  ...  6.0\n",
            "1  benchmarking deep inverse models time neural a...  ...  2.0\n",
            "2  benchmarking deep inverse models time neural a...  ...  3.0\n",
            "3  benchmarking deep inverse models time neural a...  ...  4.0\n",
            "4  benchmarking deep inverse models time neural a...  ...  7.0\n",
            "5  benchmarking deep inverse models time neural a...  ...  5.0\n",
            "6  benchmarking deep inverse models time neural a...  ...  1.0\n",
            "\n",
            "[7 rows x 6 columns]\n",
            "0    Benchmarking Deep Inverse Models over time, an...\n",
            "1    NeurIPS 2020\\n\\nBenchmarking Deep Inverse Mode...\n",
            "2    NeurIPS 2020\\n\\nBenchmarking Deep Inverse Mode...\n",
            "3    Book\\n\\nDo not remove: This comment is monitor...\n",
            "4    Abstract\\n\\nNeural Ordinary Differential Equat...\n",
            "5    Abstract\\n\\nWe introduce a general framework f...\n",
            "6    Abstract\\n\\nWe introduce JAX MD, a software pa...\n",
            "Name: text, dtype: object\n",
            "Benchmarking\n",
            "Deep\n",
            "Inverse\n",
            "Models\n",
            "over\n",
            "time\n",
            ",\n",
            "and\n",
            "the\n",
            "Neural-Adjoint\n",
            "method\n",
            "Part\n",
            "of\n",
            "Advances\n",
            "in\n",
            "Neural\n",
            "Information\n",
            "Processing\n",
            "Systems\n",
            "33\n",
            "(\n",
            "NeurIPS\n",
            "2020\n",
            ")\n",
            "Authors\n",
            "Simiao\n",
            "Ren\n",
            ",\n",
            "Willie\n",
            "Padilla\n",
            ",\n",
            "Jordan\n",
            "Malof\n",
            "Abstract\n",
            "We\n",
            "consider\n",
            "the\n",
            "task\n",
            "of\n",
            "solving\n",
            "generic\n",
            "inverse\n",
            "problems\n",
            ",\n",
            "where\n",
            "one\n",
            "wishes\n",
            "to\n",
            "determine\n",
            "the\n",
            "hidden\n",
            "parameters\n",
            "of\n",
            "a\n",
            "natural\n",
            "system\n",
            "that\n",
            "will\n",
            "give\n",
            "rise\n",
            "to\n",
            "a\n",
            "particular\n",
            "set\n",
            "of\n",
            "measurements\n",
            ".\n",
            "Recently\n",
            "many\n",
            "new\n",
            "approaches\n",
            "based\n",
            "upon\n",
            "deep\n",
            "learning\n",
            "have\n",
            "arisen\n",
            ",\n",
            "generating\n",
            "promising\n",
            "results\n",
            ".\n",
            "We\n",
            "conceptualize\n",
            "these\n",
            "models\n",
            "as\n",
            "different\n",
            "schemes\n",
            "for\n",
            "efficiently\n",
            ",\n",
            "but\n",
            "randomly\n",
            ",\n",
            "exploring\n",
            "the\n",
            "space\n",
            "of\n",
            "possible\n",
            "inverse\n",
            "solutions\n",
            ".\n",
            "As\n",
            "a\n",
            "result\n",
            ",\n",
            "the\n",
            "accuracy\n",
            "of\n",
            "each\n",
            "approach\n",
            "should\n",
            "be\n",
            "evaluated\n",
            "as\n",
            "a\n",
            "function\n",
            "of\n",
            "time\n",
            "rather\n",
            "than\n",
            "a\n",
            "single\n",
            "estimated\n",
            "solution\n",
            ",\n",
            "as\n",
            "is\n",
            "often\n",
            "done\n",
            "now\n",
            ".\n",
            "Using\n",
            "this\n",
            "metric\n",
            ",\n",
            "we\n",
            "compare\n",
            "several\n",
            "state-of-the-art\n",
            "inverse\n",
            "modeling\n",
            "approaches\n",
            "on\n",
            "four\n",
            "benchmark\n",
            "tasks\n",
            ":\n",
            "two\n",
            "existing\n",
            "tasks\n",
            ",\n",
            "a\n",
            "new\n",
            "2-dimensional\n",
            "sinusoid\n",
            "task\n",
            ",\n",
            "and\n",
            "a\n",
            "challenging\n",
            "modern\n",
            "task\n",
            "of\n",
            "meta-material\n",
            "design\n",
            ".\n",
            "Finally\n",
            ",\n",
            "inspired\n",
            "by\n",
            "our\n",
            "conception\n",
            "of\n",
            "the\n",
            "inverse\n",
            "problem\n",
            ",\n",
            "we\n",
            "explore\n",
            "a\n",
            "simple\n",
            "solution\n",
            "that\n",
            "uses\n",
            "a\n",
            "deep\n",
            "neural\n",
            "network\n",
            "as\n",
            "a\n",
            "surrogate\n",
            "(\n",
            "i.e.\n",
            ",\n",
            "approximation\n",
            ")\n",
            "for\n",
            "the\n",
            "forward\n",
            "model\n",
            ",\n",
            "and\n",
            "then\n",
            "uses\n",
            "backpropagation\n",
            "with\n",
            "respect\n",
            "to\n",
            "the\n",
            "model\n",
            "input\n",
            "to\n",
            "search\n",
            "for\n",
            "good\n",
            "inverse\n",
            "solutions\n",
            ".\n",
            "Variations\n",
            "of\n",
            "this\n",
            "approach\n",
            "-\n",
            "which\n",
            "we\n",
            "term\n",
            "the\n",
            "neural\n",
            "adjoint\n",
            "(\n",
            "NA\n",
            ")\n",
            "-\n",
            "have\n",
            "been\n",
            "explored\n",
            "recently\n",
            "on\n",
            "specific\n",
            "problems\n",
            ",\n",
            "and\n",
            "here\n",
            "we\n",
            "evaluate\n",
            "it\n",
            "comprehensively\n",
            "on\n",
            "our\n",
            "benchmark\n",
            ".\n",
            "We\n",
            "find\n",
            "that\n",
            "the\n",
            "addition\n",
            "of\n",
            "a\n",
            "simple\n",
            "novel\n",
            "loss\n",
            "term\n",
            "-\n",
            "which\n",
            "we\n",
            "term\n",
            "the\n",
            "boundary\n",
            "loss\n",
            "-\n",
            "dramatically\n",
            "improves\n",
            "the\n",
            "NA\n",
            "’\n",
            "s\n",
            "performance\n",
            ",\n",
            "and\n",
            "it\n",
            "consequentially\n",
            "achieves\n",
            "the\n",
            "best\n",
            "(\n",
            "or\n",
            "nearly\n",
            "best\n",
            ")\n",
            "performance\n",
            "in\n",
            "all\n",
            "of\n",
            "our\n",
            "benchmark\n",
            "scenarios\n",
            ".\n",
            "NeurIPS\n",
            "2020\n",
            "Benchmarking\n",
            "Deep\n",
            "Inverse\n",
            "Models\n",
            "over\n",
            "time\n",
            ",\n",
            "and\n",
            "the\n",
            "Neural-Adjoint\n",
            "method\n",
            "Review\n",
            "1\n",
            "Summary\n",
            "and\n",
            "Contributions\n",
            ":\n",
            "The\n",
            "paper\n",
            "considers\n",
            "deep\n",
            "learning\n",
            "for\n",
            "solving\n",
            "inverse\n",
            "problems\n",
            ".\n",
            "It\n",
            "compares\n",
            "existing\n",
            "approaches\n",
            "on\n",
            "several\n",
            "benchmark\n",
            "tasks\n",
            ",\n",
            "including\n",
            "one\n",
            "for\n",
            "metamaterial\n",
            "design\n",
            ".\n",
            "The\n",
            "paper\n",
            "proposes\n",
            "a\n",
            "``\n",
            "neural-adjoint\n",
            "''\n",
            "method\n",
            "which\n",
            "``\n",
            "uses\n",
            "a\n",
            "deep\n",
            "learning\n",
            "model\n",
            "to\n",
            "approximate\n",
            "the\n",
            "forward\n",
            "model\n",
            ",\n",
            "then\n",
            "uses\n",
            "backpropogation\n",
            "to\n",
            "search\n",
            "for\n",
            "good\n",
            "inverse\n",
            "solutions\n",
            "''\n",
            ".\n",
            "This\n",
            "method\n",
            "is\n",
            "demonstrated\n",
            "to\n",
            "have\n",
            "best\n",
            "or\n",
            "best-equal\n",
            "performance\n",
            "on\n",
            "most\n",
            "tasks\n",
            "as\n",
            "a\n",
            "function\n",
            "of\n",
            "number\n",
            "of\n",
            "inferences\n",
            ",\n",
            "at\n",
            "the\n",
            "cost\n",
            "of\n",
            "increased\n",
            "time\n",
            "per\n",
            "inference\n",
            ".\n",
            "Strengths\n",
            ":\n",
            "Comparing\n",
            "of\n",
            "a\n",
            "number\n",
            "of\n",
            "deep\n",
            "inverse\n",
            "models\n",
            "on\n",
            "a\n",
            "number\n",
            "of\n",
            "benchmarks\n",
            ",\n",
            "as\n",
            "a\n",
            "function\n",
            "of\n",
            "the\n",
            "number\n",
            "of\n",
            "proposed\n",
            "solutions\n",
            ",\n",
            "is\n",
            "great\n",
            "idea\n",
            ".\n",
            "The\n",
            "proposed\n",
            "``\n",
            "neural\n",
            "adjoint\n",
            "method\n",
            "''\n",
            "is\n",
            "a\n",
            "smart\n",
            "approach\n",
            "for\n",
            "inverse\n",
            "problems\n",
            "and\n",
            "the\n",
            "experimental\n",
            "evidence\n",
            "convincingly\n",
            "supports\n",
            "the\n",
            "superior\n",
            "performance\n",
            "of\n",
            "this\n",
            "to\n",
            "the\n",
            "other\n",
            "inverse\n",
            "problem\n",
            "models\n",
            "considered\n",
            ".\n",
            "Weaknesses\n",
            ":\n",
            "Given\n",
            "many\n",
            "of\n",
            "the\n",
            "benchmarks\n",
            "presented\n",
            "here\n",
            "were\n",
            "also\n",
            "presented\n",
            "in\n",
            "``\n",
            "Benchmarking\n",
            "invertible\n",
            "architectures\n",
            "on\n",
            "inverse\n",
            "problems\n",
            "''\n",
            ",\n",
            "the\n",
            "value\n",
            "of\n",
            "the\n",
            "benchmarks\n",
            "presented\n",
            "seems\n",
            "somewhat\n",
            "marginal\n",
            ".\n",
            "I\n",
            "have\n",
            "a\n",
            "concern\n",
            "about\n",
            "the\n",
            "paper\n",
            "'s\n",
            "presentation\n",
            "of\n",
            "the\n",
            "proposed\n",
            "``\n",
            "neural\n",
            "adjoint\n",
            "method\n",
            "''\n",
            ",\n",
            "which\n",
            "seems\n",
            "to\n",
            "me\n",
            "to\n",
            "be\n",
            "a\n",
            "straightforward\n",
            "application\n",
            "of\n",
            "techniques\n",
            "from\n",
            "NN\n",
            "surrogate-based\n",
            "/\n",
            "model-based\n",
            "optimization\n",
            "to\n",
            "inverse\n",
            "modeling\n",
            ".\n",
            "I\n",
            "discuss\n",
            "this\n",
            "concern\n",
            "in\n",
            "``\n",
            "relation\n",
            "to\n",
            "prior\n",
            "work\n",
            "''\n",
            "below\n",
            ".\n",
            "The\n",
            "metamaterial\n",
            "task\n",
            "is\n",
            "very\n",
            "interesting\n",
            ",\n",
            "and\n",
            "seems\n",
            "like\n",
            "a\n",
            "good\n",
            "benchmark\n",
            ":\n",
            "however\n",
            "this\n",
            "was\n",
            "proposed\n",
            "in\n",
            "a\n",
            "``\n",
            "Deep\n",
            "learning\n",
            "for\n",
            "accelerated\n",
            "all-dielectric\n",
            "metasurface\n",
            "design\n",
            "''\n",
            "and\n",
            "so\n",
            "can\n",
            "not\n",
            "be\n",
            "claimed\n",
            "as\n",
            "a\n",
            "contribution\n",
            "by\n",
            "the\n",
            "current\n",
            "paper\n",
            ".\n",
            "To\n",
            "the\n",
            "authors\n",
            ":\n",
            "does\n",
            "the\n",
            "current\n",
            "paper\n",
            "make\n",
            "a\n",
            "substantial\n",
            "novel\n",
            "contribution\n",
            ",\n",
            "beyond\n",
            "this\n",
            "prior\n",
            "work\n",
            ",\n",
            "to\n",
            "this\n",
            "task\n",
            "as\n",
            "a\n",
            "benchmark\n",
            "?\n",
            "Correctness\n",
            ":\n",
            "I\n",
            "believe\n",
            "the\n",
            "claims\n",
            "to\n",
            "be\n",
            "correct\n",
            ".\n",
            "I\n",
            "have\n",
            "not\n",
            "checked\n",
            "the\n",
            "code\n",
            "but\n",
            "the\n",
            "experimental\n",
            "design\n",
            "looks\n",
            "thorough\n",
            "and\n",
            "the\n",
            "experimental\n",
            "results\n",
            "look\n",
            "plausible\n",
            ".\n",
            "Clarity\n",
            ":\n",
            "The\n",
            "paper\n",
            "is\n",
            "well\n",
            "written\n",
            "and\n",
            "easy\n",
            "to\n",
            "read\n",
            ".\n",
            "Relation\n",
            "to\n",
            "Prior\n",
            "Work\n",
            ":\n",
            "``\n",
            "Inverse\n",
            "problems\n",
            "''\n",
            "can\n",
            "be\n",
            "framed\n",
            "as\n",
            "optimization\n",
            ",\n",
            "minimizing\n",
            "the\n",
            "loss\n",
            "L\n",
            "(\n",
            "x\n",
            ")\n",
            "where\n",
            "this\n",
            "loss\n",
            "is\n",
            "a\n",
            "distance\n",
            "between\n",
            "yhat\n",
            "=\n",
            "f\n",
            "(\n",
            "x\n",
            ")\n",
            "and\n",
            "the\n",
            "observations\n",
            "y\n",
            ".\n",
            "Thus\n",
            "I\n",
            "have\n",
            "a\n",
            "potential\n",
            "case\n",
            "with\n",
            "the\n",
            "paper\n",
            "'s\n",
            "presentation\n",
            "of\n",
            "the\n",
            "``\n",
            "neural\n",
            "adjoint\n",
            "''\n",
            "method\n",
            "as\n",
            "related\n",
            "to\n",
            "previous\n",
            "work\n",
            "There\n",
            "is\n",
            "lots\n",
            "of\n",
            "work\n",
            "on\n",
            "using\n",
            "NNs\n",
            "for\n",
            "model-based\n",
            "or\n",
            "surrogate-based\n",
            "optimization\n",
            ".\n",
            "Sometimes\n",
            "people\n",
            "model\n",
            "an\n",
            "objective\n",
            "function\n",
            "Jhat\n",
            "=\n",
            "ftheta\n",
            "(\n",
            "x\n",
            ")\n",
            ",\n",
            "and\n",
            "search\n",
            "(\n",
            "i.e\n",
            ".\n",
            "via\n",
            "gradient\n",
            "descent\n",
            ")\n",
            "for\n",
            "x\n",
            "*\n",
            "which\n",
            "minimizes\n",
            "Jhat\n",
            ":\n",
            "this\n",
            "is\n",
            "most\n",
            "common\n",
            "in\n",
            "Bayesian\n",
            "optimization\n",
            "(\n",
            "e.g\n",
            ".\n",
            "see\n",
            "``\n",
            "Scalable\n",
            "Bayesian\n",
            "optimization\n",
            "with\n",
            "neural\n",
            "networks\n",
            "''\n",
            ")\n",
            ".\n",
            "Sometimes\n",
            "people\n",
            "model\n",
            "an\n",
            "output\n",
            "yhat\n",
            "=\n",
            "ftheta\n",
            "(\n",
            "x\n",
            ")\n",
            ",\n",
            "and\n",
            "search\n",
            "(\n",
            "i.e\n",
            ".\n",
            "via\n",
            "gradient\n",
            "descent\n",
            ")\n",
            "for\n",
            "x\n",
            "*\n",
            "which\n",
            "minimizes\n",
            "J\n",
            "(\n",
            "yhat\n",
            ")\n",
            "where\n",
            "J\n",
            "is\n",
            "a\n",
            "known\n",
            "function\n",
            ":\n",
            "this\n",
            "is\n",
            "most\n",
            "common\n",
            "in\n",
            "surrogate-based\n",
            "optimization\n",
            ".\n",
            "The\n",
            "neural-adjoint\n",
            "method\n",
            "is\n",
            "clearly\n",
            "a\n",
            "special\n",
            "case\n",
            "of\n",
            "this\n",
            "latter\n",
            "scenario\n",
            ".\n",
            "See\n",
            ":\n",
            "-\n",
            "``\n",
            "Automatic\n",
            "Chemical\n",
            "Design\n",
            "Using\n",
            "a\n",
            "Data-Driven\n",
            "Continuous\n",
            "Representation\n",
            "of\n",
            "Molecules\n",
            "''\n",
            ",\n",
            "-\n",
            "``\n",
            "Multiscale\n",
            "topology\n",
            "optimization\n",
            "using\n",
            "neural\n",
            "network\n",
            "surrogate\n",
            "models\n",
            "''\n",
            ",\n",
            "-\n",
            "``\n",
            "Amortized\n",
            "Finite\n",
            "Element\n",
            "Analysis\n",
            "for\n",
            "Fast\n",
            "PDE-Constrained\n",
            "Optimization\n",
            "''\n",
            ",\n",
            "-\n",
            "``\n",
            "Conditioning\n",
            "by\n",
            "adaptive\n",
            "sampling\n",
            "for\n",
            "robust\n",
            "design\n",
            "''\n",
            ",\n",
            "-\n",
            "the\n",
            "surrogate-based\n",
            "optimization\n",
            "portions\n",
            "of\n",
            "``\n",
            "Algorithms\n",
            "for\n",
            "Optimization\n",
            "''\n",
            ".\n",
            "I\n",
            "think\n",
            "the\n",
            "framing\n",
            "of\n",
            "this\n",
            "method\n",
            "as\n",
            "novel\n",
            "and\n",
            "the\n",
            "introduction\n",
            "of\n",
            "a\n",
            "name\n",
            "for\n",
            "the\n",
            "method\n",
            "is\n",
            "inappropriate\n",
            "without\n",
            "significant\n",
            "methodological\n",
            "differences\n",
            "from\n",
            "prior\n",
            "work\n",
            ".\n",
            "I\n",
            "am\n",
            "far\n",
            "from\n",
            "an\n",
            "expert\n",
            "in\n",
            "these\n",
            "areas\n",
            "so\n",
            "may\n",
            "not\n",
            "have\n",
            "picked\n",
            "the\n",
            "best\n",
            "references\n",
            ".\n",
            "I\n",
            "do\n",
            "like\n",
            "the\n",
            "method\n",
            "itself\n",
            "of\n",
            "training\n",
            "a\n",
            "NN\n",
            "surrogate\n",
            "and\n",
            "finding\n",
            "the\n",
            "points\n",
            "which\n",
            "optimize\n",
            "the\n",
            "loss\n",
            "according\n",
            "to\n",
            "the\n",
            "surrogate\n",
            "(\n",
            "which\n",
            "has\n",
            "been\n",
            "demonstrated\n",
            "to\n",
            "be\n",
            "effective\n",
            "in\n",
            "these\n",
            "other\n",
            "problems\n",
            ")\n",
            ".\n",
            "The\n",
            "paper\n",
            "should\n",
            "clearly\n",
            "discuss\n",
            "the\n",
            "relation\n",
            "of\n",
            "the\n",
            "proposed\n",
            "method\n",
            "to\n",
            "other\n",
            "work\n",
            "in\n",
            "model-based\n",
            "optimization\n",
            "(\n",
            "making\n",
            "it\n",
            "clear\n",
            "that\n",
            "this\n",
            "is\n",
            "a\n",
            "direct\n",
            "application\n",
            "of\n",
            "NN\n",
            "surrogate\n",
            "modeling\n",
            "to\n",
            "the\n",
            "inverse\n",
            "modeling\n",
            "problem\n",
            ")\n",
            ".\n",
            "Possibly\n",
            "it\n",
            "should\n",
            "remove\n",
            "the\n",
            "``\n",
            "neural-adjoint\n",
            "''\n",
            "method\n",
            "branding\n",
            "as\n",
            "this\n",
            "branding\n",
            "is\n",
            "misleading\n",
            "in\n",
            "making\n",
            "the\n",
            "proposed\n",
            "method\n",
            "seem\n",
            "like\n",
            "a\n",
            "newly\n",
            "derived\n",
            "thing\n",
            ".\n",
            "The\n",
            "paper\n",
            "should\n",
            "also\n",
            "relate\n",
            "the\n",
            "techniques\n",
            "in\n",
            "section\n",
            "3.1\n",
            "to\n",
            "closely\n",
            "related\n",
            "techniques\n",
            "in\n",
            "safe\n",
            "exploration\n",
            "/\n",
            "safe\n",
            "Bayesian\n",
            "optimization\n",
            "(\n",
            "staying\n",
            "on\n",
            "the\n",
            "manifold\n",
            "of\n",
            "designs\n",
            ")\n",
            ".\n",
            "Reproducibility\n",
            ":\n",
            "Yes\n",
            "Additional\n",
            "Feedback\n",
            ":\n",
            "--\n",
            "-\n",
            "Update\n",
            "after\n",
            "rebuttal\n",
            ":\n",
            "Thanks\n",
            "for\n",
            "the\n",
            "effort\n",
            "you\n",
            "put\n",
            "into\n",
            "the\n",
            "response\n",
            ".\n",
            "I\n",
            "think\n",
            "if\n",
            "the\n",
            "boundary\n",
            "loss\n",
            "is\n",
            "a\n",
            "main\n",
            "contribution\n",
            "of\n",
            "the\n",
            "paper\n",
            ",\n",
            "there\n",
            "needs\n",
            "to\n",
            "be\n",
            "more\n",
            "insight\n",
            "into\n",
            "its\n",
            "design\n",
            ".\n",
            "Currently\n",
            "it\n",
            "looks\n",
            "quite\n",
            "ad-hoc\n",
            "(\n",
            "just\n",
            "a\n",
            "loss\n",
            "to\n",
            "force\n",
            "the\n",
            "x\n",
            "to\n",
            "be\n",
            "within\n",
            "2\n",
            "sigma\n",
            "of\n",
            "the\n",
            "mean\n",
            ")\n",
            "and\n",
            "it\n",
            "would\n",
            "be\n",
            "good\n",
            "to\n",
            "understand\n",
            "the\n",
            "effect\n",
            "of\n",
            "this\n",
            "on\n",
            "different\n",
            "datasets\n",
            ",\n",
            "how\n",
            "it\n",
            "varies\n",
            "with\n",
            "the\n",
            "number\n",
            "of\n",
            "sigma\n",
            "from\n",
            "the\n",
            "mean\n",
            ",\n",
            "hard/soft\n",
            "threshold\n",
            "etc\n",
            ".\n",
            "It\n",
            "'s\n",
            "worth\n",
            "noting\n",
            "that\n",
            "there\n",
            "is\n",
            "somewhat\n",
            "similar\n",
            "work\n",
            "on\n",
            "avoiding\n",
            "unrealistic\n",
            "x\n",
            "in\n",
            "surrogate-based\n",
            "optimization\n",
            ",\n",
            "albeit\n",
            "mostly\n",
            "in\n",
            "model-based\n",
            "RL\n",
            ":\n",
            "see\n",
            "model-ensemble\n",
            "TRPO\n",
            ",\n",
            "or\n",
            "model-predictive\n",
            "policy\n",
            "learning\n",
            "with\n",
            "uncertainty\n",
            "regularization\n",
            ".\n",
            "These\n",
            "seem\n",
            "to\n",
            "me\n",
            "to\n",
            "be\n",
            "more\n",
            "principled\n",
            ",\n",
            "in\n",
            "a\n",
            "sense\n",
            ",\n",
            "than\n",
            "using\n",
            "the\n",
            "mean\n",
            "and\n",
            "standard\n",
            "deviation\n",
            "of\n",
            "the\n",
            "training\n",
            "data\n",
            ".\n",
            "I\n",
            "appreciate\n",
            "the\n",
            "work\n",
            "and\n",
            "effort\n",
            "you\n",
            "put\n",
            "into\n",
            "benchmarking\n",
            "on\n",
            "a\n",
            "number\n",
            "of\n",
            "problems\n",
            "and\n",
            "I\n",
            "think\n",
            "this\n",
            "is\n",
            "of\n",
            "great\n",
            "value\n",
            ".\n",
            "I\n",
            "maintain\n",
            "my\n",
            "score\n",
            ",\n",
            "but\n",
            "I\n",
            "hope\n",
            "that\n",
            "if\n",
            "this\n",
            "is\n",
            "not\n",
            "accepted\n",
            "you\n",
            "will\n",
            "resubmit\n",
            "(\n",
            "e.g\n",
            ".\n",
            "to\n",
            "ICLR\n",
            ")\n",
            ",\n",
            "with\n",
            "a\n",
            "rewrite\n",
            "to\n",
            "adjust\n",
            "or\n",
            "remove\n",
            "the\n",
            "``\n",
            "neural\n",
            "adjoint\n",
            "''\n",
            "branding\n",
            "and\n",
            "position\n",
            "your\n",
            "work\n",
            "more\n",
            "clearly\n",
            "w.r.t\n",
            ".\n",
            "model-based\n",
            "optimization\n",
            ",\n",
            "and\n",
            "with\n",
            "more\n",
            "insight\n",
            "into\n",
            "the\n",
            "boundary\n",
            "loss\n",
            ",\n",
            "and\n",
            "understanding\n",
            "of\n",
            "this\n",
            "boundary\n",
            "loss\n",
            "vs\n",
            "other\n",
            "techniques\n",
            "in\n",
            "uncertainty-aware\n",
            "/\n",
            "safe\n",
            "/\n",
            "robust\n",
            "optimization\n",
            ".\n",
            "--\n",
            "-\n",
            "Review\n",
            "2\n",
            "Summary\n",
            "and\n",
            "Contributions\n",
            ":\n",
            "This\n",
            "paper\n",
            "proposes\n",
            "a\n",
            "new\n",
            "method\n",
            ",\n",
            "a\n",
            "new\n",
            "performance\n",
            "metric\n",
            ",\n",
            "and\n",
            "presents\n",
            "a\n",
            "benchmark\n",
            "evaluation\n",
            "on\n",
            "four\n",
            "tasks\n",
            "of\n",
            "inverse\n",
            "problems\n",
            ",\n",
            "where\n",
            "one\n",
            "of\n",
            "them\n",
            "is\n",
            "newly\n",
            "constructed\n",
            "in\n",
            "this\n",
            "paper\n",
            ".\n",
            "The\n",
            "contributions\n",
            "of\n",
            "this\n",
            "paper\n",
            "are\n",
            "three\n",
            "folds\n",
            ".\n",
            "-\n",
            "A\n",
            "simple\n",
            "yet\n",
            "strong\n",
            "method\n",
            "to\n",
            "inverse\n",
            "problems\n",
            ".\n",
            "-\n",
            "A\n",
            "new\n",
            "metric\n",
            "that\n",
            "characterizes\n",
            "the\n",
            "performance\n",
            "trade-off\n",
            "in\n",
            "terms\n",
            "of\n",
            "inference\n",
            "efficiency\n",
            ".\n",
            "-\n",
            "A\n",
            "new\n",
            "benchmark\n",
            "dataset\n",
            "constructed\n",
            "from\n",
            "training\n",
            "a\n",
            "network\n",
            "ensemble\n",
            "on\n",
            "40k\n",
            "examples\n",
            "to\n",
            "fit\n",
            "the\n",
            "simulator\n",
            "of\n",
            "meta-material\n",
            "design\n",
            ".\n",
            "Strengths\n",
            ":\n",
            "-\n",
            "The\n",
            "proposed\n",
            "inverse\n",
            "solver\n",
            "is\n",
            "simple\n",
            "yet\n",
            "accurate\n",
            ",\n",
            "which\n",
            "serves\n",
            "as\n",
            "a\n",
            "strong\n",
            "baseline\n",
            "method\n",
            "for\n",
            "future\n",
            "research\n",
            ".\n",
            "-\n",
            "The\n",
            "proposed\n",
            "evaluation\n",
            "metric\n",
            "looks\n",
            "reasonable\n",
            ".\n",
            "-\n",
            "The\n",
            "proposed\n",
            "benchmark\n",
            "evaluation\n",
            "looks\n",
            "fair\n",
            "and\n",
            "thorough\n",
            ",\n",
            "which\n",
            "builds\n",
            "a\n",
            "foundation\n",
            "for\n",
            "future\n",
            "research\n",
            ".\n",
            "Weaknesses\n",
            ":\n",
            "This\n",
            "paper\n",
            "focuses\n",
            "only\n",
            "on\n",
            "measuring\n",
            "the\n",
            "error\n",
            "of\n",
            "point\n",
            "estimates\n",
            "while\n",
            "lacking\n",
            "the\n",
            "error\n",
            "of\n",
            "the\n",
            "estimated\n",
            "“\n",
            "posterior\n",
            "probability\n",
            "distributions\n",
            ",\n",
            "”\n",
            "which\n",
            "has\n",
            "been\n",
            "done\n",
            "in\n",
            "[\n",
            "1,2\n",
            "]\n",
            ".\n",
            "Specifically\n",
            ",\n",
            "[\n",
            "1\n",
            "]\n",
            "used\n",
            "calibration\n",
            "error\n",
            ",\n",
            "and\n",
            "[\n",
            "2\n",
            "]\n",
            "used\n",
            "MMD\n",
            "as\n",
            "the\n",
            "distribution-based\n",
            "metric\n",
            ".\n",
            "In\n",
            "this\n",
            "paper\n",
            ",\n",
            "the\n",
            "“\n",
            "Inverse\n",
            "model\n",
            "performance\n",
            "metrics\n",
            "”\n",
            "subsection\n",
            "in\n",
            "Related\n",
            "Work\n",
            "(\n",
            "line\n",
            "102-106\n",
            ")\n",
            "only\n",
            "mentioned\n",
            "MSE\n",
            "of\n",
            "point\n",
            "estimates\n",
            ".\n",
            "Throughout\n",
            "the\n",
            "paper\n",
            ",\n",
            "the\n",
            "keyword\n",
            "“\n",
            "posterior\n",
            "”\n",
            "only\n",
            "appears\n",
            "once\n",
            "in\n",
            "Related\n",
            "Work\n",
            ".\n",
            "Since\n",
            "one\n",
            "of\n",
            "the\n",
            "focus\n",
            "of\n",
            "this\n",
            "paper\n",
            "is\n",
            "the\n",
            "evaluation\n",
            "metric\n",
            ",\n",
            "the\n",
            "lack\n",
            "of\n",
            "discussion\n",
            ",\n",
            "comparison\n",
            ",\n",
            "and\n",
            "experiments\n",
            "on\n",
            "distribution-based\n",
            "metrics\n",
            "pose\n",
            "a\n",
            "weakness\n",
            "in\n",
            "this\n",
            "paper\n",
            ".\n",
            "Section\n",
            "4\n",
            "can\n",
            "be\n",
            "improved\n",
            "in\n",
            "terms\n",
            "of\n",
            "technical\n",
            "writing\n",
            ".\n",
            "Specifically\n",
            ",\n",
            "I\n",
            "can\n",
            "not\n",
            "understand\n",
            "the\n",
            "four\n",
            "methods\n",
            "without\n",
            "reading\n",
            "their\n",
            "original\n",
            "papers\n",
            "since\n",
            "the\n",
            "technical\n",
            "description\n",
            "is\n",
            "not\n",
            "precise\n",
            "and\n",
            "clear\n",
            "enough\n",
            ".\n",
            "The\n",
            "main\n",
            "reason\n",
            "that\n",
            "I\n",
            "can\n",
            "not\n",
            "understand\n",
            "clearly\n",
            "is\n",
            "due\n",
            "to\n",
            "the\n",
            "somewhat\n",
            "simplified\n",
            "equations\n",
            "(\n",
            "Eq\n",
            ".\n",
            "6\n",
            ",\n",
            "7\n",
            ",\n",
            "8\n",
            ",\n",
            "and\n",
            "9\n",
            ")\n",
            ".\n",
            "For\n",
            "example\n",
            ",\n",
            "all\n",
            "the\n",
            "four\n",
            "equations\n",
            "start\n",
            "with\n",
            "“\n",
            "Loss\n",
            "”\n",
            "as\n",
            "their\n",
            "left-hand\n",
            "side\n",
            ",\n",
            "which\n",
            "is\n",
            "too\n",
            "simplified\n",
            "since\n",
            "there\n",
            "should\n",
            "have\n",
            "the\n",
            "model\n",
            "parameters\n",
            "to\n",
            "be\n",
            "learned\n",
            ".\n",
            "Furthermore\n",
            ",\n",
            "the\n",
            "actual\n",
            "expression\n",
            "of\n",
            "\\hat\n",
            "{\n",
            "x\n",
            "}\n",
            "or\n",
            "\\hat\n",
            "{\n",
            "y\n",
            "}\n",
            "in\n",
            "each\n",
            "method\n",
            "is\n",
            "not\n",
            "revealed\n",
            ".\n",
            "For\n",
            "readers\n",
            "not\n",
            "familiar\n",
            "with\n",
            "the\n",
            "area\n",
            ",\n",
            "such\n",
            "simplification\n",
            "may\n",
            "make\n",
            "the\n",
            "reading\n",
            "harder\n",
            ".\n",
            "In\n",
            "line\n",
            "94-96\n",
            ":\n",
            "“\n",
            "Earlier\n",
            "work\n",
            "on\n",
            "Mixture\n",
            "density\n",
            "networks\n",
            "[\n",
            "14\n",
            "]\n",
            "model\n",
            "the\n",
            "direct\n",
            "conditional\n",
            "distribution\n",
            "using\n",
            "gaussians\n",
            ".\n",
            "However\n",
            "due\n",
            "to\n",
            "low\n",
            "accuracy\n",
            "reported\n",
            "by\n",
            "[\n",
            "2\n",
            "]\n",
            ",\n",
            "we\n",
            "do\n",
            "not\n",
            "include\n",
            "comparison\n",
            "to\n",
            "this\n",
            "work.\n",
            "”\n",
            "I\n",
            "am\n",
            "not\n",
            "sure\n",
            "whether\n",
            "it\n",
            "is\n",
            "an\n",
            "adequate\n",
            "statement\n",
            ".\n",
            "In\n",
            "[\n",
            "2\n",
            "]\n",
            "’\n",
            "s\n",
            "Figure\n",
            "4\n",
            "and\n",
            "5\n",
            ",\n",
            "Mixture\n",
            "density\n",
            "networks\n",
            "(\n",
            "MDN\n",
            ")\n",
            "[\n",
            "14\n",
            "]\n",
            "performs\n",
            "quite\n",
            "competitively\n",
            ".\n",
            "I\n",
            "would\n",
            "like\n",
            "to\n",
            "know\n",
            "why\n",
            "this\n",
            "paper\n",
            "ignores\n",
            "the\n",
            "comparison\n",
            "with\n",
            "[\n",
            "14\n",
            "]\n",
            ".\n",
            "Correctness\n",
            ":\n",
            "Most\n",
            "of\n",
            "the\n",
            "claims\n",
            "and\n",
            "method\n",
            "in\n",
            "the\n",
            "paper\n",
            "looks\n",
            "correct\n",
            ".\n",
            "The\n",
            "empirical\n",
            "methodology\n",
            "looks\n",
            "correct\n",
            ",\n",
            "too\n",
            ".\n",
            "Clarity\n",
            ":\n",
            "The\n",
            "clarity\n",
            "of\n",
            "Section\n",
            "4\n",
            "has\n",
            "room\n",
            "for\n",
            "improvement\n",
            ".\n",
            "The\n",
            "overall\n",
            "clarity\n",
            "is\n",
            "only\n",
            "borderline\n",
            "to\n",
            "me\n",
            ".\n",
            "I\n",
            "can\n",
            "not\n",
            "have\n",
            "a\n",
            "clear\n",
            "picture\n",
            "after\n",
            "the\n",
            "first-round\n",
            "reading\n",
            ",\n",
            "though\n",
            "I\n",
            "finally\n",
            "understand\n",
            "most\n",
            "of\n",
            "the\n",
            "paper\n",
            "after\n",
            "the\n",
            "third-round\n",
            "reading\n",
            ".\n",
            "Relation\n",
            "to\n",
            "Prior\n",
            "Work\n",
            ":\n",
            "From\n",
            "my\n",
            "perspective\n",
            ",\n",
            "this\n",
            "paper\n",
            "looks\n",
            "closely\n",
            "related\n",
            "to\n",
            "[\n",
            "1\n",
            "]\n",
            "and\n",
            "[\n",
            "2\n",
            "]\n",
            ":\n",
            "[\n",
            "1\n",
            "]\n",
            "Analyzing\n",
            "inverse\n",
            "problems\n",
            "with\n",
            "invertible\n",
            "neural\n",
            "networks\n",
            ",\n",
            "ICLR19\n",
            ".\n",
            "[\n",
            "2\n",
            "]\n",
            "Benchmarking\n",
            "invertible\n",
            "architectures\n",
            "on\n",
            "inverse\n",
            "problems\n",
            ",\n",
            "ICML19\n",
            "workshop\n",
            ".\n",
            "The\n",
            "difference\n",
            "between\n",
            "this\n",
            "work\n",
            "and\n",
            "[\n",
            "1,2\n",
            "]\n",
            "can\n",
            "be\n",
            "seen\n",
            "from\n",
            "the\n",
            "contribution\n",
            "summary\n",
            "(\n",
            "line\n",
            "68-80\n",
            ")\n",
            "and\n",
            "the\n",
            "related\n",
            "work\n",
            "(\n",
            "line\n",
            "97-101\n",
            ")\n",
            ".\n",
            "Therefore\n",
            ",\n",
            "the\n",
            "relation\n",
            "to\n",
            "prior\n",
            "work\n",
            "is\n",
            "clear\n",
            "enough\n",
            "to\n",
            "me\n",
            ".\n",
            "Reproducibility\n",
            ":\n",
            "Yes\n",
            "Additional\n",
            "Feedback\n",
            ":\n",
            "The\n",
            "“\n",
            "Tandem\n",
            "model\n",
            "”\n",
            "subsection\n",
            "(\n",
            "start\n",
            "from\n",
            "line\n",
            "164\n",
            ")\n",
            "is\n",
            "hard\n",
            "to\n",
            "understand\n",
            ".\n",
            "Comparing\n",
            "with\n",
            "the\n",
            "supplementary\n",
            "material\n",
            ",\n",
            "are\n",
            "the\n",
            "role\n",
            "of\n",
            "“\n",
            "encoder\n",
            "”\n",
            "and\n",
            "“\n",
            "decoder\n",
            "”\n",
            "reversed\n",
            "in\n",
            "line\n",
            "164-166\n",
            "in\n",
            "the\n",
            "main\n",
            "paper\n",
            "?\n",
            "It\n",
            "would\n",
            "be\n",
            "better\n",
            "to\n",
            "explain\n",
            "in\n",
            "the\n",
            "caption\n",
            "of\n",
            "Figure\n",
            "3\n",
            "about\n",
            "why\n",
            "Figure\n",
            "3\n",
            "(\n",
            "d\n",
            ")\n",
            "has\n",
            "no\n",
            "yellow\n",
            "line\n",
            "(\n",
            "INN\n",
            ")\n",
            ".\n",
            "I\n",
            "know\n",
            "that\n",
            "the\n",
            "supplementary\n",
            "material\n",
            "(\n",
            "line\n",
            "151\n",
            ")\n",
            "has\n",
            "mentioned\n",
            "that\n",
            ".\n",
            "It\n",
            "is\n",
            "better\n",
            "to\n",
            "cite\n",
            "[\n",
            "1\n",
            "]\n",
            "as\n",
            "an\n",
            "ICLR19\n",
            "paper\n",
            ",\n",
            "not\n",
            "arXiv\n",
            ".\n",
            "Similarly\n",
            ",\n",
            "[\n",
            "2\n",
            "]\n",
            "should\n",
            "be\n",
            "cited\n",
            "as\n",
            "an\n",
            "ICML19\n",
            "workshop\n",
            "paper\n",
            ".\n",
            "Current\n",
            "citation\n",
            "makes\n",
            "it\n",
            "look\n",
            "like\n",
            "a\n",
            "conference\n",
            "paper\n",
            ".\n",
            "In\n",
            "the\n",
            "supplementary\n",
            "material\n",
            ",\n",
            "“\n",
            "Parameters\n",
            "”\n",
            "in\n",
            "Table\n",
            "2\n",
            "should\n",
            "be\n",
            "called\n",
            "“\n",
            "Hyperparameters.\n",
            "”\n",
            "In\n",
            "the\n",
            "supplementary\n",
            "material\n",
            ",\n",
            "I\n",
            "can\n",
            "not\n",
            "understand\n",
            "how\n",
            "to\n",
            "define\n",
            "the\n",
            "performance\n",
            "when\n",
            "T=0\n",
            "(\n",
            "subsection\n",
            "6.1\n",
            ")\n",
            ".\n",
            "It\n",
            "would\n",
            "be\n",
            "better\n",
            "to\n",
            "explain\n",
            "clearly\n",
            "how\n",
            "each\n",
            "method\n",
            "is\n",
            "applied\n",
            "with\n",
            "T=0\n",
            ".\n",
            "In\n",
            "the\n",
            "supplementary\n",
            "material\n",
            ",\n",
            "Figure\n",
            "3\n",
            "is\n",
            "hard\n",
            "to\n",
            "understand\n",
            ".\n",
            "Why\n",
            "the\n",
            "upper-left\n",
            "of\n",
            "the\n",
            "left\n",
            "subfigure\n",
            "is\n",
            "white\n",
            "?\n",
            "Why\n",
            "the\n",
            "right\n",
            "of\n",
            "the\n",
            "middle\n",
            "subfigure\n",
            "represent\n",
            "x\n",
            ",\n",
            "not\n",
            "\\hat\n",
            "{\n",
            "x\n",
            "}\n",
            "?\n",
            "Why\n",
            "the\n",
            "upper-left\n",
            "of\n",
            "the\n",
            "middle\n",
            "subfigure\n",
            "is\n",
            "y\n",
            ",\n",
            "not\n",
            "y_\n",
            "{\n",
            "gt\n",
            "}\n",
            "?\n",
            "Typos\n",
            ":\n",
            "Main\n",
            "paper\n",
            "line\n",
            "128\n",
            ":\n",
            "“\n",
            "be\n",
            "a\n",
            "our\n",
            "”\n",
            "Main\n",
            "paper\n",
            "line\n",
            "167-168\n",
            ":\n",
            "“\n",
            "but\n",
            "we\n",
            "found\n",
            "that\n",
            "adding\n",
            "in\n",
            "our\n",
            "boundary\n",
            "loss\n",
            "(\n",
            "see\n",
            "3.1\n",
            ")\n",
            ",\n",
            "”\n",
            "Main\n",
            "paper\n",
            "line\n",
            "246\n",
            ":\n",
            "“\n",
            "found\n",
            "found\n",
            "”\n",
            "Supplementary\n",
            "material\n",
            "line\n",
            "95\n",
            ":\n",
            "“\n",
            "from\n",
            "from\n",
            "”\n",
            "========\n",
            "post\n",
            "rebuttal\n",
            "========\n",
            "Thanks\n",
            "for\n",
            "the\n",
            "rebuttal\n",
            ".\n",
            "Table\n",
            "1\n",
            "in\n",
            "the\n",
            "rebuttal\n",
            "well\n",
            "addressed\n",
            "my\n",
            "first\n",
            "concern\n",
            "in\n",
            "my\n",
            "Weaknesses\n",
            "session\n",
            ".\n",
            "My\n",
            "2nd\n",
            "concern\n",
            "(\n",
            "about\n",
            "writing\n",
            ")\n",
            "is\n",
            "not\n",
            "mentioned\n",
            "in\n",
            "rebuttal\n",
            ",\n",
            "which\n",
            "I\n",
            "can\n",
            "understand\n",
            "it\n",
            "is\n",
            "due\n",
            "to\n",
            "space\n",
            "limit\n",
            ".\n",
            "My\n",
            "3rd\n",
            "concern\n",
            "is\n",
            "addressed\n",
            "and\n",
            "I\n",
            "can\n",
            "understand\n",
            "your\n",
            "situation\n",
            ".\n",
            "I\n",
            "really\n",
            "appreciate\n",
            "the\n",
            "author\n",
            "response\n",
            ",\n",
            "especially\n",
            "Table\n",
            "1\n",
            ".\n",
            "However\n",
            ",\n",
            "after\n",
            "reading\n",
            "all\n",
            "the\n",
            "reviews\n",
            "and\n",
            "the\n",
            "rebuttal\n",
            ",\n",
            "I\n",
            "am\n",
            "afraid\n",
            "that\n",
            "I\n",
            "can\n",
            "not\n",
            "give\n",
            "an\n",
            "overall\n",
            "score\n",
            "of\n",
            "7\n",
            "(\n",
            "a\n",
            "good\n",
            "submission\n",
            ",\n",
            "accept\n",
            ")\n",
            "because\n",
            "(\n",
            "1\n",
            ")\n",
            "The\n",
            "writing\n",
            "of\n",
            "the\n",
            "technical\n",
            "methods\n",
            "(\n",
            "as\n",
            "my\n",
            "second\n",
            "concern\n",
            ")\n",
            "is\n",
            "not\n",
            "ready\n",
            "to\n",
            "me\n",
            ".\n",
            "(\n",
            "2\n",
            ")\n",
            "As\n",
            "mentioned\n",
            "by\n",
            "R1\n",
            ",\n",
            "it\n",
            "seems\n",
            "that\n",
            "this\n",
            "work\n",
            "is\n",
            "somewhat\n",
            "similar\n",
            "to\n",
            "some\n",
            "particular\n",
            "works\n",
            ",\n",
            "and\n",
            "a\n",
            "major\n",
            "revision\n",
            "of\n",
            "the\n",
            "introduction\n",
            "and\n",
            "related\n",
            "work\n",
            "seems\n",
            "to\n",
            "be\n",
            "required\n",
            "for\n",
            "clarifying\n",
            "and\n",
            "positioning\n",
            "this\n",
            "work\n",
            ".\n",
            "Overall\n",
            ",\n",
            "the\n",
            "main\n",
            "reason\n",
            "this\n",
            "paper\n",
            "is\n",
            "not\n",
            "ready\n",
            "to\n",
            "me\n",
            "is\n",
            "mostly\n",
            "about\n",
            "writing\n",
            ".\n",
            "Review\n",
            "3\n",
            "Summary\n",
            "and\n",
            "Contributions\n",
            ":\n",
            "This\n",
            "paper\n",
            "proposes\n",
            "a\n",
            "neural\n",
            "inverse\n",
            "method\n",
            "that\n",
            "first\n",
            "learns\n",
            "a\n",
            "forward\n",
            "model\n",
            "and\n",
            "then\n",
            "uses\n",
            "SGD\n",
            "with\n",
            "random\n",
            "initializations\n",
            "to\n",
            "find\n",
            "the\n",
            "inverse\n",
            ".\n",
            "A\n",
            "boundary\n",
            "loss\n",
            "keeps\n",
            "the\n",
            "inverse\n",
            "solutions\n",
            "close\n",
            "to\n",
            "the\n",
            "training\n",
            "data\n",
            ".\n",
            "The\n",
            "authors\n",
            "propose\n",
            "an\n",
            "evaluation\n",
            "based\n",
            "on\n",
            "the\n",
            "number\n",
            "of\n",
            "samples\n",
            "taken\n",
            "and\n",
            "propose\n",
            "two\n",
            "new\n",
            "benchmark\n",
            "tasks\n",
            ".\n",
            "Strengths\n",
            ":\n",
            "This\n",
            "method\n",
            "can\n",
            "be\n",
            "effective\n",
            "at\n",
            "solving\n",
            "one-to-many\n",
            "inverse\n",
            "problems\n",
            "when\n",
            "the\n",
            "forward\n",
            "model\n",
            "can\n",
            "be\n",
            "well\n",
            "approximated\n",
            "by\n",
            "a\n",
            "neural\n",
            "net\n",
            ".\n",
            "This\n",
            "sidesteps\n",
            "the\n",
            "challenge\n",
            "of\n",
            "learning\n",
            "one-to-many\n",
            "inverse\n",
            "functions\n",
            ".\n",
            "Moreover\n",
            ",\n",
            "the\n",
            "inverse\n",
            "function\n",
            "doesn\n",
            "’\n",
            "t\n",
            "need\n",
            "to\n",
            "keep\n",
            "all\n",
            "its\n",
            "information\n",
            "in\n",
            "the\n",
            "weights\n",
            ",\n",
            "instead\n",
            "the\n",
            "method\n",
            "just\n",
            "requires\n",
            "a\n",
            "good\n",
            "approximation\n",
            "of\n",
            "the\n",
            "forward\n",
            "model\n",
            "and\n",
            "the\n",
            "remaining\n",
            "optimization\n",
            "can\n",
            "be\n",
            "done\n",
            "using\n",
            "SGD\n",
            ".\n",
            "Weaknesses\n",
            ":\n",
            "The\n",
            "boundary\n",
            "loss\n",
            "imposes\n",
            "a\n",
            "specific\n",
            "prior\n",
            "on\n",
            "the\n",
            "inverse\n",
            "solutions\n",
            "and\n",
            "assumes\n",
            "a\n",
            "specific\n",
            "data\n",
            "distribution\n",
            "—\n",
            "that\n",
            "the\n",
            "dimensions\n",
            "of\n",
            "x\n",
            "are\n",
            "independent\n",
            "and\n",
            "concentrated\n",
            "within\n",
            "2\n",
            "standard\n",
            "deviations\n",
            "of\n",
            "the\n",
            "mean\n",
            ".\n",
            "It\n",
            "would\n",
            "be\n",
            "hard\n",
            "to\n",
            "imagine\n",
            "this\n",
            "boundary\n",
            "loss\n",
            "working\n",
            "effectively\n",
            "in\n",
            "more\n",
            "complex\n",
            "data\n",
            "regimes\n",
            ".\n",
            "Moreover\n",
            ",\n",
            "this\n",
            "paper\n",
            "is\n",
            "primarily\n",
            "concerned\n",
            "with\n",
            "evaluating\n",
            "the\n",
            "re-simulation\n",
            "error\n",
            "with\n",
            "no\n",
            "evaluation\n",
            "of\n",
            "the\n",
            "actual\n",
            "inverses\n",
            ",\n",
            "$\n",
            "x\n",
            "$\n",
            ",\n",
            "such\n",
            "as\n",
            "whether\n",
            "the\n",
            "posterior\n",
            "$\n",
            "p\n",
            "(\n",
            "x|y\n",
            ")\n",
            "$\n",
            "can\n",
            "resemble\n",
            "that\n",
            "of\n",
            "the\n",
            "training\n",
            "distribution\n",
            ".\n",
            "Correctness\n",
            ":\n",
            "If\n",
            "re-simulation\n",
            "error\n",
            "is\n",
            "the\n",
            "only\n",
            "metric\n",
            "that\n",
            "you\n",
            "care\n",
            "about\n",
            ",\n",
            "then\n",
            "this\n",
            "method\n",
            "is\n",
            "generally\n",
            "correct\n",
            ".\n",
            "Approximating\n",
            "the\n",
            "forward\n",
            "model\n",
            "with\n",
            "a\n",
            "neural\n",
            "net\n",
            "and\n",
            "using\n",
            "SGD\n",
            "with\n",
            "random\n",
            "initializations\n",
            "can\n",
            "be\n",
            "a\n",
            "reasonable\n",
            "solution\n",
            ".\n",
            "The\n",
            "only\n",
            "concern\n",
            "is\n",
            "whether\n",
            "the\n",
            "boundary\n",
            "loss\n",
            "could\n",
            "result\n",
            "in\n",
            "a\n",
            "poor\n",
            "solution\n",
            ",\n",
            "i.e\n",
            ".\n",
            "you\n",
            "can\n",
            "imagine\n",
            "a\n",
            "$\n",
            "y\n",
            "$\n",
            "which\n",
            "requires\n",
            "some\n",
            "$\n",
            "x\n",
            "$\n",
            "outside\n",
            "of\n",
            "the\n",
            "$\n",
            "2\\sigma\n",
            "$\n",
            "range\n",
            "but\n",
            "boundary\n",
            "loss\n",
            "outweighs\n",
            "the\n",
            "L2\n",
            "loss\n",
            ".\n",
            "Clarity\n",
            ":\n",
            "The\n",
            "paper\n",
            "is\n",
            "generally\n",
            "well\n",
            "written\n",
            ".\n",
            "Some\n",
            "descriptions\n",
            "of\n",
            "the\n",
            "comparison\n",
            "models\n",
            "in\n",
            "section\n",
            "4\n",
            "have\n",
            "simplified\n",
            "losses\n",
            "and\n",
            "it\n",
            "’\n",
            "s\n",
            "not\n",
            "clear\n",
            "what\n",
            "the\n",
            "general\n",
            "loss\n",
            "is\n",
            "and\n",
            "what\n",
            "the\n",
            "learned\n",
            "parameters\n",
            "are\n",
            ".\n",
            "Relation\n",
            "to\n",
            "Prior\n",
            "Work\n",
            ":\n",
            "The\n",
            "paper\n",
            "offers\n",
            "a\n",
            "reasonable\n",
            "discussion\n",
            "of\n",
            "prior\n",
            "work\n",
            ".\n",
            "Reproducibility\n",
            ":\n",
            "Yes\n",
            "Additional\n",
            "Feedback\n",
            ":\n",
            "Update\n",
            "after\n",
            "author\n",
            "response\n",
            ":\n",
            "Generally\n",
            "I\n",
            "agree\n",
            "with\n",
            "the\n",
            "points\n",
            "made\n",
            "by\n",
            "reviewer\n",
            "1\n",
            "--\n",
            "in\n",
            "the\n",
            "context\n",
            "of\n",
            "the\n",
            "prior\n",
            "work\n",
            ",\n",
            "the\n",
            "boundary\n",
            "loss\n",
            "and\n",
            "evaluation\n",
            "are\n",
            "somewhat\n",
            "incremental\n",
            "contributions\n",
            ".\n",
            "I\n",
            "would\n",
            "have\n",
            "liked\n",
            "to\n",
            "see\n",
            "a\n",
            "more\n",
            "generalizable\n",
            "boundary\n",
            "loss/prior\n",
            "and\n",
            "more\n",
            "detailed\n",
            "evaluation\n",
            "that\n",
            "prior\n",
            "work\n",
            "has\n",
            "done\n",
            ".\n",
            "Review\n",
            "4\n",
            "Summary\n",
            "and\n",
            "Contributions\n",
            ":\n",
            "The\n",
            "paper\n",
            "has\n",
            "following\n",
            "contributions\n",
            ":\n",
            "1\n",
            ".\n",
            "A\n",
            "neural\n",
            "adjoint\n",
            "method\n",
            "for\n",
            "inverse\n",
            "problems\n",
            "which\n",
            "outperforms\n",
            "other\n",
            "strong\n",
            "baselines\n",
            "of\n",
            "[\n",
            "4,5\n",
            "]\n",
            ",\n",
            "cVAE\n",
            ",\n",
            "INN\n",
            "methods\n",
            ".\n",
            "Briefly\n",
            ",\n",
            "this\n",
            "method\n",
            "entails\n",
            "training\n",
            "a\n",
            "forward\n",
            "approximator\n",
            "``\n",
            "f\n",
            "''\n",
            "on\n",
            "data\n",
            "(\n",
            "x\n",
            ",\n",
            "y\n",
            ")\n",
            ",\n",
            "and\n",
            "then\n",
            "use\n",
            "of\n",
            "gradients\n",
            "for\n",
            "different\n",
            "initializations\n",
            "(\n",
            "x_0\n",
            ")\n",
            "to\n",
            "obtain\n",
            "the\n",
            "input\n",
            "x\n",
            "for\n",
            "given\n",
            "y\n",
            ".\n",
            "2\n",
            ".\n",
            "It\n",
            "proposes\n",
            "a\n",
            "benchmark\n",
            "with\n",
            "many\n",
            "old/new\n",
            "inverse\n",
            "problems\n",
            "and\n",
            "compares\n",
            "the\n",
            "proposed\n",
            "adjoint\n",
            "method\n",
            "to\n",
            "the\n",
            "baselines\n",
            ".\n",
            "They\n",
            "perform\n",
            "comparisons\n",
            "of\n",
            "inverse\n",
            "model\n",
            "with\n",
            "multiple\n",
            "samples\n",
            "(\n",
            "or\n",
            "over\n",
            "inference\n",
            "time\n",
            ")\n",
            ".\n",
            "with\n",
            "the\n",
            "``\n",
            "r_t\n",
            "''\n",
            "metric\n",
            ".\n",
            "Strengths\n",
            ":\n",
            "+\n",
            "Experimental\n",
            "evaluation\n",
            "is\n",
            "a\n",
            "strength\n",
            "of\n",
            "this\n",
            "work\n",
            ".\n",
            "The\n",
            "proposed\n",
            "method\n",
            "is\n",
            "compared\n",
            "to\n",
            "many\n",
            "relevant\n",
            "baselines\n",
            "in\n",
            "the\n",
            "literature\n",
            ".\n",
            "All\n",
            "the\n",
            "methods\n",
            "are\n",
            "evaluated\n",
            "on\n",
            "different\n",
            "inverse\n",
            "problems\n",
            "and\n",
            "their\n",
            "runtime\n",
            "and\n",
            "accuracy\n",
            "are\n",
            "measured\n",
            ".\n",
            "+\n",
            "The\n",
            "proposed\n",
            "neural\n",
            "adjoint\n",
            "method\n",
            "with\n",
            "enough\n",
            "inference\n",
            "budget\n",
            "obtains\n",
            "the\n",
            "best\n",
            "accuracy\n",
            "on\n",
            "the\n",
            "benchmark\n",
            ".\n",
            "Weaknesses\n",
            ":\n",
            "-\n",
            "Unlike\n",
            "Tandem\n",
            "Model\n",
            "[\n",
            "4,5\n",
            "]\n",
            "and\n",
            "cVAE\n",
            "based\n",
            "methods\n",
            "the\n",
            "proposed\n",
            "method\n",
            "uses\n",
            "gradient\n",
            "updates\n",
            "and\n",
            "therefore\n",
            "is\n",
            "slow\n",
            ".\n",
            "The\n",
            "authors\n",
            "acknowledge\n",
            "this\n",
            "in\n",
            "the\n",
            "manuscript\n",
            "and\n",
            "demonstrate\n",
            "study\n",
            "the\n",
            "method\n",
            "as\n",
            "a\n",
            "function\n",
            "of\n",
            "inference\n",
            "budget\n",
            ".\n",
            "-\n",
            "The\n",
            "sampling\n",
            "performed\n",
            "to\n",
            "obtain\n",
            "different\n",
            "initializations\n",
            "x_0\n",
            "seems\n",
            "important\n",
            "for\n",
            "the\n",
            "convergence\n",
            "to\n",
            "optimum\n",
            ".\n",
            "This\n",
            "is\n",
            "not\n",
            "experimentally\n",
            "evaluated\n",
            "carefully\n",
            "on\n",
            "the\n",
            "proposed\n",
            "benchmarks\n",
            ",\n",
            "except\n",
            "for\n",
            "Tab\n",
            ".\n",
            "1\n",
            "in\n",
            "supplementary\n",
            "where\n",
            "it\n",
            "is\n",
            "compared\n",
            "to\n",
            "sampling\n",
            "from\n",
            "uniform\n",
            "distribution\n",
            ".\n",
            "Correctness\n",
            ":\n",
            "The\n",
            "contributions\n",
            "of\n",
            "the\n",
            "method\n",
            "in\n",
            "the\n",
            "form\n",
            "of\n",
            "a\n",
            "benchmark\n",
            "for\n",
            "inverse\n",
            "problems\n",
            "and\n",
            "the\n",
            "experimental\n",
            "evaluation\n",
            "of\n",
            "proposed\n",
            "NA\n",
            "method\n",
            "and\n",
            "other\n",
            "baselines\n",
            "cVAE\n",
            ",\n",
            "INN\n",
            ",\n",
            "[\n",
            "4,5\n",
            "]\n",
            "is\n",
            "technically\n",
            "correct\n",
            "and\n",
            "sound\n",
            ".\n",
            "Clarity\n",
            ":\n",
            "The\n",
            "paper\n",
            "is\n",
            "well\n",
            "written\n",
            "and\n",
            "easy\n",
            "to\n",
            "follow\n",
            ".\n",
            "Some\n",
            "important\n",
            "ablation\n",
            "results\n",
            "(\n",
            "Tab\n",
            ".\n",
            "1\n",
            ")\n",
            "are\n",
            "in\n",
            "supplementary\n",
            "and\n",
            "can\n",
            "be\n",
            "moved\n",
            "to\n",
            "the\n",
            "main\n",
            "paper\n",
            ".\n",
            "Relation\n",
            "to\n",
            "Prior\n",
            "Work\n",
            ":\n",
            "Prior\n",
            "work\n",
            "on\n",
            "inverse\n",
            "problems\n",
            "is\n",
            "discussed\n",
            "and\n",
            "included\n",
            "in\n",
            "the\n",
            "benchmark\n",
            "of\n",
            "the\n",
            "paper\n",
            ".\n",
            "Reproducibility\n",
            ":\n",
            "Yes\n",
            "NeurIPS\n",
            "2020\n",
            "Benchmarking\n",
            "Deep\n",
            "Inverse\n",
            "Models\n",
            "over\n",
            "time\n",
            ",\n",
            "and\n",
            "the\n",
            "Neural-Adjoint\n",
            "method\n",
            "Meta\n",
            "Review\n",
            "The\n",
            "reviewers\n",
            "all\n",
            "liked\n",
            "some\n",
            "aspects\n",
            "of\n",
            "the\n",
            "paper\n",
            ",\n",
            "agreed\n",
            "that\n",
            "the\n",
            "presentation\n",
            "of\n",
            "the\n",
            "technical\n",
            "part\n",
            "can\n",
            "be\n",
            "improved\n",
            "(\n",
            "e.g\n",
            "just\n",
            "spotted\n",
            "a\n",
            "missing\n",
            "^2\n",
            "in\n",
            "eq\n",
            "7\n",
            ")\n",
            "and\n",
            "that\n",
            "the\n",
            "main\n",
            "contributions\n",
            "are\n",
            "1\n",
            ")\n",
            "a\n",
            "heuristic\n",
            "(\n",
            "eq\n",
            "5\n",
            ")\n",
            "to\n",
            "regularise\n",
            "the\n",
            "inverse\n",
            "solutions\n",
            "to\n",
            "be\n",
            "close\n",
            "to\n",
            "the\n",
            "input\n",
            "data\n",
            "and\n",
            "2\n",
            ")\n",
            "the\n",
            "empirical\n",
            "evaluation\n",
            "suite\n",
            ".\n",
            "The\n",
            "presentation\n",
            "can\n",
            "(\n",
            "and\n",
            "should\n",
            ")\n",
            "of\n",
            "course\n",
            "be\n",
            "improved\n",
            "but\n",
            "it\n",
            "is\n",
            "not\n",
            "likely\n",
            "that\n",
            "the\n",
            "method\n",
            "will\n",
            "change\n",
            "if\n",
            "the\n",
            "paper\n",
            "is\n",
            "rejected\n",
            "now\n",
            "and\n",
            "resubmitted\n",
            "to\n",
            "another\n",
            "conference\n",
            ".\n",
            "Therefore\n",
            "acceptance\n",
            "is\n",
            "recommended\n",
            "together\n",
            "with\n",
            "a\n",
            "strong\n",
            "encouragement\n",
            "to\n",
            "rework\n",
            "the\n",
            "presentation\n",
            "for\n",
            "the\n",
            "final\n",
            "version\n",
            ".\n",
            "Book\n",
            "Do\n",
            "not\n",
            "remove\n",
            ":\n",
            "This\n",
            "comment\n",
            "is\n",
            "monitored\n",
            "to\n",
            "verify\n",
            "that\n",
            "the\n",
            "site\n",
            "is\n",
            "working\n",
            "properly\n",
            "Abstract\n",
            "Neural\n",
            "Ordinary\n",
            "Differential\n",
            "Equations\n",
            "(\n",
            "NODEs\n",
            ")\n",
            "are\n",
            "a\n",
            "new\n",
            "class\n",
            "of\n",
            "models\n",
            "that\n",
            "transform\n",
            "data\n",
            "continuously\n",
            "through\n",
            "inﬁnite-depth\n",
            "architectures\n",
            ".\n",
            "The\n",
            "continuous\n",
            "nature\n",
            "of\n",
            "NODEs\n",
            "has\n",
            "made\n",
            "them\n",
            "particularly\n",
            "suitable\n",
            "for\n",
            "learning\n",
            "the\n",
            "dynamics\n",
            "of\n",
            "complex\n",
            "physical\n",
            "systems\n",
            ".\n",
            "While\n",
            "previous\n",
            "work\n",
            "has\n",
            "mostly\n",
            "been\n",
            "focused\n",
            "on\n",
            "ﬁrst\n",
            "order\n",
            "ODEs\n",
            ",\n",
            "the\n",
            "dynamics\n",
            "of\n",
            "many\n",
            "systems\n",
            ",\n",
            "especially\n",
            "in\n",
            "classical\n",
            "physics\n",
            ",\n",
            "are\n",
            "governed\n",
            "by\n",
            "second\n",
            "order\n",
            "laws\n",
            ".\n",
            "In\n",
            "this\n",
            "work\n",
            ",\n",
            "we\n",
            "consider\n",
            "Second\n",
            "Order\n",
            "Neural\n",
            "ODEs\n",
            "(\n",
            "SONODEs\n",
            ")\n",
            ".\n",
            "We\n",
            "show\n",
            "how\n",
            "the\n",
            "adjoint\n",
            "sensitivity\n",
            "method\n",
            "can\n",
            "be\n",
            "extended\n",
            "to\n",
            "SONODEs\n",
            "and\n",
            "prove\n",
            "that\n",
            "the\n",
            "optimisation\n",
            "of\n",
            "a\n",
            "ﬁrst\n",
            "order\n",
            "coupled\n",
            "ODE\n",
            "is\n",
            "equivalent\n",
            "and\n",
            "computationally\n",
            "more\n",
            "efﬁcient\n",
            ".\n",
            "Furthermore\n",
            ",\n",
            "we\n",
            "extend\n",
            "the\n",
            "theoretical\n",
            "understanding\n",
            "of\n",
            "the\n",
            "broader\n",
            "class\n",
            "of\n",
            "Augmented\n",
            "NODEs\n",
            "(\n",
            "ANODEs\n",
            ")\n",
            "by\n",
            "showing\n",
            "they\n",
            "can\n",
            "also\n",
            "learn\n",
            "higher\n",
            "order\n",
            "dynamics\n",
            "with\n",
            "a\n",
            "minimal\n",
            "number\n",
            "of\n",
            "augmented\n",
            "dimensions\n",
            ",\n",
            "but\n",
            "at\n",
            "the\n",
            "cost\n",
            "of\n",
            "interpretability\n",
            ".\n",
            "This\n",
            "indicates\n",
            "that\n",
            "the\n",
            "advantages\n",
            "of\n",
            "ANODEs\n",
            "go\n",
            "beyond\n",
            "the\n",
            "extra\n",
            "space\n",
            "offered\n",
            "by\n",
            "the\n",
            "augmented\n",
            "dimensions\n",
            ",\n",
            "as\n",
            "originally\n",
            "thought\n",
            ".\n",
            "Finally\n",
            ",\n",
            "we\n",
            "compare\n",
            "SONODEs\n",
            "and\n",
            "ANODEs\n",
            "on\n",
            "synthetic\n",
            "and\n",
            "real\n",
            "dynamical\n",
            "systems\n",
            "and\n",
            "demonstrate\n",
            "that\n",
            "the\n",
            "inductive\n",
            "biases\n",
            "of\n",
            "the\n",
            "former\n",
            "generally\n",
            "result\n",
            "in\n",
            "faster\n",
            "training\n",
            "and\n",
            "better\n",
            "performance\n",
            ".\n",
            "1\n",
            "Abstract\n",
            "We\n",
            "introduce\n",
            "a\n",
            "general\n",
            "framework\n",
            "for\n",
            "designing\n",
            "and\n",
            "training\n",
            "neural\n",
            "network\n",
            "layers\n",
            "whose\n",
            "forward\n",
            "passes\n",
            "can\n",
            "be\n",
            "interpreted\n",
            "as\n",
            "solving\n",
            "non-smooth\n",
            "convex\n",
            "optimization\n",
            "problems\n",
            ",\n",
            "and\n",
            "whose\n",
            "architectures\n",
            "are\n",
            "derived\n",
            "from\n",
            "an\n",
            "optimization\n",
            "algorithm\n",
            ".\n",
            "We\n",
            "focus\n",
            "on\n",
            "convex\n",
            "games\n",
            ",\n",
            "solved\n",
            "by\n",
            "local\n",
            "agents\n",
            "represented\n",
            "by\n",
            "the\n",
            "nodes\n",
            "of\n",
            "a\n",
            "graph\n",
            "and\n",
            "interacting\n",
            "through\n",
            "regularization\n",
            "functions\n",
            ".\n",
            "This\n",
            "approach\n",
            "is\n",
            "appealing\n",
            "for\n",
            "solving\n",
            "imaging\n",
            "problems\n",
            ",\n",
            "as\n",
            "it\n",
            "allows\n",
            "the\n",
            "use\n",
            "of\n",
            "classical\n",
            "image\n",
            "priors\n",
            "within\n",
            "deep\n",
            "models\n",
            "that\n",
            "are\n",
            "trainable\n",
            "end\n",
            "to\n",
            "end\n",
            ".\n",
            "The\n",
            "priors\n",
            "used\n",
            "in\n",
            "this\n",
            "presentation\n",
            "include\n",
            "variants\n",
            "of\n",
            "total\n",
            "variation\n",
            ",\n",
            "Laplacian\n",
            "regularization\n",
            ",\n",
            "bilateral\n",
            "ﬁltering\n",
            ",\n",
            "sparse\n",
            "coding\n",
            "on\n",
            "learned\n",
            "dictionaries\n",
            ",\n",
            "and\n",
            "non-local\n",
            "self\n",
            "similarities\n",
            ".\n",
            "Our\n",
            "models\n",
            "are\n",
            "fully\n",
            "interpretable\n",
            "as\n",
            "well\n",
            "as\n",
            "parameter\n",
            "and\n",
            "data\n",
            "efﬁcient\n",
            ".\n",
            "Our\n",
            "experiments\n",
            "demonstrate\n",
            "their\n",
            "effectiveness\n",
            "on\n",
            "a\n",
            "large\n",
            "diversity\n",
            "of\n",
            "tasks\n",
            "ranging\n",
            "from\n",
            "image\n",
            "denoising\n",
            "and\n",
            "compressed\n",
            "sensing\n",
            "for\n",
            "fMRI\n",
            "to\n",
            "dense\n",
            "stereo\n",
            "matching\n",
            ".\n",
            "1\n",
            "Abstract\n",
            "We\n",
            "introduce\n",
            "JAX\n",
            "MD\n",
            ",\n",
            "a\n",
            "software\n",
            "package\n",
            "for\n",
            "performing\n",
            "differentiable\n",
            "physics\n",
            "simulations\n",
            "with\n",
            "a\n",
            "focus\n",
            "on\n",
            "molecular\n",
            "dynamics\n",
            ".\n",
            "JAX\n",
            "MD\n",
            "includes\n",
            "a\n",
            "number\n",
            "of\n",
            "physics\n",
            "simulation\n",
            "environments\n",
            ",\n",
            "as\n",
            "well\n",
            "as\n",
            "interaction\n",
            "potentials\n",
            "and\n",
            "neural\n",
            "networks\n",
            "that\n",
            "can\n",
            "be\n",
            "integrated\n",
            "into\n",
            "these\n",
            "environments\n",
            "without\n",
            "writing\n",
            "any\n",
            "addi-\n",
            "tional\n",
            "code\n",
            ".\n",
            "Since\n",
            "the\n",
            "simulations\n",
            "themselves\n",
            "are\n",
            "differentiable\n",
            "functions\n",
            ",\n",
            "entire\n",
            "trajectories\n",
            "can\n",
            "be\n",
            "differentiated\n",
            "to\n",
            "perform\n",
            "meta-optimization\n",
            ".\n",
            "These\n",
            "features\n",
            "are\n",
            "built\n",
            "on\n",
            "primitive\n",
            "operations\n",
            ",\n",
            "such\n",
            "as\n",
            "spatial\n",
            "partitioning\n",
            ",\n",
            "that\n",
            "allow\n",
            "simulations\n",
            "to\n",
            "scale\n",
            "to\n",
            "hundreds-of-thousands\n",
            "of\n",
            "particles\n",
            "on\n",
            "a\n",
            "single\n",
            "GPU\n",
            ".\n",
            "These\n",
            "primitives\n",
            "are\n",
            "ﬂexible\n",
            "enough\n",
            "that\n",
            "they\n",
            "can\n",
            "be\n",
            "used\n",
            "to\n",
            "scale\n",
            "up\n",
            "workloads\n",
            "outside\n",
            "of\n",
            "molecular\n",
            "dynamics\n",
            ".\n",
            "We\n",
            "present\n",
            "several\n",
            "examples\n",
            "that\n",
            "highlight\n",
            "the\n",
            "features\n",
            "of\n",
            "JAX\n",
            "MD\n",
            "including\n",
            ":\n",
            "integration\n",
            "of\n",
            "graph\n",
            "neural\n",
            "networks\n",
            "into\n",
            "traditional\n",
            "simulations\n",
            ",\n",
            "meta-\n",
            "optimization\n",
            "through\n",
            "minimization\n",
            "of\n",
            "particle\n",
            "packings\n",
            ",\n",
            "and\n",
            "a\n",
            "multi-agent\n",
            "ﬂocking\n",
            "simulation\n",
            ".\n",
            "JAX\n",
            "MD\n",
            "is\n",
            "available\n",
            "at\n",
            "www.github.com/google/jax-md\n",
            ".\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "df_output                                                topic  ... rank_lda\n",
            "0             graph similarity deep learning neurips  ...      6.0\n",
            "1             graph similarity deep learning neurips  ...     10.0\n",
            "2             graph similarity deep learning neurips  ...      2.0\n",
            "3             graph similarity deep learning neurips  ...      5.0\n",
            "4             graph similarity deep learning neurips  ...      1.0\n",
            "5             graph similarity deep learning neurips  ...      8.0\n",
            "6             graph similarity deep learning neurips  ...      4.0\n",
            "7             graph similarity deep learning neurips  ...      3.0\n",
            "8             graph similarity deep learning neurips  ...      7.0\n",
            "9             graph similarity deep learning neurips  ...      9.0\n",
            "0  unsupervised information theoretic perceptual ...  ...     10.0\n",
            "1  unsupervised information theoretic perceptual ...  ...      9.0\n",
            "2  unsupervised information theoretic perceptual ...  ...      8.0\n",
            "3  unsupervised information theoretic perceptual ...  ...      2.0\n",
            "4  unsupervised information theoretic perceptual ...  ...      3.0\n",
            "5  unsupervised information theoretic perceptual ...  ...      5.0\n",
            "6  unsupervised information theoretic perceptual ...  ...      4.0\n",
            "7  unsupervised information theoretic perceptual ...  ...      7.0\n",
            "8  unsupervised information theoretic perceptual ...  ...      1.0\n",
            "9  unsupervised information theoretic perceptual ...  ...      6.0\n",
            "0  self supervised multimodal versatile networks ...  ...      6.0\n",
            "1  self supervised multimodal versatile networks ...  ...      1.0\n",
            "2  self supervised multimodal versatile networks ...  ...      4.0\n",
            "3  self supervised multimodal versatile networks ...  ...      5.0\n",
            "4  self supervised multimodal versatile networks ...  ...      2.0\n",
            "5  self supervised multimodal versatile networks ...  ...      3.0\n",
            "0  benchmarking deep inverse models time neural a...  ...      4.0\n",
            "1  benchmarking deep inverse models time neural a...  ...      7.0\n",
            "2  benchmarking deep inverse models time neural a...  ...      2.0\n",
            "3  benchmarking deep inverse models time neural a...  ...      6.0\n",
            "4  benchmarking deep inverse models time neural a...  ...      3.0\n",
            "5  benchmarking deep inverse models time neural a...  ...      5.0\n",
            "6  benchmarking deep inverse models time neural a...  ...      1.0\n",
            "\n",
            "[33 rows x 8 columns]\n",
            "topic:  off policy evaluation learning external validity covariate shift neurips id_= 4\n",
            "1 . Off-Policy Evaluation and Learning for External Validity under a ... https://papers.nips.cc/paper/2020/file/0084ae4bc24c0795d1e6a4f58444d39b-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "We consider evaluating and training a new policy for the evaluation data by using\n",
            "the historical data obtained from a different policy. The goal of off-policy evalua-\n",
            "tion (OPE) is to estimate the expected reward of a new policy over the evaluation\n",
            "data, and that of off-policy learning (OPL) is to ﬁnd a new policy that maximizes\n",
            "the expected reward over the evaluation data. Although the standard OPE and\n",
            "OPL methods assume the same distribution of covariate between the historical\n",
            "and evaluation data, a covariate shift often exists in real-world applications, i.e.,\n",
            "the distribution of the covariate of the historical data is different from that of the\n",
            "evaluation data. In this paper, we derive the efﬁciency bound of an OPE estimator\n",
            "under a covariate shift. Then, we propose doubly robust and efﬁcient estimators\n",
            "for OPE and OPL under a covariate shift by using a nonparametric estimator of\n",
            "the density ratio between the historical and evaluation data distributions. We also\n",
            "discuss other possible estimators and compare their theoretical properties. Finally,\n",
            "we conduct experiments to conﬁrm the effectiveness of the proposed estimators.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "2 . Advances in Neural Information Processing Systems 33 (NeurIPS ... https://papers.nips.cc/paper/2020\n",
            "**********************************************\n",
            "3 . Fourier Sparse Leverage Scores and Approximate Kernel Learning https://papers.nips.cc/paper/2020/file/012d9fe15b2493f21902cd55603382ec-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "s-sparse functions of the form f (x) = (cid:80)s\n",
            "\n",
            "We prove new explicit upper bounds on the leverage scores of Fourier sparse\n",
            "functions under both the Gaussian and Laplace measures. In particular, we study\n",
            "j=1 ajeiλj x for coefﬁcients aj ∈ C\n",
            "and frequencies λj ∈ R. Bounding Fourier sparse leverage scores under various\n",
            "measures is of pure mathematical interest in approximation theory, and our work\n",
            "extends existing results for the uniform measure [Erd17, CP19a]. Practically, our\n",
            "bounds are motivated by two important applications in machine learning:\n",
            "1. Kernel Approximation. They yield a new random Fourier features algorithm\n",
            "for approximating Gaussian and Cauchy (rational quadratic) kernel matrices. For\n",
            "low-dimensional data, our method uses a near optimal number of features, and its\n",
            "runtime is polynomial in the statistical dimension of the approximated kernel matrix.\n",
            "It is the ﬁrst “oblivious sketching method” with this property for any kernel besides\n",
            "the polynomial kernel, resolving an open question of [AKM+17, AKK+20b].\n",
            "2. Active Learning. They can be used as non-uniform sampling distributions\n",
            "for robust active learning when data follows a Gaussian or Laplace distribution.\n",
            "Using the framework of [AKM+19], we provide essentially optimal results for\n",
            "bandlimited and multiband interpolation, and Gaussian process regression. These\n",
            "results generalize existing work that only applies to uniformly distributed data.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "4 . Fourier Sparse Leverage Scores and Approximate Kernel Learning https://papers.nips.cc/paper/2020/file/012d9fe15b2493f21902cd55603382ec-Supplemental.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "s-sparse functions of the form f (x) = (cid:80)s\n",
            "\n",
            "We prove new explicit upper bounds on the leverage scores of Fourier sparse\n",
            "functions under both the Gaussian and Laplace measures. In particular, we study\n",
            "j=1 ajeiλj x for coefﬁcients aj ∈ C\n",
            "and frequencies λj ∈ R. Bounding Fourier sparse leverage scores under various\n",
            "measures is of pure mathematical interest in approximation theory, and our work\n",
            "extends existing results for the uniform measure [Erd17, CP19a]. Practically, our\n",
            "bounds are motivated by two important applications in machine learning:\n",
            "1. Kernel Approximation. They yield a new random Fourier features algorithm\n",
            "for approximating Gaussian and Cauchy (rational quadratic) kernel matrices. For\n",
            "low-dimensional data, our method uses a near optimal number of features, and its\n",
            "runtime is polynomial in the statistical dimension of the approximated kernel matrix.\n",
            "It is the ﬁrst “oblivious sketching method” with this property for any kernel besides\n",
            "the polynomial kernel, resolving an open question of [AKM+17, AKK+20b].\n",
            "2. Active Learning. They can be used as non-uniform sampling distributions\n",
            "for robust active learning when data follows a Gaussian or Laplace distribution.\n",
            "Using the framework of [AKM+19], we provide essentially optimal results for\n",
            "bandlimited and multiband interpolation, and Gaussian process regression. These\n",
            "results generalize existing work that only applies to uniformly distributed data.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "5 . Recurrent Switching Dynamical Systems Models for Multiple ... https://papers.nips.cc/paper/2020/file/aa1f5f73327ba40d47ebce155e785aaf-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Modern recording techniques can generate large-scale measurements of multiple\n",
            "neural populations over extended time periods. However, it remains a challenge to\n",
            "model non-stationary interactions between high-dimensional populations of neu-\n",
            "rons. To tackle this challenge, we develop recurrent switching linear dynamical\n",
            "systems models for multiple populations. Here, each high-dimensional neural\n",
            "population is represented by a unique set of latent variables, which evolve dynam-\n",
            "ically in time. Populations interact with each other through this low-dimensional\n",
            "space. We allow the nature of these interactions to change over time by using a\n",
            "discrete set of dynamical states. Additionally, we parameterize these discrete state\n",
            "transition rules to capture which neural populations are responsible for switch-\n",
            "ing between interaction states. To ﬁt the model, we use variational expectation-\n",
            "maximization with a structured mean-ﬁeld approximation. After validating the\n",
            "model on simulations, we apply it to two different neural datasets: spiking activity\n",
            "from motor areas in a non-human primate, and calcium imaging from neurons in\n",
            "the nematode C. elegans. In both datasets, the model reveals behaviorally-relevant\n",
            "discrete states with unique inter-population interactions and different populations\n",
            "that predict transitioning between these states.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "data:                                                topic  ...                                                url\n",
            "0  off policy evaluation learning external validi...  ...  https://papers.nips.cc/paper/2020/file/0084ae4...\n",
            "1  off policy evaluation learning external validi...  ...                  https://papers.nips.cc/paper/2020\n",
            "2  off policy evaluation learning external validi...  ...  https://papers.nips.cc/paper/2020/file/012d9fe...\n",
            "3  off policy evaluation learning external validi...  ...  https://papers.nips.cc/paper/2020/file/012d9fe...\n",
            "4  off policy evaluation learning external validi...  ...  https://papers.nips.cc/paper/2020/file/aa1f5f7...\n",
            "\n",
            "[5 rows x 4 columns]\n",
            "**********************************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                                               topic  ... similarity_score\n",
            "0  off policy evaluation learning external validi...  ...         0.961221\n",
            "1  off policy evaluation learning external validi...  ...         0.965306\n",
            "2  off policy evaluation learning external validi...  ...         0.961443\n",
            "3  off policy evaluation learning external validi...  ...         0.961443\n",
            "4  off policy evaluation learning external validi...  ...         0.965760\n",
            "\n",
            "[5 rows x 5 columns]\n",
            "df_final after rank=                                                topic  ... rank\n",
            "0  off policy evaluation learning external validi...  ...  5.0\n",
            "1  off policy evaluation learning external validi...  ...  2.0\n",
            "2  off policy evaluation learning external validi...  ...  4.0\n",
            "3  off policy evaluation learning external validi...  ...  4.0\n",
            "4  off policy evaluation learning external validi...  ...  1.0\n",
            "\n",
            "[5 rows x 6 columns]\n",
            "0    Abstract\\n\\nWe consider evaluating and trainin...\n",
            "1    Book\\n\\nDo not remove: This comment is monitor...\n",
            "2    Abstract\\n\\ns-sparse functions of the form f (...\n",
            "3    Abstract\\n\\ns-sparse functions of the form f (...\n",
            "4    Abstract\\n\\nModern recording techniques can ge...\n",
            "Name: text, dtype: object\n",
            "Abstract\n",
            "We\n",
            "consider\n",
            "evaluating\n",
            "and\n",
            "training\n",
            "a\n",
            "new\n",
            "policy\n",
            "for\n",
            "the\n",
            "evaluation\n",
            "data\n",
            "by\n",
            "using\n",
            "the\n",
            "historical\n",
            "data\n",
            "obtained\n",
            "from\n",
            "a\n",
            "different\n",
            "policy\n",
            ".\n",
            "The\n",
            "goal\n",
            "of\n",
            "off-policy\n",
            "evalua-\n",
            "tion\n",
            "(\n",
            "OPE\n",
            ")\n",
            "is\n",
            "to\n",
            "estimate\n",
            "the\n",
            "expected\n",
            "reward\n",
            "of\n",
            "a\n",
            "new\n",
            "policy\n",
            "over\n",
            "the\n",
            "evaluation\n",
            "data\n",
            ",\n",
            "and\n",
            "that\n",
            "of\n",
            "off-policy\n",
            "learning\n",
            "(\n",
            "OPL\n",
            ")\n",
            "is\n",
            "to\n",
            "ﬁnd\n",
            "a\n",
            "new\n",
            "policy\n",
            "that\n",
            "maximizes\n",
            "the\n",
            "expected\n",
            "reward\n",
            "over\n",
            "the\n",
            "evaluation\n",
            "data\n",
            ".\n",
            "Although\n",
            "the\n",
            "standard\n",
            "OPE\n",
            "and\n",
            "OPL\n",
            "methods\n",
            "assume\n",
            "the\n",
            "same\n",
            "distribution\n",
            "of\n",
            "covariate\n",
            "between\n",
            "the\n",
            "historical\n",
            "and\n",
            "evaluation\n",
            "data\n",
            ",\n",
            "a\n",
            "covariate\n",
            "shift\n",
            "often\n",
            "exists\n",
            "in\n",
            "real-world\n",
            "applications\n",
            ",\n",
            "i.e.\n",
            ",\n",
            "the\n",
            "distribution\n",
            "of\n",
            "the\n",
            "covariate\n",
            "of\n",
            "the\n",
            "historical\n",
            "data\n",
            "is\n",
            "different\n",
            "from\n",
            "that\n",
            "of\n",
            "the\n",
            "evaluation\n",
            "data\n",
            ".\n",
            "In\n",
            "this\n",
            "paper\n",
            ",\n",
            "we\n",
            "derive\n",
            "the\n",
            "efﬁciency\n",
            "bound\n",
            "of\n",
            "an\n",
            "OPE\n",
            "estimator\n",
            "under\n",
            "a\n",
            "covariate\n",
            "shift\n",
            ".\n",
            "Then\n",
            ",\n",
            "we\n",
            "propose\n",
            "doubly\n",
            "robust\n",
            "and\n",
            "efﬁcient\n",
            "estimators\n",
            "for\n",
            "OPE\n",
            "and\n",
            "OPL\n",
            "under\n",
            "a\n",
            "covariate\n",
            "shift\n",
            "by\n",
            "using\n",
            "a\n",
            "nonparametric\n",
            "estimator\n",
            "of\n",
            "the\n",
            "density\n",
            "ratio\n",
            "between\n",
            "the\n",
            "historical\n",
            "and\n",
            "evaluation\n",
            "data\n",
            "distributions\n",
            ".\n",
            "We\n",
            "also\n",
            "discuss\n",
            "other\n",
            "possible\n",
            "estimators\n",
            "and\n",
            "compare\n",
            "their\n",
            "theoretical\n",
            "properties\n",
            ".\n",
            "Finally\n",
            ",\n",
            "we\n",
            "conduct\n",
            "experiments\n",
            "to\n",
            "conﬁrm\n",
            "the\n",
            "effectiveness\n",
            "of\n",
            "the\n",
            "proposed\n",
            "estimators\n",
            ".\n",
            "1\n",
            "Book\n",
            "Do\n",
            "not\n",
            "remove\n",
            ":\n",
            "This\n",
            "comment\n",
            "is\n",
            "monitored\n",
            "to\n",
            "verify\n",
            "that\n",
            "the\n",
            "site\n",
            "is\n",
            "working\n",
            "properly\n",
            "Abstract\n",
            "s-sparse\n",
            "functions\n",
            "of\n",
            "the\n",
            "form\n",
            "f\n",
            "(\n",
            "x\n",
            ")\n",
            "=\n",
            "(\n",
            "cid:80\n",
            ")\n",
            "s\n",
            "We\n",
            "prove\n",
            "new\n",
            "explicit\n",
            "upper\n",
            "bounds\n",
            "on\n",
            "the\n",
            "leverage\n",
            "scores\n",
            "of\n",
            "Fourier\n",
            "sparse\n",
            "functions\n",
            "under\n",
            "both\n",
            "the\n",
            "Gaussian\n",
            "and\n",
            "Laplace\n",
            "measures\n",
            ".\n",
            "In\n",
            "particular\n",
            ",\n",
            "we\n",
            "study\n",
            "j=1\n",
            "ajeiλj\n",
            "x\n",
            "for\n",
            "coefﬁcients\n",
            "aj\n",
            "∈\n",
            "C\n",
            "and\n",
            "frequencies\n",
            "λj\n",
            "∈\n",
            "R.\n",
            "Bounding\n",
            "Fourier\n",
            "sparse\n",
            "leverage\n",
            "scores\n",
            "under\n",
            "various\n",
            "measures\n",
            "is\n",
            "of\n",
            "pure\n",
            "mathematical\n",
            "interest\n",
            "in\n",
            "approximation\n",
            "theory\n",
            ",\n",
            "and\n",
            "our\n",
            "work\n",
            "extends\n",
            "existing\n",
            "results\n",
            "for\n",
            "the\n",
            "uniform\n",
            "measure\n",
            "[\n",
            "Erd17\n",
            ",\n",
            "CP19a\n",
            "]\n",
            ".\n",
            "Practically\n",
            ",\n",
            "our\n",
            "bounds\n",
            "are\n",
            "motivated\n",
            "by\n",
            "two\n",
            "important\n",
            "applications\n",
            "in\n",
            "machine\n",
            "learning\n",
            ":\n",
            "1\n",
            ".\n",
            "Kernel\n",
            "Approximation\n",
            ".\n",
            "They\n",
            "yield\n",
            "a\n",
            "new\n",
            "random\n",
            "Fourier\n",
            "features\n",
            "algorithm\n",
            "for\n",
            "approximating\n",
            "Gaussian\n",
            "and\n",
            "Cauchy\n",
            "(\n",
            "rational\n",
            "quadratic\n",
            ")\n",
            "kernel\n",
            "matrices\n",
            ".\n",
            "For\n",
            "low-dimensional\n",
            "data\n",
            ",\n",
            "our\n",
            "method\n",
            "uses\n",
            "a\n",
            "near\n",
            "optimal\n",
            "number\n",
            "of\n",
            "features\n",
            ",\n",
            "and\n",
            "its\n",
            "runtime\n",
            "is\n",
            "polynomial\n",
            "in\n",
            "the\n",
            "statistical\n",
            "dimension\n",
            "of\n",
            "the\n",
            "approximated\n",
            "kernel\n",
            "matrix\n",
            ".\n",
            "It\n",
            "is\n",
            "the\n",
            "ﬁrst\n",
            "“\n",
            "oblivious\n",
            "sketching\n",
            "method\n",
            "”\n",
            "with\n",
            "this\n",
            "property\n",
            "for\n",
            "any\n",
            "kernel\n",
            "besides\n",
            "the\n",
            "polynomial\n",
            "kernel\n",
            ",\n",
            "resolving\n",
            "an\n",
            "open\n",
            "question\n",
            "of\n",
            "[\n",
            "AKM+17\n",
            ",\n",
            "AKK+20b\n",
            "]\n",
            ".\n",
            "2\n",
            ".\n",
            "Active\n",
            "Learning\n",
            ".\n",
            "They\n",
            "can\n",
            "be\n",
            "used\n",
            "as\n",
            "non-uniform\n",
            "sampling\n",
            "distributions\n",
            "for\n",
            "robust\n",
            "active\n",
            "learning\n",
            "when\n",
            "data\n",
            "follows\n",
            "a\n",
            "Gaussian\n",
            "or\n",
            "Laplace\n",
            "distribution\n",
            ".\n",
            "Using\n",
            "the\n",
            "framework\n",
            "of\n",
            "[\n",
            "AKM+19\n",
            "]\n",
            ",\n",
            "we\n",
            "provide\n",
            "essentially\n",
            "optimal\n",
            "results\n",
            "for\n",
            "bandlimited\n",
            "and\n",
            "multiband\n",
            "interpolation\n",
            ",\n",
            "and\n",
            "Gaussian\n",
            "process\n",
            "regression\n",
            ".\n",
            "These\n",
            "results\n",
            "generalize\n",
            "existing\n",
            "work\n",
            "that\n",
            "only\n",
            "applies\n",
            "to\n",
            "uniformly\n",
            "distributed\n",
            "data\n",
            ".\n",
            "1\n",
            "Abstract\n",
            "s-sparse\n",
            "functions\n",
            "of\n",
            "the\n",
            "form\n",
            "f\n",
            "(\n",
            "x\n",
            ")\n",
            "=\n",
            "(\n",
            "cid:80\n",
            ")\n",
            "s\n",
            "We\n",
            "prove\n",
            "new\n",
            "explicit\n",
            "upper\n",
            "bounds\n",
            "on\n",
            "the\n",
            "leverage\n",
            "scores\n",
            "of\n",
            "Fourier\n",
            "sparse\n",
            "functions\n",
            "under\n",
            "both\n",
            "the\n",
            "Gaussian\n",
            "and\n",
            "Laplace\n",
            "measures\n",
            ".\n",
            "In\n",
            "particular\n",
            ",\n",
            "we\n",
            "study\n",
            "j=1\n",
            "ajeiλj\n",
            "x\n",
            "for\n",
            "coefﬁcients\n",
            "aj\n",
            "∈\n",
            "C\n",
            "and\n",
            "frequencies\n",
            "λj\n",
            "∈\n",
            "R.\n",
            "Bounding\n",
            "Fourier\n",
            "sparse\n",
            "leverage\n",
            "scores\n",
            "under\n",
            "various\n",
            "measures\n",
            "is\n",
            "of\n",
            "pure\n",
            "mathematical\n",
            "interest\n",
            "in\n",
            "approximation\n",
            "theory\n",
            ",\n",
            "and\n",
            "our\n",
            "work\n",
            "extends\n",
            "existing\n",
            "results\n",
            "for\n",
            "the\n",
            "uniform\n",
            "measure\n",
            "[\n",
            "Erd17\n",
            ",\n",
            "CP19a\n",
            "]\n",
            ".\n",
            "Practically\n",
            ",\n",
            "our\n",
            "bounds\n",
            "are\n",
            "motivated\n",
            "by\n",
            "two\n",
            "important\n",
            "applications\n",
            "in\n",
            "machine\n",
            "learning\n",
            ":\n",
            "1\n",
            ".\n",
            "Kernel\n",
            "Approximation\n",
            ".\n",
            "They\n",
            "yield\n",
            "a\n",
            "new\n",
            "random\n",
            "Fourier\n",
            "features\n",
            "algorithm\n",
            "for\n",
            "approximating\n",
            "Gaussian\n",
            "and\n",
            "Cauchy\n",
            "(\n",
            "rational\n",
            "quadratic\n",
            ")\n",
            "kernel\n",
            "matrices\n",
            ".\n",
            "For\n",
            "low-dimensional\n",
            "data\n",
            ",\n",
            "our\n",
            "method\n",
            "uses\n",
            "a\n",
            "near\n",
            "optimal\n",
            "number\n",
            "of\n",
            "features\n",
            ",\n",
            "and\n",
            "its\n",
            "runtime\n",
            "is\n",
            "polynomial\n",
            "in\n",
            "the\n",
            "statistical\n",
            "dimension\n",
            "of\n",
            "the\n",
            "approximated\n",
            "kernel\n",
            "matrix\n",
            ".\n",
            "It\n",
            "is\n",
            "the\n",
            "ﬁrst\n",
            "“\n",
            "oblivious\n",
            "sketching\n",
            "method\n",
            "”\n",
            "with\n",
            "this\n",
            "property\n",
            "for\n",
            "any\n",
            "kernel\n",
            "besides\n",
            "the\n",
            "polynomial\n",
            "kernel\n",
            ",\n",
            "resolving\n",
            "an\n",
            "open\n",
            "question\n",
            "of\n",
            "[\n",
            "AKM+17\n",
            ",\n",
            "AKK+20b\n",
            "]\n",
            ".\n",
            "2\n",
            ".\n",
            "Active\n",
            "Learning\n",
            ".\n",
            "They\n",
            "can\n",
            "be\n",
            "used\n",
            "as\n",
            "non-uniform\n",
            "sampling\n",
            "distributions\n",
            "for\n",
            "robust\n",
            "active\n",
            "learning\n",
            "when\n",
            "data\n",
            "follows\n",
            "a\n",
            "Gaussian\n",
            "or\n",
            "Laplace\n",
            "distribution\n",
            ".\n",
            "Using\n",
            "the\n",
            "framework\n",
            "of\n",
            "[\n",
            "AKM+19\n",
            "]\n",
            ",\n",
            "we\n",
            "provide\n",
            "essentially\n",
            "optimal\n",
            "results\n",
            "for\n",
            "bandlimited\n",
            "and\n",
            "multiband\n",
            "interpolation\n",
            ",\n",
            "and\n",
            "Gaussian\n",
            "process\n",
            "regression\n",
            ".\n",
            "These\n",
            "results\n",
            "generalize\n",
            "existing\n",
            "work\n",
            "that\n",
            "only\n",
            "applies\n",
            "to\n",
            "uniformly\n",
            "distributed\n",
            "data\n",
            ".\n",
            "1\n",
            "Abstract\n",
            "Modern\n",
            "recording\n",
            "techniques\n",
            "can\n",
            "generate\n",
            "large-scale\n",
            "measurements\n",
            "of\n",
            "multiple\n",
            "neural\n",
            "populations\n",
            "over\n",
            "extended\n",
            "time\n",
            "periods\n",
            ".\n",
            "However\n",
            ",\n",
            "it\n",
            "remains\n",
            "a\n",
            "challenge\n",
            "to\n",
            "model\n",
            "non-stationary\n",
            "interactions\n",
            "between\n",
            "high-dimensional\n",
            "populations\n",
            "of\n",
            "neu-\n",
            "rons\n",
            ".\n",
            "To\n",
            "tackle\n",
            "this\n",
            "challenge\n",
            ",\n",
            "we\n",
            "develop\n",
            "recurrent\n",
            "switching\n",
            "linear\n",
            "dynamical\n",
            "systems\n",
            "models\n",
            "for\n",
            "multiple\n",
            "populations\n",
            ".\n",
            "Here\n",
            ",\n",
            "each\n",
            "high-dimensional\n",
            "neural\n",
            "population\n",
            "is\n",
            "represented\n",
            "by\n",
            "a\n",
            "unique\n",
            "set\n",
            "of\n",
            "latent\n",
            "variables\n",
            ",\n",
            "which\n",
            "evolve\n",
            "dynam-\n",
            "ically\n",
            "in\n",
            "time\n",
            ".\n",
            "Populations\n",
            "interact\n",
            "with\n",
            "each\n",
            "other\n",
            "through\n",
            "this\n",
            "low-dimensional\n",
            "space\n",
            ".\n",
            "We\n",
            "allow\n",
            "the\n",
            "nature\n",
            "of\n",
            "these\n",
            "interactions\n",
            "to\n",
            "change\n",
            "over\n",
            "time\n",
            "by\n",
            "using\n",
            "a\n",
            "discrete\n",
            "set\n",
            "of\n",
            "dynamical\n",
            "states\n",
            ".\n",
            "Additionally\n",
            ",\n",
            "we\n",
            "parameterize\n",
            "these\n",
            "discrete\n",
            "state\n",
            "transition\n",
            "rules\n",
            "to\n",
            "capture\n",
            "which\n",
            "neural\n",
            "populations\n",
            "are\n",
            "responsible\n",
            "for\n",
            "switch-\n",
            "ing\n",
            "between\n",
            "interaction\n",
            "states\n",
            ".\n",
            "To\n",
            "ﬁt\n",
            "the\n",
            "model\n",
            ",\n",
            "we\n",
            "use\n",
            "variational\n",
            "expectation-\n",
            "maximization\n",
            "with\n",
            "a\n",
            "structured\n",
            "mean-ﬁeld\n",
            "approximation\n",
            ".\n",
            "After\n",
            "validating\n",
            "the\n",
            "model\n",
            "on\n",
            "simulations\n",
            ",\n",
            "we\n",
            "apply\n",
            "it\n",
            "to\n",
            "two\n",
            "different\n",
            "neural\n",
            "datasets\n",
            ":\n",
            "spiking\n",
            "activity\n",
            "from\n",
            "motor\n",
            "areas\n",
            "in\n",
            "a\n",
            "non-human\n",
            "primate\n",
            ",\n",
            "and\n",
            "calcium\n",
            "imaging\n",
            "from\n",
            "neurons\n",
            "in\n",
            "the\n",
            "nematode\n",
            "C.\n",
            "elegans\n",
            ".\n",
            "In\n",
            "both\n",
            "datasets\n",
            ",\n",
            "the\n",
            "model\n",
            "reveals\n",
            "behaviorally-relevant\n",
            "discrete\n",
            "states\n",
            "with\n",
            "unique\n",
            "inter-population\n",
            "interactions\n",
            "and\n",
            "different\n",
            "populations\n",
            "that\n",
            "predict\n",
            "transitioning\n",
            "between\n",
            "these\n",
            "states\n",
            ".\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "df_output                                                topic  ... rank_lda\n",
            "0             graph similarity deep learning neurips  ...      6.0\n",
            "1             graph similarity deep learning neurips  ...     10.0\n",
            "2             graph similarity deep learning neurips  ...      2.0\n",
            "3             graph similarity deep learning neurips  ...      5.0\n",
            "4             graph similarity deep learning neurips  ...      1.0\n",
            "5             graph similarity deep learning neurips  ...      8.0\n",
            "6             graph similarity deep learning neurips  ...      4.0\n",
            "7             graph similarity deep learning neurips  ...      3.0\n",
            "8             graph similarity deep learning neurips  ...      7.0\n",
            "9             graph similarity deep learning neurips  ...      9.0\n",
            "0  unsupervised information theoretic perceptual ...  ...     10.0\n",
            "1  unsupervised information theoretic perceptual ...  ...      9.0\n",
            "2  unsupervised information theoretic perceptual ...  ...      8.0\n",
            "3  unsupervised information theoretic perceptual ...  ...      2.0\n",
            "4  unsupervised information theoretic perceptual ...  ...      3.0\n",
            "5  unsupervised information theoretic perceptual ...  ...      5.0\n",
            "6  unsupervised information theoretic perceptual ...  ...      4.0\n",
            "7  unsupervised information theoretic perceptual ...  ...      7.0\n",
            "8  unsupervised information theoretic perceptual ...  ...      1.0\n",
            "9  unsupervised information theoretic perceptual ...  ...      6.0\n",
            "0  self supervised multimodal versatile networks ...  ...      6.0\n",
            "1  self supervised multimodal versatile networks ...  ...      1.0\n",
            "2  self supervised multimodal versatile networks ...  ...      4.0\n",
            "3  self supervised multimodal versatile networks ...  ...      5.0\n",
            "4  self supervised multimodal versatile networks ...  ...      2.0\n",
            "5  self supervised multimodal versatile networks ...  ...      3.0\n",
            "0  benchmarking deep inverse models time neural a...  ...      4.0\n",
            "1  benchmarking deep inverse models time neural a...  ...      7.0\n",
            "2  benchmarking deep inverse models time neural a...  ...      2.0\n",
            "3  benchmarking deep inverse models time neural a...  ...      6.0\n",
            "4  benchmarking deep inverse models time neural a...  ...      3.0\n",
            "5  benchmarking deep inverse models time neural a...  ...      5.0\n",
            "6  benchmarking deep inverse models time neural a...  ...      1.0\n",
            "0  off policy evaluation learning external validi...  ...      3.0\n",
            "1  off policy evaluation learning external validi...  ...      4.0\n",
            "2  off policy evaluation learning external validi...  ...      5.0\n",
            "3  off policy evaluation learning external validi...  ...      1.0\n",
            "4  off policy evaluation learning external validi...  ...      2.0\n",
            "\n",
            "[38 rows x 8 columns]\n",
            "topic:  neural methods point wise dependency estimation neurips id_= 5\n",
            "1 . Neural Methods for Point-wise Dependency Estimation https://papers.nips.cc/paper/2020/file/00a03ec6533ca7f5c644d198d815329c-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Since its inception, the neural estimation of mutual information (MI) has demon-\n",
            "strated the empirical success of modeling expected dependency between high-\n",
            "dimensional random variables. However, MI is an aggregate statistic and cannot\n",
            "be used to measure point-wise dependency between different events. In this work,\n",
            "instead of estimating the expected dependency, we focus on estimating point-wise\n",
            "dependency (PD), which quantitatively measures how likely two outcomes co-\n",
            "occur. We show that we can naturally obtain PD when we are optimizing MI neural\n",
            "variational bounds. However, optimizing these bounds is challenging due to its\n",
            "large variance in practice. To address this issue, we develop two methods (free\n",
            "of optimizing MI variational bounds): Probabilistic Classiﬁer and Density-Ratio\n",
            "Fitting.We demonstrate the effectiveness of our approaches in 1) MI estimation, 2)\n",
            "self-supervised representation learning, and 3) cross-modal retrieval task.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "2 . Neural Methods for Point-wise Dependency Estimation https://papers.nips.cc/paper/2020/hash/00a03ec6533ca7f5c644d198d815329c-Abstract.html\n",
            "**********************************************\n",
            "3 . Neural Methods for Point-wise ... - Review for NeurIPS paper https://papers.nips.cc/paper/2020/file/00a03ec6533ca7f5c644d198d815329c-Review.html\n",
            "**********************************************\n",
            "4 . Advances in Neural Information Processing Systems 33 (NeurIPS ... https://papers.nips.cc/paper/2020\n",
            "**********************************************\n",
            "5 . CaSPR: Learning Canonical Spatiotemporal Point Cloud ... https://papers.nips.cc/paper/2020/file/9de6d14fff9806d4bcd1ef555be766cd-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "We propose CaSPR, a method to learn object-centric Canonical Spatiotemporal\n",
            "Point Cloud Representations of dynamically moving or evolving objects. Our\n",
            "goal is to enable information aggregation over time and the interrogation of object\n",
            "state at any spatiotemporal neighborhood in the past, observed or not. Different\n",
            "from previous work, CaSPR learns representations that support spacetime conti-\n",
            "nuity, are robust to variable and irregularly spacetime-sampled point clouds, and\n",
            "generalize to unseen object instances. Our approach divides the problem into\n",
            "two subtasks. First, we explicitly encode time by mapping an input point cloud\n",
            "sequence to a spatiotemporally-canonicalized object space. We then leverage\n",
            "this canonicalization to learn a spatiotemporal latent representation using neural\n",
            "ordinary differential equations and a generative model of dynamically evolving\n",
            "shapes using continuous normalizing ﬂows. We demonstrate the effectiveness of\n",
            "our method on several applications including shape reconstruction, camera pose es-\n",
            "timation, continuous spatiotemporal sequence reconstruction, and correspondence\n",
            "estimation from irregularly or intermittently sampled observations.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "6 . Exchangeable Neural ODE for Set Modeling https://papers.nips.cc/paper/2020/file/4db73860ecb5533b5a6c710341d5bbec-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Reasoning over an instance composed of a set of vectors, like a point cloud, requires\n",
            "that one accounts for intra-set dependent features among elements. However, since\n",
            "such instances are unordered, the elements’ features should remain unchanged\n",
            "when the input’s order is permuted. This property, permutation equivariance, is\n",
            "a challenging constraint for most neural architectures. While recent work has\n",
            "proposed global pooling and attention-based solutions, these may be limited in the\n",
            "way that intradependencies are captured in practice. In this work we propose a\n",
            "more general formulation to achieve permutation equivariance through ordinary\n",
            "differential equations (ODE). Our proposed module, Exchangeable Neural ODE\n",
            "(ExNODE), can be seamlessly applied for both discriminative and generative tasks.\n",
            "We also extend set modeling in the temporal dimension and propose a VAE based\n",
            "model for temporal set modeling. Extensive experiments demonstrate the efﬁcacy\n",
            "of our method over strong baselines.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "7 . Path Sample-Analytic Gradient Estimators for Stochastic Binary ... https://papers.nips.cc/paper/2020/file/96fca94df72984fc97ee5095410d4dec-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "In neural networks with binary activations and or binary weights the training by\n",
            "gradient descent is complicated as the model has piecewise constant response. We\n",
            "consider stochastic binary networks, obtained by adding noises in front of activa-\n",
            "tions. The expected model response becomes a smooth function of parameters, its\n",
            "gradient is well deﬁned but it is challenging to estimate it accurately. We propose\n",
            "a new method for this estimation problem combining sampling and analytic ap-\n",
            "proximation steps. The method has a signiﬁcantly reduced variance at the price\n",
            "of a small bias which gives a very practical tradeoff in comparison with existing\n",
            "unbiased and biased estimators. We further show that one extra linearization step\n",
            "leads to a deep straight-through estimator previously known only as an ad-hoc\n",
            "heuristic. We experimentally show higher accuracy in gradient estimation and\n",
            "demonstrate a more stable and better performing training in deep convolutional\n",
            "models with both proposed methods.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "8 . Matrix Inference and Estimation in Multi-Layer Models https://papers.nips.cc/paper/2020/file/fe2b421b8b5f0e7c355ace66a9fe0206-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "We consider the problem of estimating the input and hidden variables of a stochastic\n",
            "multi-layer neural network from an observation of the output. The hidden variables\n",
            "in each layer are represented as matrices with statistical interactions along both\n",
            "rows as well as columns. This problem applies to matrix imputation, signal recovery\n",
            "via deep generative prior models, multi-task and mixed regression, and learning\n",
            "certain classes of two-layer neural networks. We extend a recently-developed\n",
            "algorithm – Multi-Layer Vector Approximate Message Passing (ML-VAMP), for\n",
            "this matrix-valued inference problem. It is shown that the performance of the\n",
            "proposed Multi-Layer Matrix VAMP (ML-Mat-VAMP) algorithm can be exactly\n",
            "predicted in a certain random large-system limit, where the dimensions N ×d of the\n",
            "unknown quantities grow as N → ∞ with d ﬁxed. In the two-layer neural-network\n",
            "learning problem, this scaling corresponds to the case where the number of input\n",
            "features as well as training samples grow to inﬁnity but the number of hidden nodes\n",
            "stays ﬁxed. The analysis enables a precise prediction of the parameter and test\n",
            "error of the learning.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "9 . Forget About the LiDAR: Self-Supervised Depth Estimators with ... https://papers.nips.cc/paper/2020/file/951124d4a093eeae83d9726a20295498-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Self-supervised depth estimators have recently shown results comparable to the\n",
            "supervised methods on the challenging single image depth estimation (SIDE) task,\n",
            "by exploiting the geometrical relations between target and reference views in the\n",
            "training data. However, previous methods usually learn forward or backward image\n",
            "synthesis, but not depth estimation, as they cannot effectively neglect occlusions be-\n",
            "tween the target and the reference images. Previous works rely on rigid photometric\n",
            "assumptions or on the SIDE network to infer depth and occlusions, resulting in\n",
            "limited performance. On the other hand, we propose a method to “Forget About the\n",
            "LiDAR” (FAL), with Mirrored Exponential Disparity (MED) probability volumes\n",
            "for the training of monocular depth estimators from stereo images. Our MED repre-\n",
            "sentation allows us to obtain geometrically inspired occlusion maps with our novel\n",
            "Mirrored Occlusion Module (MOM), which does not impose a learning burden\n",
            "on our FAL-net. Contrary to the previous methods that learn SIDE from stereo\n",
            "pairs by regressing disparity in the linear space, our FAL-net regresses disparity by\n",
            "binning it into the exponential space, which allows for better detection of distant\n",
            "and nearby objects. We deﬁne a two-step training strategy for our FAL-net: It\n",
            "is ﬁrst trained for view synthesis and then ﬁne-tuned for depth estimation with\n",
            "our MOM. Our FAL-net is remarkably light-weight and outperforms the previous\n",
            "state-of-the-art methods with 8× fewer parameters and 3× faster inference speeds\n",
            "on the challenging KITTI dataset. We present extensive experimental results on\n",
            "the KITTI, CityScapes, and Make3D datasets to verify our method’s effectiveness.\n",
            "To the authors’ best knowledge, the presented method performs the best among all\n",
            "the previous self-supervised methods until now.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "10 . User-dependent neural sequence models for continuous-time event ... https://papers.nips.cc/paper/2020/file/f56de5ef149cf0aedcc8f4797031e229-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Continuous-time event data are common in applications such as individual behavior\n",
            "data, ﬁnancial transactions, and medical health records. Modeling such data can be\n",
            "very challenging, in particular for applications with many different types of events,\n",
            "since it requires a model to predict the event types as well as the time of occurrence.\n",
            "Recurrent neural networks that parameterize time-varying intensity functions are\n",
            "the current state-of-the-art for predictive modeling with such data. These models\n",
            "typically assume that all event sequences come from the same data distribution.\n",
            "However, in many applications event sequences are generated by different sources,\n",
            "or users, and their characteristics can be very different. In this paper, we extend the\n",
            "broad class of neural marked point process models to mixtures of latent embeddings,\n",
            "where each mixture component models the characteristic traits of a given user. Our\n",
            "approach relies on augmenting these models with a latent variable that encodes\n",
            "user characteristics, represented by a mixture model over user behavior that is\n",
            "trained via amortized variational inference. We evaluate our methods on four large\n",
            "real-world datasets and demonstrate systematic improvements from our approach\n",
            "over existing work for a variety of predictive metrics such as log-likelihood, next\n",
            "event ranking, and source-of-sequence identiﬁcation.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "data:                                                topic  ...                                                url\n",
            "0  neural methods point wise dependency estimatio...  ...  https://papers.nips.cc/paper/2020/file/00a03ec...\n",
            "1  neural methods point wise dependency estimatio...  ...  https://papers.nips.cc/paper/2020/hash/00a03ec...\n",
            "2  neural methods point wise dependency estimatio...  ...  https://papers.nips.cc/paper/2020/file/00a03ec...\n",
            "3  neural methods point wise dependency estimatio...  ...                  https://papers.nips.cc/paper/2020\n",
            "4  neural methods point wise dependency estimatio...  ...  https://papers.nips.cc/paper/2020/file/9de6d14...\n",
            "5  neural methods point wise dependency estimatio...  ...  https://papers.nips.cc/paper/2020/file/4db7386...\n",
            "6  neural methods point wise dependency estimatio...  ...  https://papers.nips.cc/paper/2020/file/96fca94...\n",
            "7  neural methods point wise dependency estimatio...  ...  https://papers.nips.cc/paper/2020/file/fe2b421...\n",
            "8  neural methods point wise dependency estimatio...  ...  https://papers.nips.cc/paper/2020/file/951124d...\n",
            "9  neural methods point wise dependency estimatio...  ...  https://papers.nips.cc/paper/2020/file/f56de5e...\n",
            "\n",
            "[10 rows x 4 columns]\n",
            "**********************************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                                               topic  ... similarity_score\n",
            "0  neural methods point wise dependency estimatio...  ...         0.965585\n",
            "1  neural methods point wise dependency estimatio...  ...         0.960263\n",
            "2  neural methods point wise dependency estimatio...  ...         0.965460\n",
            "3  neural methods point wise dependency estimatio...  ...         0.965418\n",
            "4  neural methods point wise dependency estimatio...  ...         0.960500\n",
            "5  neural methods point wise dependency estimatio...  ...         0.960426\n",
            "6  neural methods point wise dependency estimatio...  ...         0.960962\n",
            "7  neural methods point wise dependency estimatio...  ...         0.967176\n",
            "8  neural methods point wise dependency estimatio...  ...         0.965681\n",
            "9  neural methods point wise dependency estimatio...  ...         0.961511\n",
            "\n",
            "[10 rows x 5 columns]\n",
            "df_final after rank=                                                topic  ...  rank\n",
            "0  neural methods point wise dependency estimatio...  ...   3.0\n",
            "1  neural methods point wise dependency estimatio...  ...  10.0\n",
            "2  neural methods point wise dependency estimatio...  ...   4.0\n",
            "3  neural methods point wise dependency estimatio...  ...   5.0\n",
            "4  neural methods point wise dependency estimatio...  ...   8.0\n",
            "5  neural methods point wise dependency estimatio...  ...   9.0\n",
            "6  neural methods point wise dependency estimatio...  ...   7.0\n",
            "7  neural methods point wise dependency estimatio...  ...   1.0\n",
            "8  neural methods point wise dependency estimatio...  ...   2.0\n",
            "9  neural methods point wise dependency estimatio...  ...   6.0\n",
            "\n",
            "[10 rows x 6 columns]\n",
            "0    Abstract\\n\\nSince its inception, the neural es...\n",
            "1    Neural Methods for Point-wise Dependency Estim...\n",
            "2    NeurIPS 2020\\n\\nNeural Methods for Point-wise ...\n",
            "3    Book\\n\\nDo not remove: This comment is monitor...\n",
            "4    Abstract\\n\\nWe propose CaSPR, a method to lear...\n",
            "5    Abstract\\n\\nReasoning over an instance compose...\n",
            "6    Abstract\\n\\nIn neural networks with binary act...\n",
            "7    Abstract\\n\\nWe consider the problem of estimat...\n",
            "8    Abstract\\n\\nSelf-supervised depth estimators h...\n",
            "9    Abstract\\n\\nContinuous-time event data are com...\n",
            "Name: text, dtype: object\n",
            "Abstract\n",
            "Since\n",
            "its\n",
            "inception\n",
            ",\n",
            "the\n",
            "neural\n",
            "estimation\n",
            "of\n",
            "mutual\n",
            "information\n",
            "(\n",
            "MI\n",
            ")\n",
            "has\n",
            "demon-\n",
            "strated\n",
            "the\n",
            "empirical\n",
            "success\n",
            "of\n",
            "modeling\n",
            "expected\n",
            "dependency\n",
            "between\n",
            "high-\n",
            "dimensional\n",
            "random\n",
            "variables\n",
            ".\n",
            "However\n",
            ",\n",
            "MI\n",
            "is\n",
            "an\n",
            "aggregate\n",
            "statistic\n",
            "and\n",
            "can\n",
            "not\n",
            "be\n",
            "used\n",
            "to\n",
            "measure\n",
            "point-wise\n",
            "dependency\n",
            "between\n",
            "different\n",
            "events\n",
            ".\n",
            "In\n",
            "this\n",
            "work\n",
            ",\n",
            "instead\n",
            "of\n",
            "estimating\n",
            "the\n",
            "expected\n",
            "dependency\n",
            ",\n",
            "we\n",
            "focus\n",
            "on\n",
            "estimating\n",
            "point-wise\n",
            "dependency\n",
            "(\n",
            "PD\n",
            ")\n",
            ",\n",
            "which\n",
            "quantitatively\n",
            "measures\n",
            "how\n",
            "likely\n",
            "two\n",
            "outcomes\n",
            "co-\n",
            "occur\n",
            ".\n",
            "We\n",
            "show\n",
            "that\n",
            "we\n",
            "can\n",
            "naturally\n",
            "obtain\n",
            "PD\n",
            "when\n",
            "we\n",
            "are\n",
            "optimizing\n",
            "MI\n",
            "neural\n",
            "variational\n",
            "bounds\n",
            ".\n",
            "However\n",
            ",\n",
            "optimizing\n",
            "these\n",
            "bounds\n",
            "is\n",
            "challenging\n",
            "due\n",
            "to\n",
            "its\n",
            "large\n",
            "variance\n",
            "in\n",
            "practice\n",
            ".\n",
            "To\n",
            "address\n",
            "this\n",
            "issue\n",
            ",\n",
            "we\n",
            "develop\n",
            "two\n",
            "methods\n",
            "(\n",
            "free\n",
            "of\n",
            "optimizing\n",
            "MI\n",
            "variational\n",
            "bounds\n",
            ")\n",
            ":\n",
            "Probabilistic\n",
            "Classiﬁer\n",
            "and\n",
            "Density-Ratio\n",
            "Fitting.We\n",
            "demonstrate\n",
            "the\n",
            "effectiveness\n",
            "of\n",
            "our\n",
            "approaches\n",
            "in\n",
            "1\n",
            ")\n",
            "MI\n",
            "estimation\n",
            ",\n",
            "2\n",
            ")\n",
            "self-supervised\n",
            "representation\n",
            "learning\n",
            ",\n",
            "and\n",
            "3\n",
            ")\n",
            "cross-modal\n",
            "retrieval\n",
            "task\n",
            ".\n",
            "1\n",
            "Neural\n",
            "Methods\n",
            "for\n",
            "Point-wise\n",
            "Dependency\n",
            "Estimation\n",
            "Part\n",
            "of\n",
            "Advances\n",
            "in\n",
            "Neural\n",
            "Information\n",
            "Processing\n",
            "Systems\n",
            "33\n",
            "(\n",
            "NeurIPS\n",
            "2020\n",
            ")\n",
            "Authors\n",
            "Yao-Hung\n",
            "Hubert\n",
            "Tsai\n",
            ",\n",
            "Han\n",
            "Zhao\n",
            ",\n",
            "Makoto\n",
            "Yamada\n",
            ",\n",
            "Louis-Philippe\n",
            "Morency\n",
            ",\n",
            "Russ\n",
            "R.\n",
            "Salakhutdinov\n",
            "Abstract\n",
            "Since\n",
            "its\n",
            "inception\n",
            ",\n",
            "the\n",
            "neural\n",
            "estimation\n",
            "of\n",
            "mutual\n",
            "information\n",
            "(\n",
            "MI\n",
            ")\n",
            "has\n",
            "demonstrated\n",
            "the\n",
            "empirical\n",
            "success\n",
            "of\n",
            "modeling\n",
            "expected\n",
            "dependency\n",
            "between\n",
            "high-dimensional\n",
            "random\n",
            "variables\n",
            ".\n",
            "However\n",
            ",\n",
            "MI\n",
            "is\n",
            "an\n",
            "aggregate\n",
            "statistic\n",
            "and\n",
            "can\n",
            "not\n",
            "be\n",
            "used\n",
            "to\n",
            "measure\n",
            "point-wise\n",
            "dependency\n",
            "between\n",
            "different\n",
            "events\n",
            ".\n",
            "In\n",
            "this\n",
            "work\n",
            ",\n",
            "instead\n",
            "of\n",
            "estimating\n",
            "the\n",
            "expected\n",
            "dependency\n",
            ",\n",
            "we\n",
            "focus\n",
            "on\n",
            "estimating\n",
            "point-wise\n",
            "dependency\n",
            "(\n",
            "PD\n",
            ")\n",
            ",\n",
            "which\n",
            "quantitatively\n",
            "measures\n",
            "how\n",
            "likely\n",
            "two\n",
            "outcomes\n",
            "co-occur\n",
            ".\n",
            "We\n",
            "show\n",
            "that\n",
            "we\n",
            "can\n",
            "naturally\n",
            "obtain\n",
            "PD\n",
            "when\n",
            "we\n",
            "are\n",
            "optimizing\n",
            "MI\n",
            "neural\n",
            "variational\n",
            "bounds\n",
            ".\n",
            "However\n",
            ",\n",
            "optimizing\n",
            "these\n",
            "bounds\n",
            "is\n",
            "challenging\n",
            "due\n",
            "to\n",
            "its\n",
            "large\n",
            "variance\n",
            "in\n",
            "practice\n",
            ".\n",
            "To\n",
            "address\n",
            "this\n",
            "issue\n",
            ",\n",
            "we\n",
            "develop\n",
            "two\n",
            "methods\n",
            "(\n",
            "free\n",
            "of\n",
            "optimizing\n",
            "MI\n",
            "variational\n",
            "bounds\n",
            ")\n",
            ":\n",
            "Probabilistic\n",
            "Classifier\n",
            "and\n",
            "Density-Ratio\n",
            "Fitting\n",
            ".\n",
            "We\n",
            "demonstrate\n",
            "the\n",
            "effectiveness\n",
            "of\n",
            "our\n",
            "approaches\n",
            "in\n",
            "1\n",
            ")\n",
            "MI\n",
            "estimation\n",
            ",\n",
            "2\n",
            ")\n",
            "self-supervised\n",
            "representation\n",
            "learning\n",
            ",\n",
            "and\n",
            "3\n",
            ")\n",
            "cross-modal\n",
            "retrieval\n",
            "task\n",
            ".\n",
            "NeurIPS\n",
            "2020\n",
            "Neural\n",
            "Methods\n",
            "for\n",
            "Point-wise\n",
            "Dependency\n",
            "Estimation\n",
            "Review\n",
            "1\n",
            "Summary\n",
            "and\n",
            "Contributions\n",
            ":\n",
            "The\n",
            "paper\n",
            "focuses\n",
            "on\n",
            "developing\n",
            "methods\n",
            "for\n",
            "estimating\n",
            "point-wise\n",
            "dependency\n",
            ".\n",
            "Strengths\n",
            ":\n",
            "The\n",
            "paper\n",
            "is\n",
            "well\n",
            "written\n",
            ",\n",
            "introducing\n",
            "all\n",
            "the\n",
            "required\n",
            "details\n",
            "and\n",
            "motivating\n",
            "the\n",
            "need\n",
            "to\n",
            "study\n",
            "point-wise\n",
            "dependency\n",
            ".\n",
            "The\n",
            "strength\n",
            "of\n",
            "the\n",
            "paper\n",
            "is\n",
            "in\n",
            "the\n",
            "experiments\n",
            ".\n",
            "1\n",
            ".\n",
            "There\n",
            "are\n",
            "multiple\n",
            "different\n",
            "application\n",
            "scenarios\n",
            "studied\n",
            ",\n",
            "that\n",
            "are\n",
            "broad\n",
            "and\n",
            "representative\n",
            ".\n",
            "2\n",
            ".\n",
            "The\n",
            "comparisons\n",
            "are\n",
            "extensive\n",
            "though\n",
            "they\n",
            "can\n",
            "be\n",
            "represented\n",
            "more\n",
            "convincingly\n",
            "(\n",
            "see\n",
            "below\n",
            ")\n",
            ".\n",
            "3\n",
            ".\n",
            "Self-supervised\n",
            "representation\n",
            "learning\n",
            "is\n",
            "a\n",
            "good\n",
            "useful\n",
            "application\n",
            ".\n",
            "Weaknesses\n",
            ":\n",
            "The\n",
            "connection\n",
            "between\n",
            "Section\n",
            "3.1\n",
            "and\n",
            "Section\n",
            "3.2\n",
            "is\n",
            "hard\n",
            "to\n",
            "follow\n",
            "and\n",
            "can\n",
            "be\n",
            "written\n",
            "better\n",
            ".\n",
            "The\n",
            "paper\n",
            "discusses\n",
            "how\n",
            "PD\n",
            "can\n",
            "be\n",
            "naturally\n",
            "obtained\n",
            "when\n",
            "optimizing\n",
            "fro\n",
            "MI\n",
            "neural\n",
            "variational\n",
            "bounds\n",
            "but\n",
            "the\n",
            "part\n",
            "on\n",
            "these\n",
            "methods\n",
            "having\n",
            "large\n",
            "variance\n",
            "and\n",
            "hence\n",
            "the\n",
            "need\n",
            "for\n",
            "other\n",
            "methods\n",
            "for\n",
            "PD\n",
            "estimation\n",
            "could\n",
            "be\n",
            "motivated\n",
            "better\n",
            ".\n",
            "The\n",
            "proposed\n",
            "methods\n",
            "address\n",
            "an\n",
            "interesting\n",
            "problem\n",
            "but\n",
            "they\n",
            "follow\n",
            "from\n",
            "the\n",
            "density\n",
            "ratio\n",
            "method\n",
            "for\n",
            "PMI\n",
            ".\n",
            "More\n",
            "details\n",
            "on\n",
            "the\n",
            "novelty\n",
            "of\n",
            "the\n",
            "proposed\n",
            "approach\n",
            "can\n",
            "be\n",
            "helpful\n",
            "to\n",
            "the\n",
            "reviewer\n",
            "and\n",
            "some\n",
            "details\n",
            "in\n",
            "Section\n",
            "3.1\n",
            "can\n",
            "be\n",
            "abstracted\n",
            "and\n",
            "absorbed\n",
            "into\n",
            "related\n",
            "work\n",
            "as\n",
            "this\n",
            "is\n",
            "not\n",
            "really\n",
            "the\n",
            "paper\n",
            "'s\n",
            "contribution\n",
            ".\n",
            "The\n",
            "results\n",
            "also\n",
            "can\n",
            "be\n",
            "represented\n",
            "and\n",
            "explained\n",
            "better\n",
            ".\n",
            "Especially\n",
            "connecting\n",
            "the\n",
            "high\n",
            "variance\n",
            "of\n",
            "the\n",
            "existing\n",
            "approaches\n",
            "and\n",
            "how\n",
            "the\n",
            "proposed\n",
            "approaches\n",
            "are\n",
            "better\n",
            ".\n",
            "For\n",
            "example\n",
            ",\n",
            "It\n",
            "is\n",
            "hard\n",
            "to\n",
            "understand\n",
            "how\n",
            "the\n",
            "results\n",
            "are\n",
            "better\n",
            "than\n",
            "SMILE\n",
            "in\n",
            "Figure\n",
            "1\n",
            ".\n",
            "Given\n",
            "that\n",
            "the\n",
            "experiments\n",
            "are\n",
            "the\n",
            "major\n",
            "strength\n",
            "of\n",
            "the\n",
            "paper\n",
            ",\n",
            "this\n",
            "can\n",
            "be\n",
            "expressed\n",
            "more\n",
            "convincingly\n",
            ".\n",
            "Correctness\n",
            ":\n",
            "The\n",
            "claims\n",
            "and\n",
            "methodology\n",
            "is\n",
            "interesting\n",
            "and\n",
            "correct\n",
            ".\n",
            "Clarity\n",
            ":\n",
            "The\n",
            "paper\n",
            "is\n",
            "well-written\n",
            "and\n",
            "easy\n",
            "to\n",
            "read\n",
            ".\n",
            "Relation\n",
            "to\n",
            "Prior\n",
            "Work\n",
            ":\n",
            "The\n",
            "paper\n",
            "clearly\n",
            "articulates\n",
            "its\n",
            "position\n",
            "with\n",
            "respect\n",
            "to\n",
            "the\n",
            "prior\n",
            "literature\n",
            ".\n",
            "Reproducibility\n",
            ":\n",
            "Yes\n",
            "Additional\n",
            "Feedback\n",
            ":\n",
            "Review\n",
            "2\n",
            "Summary\n",
            "and\n",
            "Contributions\n",
            ":\n",
            "This\n",
            "paper\n",
            "focuses\n",
            "on\n",
            "estimating\n",
            "the\n",
            "point-wise\n",
            "dependency\n",
            "(\n",
            "PD\n",
            ")\n",
            "that\n",
            "measures\n",
            "the\n",
            "instance-level\n",
            "dependency\n",
            "between\n",
            "events\n",
            "taken\n",
            "by\n",
            "two\n",
            "random\n",
            "variables\n",
            ".\n",
            "The\n",
            "authors\n",
            "show\n",
            "that\n",
            "although\n",
            "PD\n",
            "can\n",
            "be\n",
            "obtained\n",
            "via\n",
            "optimizing\n",
            "mutual\n",
            "information\n",
            "(\n",
            "MI\n",
            ")\n",
            "neural\n",
            "variational\n",
            "bounds\n",
            ",\n",
            "it\n",
            "leads\n",
            "to\n",
            "large\n",
            "variance\n",
            ".\n",
            "The\n",
            "authors\n",
            "further\n",
            "propose\n",
            "two\n",
            "data-driven\n",
            "approaches\n",
            "to\n",
            "estimate\n",
            "PD\n",
            ":\n",
            "(\n",
            "1\n",
            ")\n",
            "Probabilistic\n",
            "Classifier\n",
            "and\n",
            "(\n",
            "2\n",
            ")\n",
            "Density-Ratio\n",
            "Fitting\n",
            ".\n",
            "The\n",
            "first\n",
            "one\n",
            "casts\n",
            "the\n",
            "problem\n",
            "into\n",
            "a\n",
            "binary\n",
            "classification\n",
            "by\n",
            "sampling\n",
            "data\n",
            "pairs\n",
            "from\n",
            "joint\n",
            "density\n",
            "as\n",
            "positive\n",
            "labels\n",
            "and\n",
            "from\n",
            "the\n",
            "product\n",
            "of\n",
            "marginals\n",
            "as\n",
            "negative\n",
            "labels\n",
            ".\n",
            "The\n",
            "second\n",
            "approach\n",
            "directly\n",
            "minimizes\n",
            "the\n",
            "expected\n",
            "square\n",
            "distance\n",
            "between\n",
            "the\n",
            "true\n",
            "and\n",
            "estimated\n",
            "PD\n",
            ".\n",
            "The\n",
            "authors\n",
            "applied\n",
            "their\n",
            "PD\n",
            "estimation\n",
            "method\n",
            "in\n",
            "several\n",
            "applications\n",
            ",\n",
            "including\n",
            "MI\n",
            "estimation\n",
            "(\n",
            "by\n",
            "plugging-in\n",
            "the\n",
            "point-wise\n",
            "MI\n",
            "obtained\n",
            "by\n",
            "taking\n",
            "the\n",
            "log\n",
            "of\n",
            "PD\n",
            ")\n",
            ",\n",
            "self-supervised\n",
            "representation\n",
            "learning\n",
            "(\n",
            "by\n",
            "using\n",
            "the\n",
            "constructive\n",
            "learning\n",
            "approach\n",
            ",\n",
            "i.e.\n",
            ",\n",
            "similar\n",
            "pairs\n",
            "having\n",
            "higher\n",
            "PD\n",
            ")\n",
            "and\n",
            "cross-model\n",
            "retrieval\n",
            "(\n",
            "using\n",
            "audio\n",
            "and\n",
            "text\n",
            "data\n",
            ")\n",
            ".\n",
            "The\n",
            "proposed\n",
            "method\n",
            "was\n",
            "shown\n",
            "empirically\n",
            "comparable\n",
            "to\n",
            "the\n",
            "baselines\n",
            ".\n",
            "Strengths\n",
            ":\n",
            "Point-wise\n",
            "dependency\n",
            "estimation\n",
            "is\n",
            "an\n",
            "interesting\n",
            "yet\n",
            "understudied\n",
            "research\n",
            "issue\n",
            ".\n",
            "I\n",
            "am\n",
            "glad\n",
            "to\n",
            "see\n",
            "efforts\n",
            "beyond\n",
            "just\n",
            "estimating\n",
            "the\n",
            "aggregated\n",
            "MI\n",
            ".\n",
            "The\n",
            "problem\n",
            "studied\n",
            "and\n",
            "the\n",
            "approaches\n",
            "taken\n",
            "seem\n",
            "pretty\n",
            "novel\n",
            "to\n",
            "me\n",
            "and\n",
            "are\n",
            "technically\n",
            "sound\n",
            ".\n",
            "The\n",
            "paper\n",
            "is\n",
            "well-written\n",
            "and\n",
            "organized\n",
            ".\n",
            "Intuitions\n",
            "are\n",
            "given\n",
            "as\n",
            "well\n",
            "as\n",
            "rigorous\n",
            "mathematical\n",
            "descriptions\n",
            ",\n",
            "which\n",
            "makes\n",
            "it\n",
            "very\n",
            "easy\n",
            "to\n",
            "follow\n",
            ",\n",
            "and\n",
            "I\n",
            "find\n",
            "it\n",
            "enjoyable\n",
            "to\n",
            "read\n",
            ".\n",
            "Besides\n",
            ",\n",
            "the\n",
            "evaluations\n",
            ",\n",
            "theoretical\n",
            "analysis\n",
            "and\n",
            "relevant\n",
            "discussion\n",
            "are\n",
            "also\n",
            "done\n",
            "with\n",
            "high\n",
            "standards\n",
            ".\n",
            "Weaknesses\n",
            ":\n",
            "1\n",
            ".\n",
            "In\n",
            "Fig.1\n",
            ",\n",
            "it\n",
            "seems\n",
            "that\n",
            "the\n",
            "probabilistic\n",
            "classifier\n",
            "approach\n",
            "is\n",
            "better\n",
            "than\n",
            "the\n",
            "density-ratio\n",
            "fitting\n",
            "approach\n",
            ",\n",
            "as\n",
            "it\n",
            "has\n",
            "both\n",
            "smaller\n",
            "bias\n",
            "and\n",
            "variance\n",
            ".\n",
            "However\n",
            ",\n",
            "in\n",
            "Fig\n",
            ".\n",
            "2\n",
            "for\n",
            "another\n",
            "task\n",
            ",\n",
            "the\n",
            "density-ratio\n",
            "fitting\n",
            "is\n",
            "consistently\n",
            "better\n",
            "than\n",
            "all\n",
            "other\n",
            "approaches\n",
            ".\n",
            "I\n",
            "am\n",
            "wondering\n",
            "if\n",
            "authors\n",
            "have\n",
            "any\n",
            "insights\n",
            "to\n",
            "the\n",
            "differences\n",
            "between\n",
            "their\n",
            "performance\n",
            "in\n",
            "different\n",
            "tasks\n",
            ".\n",
            "2\n",
            ".\n",
            "In\n",
            "the\n",
            "cross-modal\n",
            "learning\n",
            "section\n",
            ",\n",
            "no\n",
            "baselines\n",
            "were\n",
            "compared\n",
            ",\n",
            "and\n",
            "the\n",
            "density-ratio\n",
            "fitting\n",
            "was\n",
            "neither\n",
            "compared\n",
            ".\n",
            "While\n",
            "I\n",
            "understand\n",
            "that\n",
            "the\n",
            "main\n",
            "purpose\n",
            "is\n",
            "to\n",
            "showcase\n",
            "the\n",
            "usage\n",
            "of\n",
            "PD\n",
            ",\n",
            "cross-modality\n",
            "learning\n",
            "is\n",
            "potentially\n",
            "an\n",
            "important\n",
            "application\n",
            "of\n",
            "PD\n",
            "estimation\n",
            ",\n",
            "so\n",
            "I\n",
            "would\n",
            "suggest\n",
            "authors\n",
            "to\n",
            "compare\n",
            "against\n",
            "some\n",
            "SOTA\n",
            "baselines\n",
            "in\n",
            "this\n",
            "topic\n",
            ".\n",
            "Correctness\n",
            ":\n",
            "The\n",
            "approaches\n",
            "developed\n",
            "are\n",
            "technically\n",
            "sound\n",
            ".\n",
            "Both\n",
            "theoretical\n",
            "analysis\n",
            "and\n",
            "empirical\n",
            "evaluations\n",
            "are\n",
            "present\n",
            "and\n",
            "solid\n",
            ".\n",
            "Clarity\n",
            ":\n",
            "The\n",
            "paper\n",
            "is\n",
            "well-written\n",
            ",\n",
            "organized\n",
            "and\n",
            "extremely\n",
            "easy\n",
            "to\n",
            "follow\n",
            ".\n",
            "Relation\n",
            "to\n",
            "Prior\n",
            "Work\n",
            ":\n",
            "Relevant\n",
            "prior\n",
            "works\n",
            "are\n",
            "properly\n",
            "cited\n",
            ",\n",
            "discussed\n",
            "and\n",
            "compared\n",
            ".\n",
            "Reproducibility\n",
            ":\n",
            "Yes\n",
            "Additional\n",
            "Feedback\n",
            ":\n",
            "Please\n",
            "kindly\n",
            "see\n",
            "the\n",
            "Weaknesses\n",
            "section\n",
            ".\n",
            "Review\n",
            "3\n",
            "Summary\n",
            "and\n",
            "Contributions\n",
            ":\n",
            "This\n",
            "paper\n",
            "studies\n",
            "estimating\n",
            "point-wise\n",
            "dependency\n",
            "of\n",
            "data\n",
            "instance\n",
            ".\n",
            "For\n",
            "this\n",
            "purpose\n",
            ",\n",
            "two\n",
            "methods\n",
            "are\n",
            "proposed\n",
            ".\n",
            "Experiments\n",
            "on\n",
            "three\n",
            "tasks\n",
            "demonstrate\n",
            "the\n",
            "effectiveness\n",
            "of\n",
            "the\n",
            "proposed\n",
            "methods\n",
            ".\n",
            "Strengths\n",
            ":\n",
            "1\n",
            ".\n",
            "The\n",
            "problem\n",
            "is\n",
            "important\n",
            "to\n",
            "the\n",
            "NeurIPS\n",
            "community\n",
            ".\n",
            "2\n",
            ".\n",
            "The\n",
            "method\n",
            "is\n",
            "theoretically\n",
            "sound\n",
            ".\n",
            "3\n",
            ".\n",
            "The\n",
            "empirical\n",
            "evaluation\n",
            "is\n",
            "extensive\n",
            ".\n",
            "Weaknesses\n",
            ":\n",
            "1\n",
            ".\n",
            "The\n",
            "contribution\n",
            "is\n",
            "not\n",
            "significant\n",
            ",\n",
            "given\n",
            "existing\n",
            "neural\n",
            "method\n",
            "for\n",
            "density\n",
            "ratio\n",
            "estimation\n",
            "and\n",
            "point-wise\n",
            "mutual\n",
            "information\n",
            "estimation\n",
            ".\n",
            "2\n",
            ".\n",
            "The\n",
            "experiment\n",
            "is\n",
            "mainly\n",
            "conducted\n",
            "on\n",
            "toy\n",
            "data\n",
            ".\n",
            "Correctness\n",
            ":\n",
            "They\n",
            "are\n",
            "correct\n",
            ".\n",
            "Clarity\n",
            ":\n",
            "The\n",
            "paper\n",
            "is\n",
            "well\n",
            "written\n",
            ".\n",
            "Relation\n",
            "to\n",
            "Prior\n",
            "Work\n",
            ":\n",
            "The\n",
            "discussion\n",
            "is\n",
            "clear\n",
            ".\n",
            "Reproducibility\n",
            ":\n",
            "Yes\n",
            "Additional\n",
            "Feedback\n",
            ":\n",
            "This\n",
            "paper\n",
            "studies\n",
            "estimating\n",
            "point-wise\n",
            "dependency\n",
            "of\n",
            "data\n",
            "instance\n",
            ".\n",
            "For\n",
            "this\n",
            "purpose\n",
            ",\n",
            "two\n",
            "methods\n",
            "are\n",
            "proposed\n",
            ".\n",
            "Experiments\n",
            "on\n",
            "three\n",
            "tasks\n",
            "demonstrate\n",
            "the\n",
            "effectiveness\n",
            "of\n",
            "the\n",
            "proposed\n",
            "methods\n",
            ".\n",
            "The\n",
            "paper\n",
            "also\n",
            "has\n",
            "several\n",
            "weaknesses\n",
            ":\n",
            "1\n",
            ".\n",
            "The\n",
            "contribution\n",
            "is\n",
            "not\n",
            "so\n",
            "significant\n",
            ".\n",
            "1\n",
            ")\n",
            "This\n",
            "paper\n",
            "focuses\n",
            "on\n",
            "estimating\n",
            "point-wise\n",
            "dependency\n",
            "of\n",
            "data\n",
            "instance\n",
            ",\n",
            "and\n",
            "the\n",
            "proposed\n",
            "methods\n",
            "are\n",
            "principled\n",
            "and\n",
            "theoretically\n",
            "sound\n",
            ".\n",
            "Despite\n",
            "the\n",
            "merit\n",
            ",\n",
            "similar\n",
            "problems\n",
            "have\n",
            "been\n",
            "extensively\n",
            "studied\n",
            "in\n",
            "the\n",
            "machine\n",
            "learning\n",
            "literature\n",
            ".\n",
            "For\n",
            "example\n",
            ",\n",
            "many\n",
            "prior\n",
            "works\n",
            "estimate\n",
            "the\n",
            "density\n",
            "ratio\n",
            "of\n",
            "two\n",
            "distributions\n",
            "by\n",
            "using\n",
            "the\n",
            "conjugate\n",
            "form\n",
            "of\n",
            "f-divergence\n",
            ",\n",
            "and\n",
            "these\n",
            "methods\n",
            "can\n",
            "be\n",
            "used\n",
            "to\n",
            "estimate\n",
            "the\n",
            "point-wise\n",
            "dependency\n",
            ".\n",
            "Also\n",
            ",\n",
            "some\n",
            "other\n",
            "works\n",
            "try\n",
            "to\n",
            "use\n",
            "neural\n",
            "method\n",
            "to\n",
            "estimate\n",
            "point-wise\n",
            "mutual\n",
            "information\n",
            ",\n",
            "which\n",
            "are\n",
            "also\n",
            "able\n",
            "to\n",
            "estimate\n",
            "the\n",
            "point-wise\n",
            "dependency\n",
            ".\n",
            "Given\n",
            "these\n",
            "existing\n",
            "studies\n",
            ",\n",
            "the\n",
            "idea\n",
            "of\n",
            "the\n",
            "paper\n",
            "seems\n",
            "quite\n",
            "straightforward\n",
            ".\n",
            "2\n",
            ")\n",
            "For\n",
            "point-wise\n",
            "dependency\n",
            "estimation\n",
            ",\n",
            "two\n",
            "methods\n",
            "are\n",
            "proposed\n",
            ".\n",
            "The\n",
            "first\n",
            "Probabilistic\n",
            "Classifier\n",
            "method\n",
            "optimizes\n",
            "a\n",
            "classifier\n",
            ",\n",
            "which\n",
            "is\n",
            "then\n",
            "used\n",
            "to\n",
            "estimate\n",
            "the\n",
            "point-wise\n",
            "dependency\n",
            ".\n",
            "However\n",
            ",\n",
            "I\n",
            "feel\n",
            "like\n",
            "this\n",
            "method\n",
            "is\n",
            "a\n",
            "direct\n",
            "extension\n",
            "of\n",
            "GAN\n",
            "and\n",
            "f-divergence\n",
            "for\n",
            "density\n",
            "ratio\n",
            "estimation\n",
            ".\n",
            "For\n",
            "the\n",
            "second\n",
            "Density-Ratio\n",
            "Fitting\n",
            "method\n",
            ",\n",
            "it\n",
            "is\n",
            "also\n",
            "inspired\n",
            "by\n",
            "a\n",
            "prior\n",
            "work\n",
            ".\n",
            "In\n",
            "this\n",
            "sense\n",
            ",\n",
            "this\n",
            "paper\n",
            "does\n",
            "not\n",
            "propose\n",
            "much\n",
            "new\n",
            "insight\n",
            "on\n",
            "methodology\n",
            ".\n",
            "3\n",
            ")\n",
            "The\n",
            "paper\n",
            "also\n",
            "points\n",
            "out\n",
            "that\n",
            "the\n",
            "problem\n",
            "of\n",
            "point-wise\n",
            "dependency\n",
            "estimation\n",
            "can\n",
            "be\n",
            "solved\n",
            "by\n",
            "existing\n",
            "neural\n",
            "estimator\n",
            "of\n",
            "mutual\n",
            "information\n",
            ".\n",
            "From\n",
            "my\n",
            "understanding\n",
            ",\n",
            "the\n",
            "proposed\n",
            "methods\n",
            "share\n",
            "very\n",
            "similar\n",
            "methodology\n",
            "to\n",
            "these\n",
            "methods\n",
            ".\n",
            "I\n",
            "wonder\n",
            "what\n",
            "is\n",
            "the\n",
            "advantage\n",
            "of\n",
            "the\n",
            "proposed\n",
            "methods\n",
            "for\n",
            "estimating\n",
            "point-wise\n",
            "dependency\n",
            "over\n",
            "these\n",
            "related\n",
            "methods\n",
            "?\n",
            "2\n",
            ".\n",
            "The\n",
            "experiment\n",
            "is\n",
            "only\n",
            "conducted\n",
            "on\n",
            "toy\n",
            "dataset\n",
            ".\n",
            "Although\n",
            "the\n",
            "experiment\n",
            "in\n",
            "the\n",
            "paper\n",
            "is\n",
            "extensive\n",
            ",\n",
            "where\n",
            "three\n",
            "tasks\n",
            "are\n",
            "considered\n",
            ",\n",
            "the\n",
            "experiment\n",
            "is\n",
            "only\n",
            "conducted\n",
            "on\n",
            "toy\n",
            "datasets\n",
            ".\n",
            "For\n",
            "example\n",
            ",\n",
            "in\n",
            "application\n",
            "1\n",
            ",\n",
            "different\n",
            "methods\n",
            "are\n",
            "evaluated\n",
            "with\n",
            "correlated\n",
            "Gaussian\n",
            "distributions\n",
            ";\n",
            "in\n",
            "application\n",
            "2\n",
            ",\n",
            "two\n",
            "small\n",
            "datasets\n",
            "MNIST\n",
            "and\n",
            "CIFAR\n",
            "are\n",
            "used\n",
            ".\n",
            "For\n",
            "application\n",
            "1\n",
            ",\n",
            "it\n",
            "is\n",
            "possible\n",
            "to\n",
            "evaluate\n",
            "with\n",
            "some\n",
            "other\n",
            "distributions\n",
            "?\n",
            "For\n",
            "application\n",
            "2\n",
            ",\n",
            "is\n",
            "it\n",
            "possible\n",
            "to\n",
            "evaluate\n",
            "on\n",
            "ImageNet\n",
            "?\n",
            "For\n",
            "application\n",
            "3\n",
            ",\n",
            "is\n",
            "there\n",
            "any\n",
            "baseline\n",
            "method\n",
            "to\n",
            "compare\n",
            "against\n",
            "?\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "-\n",
            "Thanks\n",
            "the\n",
            "authors\n",
            "for\n",
            "the\n",
            "clarity\n",
            "on\n",
            "the\n",
            "contribution\n",
            "and\n",
            "the\n",
            "additional\n",
            "experimental\n",
            "results\n",
            "!\n",
            "Overall\n",
            ",\n",
            "this\n",
            "is\n",
            "a\n",
            "solid\n",
            "work\n",
            "and\n",
            "I\n",
            "lean\n",
            "towards\n",
            "an\n",
            "accept\n",
            ".\n",
            "Review\n",
            "4\n",
            "Summary\n",
            "and\n",
            "Contributions\n",
            ":\n",
            "In\n",
            "this\n",
            "paper\n",
            ",\n",
            "the\n",
            "authors\n",
            "study\n",
            "how\n",
            "to\n",
            "efficiently\n",
            "and\n",
            "effectively\n",
            "perform\n",
            "point-wise\n",
            "dependency\n",
            "estimation\n",
            "by\n",
            "neural\n",
            "methods\n",
            ".\n",
            "The\n",
            "main\n",
            "contribution\n",
            "could\n",
            "be\n",
            "summarized\n",
            "as\n",
            "follows\n",
            ".\n",
            "C1\n",
            ".\n",
            "An\n",
            "interesting\n",
            "angle\n",
            "to\n",
            "address\n",
            "mutual\n",
            "information\n",
            "estimation\n",
            "is\n",
            "discussed\n",
            ".\n",
            "C2\n",
            ".\n",
            "Probabilistic\n",
            "classifier\n",
            "and\n",
            "density-ratio\n",
            "fitting\n",
            "are\n",
            "proposed\n",
            "to\n",
            "enable\n",
            "effective\n",
            "point-wise\n",
            "dependency\n",
            "estimation\n",
            ".\n",
            "C3\n",
            ".\n",
            "The\n",
            "value\n",
            "of\n",
            "point-wise\n",
            "dependency\n",
            "estimation\n",
            "is\n",
            "highlighted\n",
            "from\n",
            "empirical\n",
            "study\n",
            ".\n",
            "Strengths\n",
            ":\n",
            "S1\n",
            ".\n",
            "The\n",
            "authors\n",
            "suggest\n",
            "interesting\n",
            "perspectives\n",
            "to\n",
            "approach\n",
            "point-wise\n",
            "dependency\n",
            "estimation\n",
            ".\n",
            "S2\n",
            ".\n",
            "Theoretical\n",
            "evidences\n",
            "are\n",
            "provided\n",
            "to\n",
            "enrich\n",
            "the\n",
            "discussion\n",
            "on\n",
            "mutual\n",
            "information\n",
            "estimation\n",
            ".\n",
            "S3\n",
            ".\n",
            "The\n",
            "author\n",
            "explore\n",
            "multiple\n",
            "applications\n",
            "to\n",
            "demonstrate\n",
            "the\n",
            "value\n",
            "in\n",
            "point-wise\n",
            "dependency\n",
            "estimation\n",
            ".\n",
            "Weaknesses\n",
            ":\n",
            "W1\n",
            ".\n",
            "It\n",
            "is\n",
            "difficult\n",
            "to\n",
            "clearly\n",
            "see\n",
            "the\n",
            "concrete\n",
            "difference/impact\n",
            "brought\n",
            "by\n",
            "either\n",
            "probabilistic\n",
            "classifier\n",
            "or\n",
            "density-ratio\n",
            "fitting\n",
            ".\n",
            "It\n",
            "could\n",
            "be\n",
            "the\n",
            "presentation\n",
            "in\n",
            "Figure\n",
            "1\n",
            ".\n",
            "Instead\n",
            "of\n",
            "being\n",
            "qualitative\n",
            ",\n",
            "the\n",
            "authors\n",
            "may\n",
            "make\n",
            "this\n",
            "comparison\n",
            "more\n",
            "quantitative\n",
            ".\n",
            "W2\n",
            ".\n",
            "The\n",
            "value\n",
            "of\n",
            "point-wise\n",
            "dependency\n",
            "estimation\n",
            "in\n",
            "cross-modal\n",
            "learning\n",
            "is\n",
            "a\n",
            "bit\n",
            "weak\n",
            ".\n",
            "The\n",
            "task\n",
            "discussed\n",
            "in\n",
            "Section\n",
            "6\n",
            "seems\n",
            "to\n",
            "be\n",
            "a\n",
            "typical\n",
            "classification\n",
            "or\n",
            "ranking\n",
            "problem\n",
            ".\n",
            "To\n",
            "this\n",
            "end\n",
            ",\n",
            "to\n",
            "better\n",
            "show\n",
            "the\n",
            "value\n",
            "of\n",
            "point-wise\n",
            "estimation\n",
            ",\n",
            "it\n",
            "is\n",
            "important\n",
            "to\n",
            "make\n",
            "comparison\n",
            "with\n",
            "state-of-the-art\n",
            "baselines\n",
            ".\n",
            "Otherwise\n",
            ",\n",
            "only\n",
            "feasibility\n",
            "could\n",
            "be\n",
            "claimed\n",
            ",\n",
            "leaving\n",
            "limited\n",
            "impact\n",
            ".\n",
            "Correctness\n",
            ":\n",
            "In\n",
            "general\n",
            ",\n",
            "yes\n",
            ",\n",
            "but\n",
            "the\n",
            "empirical\n",
            "results\n",
            "presentation\n",
            "may\n",
            "need\n",
            "improvement\n",
            ".\n",
            "Clarity\n",
            ":\n",
            "Yes\n",
            "Relation\n",
            "to\n",
            "Prior\n",
            "Work\n",
            ":\n",
            "Yes\n",
            "Reproducibility\n",
            ":\n",
            "Yes\n",
            "Book\n",
            "Do\n",
            "not\n",
            "remove\n",
            ":\n",
            "This\n",
            "comment\n",
            "is\n",
            "monitored\n",
            "to\n",
            "verify\n",
            "that\n",
            "the\n",
            "site\n",
            "is\n",
            "working\n",
            "properly\n",
            "Abstract\n",
            "We\n",
            "propose\n",
            "CaSPR\n",
            ",\n",
            "a\n",
            "method\n",
            "to\n",
            "learn\n",
            "object-centric\n",
            "Canonical\n",
            "Spatiotemporal\n",
            "Point\n",
            "Cloud\n",
            "Representations\n",
            "of\n",
            "dynamically\n",
            "moving\n",
            "or\n",
            "evolving\n",
            "objects\n",
            ".\n",
            "Our\n",
            "goal\n",
            "is\n",
            "to\n",
            "enable\n",
            "information\n",
            "aggregation\n",
            "over\n",
            "time\n",
            "and\n",
            "the\n",
            "interrogation\n",
            "of\n",
            "object\n",
            "state\n",
            "at\n",
            "any\n",
            "spatiotemporal\n",
            "neighborhood\n",
            "in\n",
            "the\n",
            "past\n",
            ",\n",
            "observed\n",
            "or\n",
            "not\n",
            ".\n",
            "Different\n",
            "from\n",
            "previous\n",
            "work\n",
            ",\n",
            "CaSPR\n",
            "learns\n",
            "representations\n",
            "that\n",
            "support\n",
            "spacetime\n",
            "conti-\n",
            "nuity\n",
            ",\n",
            "are\n",
            "robust\n",
            "to\n",
            "variable\n",
            "and\n",
            "irregularly\n",
            "spacetime-sampled\n",
            "point\n",
            "clouds\n",
            ",\n",
            "and\n",
            "generalize\n",
            "to\n",
            "unseen\n",
            "object\n",
            "instances\n",
            ".\n",
            "Our\n",
            "approach\n",
            "divides\n",
            "the\n",
            "problem\n",
            "into\n",
            "two\n",
            "subtasks\n",
            ".\n",
            "First\n",
            ",\n",
            "we\n",
            "explicitly\n",
            "encode\n",
            "time\n",
            "by\n",
            "mapping\n",
            "an\n",
            "input\n",
            "point\n",
            "cloud\n",
            "sequence\n",
            "to\n",
            "a\n",
            "spatiotemporally-canonicalized\n",
            "object\n",
            "space\n",
            ".\n",
            "We\n",
            "then\n",
            "leverage\n",
            "this\n",
            "canonicalization\n",
            "to\n",
            "learn\n",
            "a\n",
            "spatiotemporal\n",
            "latent\n",
            "representation\n",
            "using\n",
            "neural\n",
            "ordinary\n",
            "differential\n",
            "equations\n",
            "and\n",
            "a\n",
            "generative\n",
            "model\n",
            "of\n",
            "dynamically\n",
            "evolving\n",
            "shapes\n",
            "using\n",
            "continuous\n",
            "normalizing\n",
            "ﬂows\n",
            ".\n",
            "We\n",
            "demonstrate\n",
            "the\n",
            "effectiveness\n",
            "of\n",
            "our\n",
            "method\n",
            "on\n",
            "several\n",
            "applications\n",
            "including\n",
            "shape\n",
            "reconstruction\n",
            ",\n",
            "camera\n",
            "pose\n",
            "es-\n",
            "timation\n",
            ",\n",
            "continuous\n",
            "spatiotemporal\n",
            "sequence\n",
            "reconstruction\n",
            ",\n",
            "and\n",
            "correspondence\n",
            "estimation\n",
            "from\n",
            "irregularly\n",
            "or\n",
            "intermittently\n",
            "sampled\n",
            "observations\n",
            ".\n",
            "1\n",
            "Abstract\n",
            "Reasoning\n",
            "over\n",
            "an\n",
            "instance\n",
            "composed\n",
            "of\n",
            "a\n",
            "set\n",
            "of\n",
            "vectors\n",
            ",\n",
            "like\n",
            "a\n",
            "point\n",
            "cloud\n",
            ",\n",
            "requires\n",
            "that\n",
            "one\n",
            "accounts\n",
            "for\n",
            "intra-set\n",
            "dependent\n",
            "features\n",
            "among\n",
            "elements\n",
            ".\n",
            "However\n",
            ",\n",
            "since\n",
            "such\n",
            "instances\n",
            "are\n",
            "unordered\n",
            ",\n",
            "the\n",
            "elements\n",
            "’\n",
            "features\n",
            "should\n",
            "remain\n",
            "unchanged\n",
            "when\n",
            "the\n",
            "input\n",
            "’\n",
            "s\n",
            "order\n",
            "is\n",
            "permuted\n",
            ".\n",
            "This\n",
            "property\n",
            ",\n",
            "permutation\n",
            "equivariance\n",
            ",\n",
            "is\n",
            "a\n",
            "challenging\n",
            "constraint\n",
            "for\n",
            "most\n",
            "neural\n",
            "architectures\n",
            ".\n",
            "While\n",
            "recent\n",
            "work\n",
            "has\n",
            "proposed\n",
            "global\n",
            "pooling\n",
            "and\n",
            "attention-based\n",
            "solutions\n",
            ",\n",
            "these\n",
            "may\n",
            "be\n",
            "limited\n",
            "in\n",
            "the\n",
            "way\n",
            "that\n",
            "intradependencies\n",
            "are\n",
            "captured\n",
            "in\n",
            "practice\n",
            ".\n",
            "In\n",
            "this\n",
            "work\n",
            "we\n",
            "propose\n",
            "a\n",
            "more\n",
            "general\n",
            "formulation\n",
            "to\n",
            "achieve\n",
            "permutation\n",
            "equivariance\n",
            "through\n",
            "ordinary\n",
            "differential\n",
            "equations\n",
            "(\n",
            "ODE\n",
            ")\n",
            ".\n",
            "Our\n",
            "proposed\n",
            "module\n",
            ",\n",
            "Exchangeable\n",
            "Neural\n",
            "ODE\n",
            "(\n",
            "ExNODE\n",
            ")\n",
            ",\n",
            "can\n",
            "be\n",
            "seamlessly\n",
            "applied\n",
            "for\n",
            "both\n",
            "discriminative\n",
            "and\n",
            "generative\n",
            "tasks\n",
            ".\n",
            "We\n",
            "also\n",
            "extend\n",
            "set\n",
            "modeling\n",
            "in\n",
            "the\n",
            "temporal\n",
            "dimension\n",
            "and\n",
            "propose\n",
            "a\n",
            "VAE\n",
            "based\n",
            "model\n",
            "for\n",
            "temporal\n",
            "set\n",
            "modeling\n",
            ".\n",
            "Extensive\n",
            "experiments\n",
            "demonstrate\n",
            "the\n",
            "efﬁcacy\n",
            "of\n",
            "our\n",
            "method\n",
            "over\n",
            "strong\n",
            "baselines\n",
            ".\n",
            "1\n",
            "Abstract\n",
            "In\n",
            "neural\n",
            "networks\n",
            "with\n",
            "binary\n",
            "activations\n",
            "and\n",
            "or\n",
            "binary\n",
            "weights\n",
            "the\n",
            "training\n",
            "by\n",
            "gradient\n",
            "descent\n",
            "is\n",
            "complicated\n",
            "as\n",
            "the\n",
            "model\n",
            "has\n",
            "piecewise\n",
            "constant\n",
            "response\n",
            ".\n",
            "We\n",
            "consider\n",
            "stochastic\n",
            "binary\n",
            "networks\n",
            ",\n",
            "obtained\n",
            "by\n",
            "adding\n",
            "noises\n",
            "in\n",
            "front\n",
            "of\n",
            "activa-\n",
            "tions\n",
            ".\n",
            "The\n",
            "expected\n",
            "model\n",
            "response\n",
            "becomes\n",
            "a\n",
            "smooth\n",
            "function\n",
            "of\n",
            "parameters\n",
            ",\n",
            "its\n",
            "gradient\n",
            "is\n",
            "well\n",
            "deﬁned\n",
            "but\n",
            "it\n",
            "is\n",
            "challenging\n",
            "to\n",
            "estimate\n",
            "it\n",
            "accurately\n",
            ".\n",
            "We\n",
            "propose\n",
            "a\n",
            "new\n",
            "method\n",
            "for\n",
            "this\n",
            "estimation\n",
            "problem\n",
            "combining\n",
            "sampling\n",
            "and\n",
            "analytic\n",
            "ap-\n",
            "proximation\n",
            "steps\n",
            ".\n",
            "The\n",
            "method\n",
            "has\n",
            "a\n",
            "signiﬁcantly\n",
            "reduced\n",
            "variance\n",
            "at\n",
            "the\n",
            "price\n",
            "of\n",
            "a\n",
            "small\n",
            "bias\n",
            "which\n",
            "gives\n",
            "a\n",
            "very\n",
            "practical\n",
            "tradeoff\n",
            "in\n",
            "comparison\n",
            "with\n",
            "existing\n",
            "unbiased\n",
            "and\n",
            "biased\n",
            "estimators\n",
            ".\n",
            "We\n",
            "further\n",
            "show\n",
            "that\n",
            "one\n",
            "extra\n",
            "linearization\n",
            "step\n",
            "leads\n",
            "to\n",
            "a\n",
            "deep\n",
            "straight-through\n",
            "estimator\n",
            "previously\n",
            "known\n",
            "only\n",
            "as\n",
            "an\n",
            "ad-hoc\n",
            "heuristic\n",
            ".\n",
            "We\n",
            "experimentally\n",
            "show\n",
            "higher\n",
            "accuracy\n",
            "in\n",
            "gradient\n",
            "estimation\n",
            "and\n",
            "demonstrate\n",
            "a\n",
            "more\n",
            "stable\n",
            "and\n",
            "better\n",
            "performing\n",
            "training\n",
            "in\n",
            "deep\n",
            "convolutional\n",
            "models\n",
            "with\n",
            "both\n",
            "proposed\n",
            "methods\n",
            ".\n",
            "1\n",
            "Abstract\n",
            "We\n",
            "consider\n",
            "the\n",
            "problem\n",
            "of\n",
            "estimating\n",
            "the\n",
            "input\n",
            "and\n",
            "hidden\n",
            "variables\n",
            "of\n",
            "a\n",
            "stochastic\n",
            "multi-layer\n",
            "neural\n",
            "network\n",
            "from\n",
            "an\n",
            "observation\n",
            "of\n",
            "the\n",
            "output\n",
            ".\n",
            "The\n",
            "hidden\n",
            "variables\n",
            "in\n",
            "each\n",
            "layer\n",
            "are\n",
            "represented\n",
            "as\n",
            "matrices\n",
            "with\n",
            "statistical\n",
            "interactions\n",
            "along\n",
            "both\n",
            "rows\n",
            "as\n",
            "well\n",
            "as\n",
            "columns\n",
            ".\n",
            "This\n",
            "problem\n",
            "applies\n",
            "to\n",
            "matrix\n",
            "imputation\n",
            ",\n",
            "signal\n",
            "recovery\n",
            "via\n",
            "deep\n",
            "generative\n",
            "prior\n",
            "models\n",
            ",\n",
            "multi-task\n",
            "and\n",
            "mixed\n",
            "regression\n",
            ",\n",
            "and\n",
            "learning\n",
            "certain\n",
            "classes\n",
            "of\n",
            "two-layer\n",
            "neural\n",
            "networks\n",
            ".\n",
            "We\n",
            "extend\n",
            "a\n",
            "recently-developed\n",
            "algorithm\n",
            "–\n",
            "Multi-Layer\n",
            "Vector\n",
            "Approximate\n",
            "Message\n",
            "Passing\n",
            "(\n",
            "ML-VAMP\n",
            ")\n",
            ",\n",
            "for\n",
            "this\n",
            "matrix-valued\n",
            "inference\n",
            "problem\n",
            ".\n",
            "It\n",
            "is\n",
            "shown\n",
            "that\n",
            "the\n",
            "performance\n",
            "of\n",
            "the\n",
            "proposed\n",
            "Multi-Layer\n",
            "Matrix\n",
            "VAMP\n",
            "(\n",
            "ML-Mat-VAMP\n",
            ")\n",
            "algorithm\n",
            "can\n",
            "be\n",
            "exactly\n",
            "predicted\n",
            "in\n",
            "a\n",
            "certain\n",
            "random\n",
            "large-system\n",
            "limit\n",
            ",\n",
            "where\n",
            "the\n",
            "dimensions\n",
            "N\n",
            "×d\n",
            "of\n",
            "the\n",
            "unknown\n",
            "quantities\n",
            "grow\n",
            "as\n",
            "N\n",
            "→\n",
            "∞\n",
            "with\n",
            "d\n",
            "ﬁxed\n",
            ".\n",
            "In\n",
            "the\n",
            "two-layer\n",
            "neural-network\n",
            "learning\n",
            "problem\n",
            ",\n",
            "this\n",
            "scaling\n",
            "corresponds\n",
            "to\n",
            "the\n",
            "case\n",
            "where\n",
            "the\n",
            "number\n",
            "of\n",
            "input\n",
            "features\n",
            "as\n",
            "well\n",
            "as\n",
            "training\n",
            "samples\n",
            "grow\n",
            "to\n",
            "inﬁnity\n",
            "but\n",
            "the\n",
            "number\n",
            "of\n",
            "hidden\n",
            "nodes\n",
            "stays\n",
            "ﬁxed\n",
            ".\n",
            "The\n",
            "analysis\n",
            "enables\n",
            "a\n",
            "precise\n",
            "prediction\n",
            "of\n",
            "the\n",
            "parameter\n",
            "and\n",
            "test\n",
            "error\n",
            "of\n",
            "the\n",
            "learning\n",
            ".\n",
            "1\n",
            "Abstract\n",
            "Self-supervised\n",
            "depth\n",
            "estimators\n",
            "have\n",
            "recently\n",
            "shown\n",
            "results\n",
            "comparable\n",
            "to\n",
            "the\n",
            "supervised\n",
            "methods\n",
            "on\n",
            "the\n",
            "challenging\n",
            "single\n",
            "image\n",
            "depth\n",
            "estimation\n",
            "(\n",
            "SIDE\n",
            ")\n",
            "task\n",
            ",\n",
            "by\n",
            "exploiting\n",
            "the\n",
            "geometrical\n",
            "relations\n",
            "between\n",
            "target\n",
            "and\n",
            "reference\n",
            "views\n",
            "in\n",
            "the\n",
            "training\n",
            "data\n",
            ".\n",
            "However\n",
            ",\n",
            "previous\n",
            "methods\n",
            "usually\n",
            "learn\n",
            "forward\n",
            "or\n",
            "backward\n",
            "image\n",
            "synthesis\n",
            ",\n",
            "but\n",
            "not\n",
            "depth\n",
            "estimation\n",
            ",\n",
            "as\n",
            "they\n",
            "can\n",
            "not\n",
            "effectively\n",
            "neglect\n",
            "occlusions\n",
            "be-\n",
            "tween\n",
            "the\n",
            "target\n",
            "and\n",
            "the\n",
            "reference\n",
            "images\n",
            ".\n",
            "Previous\n",
            "works\n",
            "rely\n",
            "on\n",
            "rigid\n",
            "photometric\n",
            "assumptions\n",
            "or\n",
            "on\n",
            "the\n",
            "SIDE\n",
            "network\n",
            "to\n",
            "infer\n",
            "depth\n",
            "and\n",
            "occlusions\n",
            ",\n",
            "resulting\n",
            "in\n",
            "limited\n",
            "performance\n",
            ".\n",
            "On\n",
            "the\n",
            "other\n",
            "hand\n",
            ",\n",
            "we\n",
            "propose\n",
            "a\n",
            "method\n",
            "to\n",
            "“\n",
            "Forget\n",
            "About\n",
            "the\n",
            "LiDAR\n",
            "”\n",
            "(\n",
            "FAL\n",
            ")\n",
            ",\n",
            "with\n",
            "Mirrored\n",
            "Exponential\n",
            "Disparity\n",
            "(\n",
            "MED\n",
            ")\n",
            "probability\n",
            "volumes\n",
            "for\n",
            "the\n",
            "training\n",
            "of\n",
            "monocular\n",
            "depth\n",
            "estimators\n",
            "from\n",
            "stereo\n",
            "images\n",
            ".\n",
            "Our\n",
            "MED\n",
            "repre-\n",
            "sentation\n",
            "allows\n",
            "us\n",
            "to\n",
            "obtain\n",
            "geometrically\n",
            "inspired\n",
            "occlusion\n",
            "maps\n",
            "with\n",
            "our\n",
            "novel\n",
            "Mirrored\n",
            "Occlusion\n",
            "Module\n",
            "(\n",
            "MOM\n",
            ")\n",
            ",\n",
            "which\n",
            "does\n",
            "not\n",
            "impose\n",
            "a\n",
            "learning\n",
            "burden\n",
            "on\n",
            "our\n",
            "FAL-net\n",
            ".\n",
            "Contrary\n",
            "to\n",
            "the\n",
            "previous\n",
            "methods\n",
            "that\n",
            "learn\n",
            "SIDE\n",
            "from\n",
            "stereo\n",
            "pairs\n",
            "by\n",
            "regressing\n",
            "disparity\n",
            "in\n",
            "the\n",
            "linear\n",
            "space\n",
            ",\n",
            "our\n",
            "FAL-net\n",
            "regresses\n",
            "disparity\n",
            "by\n",
            "binning\n",
            "it\n",
            "into\n",
            "the\n",
            "exponential\n",
            "space\n",
            ",\n",
            "which\n",
            "allows\n",
            "for\n",
            "better\n",
            "detection\n",
            "of\n",
            "distant\n",
            "and\n",
            "nearby\n",
            "objects\n",
            ".\n",
            "We\n",
            "deﬁne\n",
            "a\n",
            "two-step\n",
            "training\n",
            "strategy\n",
            "for\n",
            "our\n",
            "FAL-net\n",
            ":\n",
            "It\n",
            "is\n",
            "ﬁrst\n",
            "trained\n",
            "for\n",
            "view\n",
            "synthesis\n",
            "and\n",
            "then\n",
            "ﬁne-tuned\n",
            "for\n",
            "depth\n",
            "estimation\n",
            "with\n",
            "our\n",
            "MOM\n",
            ".\n",
            "Our\n",
            "FAL-net\n",
            "is\n",
            "remarkably\n",
            "light-weight\n",
            "and\n",
            "outperforms\n",
            "the\n",
            "previous\n",
            "state-of-the-art\n",
            "methods\n",
            "with\n",
            "8×\n",
            "fewer\n",
            "parameters\n",
            "and\n",
            "3×\n",
            "faster\n",
            "inference\n",
            "speeds\n",
            "on\n",
            "the\n",
            "challenging\n",
            "KITTI\n",
            "dataset\n",
            ".\n",
            "We\n",
            "present\n",
            "extensive\n",
            "experimental\n",
            "results\n",
            "on\n",
            "the\n",
            "KITTI\n",
            ",\n",
            "CityScapes\n",
            ",\n",
            "and\n",
            "Make3D\n",
            "datasets\n",
            "to\n",
            "verify\n",
            "our\n",
            "method\n",
            "’\n",
            "s\n",
            "effectiveness\n",
            ".\n",
            "To\n",
            "the\n",
            "authors\n",
            "’\n",
            "best\n",
            "knowledge\n",
            ",\n",
            "the\n",
            "presented\n",
            "method\n",
            "performs\n",
            "the\n",
            "best\n",
            "among\n",
            "all\n",
            "the\n",
            "previous\n",
            "self-supervised\n",
            "methods\n",
            "until\n",
            "now\n",
            ".\n",
            "1\n",
            "Abstract\n",
            "Continuous-time\n",
            "event\n",
            "data\n",
            "are\n",
            "common\n",
            "in\n",
            "applications\n",
            "such\n",
            "as\n",
            "individual\n",
            "behavior\n",
            "data\n",
            ",\n",
            "ﬁnancial\n",
            "transactions\n",
            ",\n",
            "and\n",
            "medical\n",
            "health\n",
            "records\n",
            ".\n",
            "Modeling\n",
            "such\n",
            "data\n",
            "can\n",
            "be\n",
            "very\n",
            "challenging\n",
            ",\n",
            "in\n",
            "particular\n",
            "for\n",
            "applications\n",
            "with\n",
            "many\n",
            "different\n",
            "types\n",
            "of\n",
            "events\n",
            ",\n",
            "since\n",
            "it\n",
            "requires\n",
            "a\n",
            "model\n",
            "to\n",
            "predict\n",
            "the\n",
            "event\n",
            "types\n",
            "as\n",
            "well\n",
            "as\n",
            "the\n",
            "time\n",
            "of\n",
            "occurrence\n",
            ".\n",
            "Recurrent\n",
            "neural\n",
            "networks\n",
            "that\n",
            "parameterize\n",
            "time-varying\n",
            "intensity\n",
            "functions\n",
            "are\n",
            "the\n",
            "current\n",
            "state-of-the-art\n",
            "for\n",
            "predictive\n",
            "modeling\n",
            "with\n",
            "such\n",
            "data\n",
            ".\n",
            "These\n",
            "models\n",
            "typically\n",
            "assume\n",
            "that\n",
            "all\n",
            "event\n",
            "sequences\n",
            "come\n",
            "from\n",
            "the\n",
            "same\n",
            "data\n",
            "distribution\n",
            ".\n",
            "However\n",
            ",\n",
            "in\n",
            "many\n",
            "applications\n",
            "event\n",
            "sequences\n",
            "are\n",
            "generated\n",
            "by\n",
            "different\n",
            "sources\n",
            ",\n",
            "or\n",
            "users\n",
            ",\n",
            "and\n",
            "their\n",
            "characteristics\n",
            "can\n",
            "be\n",
            "very\n",
            "different\n",
            ".\n",
            "In\n",
            "this\n",
            "paper\n",
            ",\n",
            "we\n",
            "extend\n",
            "the\n",
            "broad\n",
            "class\n",
            "of\n",
            "neural\n",
            "marked\n",
            "point\n",
            "process\n",
            "models\n",
            "to\n",
            "mixtures\n",
            "of\n",
            "latent\n",
            "embeddings\n",
            ",\n",
            "where\n",
            "each\n",
            "mixture\n",
            "component\n",
            "models\n",
            "the\n",
            "characteristic\n",
            "traits\n",
            "of\n",
            "a\n",
            "given\n",
            "user\n",
            ".\n",
            "Our\n",
            "approach\n",
            "relies\n",
            "on\n",
            "augmenting\n",
            "these\n",
            "models\n",
            "with\n",
            "a\n",
            "latent\n",
            "variable\n",
            "that\n",
            "encodes\n",
            "user\n",
            "characteristics\n",
            ",\n",
            "represented\n",
            "by\n",
            "a\n",
            "mixture\n",
            "model\n",
            "over\n",
            "user\n",
            "behavior\n",
            "that\n",
            "is\n",
            "trained\n",
            "via\n",
            "amortized\n",
            "variational\n",
            "inference\n",
            ".\n",
            "We\n",
            "evaluate\n",
            "our\n",
            "methods\n",
            "on\n",
            "four\n",
            "large\n",
            "real-world\n",
            "datasets\n",
            "and\n",
            "demonstrate\n",
            "systematic\n",
            "improvements\n",
            "from\n",
            "our\n",
            "approach\n",
            "over\n",
            "existing\n",
            "work\n",
            "for\n",
            "a\n",
            "variety\n",
            "of\n",
            "predictive\n",
            "metrics\n",
            "such\n",
            "as\n",
            "log-likelihood\n",
            ",\n",
            "next\n",
            "event\n",
            "ranking\n",
            ",\n",
            "and\n",
            "source-of-sequence\n",
            "identiﬁcation\n",
            ".\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "df_output                                                topic  ... rank_lda\n",
            "0             graph similarity deep learning neurips  ...      6.0\n",
            "1             graph similarity deep learning neurips  ...     10.0\n",
            "2             graph similarity deep learning neurips  ...      2.0\n",
            "3             graph similarity deep learning neurips  ...      5.0\n",
            "4             graph similarity deep learning neurips  ...      1.0\n",
            "5             graph similarity deep learning neurips  ...      8.0\n",
            "6             graph similarity deep learning neurips  ...      4.0\n",
            "7             graph similarity deep learning neurips  ...      3.0\n",
            "8             graph similarity deep learning neurips  ...      7.0\n",
            "9             graph similarity deep learning neurips  ...      9.0\n",
            "0  unsupervised information theoretic perceptual ...  ...     10.0\n",
            "1  unsupervised information theoretic perceptual ...  ...      9.0\n",
            "2  unsupervised information theoretic perceptual ...  ...      8.0\n",
            "3  unsupervised information theoretic perceptual ...  ...      2.0\n",
            "4  unsupervised information theoretic perceptual ...  ...      3.0\n",
            "5  unsupervised information theoretic perceptual ...  ...      5.0\n",
            "6  unsupervised information theoretic perceptual ...  ...      4.0\n",
            "7  unsupervised information theoretic perceptual ...  ...      7.0\n",
            "8  unsupervised information theoretic perceptual ...  ...      1.0\n",
            "9  unsupervised information theoretic perceptual ...  ...      6.0\n",
            "0  self supervised multimodal versatile networks ...  ...      6.0\n",
            "1  self supervised multimodal versatile networks ...  ...      1.0\n",
            "2  self supervised multimodal versatile networks ...  ...      4.0\n",
            "3  self supervised multimodal versatile networks ...  ...      5.0\n",
            "4  self supervised multimodal versatile networks ...  ...      2.0\n",
            "5  self supervised multimodal versatile networks ...  ...      3.0\n",
            "0  benchmarking deep inverse models time neural a...  ...      4.0\n",
            "1  benchmarking deep inverse models time neural a...  ...      7.0\n",
            "2  benchmarking deep inverse models time neural a...  ...      2.0\n",
            "3  benchmarking deep inverse models time neural a...  ...      6.0\n",
            "4  benchmarking deep inverse models time neural a...  ...      3.0\n",
            "5  benchmarking deep inverse models time neural a...  ...      5.0\n",
            "6  benchmarking deep inverse models time neural a...  ...      1.0\n",
            "0  off policy evaluation learning external validi...  ...      3.0\n",
            "1  off policy evaluation learning external validi...  ...      4.0\n",
            "2  off policy evaluation learning external validi...  ...      5.0\n",
            "3  off policy evaluation learning external validi...  ...      1.0\n",
            "4  off policy evaluation learning external validi...  ...      2.0\n",
            "0  neural methods point wise dependency estimatio...  ...      1.0\n",
            "1  neural methods point wise dependency estimatio...  ...      5.0\n",
            "2  neural methods point wise dependency estimatio...  ...      2.0\n",
            "3  neural methods point wise dependency estimatio...  ...      6.0\n",
            "4  neural methods point wise dependency estimatio...  ...      8.0\n",
            "5  neural methods point wise dependency estimatio...  ...      4.0\n",
            "6  neural methods point wise dependency estimatio...  ...      9.0\n",
            "7  neural methods point wise dependency estimatio...  ...     10.0\n",
            "8  neural methods point wise dependency estimatio...  ...      3.0\n",
            "9  neural methods point wise dependency estimatio...  ...      7.0\n",
            "\n",
            "[48 rows x 8 columns]\n",
            "topic:  fast flexible temporal point processes triangular maps neurips id_= 6\n",
            "1 . Fast and Flexible Temporal Point Processes with Triangular Maps https://papers.nips.cc/paper/2020/hash/00ac8ed3b4327bdd4ebbebcb2ba10a00-Abstract.html\n",
            "**********************************************\n",
            "2 . Fast and Flexible Temporal Point Processes with Triangular Maps https://papers.nips.cc/paper/2020/file/00ac8ed3b4327bdd4ebbebcb2ba10a00-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Temporal point process (TPP) models combined with recurrent neural networks\n",
            "provide a powerful framework for modeling continuous-time event data. While\n",
            "such models are ﬂexible, they are inherently sequential and therefore cannot beneﬁt\n",
            "from the parallelism of modern hardware. By exploiting the recent developments\n",
            "in the ﬁeld of normalizing ﬂows, we design TriTPP— a new class of non-recurrent\n",
            "TPP models, where both sampling and likelihood computation can be done in\n",
            "parallel. TriTPP matches the ﬂexibility of RNN-based methods but permits orders\n",
            "of magnitude faster sampling. This enables us to use the new model for variational\n",
            "inference in continuous-time discrete-state systems. We demonstrate the advantages\n",
            "of the proposed framework on synthetic and real-world datasets.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "3 . Advances in Neural Information Processing Systems 33 (NeurIPS ... https://papers.nips.cc/paper/2020\n",
            "**********************************************\n",
            "4 . Exchangeable Neural ODE for Set Modeling https://papers.nips.cc/paper/2020/file/4db73860ecb5533b5a6c710341d5bbec-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Temporal point process (TPP) models combined with recurrent neural networks\n",
            "provide a powerful framework for modeling continuous-time event data. While\n",
            "such models are ﬂexible, they are inherently sequential and therefore cannot beneﬁt\n",
            "from the parallelism of modern hardware. By exploiting the recent developments\n",
            "in the ﬁeld of normalizing ﬂows, we design TriTPP— a new class of non-recurrent\n",
            "TPP models, where both sampling and likelihood computation can be done in\n",
            "parallel. TriTPP matches the ﬂexibility of RNN-based methods but permits orders\n",
            "of magnitude faster sampling. This enables us to use the new model for variational\n",
            "inference in continuous-time discrete-state systems. We demonstrate the advantages\n",
            "of the proposed framework on synthetic and real-world datasets.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "5 . Finite-Sample Analysis of Contractive Stochastic Approximation ... https://papers.nips.cc/paper/2020/file/5d44ee6f2c3f71b73125876103c8f6c4-Supplemental.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Stochastic Approximation (SA) is a popular approach for solving ﬁxed-point\n",
            "equations where the information is corrupted by noise. In this paper, we consider\n",
            "an SA involving a contraction mapping with respect to an arbitrary norm, and\n",
            "show its ﬁnite-sample error bounds while using different stepsizes. The idea is\n",
            "to construct a smooth Lyapunov function using the generalized Moreau envelope,\n",
            "and show that the iterates of SA have negative drift with respect to that Lyapunov\n",
            "function. Our result is applicable in Reinforcement Learning (RL). In particular,\n",
            "we use it to establish the ﬁrst-known convergence rate of the V-trace algorithm\n",
            "for off-policy TD-learning [18]. Importantly, our construction results in only a\n",
            "logarithmic dependence of the convergence bound on the size of the state-space.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "6 . Sparse Graphical Memory for Robust Planning https://papers.nips.cc/paper/2020/file/385822e359afa26d52b5b286226f2cea-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "To operate effectively in the real world, agents should be able to act from high-\n",
            "dimensional raw sensory input such as images and achieve diverse goals across long\n",
            "time-horizons. Current deep reinforcement and imitation learning methods can\n",
            "learn directly from high-dimensional inputs but do not scale well to long-horizon\n",
            "tasks. In contrast, classical graphical methods like A* search are able to solve\n",
            "long-horizon tasks, but assume that the state space is abstracted away from raw\n",
            "sensory input. Recent works have attempted to combine the strengths of deep\n",
            "learning and classical planning; however, dominant methods in this domain are\n",
            "still quite brittle and scale poorly with the size of the environment. We introduce\n",
            "Sparse Graphical Memory (SGM), a new data structure that stores states and\n",
            "feasible transitions in a sparse memory. SGM aggregates states according to a\n",
            "novel two-way consistency objective, adapting classic state aggregation criteria\n",
            "to goal-conditioned RL: two states are redundant when they are interchangeable\n",
            "both as goals and as starting states. Theoretically, we prove that merging nodes\n",
            "according to two-way consistency leads to an increase in shortest path lengths that\n",
            "scales only linearly with the merging threshold. Experimentally, we show that SGM\n",
            "signiﬁcantly outperforms current state of the art methods on long horizon, sparse-\n",
            "reward visual navigation tasks. Project video and code are available at https:\n",
            "//mishalaskin.github.io/sgm/.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "7 . Neural Dynamic Policies for End-to-End Sensorimotor Learning https://papers.nips.cc/paper/2020/file/354ac345fd8c6d7ef634d9a8e3d47b83-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "The current dominant paradigm in sensorimotor control, whether imitation or\n",
            "reinforcement learning, is to train policies directly in raw action spaces such\n",
            "as torque, joint angle, or end-effector position. This forces the agent to make\n",
            "decision at each point in training, and hence, limit the scalability to continuous,\n",
            "high-dimensional, and long-horizon tasks. In contrast, research in classical robotics\n",
            "has, for a long time, exploited dynamical systems as a policy representation to\n",
            "learn robot behaviors via demonstrations. These techniques, however, lack the\n",
            "ﬂexibility and generalizability provided by deep learning or deep reinforcement\n",
            "learning and have remained under-explored in such settings. In this work, we begin\n",
            "to close this gap and embed dynamics structure into deep neural network-based\n",
            "policies by reparameterizing action spaces with differential equations. We propose\n",
            "Neural Dynamic Policies (NDPs) that make predictions in trajectory distribution\n",
            "space as opposed to prior policy learning methods where action represents the\n",
            "raw control space. The embedded structure allow us to perform end-to-end policy\n",
            "learning under both reinforcement and imitation learning setups. We show that\n",
            "NDPs achieve better or comparable performance to state-of-the-art approaches on\n",
            "many robotic control tasks using both reward-based training and demonstrations.\n",
            "Project video and code are available at: https://shikharbahl.github.io/\n",
            "neural-dynamic-policies/.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "8 . Memory Based Trajectory-conditioned Policies for Learning from ... https://papers.nips.cc/paper/2020/file/2df45244f09369e16ea3f9117ca45157-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Reinforcement learning with sparse rewards is challenging because an agent can\n",
            "rarely obtain non-zero rewards and hence, gradient-based optimization of param-\n",
            "eterized policies can be incremental and slow. Recent work demonstrated that\n",
            "using a memory buffer of previous successful trajectories can result in more ef-\n",
            "fective policies. However, existing methods may overly exploit past successful\n",
            "experiences, which can encourage the agent to adopt sub-optimal and myopic\n",
            "behaviors. In this work, instead of focusing on good experiences with limited\n",
            "diversity, we propose to learn a trajectory-conditioned policy to follow and expand\n",
            "diverse past trajectories from a memory buffer. Our method allows the agent to\n",
            "reach diverse regions in the state space and improve upon the past trajectories to\n",
            "reach new states. We empirically show that our approach signiﬁcantly outperforms\n",
            "count-based exploration methods (parametric approach) and self-imitation learning\n",
            "(parametric approach with non-parametric memory) on various complex tasks with\n",
            "local optima. In particular, without using expert demonstrations or resetting to\n",
            "arbitrary states, we achieve the state-of-the-art scores under ﬁve billion number of\n",
            "frames, on challenging Atari games such as Montezuma’s Revenge and Pitfall.\n",
            "\n",
            "\n",
            "**********************************************\n",
            "9 . Multi-Robot Collision Avoidance under Uncertainty with Probabilistic ... https://papers.nips.cc/paper/2020/file/03793ef7d06ffd63d34ade9d091f1ced-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Safety in terms of collision avoidance for multi-robot systems is a difﬁcult challenge\n",
            "under uncertainty, non-determinism and lack of complete information. This paper\n",
            "aims to propose a collision avoidance method that accounts for both measurement\n",
            "uncertainty and motion uncertainty. In particular, we propose Probabilistic Safety\n",
            "Barrier Certiﬁcates (PrSBC) using Control Barrier Functions to deﬁne the space\n",
            "of admissible control actions that are probabilistically safe with formally provable\n",
            "theoretical guarantee. By formulating the chance constrained safety set into deter-\n",
            "ministic control constraints with PrSBC, the method entails minimally modifying\n",
            "an existing controller to determine an alternative safe controller via quadratic pro-\n",
            "gramming constrained to PrSBC constraints. The key advantage of the approach\n",
            "is that no assumptions about the form of uncertainty are required other than ﬁnite\n",
            "support, also enabling worst-case guarantees. We demonstrate effectiveness of the\n",
            "approach through experiments on realistic simulation environments.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "10 . Learning Physical Graph Representations from Visual Scenes https://papers.nips.cc/paper/2020/file/4324e8d0d37b110ee1a4f1633ac52df5-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Convolutional Neural Networks (CNNs) have proved exceptional at learning repre-\n",
            "sentations for visual object categorization. However, CNNs do not explicitly encode\n",
            "objects, parts, and their physical properties, which has limited CNNs’ success on\n",
            "tasks that require structured understanding of visual scenes. To overcome these lim-\n",
            "itations, we introduce the idea of “Physical Scene Graphs” (PSGs), which represent\n",
            "scenes as hierarchical graphs, with nodes in the hierarchy corresponding intuitively\n",
            "to object parts at different scales, and edges to physical connections between parts.\n",
            "Bound to each node is a vector of latent attributes that intuitively represent ob-\n",
            "ject properties such as surface shape and texture. We also describe PSGNet, a\n",
            "network architecture that learns to extract PSGs by reconstructing scenes through\n",
            "a PSG-structured bottleneck. PSGNet augments standard CNNs by including:\n",
            "recurrent feedback connections to combine low and high-level image information;\n",
            "graph pooling and vectorization operations that convert spatially-uniform feature\n",
            "maps into object-centric graph structures; and perceptual grouping principles to\n",
            "encourage the identiﬁcation of meaningful scene elements. We show that PSGNet\n",
            "outperforms alternative self-supervised scene representation algorithms at scene\n",
            "segmentation tasks, especially on complex real-world images, and generalizes well\n",
            "to unseen object types and scene arrangements. PSGNet is also able learn from\n",
            "physical motion, enhancing scene estimates even for static images. We present a\n",
            "series of ablation studies illustrating the importance of each component of the PS-\n",
            "GNet architecture, analyses showing that learned latent attributes capture intuitive\n",
            "scene properties, and illustrate the use of PSGs for compositional scene inference.\n",
            "\n",
            "\n",
            "**********************************************\n",
            "data:                                                topic  ...                                                url\n",
            "0  fast flexible temporal point processes triangu...  ...  https://papers.nips.cc/paper/2020/hash/00ac8ed...\n",
            "1  fast flexible temporal point processes triangu...  ...  https://papers.nips.cc/paper/2020/file/00ac8ed...\n",
            "2  fast flexible temporal point processes triangu...  ...                  https://papers.nips.cc/paper/2020\n",
            "3  fast flexible temporal point processes triangu...  ...  https://papers.nips.cc/paper/2020/file/4db7386...\n",
            "4  fast flexible temporal point processes triangu...  ...  https://papers.nips.cc/paper/2020/file/5d44ee6...\n",
            "5  fast flexible temporal point processes triangu...  ...  https://papers.nips.cc/paper/2020/file/385822e...\n",
            "6  fast flexible temporal point processes triangu...  ...  https://papers.nips.cc/paper/2020/file/354ac34...\n",
            "7  fast flexible temporal point processes triangu...  ...  https://papers.nips.cc/paper/2020/file/2df4524...\n",
            "8  fast flexible temporal point processes triangu...  ...  https://papers.nips.cc/paper/2020/file/03793ef...\n",
            "9  fast flexible temporal point processes triangu...  ...  https://papers.nips.cc/paper/2020/file/4324e8d...\n",
            "\n",
            "[10 rows x 4 columns]\n",
            "**********************************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                                               topic  ... similarity_score\n",
            "0  fast flexible temporal point processes triangu...  ...         0.966598\n",
            "1  fast flexible temporal point processes triangu...  ...         0.967060\n",
            "2  fast flexible temporal point processes triangu...  ...         0.966444\n",
            "3  fast flexible temporal point processes triangu...  ...         0.967060\n",
            "4  fast flexible temporal point processes triangu...  ...         0.965445\n",
            "5  fast flexible temporal point processes triangu...  ...         0.961598\n",
            "6  fast flexible temporal point processes triangu...  ...         0.966305\n",
            "7  fast flexible temporal point processes triangu...  ...         0.962180\n",
            "8  fast flexible temporal point processes triangu...  ...         0.963151\n",
            "9  fast flexible temporal point processes triangu...  ...         0.962566\n",
            "\n",
            "[10 rows x 5 columns]\n",
            "df_final after rank=                                                topic  ...  rank\n",
            "0  fast flexible temporal point processes triangu...  ...   3.0\n",
            "1  fast flexible temporal point processes triangu...  ...   2.0\n",
            "2  fast flexible temporal point processes triangu...  ...   4.0\n",
            "3  fast flexible temporal point processes triangu...  ...   2.0\n",
            "4  fast flexible temporal point processes triangu...  ...   6.0\n",
            "5  fast flexible temporal point processes triangu...  ...  10.0\n",
            "6  fast flexible temporal point processes triangu...  ...   5.0\n",
            "7  fast flexible temporal point processes triangu...  ...   9.0\n",
            "8  fast flexible temporal point processes triangu...  ...   7.0\n",
            "9  fast flexible temporal point processes triangu...  ...   8.0\n",
            "\n",
            "[10 rows x 6 columns]\n",
            "0    Fast and Flexible Temporal Point Processes wit...\n",
            "1    Abstract\\n\\nTemporal point process (TPP) model...\n",
            "2    Book\\n\\nDo not remove: This comment is monitor...\n",
            "3    Abstract\\n\\nTemporal point process (TPP) model...\n",
            "4    Abstract\\n\\nStochastic Approximation (SA) is a...\n",
            "5    Abstract\\n\\nTo operate effectively in the real...\n",
            "6    Abstract\\n\\nThe current dominant paradigm in s...\n",
            "7    Abstract\\n\\nReinforcement learning with sparse...\n",
            "8    Abstract\\n\\nSafety in terms of collision avoid...\n",
            "9    Abstract\\n\\nConvolutional Neural Networks (CNN...\n",
            "Name: text, dtype: object\n",
            "Fast\n",
            "and\n",
            "Flexible\n",
            "Temporal\n",
            "Point\n",
            "Processes\n",
            "with\n",
            "Triangular\n",
            "Maps\n",
            "Part\n",
            "of\n",
            "Advances\n",
            "in\n",
            "Neural\n",
            "Information\n",
            "Processing\n",
            "Systems\n",
            "33\n",
            "(\n",
            "NeurIPS\n",
            "2020\n",
            ")\n",
            "Authors\n",
            "Oleksandr\n",
            "Shchur\n",
            ",\n",
            "Nicholas\n",
            "Gao\n",
            ",\n",
            "Marin\n",
            "Biloš\n",
            ",\n",
            "Stephan\n",
            "Günnemann\n",
            "Abstract\n",
            "Temporal\n",
            "point\n",
            "process\n",
            "(\n",
            "TPP\n",
            ")\n",
            "models\n",
            "combined\n",
            "with\n",
            "recurrent\n",
            "neural\n",
            "networks\n",
            "provide\n",
            "a\n",
            "powerful\n",
            "framework\n",
            "for\n",
            "modeling\n",
            "continuous-time\n",
            "event\n",
            "data\n",
            ".\n",
            "While\n",
            "such\n",
            "models\n",
            "are\n",
            "flexible\n",
            ",\n",
            "they\n",
            "are\n",
            "inherently\n",
            "sequential\n",
            "and\n",
            "therefore\n",
            "can\n",
            "not\n",
            "benefit\n",
            "from\n",
            "the\n",
            "parallelism\n",
            "of\n",
            "modern\n",
            "hardware\n",
            ".\n",
            "By\n",
            "exploiting\n",
            "the\n",
            "recent\n",
            "developments\n",
            "in\n",
            "the\n",
            "field\n",
            "of\n",
            "normalizing\n",
            "flows\n",
            ",\n",
            "we\n",
            "design\n",
            "TriTPP\n",
            "-\n",
            "a\n",
            "new\n",
            "class\n",
            "of\n",
            "non-recurrent\n",
            "TPP\n",
            "models\n",
            ",\n",
            "where\n",
            "both\n",
            "sampling\n",
            "and\n",
            "likelihood\n",
            "computation\n",
            "can\n",
            "be\n",
            "done\n",
            "in\n",
            "parallel\n",
            ".\n",
            "TriTPP\n",
            "matches\n",
            "the\n",
            "flexibility\n",
            "of\n",
            "RNN-based\n",
            "methods\n",
            "but\n",
            "permits\n",
            "several\n",
            "orders\n",
            "of\n",
            "magnitude\n",
            "faster\n",
            "sampling\n",
            ".\n",
            "This\n",
            "enables\n",
            "us\n",
            "to\n",
            "use\n",
            "the\n",
            "new\n",
            "model\n",
            "for\n",
            "variational\n",
            "inference\n",
            "in\n",
            "continuous-time\n",
            "discrete-state\n",
            "systems\n",
            ".\n",
            "We\n",
            "demonstrate\n",
            "the\n",
            "advantages\n",
            "of\n",
            "the\n",
            "proposed\n",
            "framework\n",
            "on\n",
            "synthetic\n",
            "and\n",
            "real-world\n",
            "datasets\n",
            ".\n",
            "Abstract\n",
            "Temporal\n",
            "point\n",
            "process\n",
            "(\n",
            "TPP\n",
            ")\n",
            "models\n",
            "combined\n",
            "with\n",
            "recurrent\n",
            "neural\n",
            "networks\n",
            "provide\n",
            "a\n",
            "powerful\n",
            "framework\n",
            "for\n",
            "modeling\n",
            "continuous-time\n",
            "event\n",
            "data\n",
            ".\n",
            "While\n",
            "such\n",
            "models\n",
            "are\n",
            "ﬂexible\n",
            ",\n",
            "they\n",
            "are\n",
            "inherently\n",
            "sequential\n",
            "and\n",
            "therefore\n",
            "can\n",
            "not\n",
            "beneﬁt\n",
            "from\n",
            "the\n",
            "parallelism\n",
            "of\n",
            "modern\n",
            "hardware\n",
            ".\n",
            "By\n",
            "exploiting\n",
            "the\n",
            "recent\n",
            "developments\n",
            "in\n",
            "the\n",
            "ﬁeld\n",
            "of\n",
            "normalizing\n",
            "ﬂows\n",
            ",\n",
            "we\n",
            "design\n",
            "TriTPP—\n",
            "a\n",
            "new\n",
            "class\n",
            "of\n",
            "non-recurrent\n",
            "TPP\n",
            "models\n",
            ",\n",
            "where\n",
            "both\n",
            "sampling\n",
            "and\n",
            "likelihood\n",
            "computation\n",
            "can\n",
            "be\n",
            "done\n",
            "in\n",
            "parallel\n",
            ".\n",
            "TriTPP\n",
            "matches\n",
            "the\n",
            "ﬂexibility\n",
            "of\n",
            "RNN-based\n",
            "methods\n",
            "but\n",
            "permits\n",
            "orders\n",
            "of\n",
            "magnitude\n",
            "faster\n",
            "sampling\n",
            ".\n",
            "This\n",
            "enables\n",
            "us\n",
            "to\n",
            "use\n",
            "the\n",
            "new\n",
            "model\n",
            "for\n",
            "variational\n",
            "inference\n",
            "in\n",
            "continuous-time\n",
            "discrete-state\n",
            "systems\n",
            ".\n",
            "We\n",
            "demonstrate\n",
            "the\n",
            "advantages\n",
            "of\n",
            "the\n",
            "proposed\n",
            "framework\n",
            "on\n",
            "synthetic\n",
            "and\n",
            "real-world\n",
            "datasets\n",
            ".\n",
            "1\n",
            "Book\n",
            "Do\n",
            "not\n",
            "remove\n",
            ":\n",
            "This\n",
            "comment\n",
            "is\n",
            "monitored\n",
            "to\n",
            "verify\n",
            "that\n",
            "the\n",
            "site\n",
            "is\n",
            "working\n",
            "properly\n",
            "Abstract\n",
            "Temporal\n",
            "point\n",
            "process\n",
            "(\n",
            "TPP\n",
            ")\n",
            "models\n",
            "combined\n",
            "with\n",
            "recurrent\n",
            "neural\n",
            "networks\n",
            "provide\n",
            "a\n",
            "powerful\n",
            "framework\n",
            "for\n",
            "modeling\n",
            "continuous-time\n",
            "event\n",
            "data\n",
            ".\n",
            "While\n",
            "such\n",
            "models\n",
            "are\n",
            "ﬂexible\n",
            ",\n",
            "they\n",
            "are\n",
            "inherently\n",
            "sequential\n",
            "and\n",
            "therefore\n",
            "can\n",
            "not\n",
            "beneﬁt\n",
            "from\n",
            "the\n",
            "parallelism\n",
            "of\n",
            "modern\n",
            "hardware\n",
            ".\n",
            "By\n",
            "exploiting\n",
            "the\n",
            "recent\n",
            "developments\n",
            "in\n",
            "the\n",
            "ﬁeld\n",
            "of\n",
            "normalizing\n",
            "ﬂows\n",
            ",\n",
            "we\n",
            "design\n",
            "TriTPP—\n",
            "a\n",
            "new\n",
            "class\n",
            "of\n",
            "non-recurrent\n",
            "TPP\n",
            "models\n",
            ",\n",
            "where\n",
            "both\n",
            "sampling\n",
            "and\n",
            "likelihood\n",
            "computation\n",
            "can\n",
            "be\n",
            "done\n",
            "in\n",
            "parallel\n",
            ".\n",
            "TriTPP\n",
            "matches\n",
            "the\n",
            "ﬂexibility\n",
            "of\n",
            "RNN-based\n",
            "methods\n",
            "but\n",
            "permits\n",
            "orders\n",
            "of\n",
            "magnitude\n",
            "faster\n",
            "sampling\n",
            ".\n",
            "This\n",
            "enables\n",
            "us\n",
            "to\n",
            "use\n",
            "the\n",
            "new\n",
            "model\n",
            "for\n",
            "variational\n",
            "inference\n",
            "in\n",
            "continuous-time\n",
            "discrete-state\n",
            "systems\n",
            ".\n",
            "We\n",
            "demonstrate\n",
            "the\n",
            "advantages\n",
            "of\n",
            "the\n",
            "proposed\n",
            "framework\n",
            "on\n",
            "synthetic\n",
            "and\n",
            "real-world\n",
            "datasets\n",
            ".\n",
            "1\n",
            "Abstract\n",
            "Stochastic\n",
            "Approximation\n",
            "(\n",
            "SA\n",
            ")\n",
            "is\n",
            "a\n",
            "popular\n",
            "approach\n",
            "for\n",
            "solving\n",
            "ﬁxed-point\n",
            "equations\n",
            "where\n",
            "the\n",
            "information\n",
            "is\n",
            "corrupted\n",
            "by\n",
            "noise\n",
            ".\n",
            "In\n",
            "this\n",
            "paper\n",
            ",\n",
            "we\n",
            "consider\n",
            "an\n",
            "SA\n",
            "involving\n",
            "a\n",
            "contraction\n",
            "mapping\n",
            "with\n",
            "respect\n",
            "to\n",
            "an\n",
            "arbitrary\n",
            "norm\n",
            ",\n",
            "and\n",
            "show\n",
            "its\n",
            "ﬁnite-sample\n",
            "error\n",
            "bounds\n",
            "while\n",
            "using\n",
            "different\n",
            "stepsizes\n",
            ".\n",
            "The\n",
            "idea\n",
            "is\n",
            "to\n",
            "construct\n",
            "a\n",
            "smooth\n",
            "Lyapunov\n",
            "function\n",
            "using\n",
            "the\n",
            "generalized\n",
            "Moreau\n",
            "envelope\n",
            ",\n",
            "and\n",
            "show\n",
            "that\n",
            "the\n",
            "iterates\n",
            "of\n",
            "SA\n",
            "have\n",
            "negative\n",
            "drift\n",
            "with\n",
            "respect\n",
            "to\n",
            "that\n",
            "Lyapunov\n",
            "function\n",
            ".\n",
            "Our\n",
            "result\n",
            "is\n",
            "applicable\n",
            "in\n",
            "Reinforcement\n",
            "Learning\n",
            "(\n",
            "RL\n",
            ")\n",
            ".\n",
            "In\n",
            "particular\n",
            ",\n",
            "we\n",
            "use\n",
            "it\n",
            "to\n",
            "establish\n",
            "the\n",
            "ﬁrst-known\n",
            "convergence\n",
            "rate\n",
            "of\n",
            "the\n",
            "V-trace\n",
            "algorithm\n",
            "for\n",
            "off-policy\n",
            "TD-learning\n",
            "[\n",
            "18\n",
            "]\n",
            ".\n",
            "Importantly\n",
            ",\n",
            "our\n",
            "construction\n",
            "results\n",
            "in\n",
            "only\n",
            "a\n",
            "logarithmic\n",
            "dependence\n",
            "of\n",
            "the\n",
            "convergence\n",
            "bound\n",
            "on\n",
            "the\n",
            "size\n",
            "of\n",
            "the\n",
            "state-space\n",
            ".\n",
            "1\n",
            "Abstract\n",
            "To\n",
            "operate\n",
            "effectively\n",
            "in\n",
            "the\n",
            "real\n",
            "world\n",
            ",\n",
            "agents\n",
            "should\n",
            "be\n",
            "able\n",
            "to\n",
            "act\n",
            "from\n",
            "high-\n",
            "dimensional\n",
            "raw\n",
            "sensory\n",
            "input\n",
            "such\n",
            "as\n",
            "images\n",
            "and\n",
            "achieve\n",
            "diverse\n",
            "goals\n",
            "across\n",
            "long\n",
            "time-horizons\n",
            ".\n",
            "Current\n",
            "deep\n",
            "reinforcement\n",
            "and\n",
            "imitation\n",
            "learning\n",
            "methods\n",
            "can\n",
            "learn\n",
            "directly\n",
            "from\n",
            "high-dimensional\n",
            "inputs\n",
            "but\n",
            "do\n",
            "not\n",
            "scale\n",
            "well\n",
            "to\n",
            "long-horizon\n",
            "tasks\n",
            ".\n",
            "In\n",
            "contrast\n",
            ",\n",
            "classical\n",
            "graphical\n",
            "methods\n",
            "like\n",
            "A\n",
            "*\n",
            "search\n",
            "are\n",
            "able\n",
            "to\n",
            "solve\n",
            "long-horizon\n",
            "tasks\n",
            ",\n",
            "but\n",
            "assume\n",
            "that\n",
            "the\n",
            "state\n",
            "space\n",
            "is\n",
            "abstracted\n",
            "away\n",
            "from\n",
            "raw\n",
            "sensory\n",
            "input\n",
            ".\n",
            "Recent\n",
            "works\n",
            "have\n",
            "attempted\n",
            "to\n",
            "combine\n",
            "the\n",
            "strengths\n",
            "of\n",
            "deep\n",
            "learning\n",
            "and\n",
            "classical\n",
            "planning\n",
            ";\n",
            "however\n",
            ",\n",
            "dominant\n",
            "methods\n",
            "in\n",
            "this\n",
            "domain\n",
            "are\n",
            "still\n",
            "quite\n",
            "brittle\n",
            "and\n",
            "scale\n",
            "poorly\n",
            "with\n",
            "the\n",
            "size\n",
            "of\n",
            "the\n",
            "environment\n",
            ".\n",
            "We\n",
            "introduce\n",
            "Sparse\n",
            "Graphical\n",
            "Memory\n",
            "(\n",
            "SGM\n",
            ")\n",
            ",\n",
            "a\n",
            "new\n",
            "data\n",
            "structure\n",
            "that\n",
            "stores\n",
            "states\n",
            "and\n",
            "feasible\n",
            "transitions\n",
            "in\n",
            "a\n",
            "sparse\n",
            "memory\n",
            ".\n",
            "SGM\n",
            "aggregates\n",
            "states\n",
            "according\n",
            "to\n",
            "a\n",
            "novel\n",
            "two-way\n",
            "consistency\n",
            "objective\n",
            ",\n",
            "adapting\n",
            "classic\n",
            "state\n",
            "aggregation\n",
            "criteria\n",
            "to\n",
            "goal-conditioned\n",
            "RL\n",
            ":\n",
            "two\n",
            "states\n",
            "are\n",
            "redundant\n",
            "when\n",
            "they\n",
            "are\n",
            "interchangeable\n",
            "both\n",
            "as\n",
            "goals\n",
            "and\n",
            "as\n",
            "starting\n",
            "states\n",
            ".\n",
            "Theoretically\n",
            ",\n",
            "we\n",
            "prove\n",
            "that\n",
            "merging\n",
            "nodes\n",
            "according\n",
            "to\n",
            "two-way\n",
            "consistency\n",
            "leads\n",
            "to\n",
            "an\n",
            "increase\n",
            "in\n",
            "shortest\n",
            "path\n",
            "lengths\n",
            "that\n",
            "scales\n",
            "only\n",
            "linearly\n",
            "with\n",
            "the\n",
            "merging\n",
            "threshold\n",
            ".\n",
            "Experimentally\n",
            ",\n",
            "we\n",
            "show\n",
            "that\n",
            "SGM\n",
            "signiﬁcantly\n",
            "outperforms\n",
            "current\n",
            "state\n",
            "of\n",
            "the\n",
            "art\n",
            "methods\n",
            "on\n",
            "long\n",
            "horizon\n",
            ",\n",
            "sparse-\n",
            "reward\n",
            "visual\n",
            "navigation\n",
            "tasks\n",
            ".\n",
            "Project\n",
            "video\n",
            "and\n",
            "code\n",
            "are\n",
            "available\n",
            "at\n",
            "https\n",
            ":\n",
            "//mishalaskin.github.io/sgm/\n",
            ".\n",
            "1\n",
            "Abstract\n",
            "The\n",
            "current\n",
            "dominant\n",
            "paradigm\n",
            "in\n",
            "sensorimotor\n",
            "control\n",
            ",\n",
            "whether\n",
            "imitation\n",
            "or\n",
            "reinforcement\n",
            "learning\n",
            ",\n",
            "is\n",
            "to\n",
            "train\n",
            "policies\n",
            "directly\n",
            "in\n",
            "raw\n",
            "action\n",
            "spaces\n",
            "such\n",
            "as\n",
            "torque\n",
            ",\n",
            "joint\n",
            "angle\n",
            ",\n",
            "or\n",
            "end-effector\n",
            "position\n",
            ".\n",
            "This\n",
            "forces\n",
            "the\n",
            "agent\n",
            "to\n",
            "make\n",
            "decision\n",
            "at\n",
            "each\n",
            "point\n",
            "in\n",
            "training\n",
            ",\n",
            "and\n",
            "hence\n",
            ",\n",
            "limit\n",
            "the\n",
            "scalability\n",
            "to\n",
            "continuous\n",
            ",\n",
            "high-dimensional\n",
            ",\n",
            "and\n",
            "long-horizon\n",
            "tasks\n",
            ".\n",
            "In\n",
            "contrast\n",
            ",\n",
            "research\n",
            "in\n",
            "classical\n",
            "robotics\n",
            "has\n",
            ",\n",
            "for\n",
            "a\n",
            "long\n",
            "time\n",
            ",\n",
            "exploited\n",
            "dynamical\n",
            "systems\n",
            "as\n",
            "a\n",
            "policy\n",
            "representation\n",
            "to\n",
            "learn\n",
            "robot\n",
            "behaviors\n",
            "via\n",
            "demonstrations\n",
            ".\n",
            "These\n",
            "techniques\n",
            ",\n",
            "however\n",
            ",\n",
            "lack\n",
            "the\n",
            "ﬂexibility\n",
            "and\n",
            "generalizability\n",
            "provided\n",
            "by\n",
            "deep\n",
            "learning\n",
            "or\n",
            "deep\n",
            "reinforcement\n",
            "learning\n",
            "and\n",
            "have\n",
            "remained\n",
            "under-explored\n",
            "in\n",
            "such\n",
            "settings\n",
            ".\n",
            "In\n",
            "this\n",
            "work\n",
            ",\n",
            "we\n",
            "begin\n",
            "to\n",
            "close\n",
            "this\n",
            "gap\n",
            "and\n",
            "embed\n",
            "dynamics\n",
            "structure\n",
            "into\n",
            "deep\n",
            "neural\n",
            "network-based\n",
            "policies\n",
            "by\n",
            "reparameterizing\n",
            "action\n",
            "spaces\n",
            "with\n",
            "differential\n",
            "equations\n",
            ".\n",
            "We\n",
            "propose\n",
            "Neural\n",
            "Dynamic\n",
            "Policies\n",
            "(\n",
            "NDPs\n",
            ")\n",
            "that\n",
            "make\n",
            "predictions\n",
            "in\n",
            "trajectory\n",
            "distribution\n",
            "space\n",
            "as\n",
            "opposed\n",
            "to\n",
            "prior\n",
            "policy\n",
            "learning\n",
            "methods\n",
            "where\n",
            "action\n",
            "represents\n",
            "the\n",
            "raw\n",
            "control\n",
            "space\n",
            ".\n",
            "The\n",
            "embedded\n",
            "structure\n",
            "allow\n",
            "us\n",
            "to\n",
            "perform\n",
            "end-to-end\n",
            "policy\n",
            "learning\n",
            "under\n",
            "both\n",
            "reinforcement\n",
            "and\n",
            "imitation\n",
            "learning\n",
            "setups\n",
            ".\n",
            "We\n",
            "show\n",
            "that\n",
            "NDPs\n",
            "achieve\n",
            "better\n",
            "or\n",
            "comparable\n",
            "performance\n",
            "to\n",
            "state-of-the-art\n",
            "approaches\n",
            "on\n",
            "many\n",
            "robotic\n",
            "control\n",
            "tasks\n",
            "using\n",
            "both\n",
            "reward-based\n",
            "training\n",
            "and\n",
            "demonstrations\n",
            ".\n",
            "Project\n",
            "video\n",
            "and\n",
            "code\n",
            "are\n",
            "available\n",
            "at\n",
            ":\n",
            "https\n",
            ":\n",
            "//shikharbahl.github.io/\n",
            "neural-dynamic-policies/\n",
            ".\n",
            "1\n",
            "Abstract\n",
            "Reinforcement\n",
            "learning\n",
            "with\n",
            "sparse\n",
            "rewards\n",
            "is\n",
            "challenging\n",
            "because\n",
            "an\n",
            "agent\n",
            "can\n",
            "rarely\n",
            "obtain\n",
            "non-zero\n",
            "rewards\n",
            "and\n",
            "hence\n",
            ",\n",
            "gradient-based\n",
            "optimization\n",
            "of\n",
            "param-\n",
            "eterized\n",
            "policies\n",
            "can\n",
            "be\n",
            "incremental\n",
            "and\n",
            "slow\n",
            ".\n",
            "Recent\n",
            "work\n",
            "demonstrated\n",
            "that\n",
            "using\n",
            "a\n",
            "memory\n",
            "buffer\n",
            "of\n",
            "previous\n",
            "successful\n",
            "trajectories\n",
            "can\n",
            "result\n",
            "in\n",
            "more\n",
            "ef-\n",
            "fective\n",
            "policies\n",
            ".\n",
            "However\n",
            ",\n",
            "existing\n",
            "methods\n",
            "may\n",
            "overly\n",
            "exploit\n",
            "past\n",
            "successful\n",
            "experiences\n",
            ",\n",
            "which\n",
            "can\n",
            "encourage\n",
            "the\n",
            "agent\n",
            "to\n",
            "adopt\n",
            "sub-optimal\n",
            "and\n",
            "myopic\n",
            "behaviors\n",
            ".\n",
            "In\n",
            "this\n",
            "work\n",
            ",\n",
            "instead\n",
            "of\n",
            "focusing\n",
            "on\n",
            "good\n",
            "experiences\n",
            "with\n",
            "limited\n",
            "diversity\n",
            ",\n",
            "we\n",
            "propose\n",
            "to\n",
            "learn\n",
            "a\n",
            "trajectory-conditioned\n",
            "policy\n",
            "to\n",
            "follow\n",
            "and\n",
            "expand\n",
            "diverse\n",
            "past\n",
            "trajectories\n",
            "from\n",
            "a\n",
            "memory\n",
            "buffer\n",
            ".\n",
            "Our\n",
            "method\n",
            "allows\n",
            "the\n",
            "agent\n",
            "to\n",
            "reach\n",
            "diverse\n",
            "regions\n",
            "in\n",
            "the\n",
            "state\n",
            "space\n",
            "and\n",
            "improve\n",
            "upon\n",
            "the\n",
            "past\n",
            "trajectories\n",
            "to\n",
            "reach\n",
            "new\n",
            "states\n",
            ".\n",
            "We\n",
            "empirically\n",
            "show\n",
            "that\n",
            "our\n",
            "approach\n",
            "signiﬁcantly\n",
            "outperforms\n",
            "count-based\n",
            "exploration\n",
            "methods\n",
            "(\n",
            "parametric\n",
            "approach\n",
            ")\n",
            "and\n",
            "self-imitation\n",
            "learning\n",
            "(\n",
            "parametric\n",
            "approach\n",
            "with\n",
            "non-parametric\n",
            "memory\n",
            ")\n",
            "on\n",
            "various\n",
            "complex\n",
            "tasks\n",
            "with\n",
            "local\n",
            "optima\n",
            ".\n",
            "In\n",
            "particular\n",
            ",\n",
            "without\n",
            "using\n",
            "expert\n",
            "demonstrations\n",
            "or\n",
            "resetting\n",
            "to\n",
            "arbitrary\n",
            "states\n",
            ",\n",
            "we\n",
            "achieve\n",
            "the\n",
            "state-of-the-art\n",
            "scores\n",
            "under\n",
            "ﬁve\n",
            "billion\n",
            "number\n",
            "of\n",
            "frames\n",
            ",\n",
            "on\n",
            "challenging\n",
            "Atari\n",
            "games\n",
            "such\n",
            "as\n",
            "Montezuma\n",
            "’\n",
            "s\n",
            "Revenge\n",
            "and\n",
            "Pitfall\n",
            ".\n",
            "Abstract\n",
            "Safety\n",
            "in\n",
            "terms\n",
            "of\n",
            "collision\n",
            "avoidance\n",
            "for\n",
            "multi-robot\n",
            "systems\n",
            "is\n",
            "a\n",
            "difﬁcult\n",
            "challenge\n",
            "under\n",
            "uncertainty\n",
            ",\n",
            "non-determinism\n",
            "and\n",
            "lack\n",
            "of\n",
            "complete\n",
            "information\n",
            ".\n",
            "This\n",
            "paper\n",
            "aims\n",
            "to\n",
            "propose\n",
            "a\n",
            "collision\n",
            "avoidance\n",
            "method\n",
            "that\n",
            "accounts\n",
            "for\n",
            "both\n",
            "measurement\n",
            "uncertainty\n",
            "and\n",
            "motion\n",
            "uncertainty\n",
            ".\n",
            "In\n",
            "particular\n",
            ",\n",
            "we\n",
            "propose\n",
            "Probabilistic\n",
            "Safety\n",
            "Barrier\n",
            "Certiﬁcates\n",
            "(\n",
            "PrSBC\n",
            ")\n",
            "using\n",
            "Control\n",
            "Barrier\n",
            "Functions\n",
            "to\n",
            "deﬁne\n",
            "the\n",
            "space\n",
            "of\n",
            "admissible\n",
            "control\n",
            "actions\n",
            "that\n",
            "are\n",
            "probabilistically\n",
            "safe\n",
            "with\n",
            "formally\n",
            "provable\n",
            "theoretical\n",
            "guarantee\n",
            ".\n",
            "By\n",
            "formulating\n",
            "the\n",
            "chance\n",
            "constrained\n",
            "safety\n",
            "set\n",
            "into\n",
            "deter-\n",
            "ministic\n",
            "control\n",
            "constraints\n",
            "with\n",
            "PrSBC\n",
            ",\n",
            "the\n",
            "method\n",
            "entails\n",
            "minimally\n",
            "modifying\n",
            "an\n",
            "existing\n",
            "controller\n",
            "to\n",
            "determine\n",
            "an\n",
            "alternative\n",
            "safe\n",
            "controller\n",
            "via\n",
            "quadratic\n",
            "pro-\n",
            "gramming\n",
            "constrained\n",
            "to\n",
            "PrSBC\n",
            "constraints\n",
            ".\n",
            "The\n",
            "key\n",
            "advantage\n",
            "of\n",
            "the\n",
            "approach\n",
            "is\n",
            "that\n",
            "no\n",
            "assumptions\n",
            "about\n",
            "the\n",
            "form\n",
            "of\n",
            "uncertainty\n",
            "are\n",
            "required\n",
            "other\n",
            "than\n",
            "ﬁnite\n",
            "support\n",
            ",\n",
            "also\n",
            "enabling\n",
            "worst-case\n",
            "guarantees\n",
            ".\n",
            "We\n",
            "demonstrate\n",
            "effectiveness\n",
            "of\n",
            "the\n",
            "approach\n",
            "through\n",
            "experiments\n",
            "on\n",
            "realistic\n",
            "simulation\n",
            "environments\n",
            ".\n",
            "1\n",
            "Abstract\n",
            "Convolutional\n",
            "Neural\n",
            "Networks\n",
            "(\n",
            "CNNs\n",
            ")\n",
            "have\n",
            "proved\n",
            "exceptional\n",
            "at\n",
            "learning\n",
            "repre-\n",
            "sentations\n",
            "for\n",
            "visual\n",
            "object\n",
            "categorization\n",
            ".\n",
            "However\n",
            ",\n",
            "CNNs\n",
            "do\n",
            "not\n",
            "explicitly\n",
            "encode\n",
            "objects\n",
            ",\n",
            "parts\n",
            ",\n",
            "and\n",
            "their\n",
            "physical\n",
            "properties\n",
            ",\n",
            "which\n",
            "has\n",
            "limited\n",
            "CNNs\n",
            "’\n",
            "success\n",
            "on\n",
            "tasks\n",
            "that\n",
            "require\n",
            "structured\n",
            "understanding\n",
            "of\n",
            "visual\n",
            "scenes\n",
            ".\n",
            "To\n",
            "overcome\n",
            "these\n",
            "lim-\n",
            "itations\n",
            ",\n",
            "we\n",
            "introduce\n",
            "the\n",
            "idea\n",
            "of\n",
            "“\n",
            "Physical\n",
            "Scene\n",
            "Graphs\n",
            "”\n",
            "(\n",
            "PSGs\n",
            ")\n",
            ",\n",
            "which\n",
            "represent\n",
            "scenes\n",
            "as\n",
            "hierarchical\n",
            "graphs\n",
            ",\n",
            "with\n",
            "nodes\n",
            "in\n",
            "the\n",
            "hierarchy\n",
            "corresponding\n",
            "intuitively\n",
            "to\n",
            "object\n",
            "parts\n",
            "at\n",
            "different\n",
            "scales\n",
            ",\n",
            "and\n",
            "edges\n",
            "to\n",
            "physical\n",
            "connections\n",
            "between\n",
            "parts\n",
            ".\n",
            "Bound\n",
            "to\n",
            "each\n",
            "node\n",
            "is\n",
            "a\n",
            "vector\n",
            "of\n",
            "latent\n",
            "attributes\n",
            "that\n",
            "intuitively\n",
            "represent\n",
            "ob-\n",
            "ject\n",
            "properties\n",
            "such\n",
            "as\n",
            "surface\n",
            "shape\n",
            "and\n",
            "texture\n",
            ".\n",
            "We\n",
            "also\n",
            "describe\n",
            "PSGNet\n",
            ",\n",
            "a\n",
            "network\n",
            "architecture\n",
            "that\n",
            "learns\n",
            "to\n",
            "extract\n",
            "PSGs\n",
            "by\n",
            "reconstructing\n",
            "scenes\n",
            "through\n",
            "a\n",
            "PSG-structured\n",
            "bottleneck\n",
            ".\n",
            "PSGNet\n",
            "augments\n",
            "standard\n",
            "CNNs\n",
            "by\n",
            "including\n",
            ":\n",
            "recurrent\n",
            "feedback\n",
            "connections\n",
            "to\n",
            "combine\n",
            "low\n",
            "and\n",
            "high-level\n",
            "image\n",
            "information\n",
            ";\n",
            "graph\n",
            "pooling\n",
            "and\n",
            "vectorization\n",
            "operations\n",
            "that\n",
            "convert\n",
            "spatially-uniform\n",
            "feature\n",
            "maps\n",
            "into\n",
            "object-centric\n",
            "graph\n",
            "structures\n",
            ";\n",
            "and\n",
            "perceptual\n",
            "grouping\n",
            "principles\n",
            "to\n",
            "encourage\n",
            "the\n",
            "identiﬁcation\n",
            "of\n",
            "meaningful\n",
            "scene\n",
            "elements\n",
            ".\n",
            "We\n",
            "show\n",
            "that\n",
            "PSGNet\n",
            "outperforms\n",
            "alternative\n",
            "self-supervised\n",
            "scene\n",
            "representation\n",
            "algorithms\n",
            "at\n",
            "scene\n",
            "segmentation\n",
            "tasks\n",
            ",\n",
            "especially\n",
            "on\n",
            "complex\n",
            "real-world\n",
            "images\n",
            ",\n",
            "and\n",
            "generalizes\n",
            "well\n",
            "to\n",
            "unseen\n",
            "object\n",
            "types\n",
            "and\n",
            "scene\n",
            "arrangements\n",
            ".\n",
            "PSGNet\n",
            "is\n",
            "also\n",
            "able\n",
            "learn\n",
            "from\n",
            "physical\n",
            "motion\n",
            ",\n",
            "enhancing\n",
            "scene\n",
            "estimates\n",
            "even\n",
            "for\n",
            "static\n",
            "images\n",
            ".\n",
            "We\n",
            "present\n",
            "a\n",
            "series\n",
            "of\n",
            "ablation\n",
            "studies\n",
            "illustrating\n",
            "the\n",
            "importance\n",
            "of\n",
            "each\n",
            "component\n",
            "of\n",
            "the\n",
            "PS-\n",
            "GNet\n",
            "architecture\n",
            ",\n",
            "analyses\n",
            "showing\n",
            "that\n",
            "learned\n",
            "latent\n",
            "attributes\n",
            "capture\n",
            "intuitive\n",
            "scene\n",
            "properties\n",
            ",\n",
            "and\n",
            "illustrate\n",
            "the\n",
            "use\n",
            "of\n",
            "PSGs\n",
            "for\n",
            "compositional\n",
            "scene\n",
            "inference\n",
            ".\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "df_output                                                topic  ... rank_lda\n",
            "0             graph similarity deep learning neurips  ...      6.0\n",
            "1             graph similarity deep learning neurips  ...     10.0\n",
            "2             graph similarity deep learning neurips  ...      2.0\n",
            "3             graph similarity deep learning neurips  ...      5.0\n",
            "4             graph similarity deep learning neurips  ...      1.0\n",
            "5             graph similarity deep learning neurips  ...      8.0\n",
            "6             graph similarity deep learning neurips  ...      4.0\n",
            "7             graph similarity deep learning neurips  ...      3.0\n",
            "8             graph similarity deep learning neurips  ...      7.0\n",
            "9             graph similarity deep learning neurips  ...      9.0\n",
            "0  unsupervised information theoretic perceptual ...  ...     10.0\n",
            "1  unsupervised information theoretic perceptual ...  ...      9.0\n",
            "2  unsupervised information theoretic perceptual ...  ...      8.0\n",
            "3  unsupervised information theoretic perceptual ...  ...      2.0\n",
            "4  unsupervised information theoretic perceptual ...  ...      3.0\n",
            "5  unsupervised information theoretic perceptual ...  ...      5.0\n",
            "6  unsupervised information theoretic perceptual ...  ...      4.0\n",
            "7  unsupervised information theoretic perceptual ...  ...      7.0\n",
            "8  unsupervised information theoretic perceptual ...  ...      1.0\n",
            "9  unsupervised information theoretic perceptual ...  ...      6.0\n",
            "0  self supervised multimodal versatile networks ...  ...      6.0\n",
            "1  self supervised multimodal versatile networks ...  ...      1.0\n",
            "2  self supervised multimodal versatile networks ...  ...      4.0\n",
            "3  self supervised multimodal versatile networks ...  ...      5.0\n",
            "4  self supervised multimodal versatile networks ...  ...      2.0\n",
            "5  self supervised multimodal versatile networks ...  ...      3.0\n",
            "0  benchmarking deep inverse models time neural a...  ...      4.0\n",
            "1  benchmarking deep inverse models time neural a...  ...      7.0\n",
            "2  benchmarking deep inverse models time neural a...  ...      2.0\n",
            "3  benchmarking deep inverse models time neural a...  ...      6.0\n",
            "4  benchmarking deep inverse models time neural a...  ...      3.0\n",
            "5  benchmarking deep inverse models time neural a...  ...      5.0\n",
            "6  benchmarking deep inverse models time neural a...  ...      1.0\n",
            "0  off policy evaluation learning external validi...  ...      3.0\n",
            "1  off policy evaluation learning external validi...  ...      4.0\n",
            "2  off policy evaluation learning external validi...  ...      5.0\n",
            "3  off policy evaluation learning external validi...  ...      1.0\n",
            "4  off policy evaluation learning external validi...  ...      2.0\n",
            "0  neural methods point wise dependency estimatio...  ...      1.0\n",
            "1  neural methods point wise dependency estimatio...  ...      5.0\n",
            "2  neural methods point wise dependency estimatio...  ...      2.0\n",
            "3  neural methods point wise dependency estimatio...  ...      6.0\n",
            "4  neural methods point wise dependency estimatio...  ...      8.0\n",
            "5  neural methods point wise dependency estimatio...  ...      4.0\n",
            "6  neural methods point wise dependency estimatio...  ...      9.0\n",
            "7  neural methods point wise dependency estimatio...  ...     10.0\n",
            "8  neural methods point wise dependency estimatio...  ...      3.0\n",
            "9  neural methods point wise dependency estimatio...  ...      7.0\n",
            "0  fast flexible temporal point processes triangu...  ...      4.0\n",
            "1  fast flexible temporal point processes triangu...  ...      1.0\n",
            "2  fast flexible temporal point processes triangu...  ...      3.0\n",
            "3  fast flexible temporal point processes triangu...  ...      2.0\n",
            "4  fast flexible temporal point processes triangu...  ...      8.0\n",
            "5  fast flexible temporal point processes triangu...  ...     10.0\n",
            "6  fast flexible temporal point processes triangu...  ...      9.0\n",
            "7  fast flexible temporal point processes triangu...  ...      6.0\n",
            "8  fast flexible temporal point processes triangu...  ...      5.0\n",
            "9  fast flexible temporal point processes triangu...  ...      7.0\n",
            "\n",
            "[58 rows x 8 columns]\n",
            "topic:  backpropagating linearly improves transferability adversarial examples neurips id_= 7\n",
            "1 . Backpropagating Linearly Improves Transferability of Adversarial ... https://papers.nips.cc/paper/2020/hash/00e26af6ac3b1c1c49d7c3d79c60d000-Abstract.html\n",
            "**********************************************\n",
            "2 . Backpropagating Linearly Improves Transferability of Adversarial ... https://papers.nips.cc/paper/2020/file/00e26af6ac3b1c1c49d7c3d79c60d000-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "The vulnerability of deep neural networks (DNNs) to adversarial examples has\n",
            "drawn great attention from the community. In this paper, we study the transferability\n",
            "of such examples, which lays the foundation of many black-box attacks on DNNs.\n",
            "We revisit a not so new but deﬁnitely noteworthy hypothesis of Goodfellow et al.’s\n",
            "and disclose that the transferability can be enhanced by improving the linearity of\n",
            "DNNs in an appropriate manner. We introduce linear backpropagation (LinBP), a\n",
            "method that performs backpropagation in a more linear fashion using off-the-shelf\n",
            "attacks that exploit gradients. More speciﬁcally, it calculates forward as normal but\n",
            "backpropagates loss as if some nonlinear activations are not encountered in the for-\n",
            "ward pass. Experimental results demonstrate that this simple yet effective method\n",
            "obviously outperforms current state-of-the-arts in crafting transferable adversarial\n",
            "examples on CIFAR-10 and ImageNet, leading to more effective attacks on a variety\n",
            "of DNNs. Code at: https://github.com/qizhangli/linbp-attack.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "3 . Backpropagating Linearly Improves ... - Review for NeurIPS paper https://papers.nips.cc/paper/2020/file/00e26af6ac3b1c1c49d7c3d79c60d000-MetaReview.html\n",
            "**********************************************\n",
            "4 . Backpropagating Linearly Improves ... - Review for NeurIPS paper https://papers.nips.cc/paper/2020/file/00e26af6ac3b1c1c49d7c3d79c60d000-Review.html\n",
            "**********************************************\n",
            "5 . Backpropagating Linearly Improves Transferability of Adversarial ... https://papers.nips.cc/paper/2020/file/00e26af6ac3b1c1c49d7c3d79c60d000-Supplemental.pdf\n",
            "example.pdf\n",
            "\n",
            "5 . Advances in Neural Information Processing Systems 33 (NeurIPS ... https://papers.nips.cc/paper/2020\n",
            "**********************************************\n",
            "6 . Practical No-box Adversarial Attacks against DNNs https://papers.nips.cc/paper/2020/file/96e07156db854ca7b00b5df21716b0c6-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "The study of adversarial vulnerabilities of deep neural networks (DNNs) has pro-\n",
            "gressed rapidly. Existing attacks require either internal access (to the architecture,\n",
            "parameters, or training set of the victim model) or external access (to query the\n",
            "model). However, both the access may be infeasible or expensive in many scenarios.\n",
            "We investigate no-box adversarial examples, where the attacker can neither access\n",
            "the model information or the training set nor query the model. Instead, the attacker\n",
            "can only gather a small number of examples from the same problem domain as that\n",
            "of the victim model. Such a stronger threat model greatly expands the applicability\n",
            "of adversarial attacks. We propose three mechanisms for training with a very small\n",
            "dataset (on the order of tens of examples) and ﬁnd that prototypical reconstruction\n",
            "is the most effective. Our experiments show that adversarial examples crafted on\n",
            "prototypical auto-encoding models transfer well to a variety of image classiﬁcation\n",
            "and face veriﬁcation models. On a commercial celebrity recognition system held\n",
            "by clarifai.com, our approach signiﬁcantly diminishes the average prediction\n",
            "accuracy of the system to only 15.40%, which is on par with the attack that trans-\n",
            "fers adversarial examples from a pre-trained Arcface model. Our code is publicly\n",
            "available at: https://github.com/qizhangli/nobox-attacks.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "7 . A Causal View on Robustness of Neural Networks https://papers.nips.cc/paper/2020/file/02ed812220b0705fabb868ddbf17ea20-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "We present a causal view on the robustness of neural networks against input manip-\n",
            "ulations, which applies not only to traditional classiﬁcation tasks but also to general\n",
            "measurement data. Based on this view, we design a deep causal manipulation\n",
            "augmented model (deep CAMA) which explicitly models possible manipulations\n",
            "on certain causes leading to changes in the observed effect. We further develop\n",
            "data augmentation and test-time ﬁne-tuning methods to improve deep CAMA’s ro-\n",
            "bustness. When compared with discriminative deep neural networks, our proposed\n",
            "model shows superior robustness against unseen manipulations. As a by-product,\n",
            "our model achieves disentangled representation which separates the representation\n",
            "of manipulations from those of other latent causes.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "8 . Denoised Smoothing: A Provable Defense for Pretrained Classifiers https://papers.nips.cc/paper/2020/file/f9fd2624beefbc7808e4e405d73f57ab-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "We present a method for provably defending any pretrained image classiﬁer against\n",
            "(cid:96)p adversarial attacks. This method, for instance, allows public vision API providers\n",
            "and users to seamlessly convert pretrained non-robust classiﬁcation services into\n",
            "provably robust ones. By prepending a custom-trained denoiser to any off-the-\n",
            "shelf image classiﬁer and using randomized smoothing, we effectively create a\n",
            "new classiﬁer that is guaranteed to be (cid:96)p-robust to adversarial examples, without\n",
            "modifying the pretrained classiﬁer. Our approach applies to both the white-box\n",
            "and the black-box settings of the pretrained classiﬁer. We refer to this defense\n",
            "as denoised smoothing, and we demonstrate its effectiveness through extensive\n",
            "experimentation on ImageNet and CIFAR-10. Finally, we use our approach to\n",
            "provably defend the Azure, Google, AWS, and ClarifAI image classiﬁcation APIs.\n",
            "Our code replicating all the experiments in the paper can be found at: https:\n",
            "//github.com/microsoft/denoised-smoothing1.\n",
            "\n",
            "\n",
            "**********************************************\n",
            "9 . Automatically Learning Compact Quality-aware Surrogates for ... https://papers.nips.cc/paper/2020/file/6d0c932802f6953f70eb20931645fa40-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Solving optimization problems with unknown parameters often requires learning a\n",
            "predictive model to predict the values of the unknown parameters and then solving\n",
            "the problem using these values. Recent work has shown that including the opti-\n",
            "mization problem as a layer in the model training pipeline results in predictions\n",
            "of the unobserved parameters that lead to higher decision quality. Unfortunately,\n",
            "this process comes at a large computational cost because the optimization problem\n",
            "must be solved and differentiated through in each training iteration; furthermore,\n",
            "it may also sometimes fail to improve solution quality due to non-smoothness\n",
            "issues that arise when training through a complex optimization layer. To address\n",
            "these shortcomings, we learn a low-dimensional surrogate model of a large opti-\n",
            "mization problem by representing the feasible space in terms of meta-variables,\n",
            "each of which is a linear combination of the original variables. By training a\n",
            "low-dimensional surrogate model end-to-end, and jointly with the predictive model,\n",
            "we achieve: i) a large reduction in training and inference time; and ii) improved per-\n",
            "formance by focusing attention on the more important variables in the optimization\n",
            "and learning in a smoother space. Empirically, we demonstrate these improvements\n",
            "on a non-convex adversary modeling task, a submodular recommendation task and\n",
            "a convex portfolio optimization task.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "data:                                                topic  ...                                                url\n",
            "0  backpropagating linearly improves transferabil...  ...  https://papers.nips.cc/paper/2020/hash/00e26af...\n",
            "1  backpropagating linearly improves transferabil...  ...  https://papers.nips.cc/paper/2020/file/00e26af...\n",
            "2  backpropagating linearly improves transferabil...  ...  https://papers.nips.cc/paper/2020/file/00e26af...\n",
            "3  backpropagating linearly improves transferabil...  ...  https://papers.nips.cc/paper/2020/file/00e26af...\n",
            "4  backpropagating linearly improves transferabil...  ...                  https://papers.nips.cc/paper/2020\n",
            "5  backpropagating linearly improves transferabil...  ...  https://papers.nips.cc/paper/2020/file/96e0715...\n",
            "6  backpropagating linearly improves transferabil...  ...  https://papers.nips.cc/paper/2020/file/02ed812...\n",
            "7  backpropagating linearly improves transferabil...  ...  https://papers.nips.cc/paper/2020/file/f9fd262...\n",
            "8  backpropagating linearly improves transferabil...  ...  https://papers.nips.cc/paper/2020/file/6d0c932...\n",
            "\n",
            "[9 rows x 4 columns]\n",
            "**********************************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "some\n",
            "key\n",
            "experimental\n",
            "choices\n",
            "require\n",
            "some\n",
            "serious\n",
            "re-working\n",
            "(\n",
            "in\n",
            "the\n",
            "main\n",
            "manuscript\n",
            ",\n",
            "not\n",
            "just\n",
            "in\n",
            "the\n",
            "supplemental\n",
            ")\n",
            ".\n",
            "My\n",
            "suggestions\n",
            "are\n",
            ":\n",
            "-\n",
            "[\n",
            "p0\n",
            "]\n",
            "Improved\n",
            "source\n",
            "target\n",
            "transfer\n",
            "notation\n",
            "for\n",
            "clarity\n",
            "-\n",
            "[\n",
            "p0\n",
            "]\n",
            "Move\n",
            "attack\n",
            "results\n",
            "to\n",
            "16/255\n",
            ",\n",
            "8/255\n",
            ",\n",
            "4/255\n",
            "as\n",
            "to\n",
            "be\n",
            "more\n",
            "fairly\n",
            "compared\n",
            "across\n",
            "contemporary\n",
            "works\n",
            ".\n",
            "Also\n",
            ",\n",
            "remove\n",
            "any\n",
            "discussion\n",
            "of\n",
            "eps=0.1\n",
            "as\n",
            "a\n",
            "main\n",
            "result\n",
            ",\n",
            "it\n",
            "is\n",
            "simply\n",
            "too\n",
            "high\n",
            ".\n",
            "-\n",
            "[\n",
            "p0\n",
            "]\n",
            "Include\n",
            "transfers\n",
            "with\n",
            "other\n",
            "source\n",
            "models\n",
            "for\n",
            "each\n",
            "dataset\n",
            "in\n",
            "the\n",
            "main\n",
            "tables\n",
            ".\n",
            "-\n",
            "[\n",
            "p1\n",
            "]\n",
            "Add\n",
            "some\n",
            "of\n",
            "the\n",
            "other\n",
            "baseline\n",
            "methods\n",
            "(\n",
            "e.g.\n",
            ",\n",
            "momentum\n",
            "iterative\n",
            ")\n",
            "in\n",
            "the\n",
            "main\n",
            "tables\n",
            "-\n",
            "[\n",
            "p2\n",
            "]\n",
            "Include\n",
            "discussion\n",
            "of\n",
            "targeted\n",
            "attacks\n",
            "and/or\n",
            "transfers\n",
            "to\n",
            "robust\n",
            "models\n",
            ".\n",
            "This\n",
            "may\n",
            "be\n",
            "acceptable\n",
            "to\n",
            "go\n",
            "in\n",
            "the\n",
            "supplemental\n",
            "but\n",
            "it\n",
            "would\n",
            "be\n",
            "interesting\n",
            "in\n",
            "the\n",
            "main\n",
            "document\n",
            "if\n",
            "there\n",
            "is\n",
            "room\n",
            ".\n",
            "-\n",
            "Suggestions\n",
            "for\n",
            "saving\n",
            "space\n",
            "to\n",
            "accommodate\n",
            "above\n",
            "changes\n",
            ":\n",
            "It\n",
            "is\n",
            "unnecessary\n",
            "for\n",
            "figure\n",
            "3\n",
            "to\n",
            "take\n",
            "the\n",
            "whole\n",
            "column\n",
            ".\n",
            "Consider\n",
            "putting\n",
            "this\n",
            "in\n",
            "a\n",
            "wrapfigure\n",
            "with\n",
            "~20\n",
            "%\n",
            "of\n",
            "the\n",
            "column\n",
            "width\n",
            "so\n",
            "there\n",
            "is\n",
            "more\n",
            "room\n",
            "for\n",
            "the\n",
            "above\n",
            "changes\n",
            ".\n",
            "Also\n",
            "Table\n",
            "2\n",
            "can\n",
            "be\n",
            "moved\n",
            "to\n",
            "the\n",
            "supplemental\n",
            "as\n",
            "it\n",
            "takes\n",
            "up\n",
            "a\n",
            "lot\n",
            "of\n",
            "room\n",
            "and\n",
            "provides\n",
            "almost\n",
            "no\n",
            "value\n",
            ".\n",
            "Review\n",
            "2\n",
            "Summary\n",
            "and\n",
            "Contributions\n",
            ":\n",
            "The\n",
            "basic\n",
            "premise\n",
            "of\n",
            "the\n",
            "paper\n",
            "is\n",
            "that\n",
            "the\n",
            "transferability\n",
            "of\n",
            "adversarial\n",
            "attacks\n",
            "can\n",
            "be\n",
            "exploited\n",
            "through\n",
            "deliberate\n",
            "use\n",
            "of\n",
            "linear\n",
            "approximations\n",
            ".\n",
            "The\n",
            "approach\n",
            ",\n",
            "dubbed\n",
            "``\n",
            "LinBP\n",
            "''\n",
            ",\n",
            "involves\n",
            "doing\n",
            "forward\n",
            "propagation\n",
            "as\n",
            "normal\n",
            ",\n",
            "but\n",
            "backpropagating\n",
            "``\n",
            "as\n",
            "if\n",
            "some\n",
            "nonlinear\n",
            "activations\n",
            "are\n",
            "not\n",
            "encountered\n",
            "in\n",
            "the\n",
            "forward\n",
            "pass\n",
            "''\n",
            ".\n",
            "The\n",
            "core\n",
            "experimental\n",
            "claim\n",
            "is\n",
            "that\n",
            "this\n",
            "method\n",
            "``\n",
            "obviously\n",
            "outperforms\n",
            "current\n",
            "state-of-the-arts\n",
            "[\n",
            "sic\n",
            "]\n",
            "in\n",
            "crafting\n",
            "transferable\n",
            "adversarial\n",
            "examples\n",
            "on\n",
            "CIFAR-10\n",
            "and\n",
            "ImageNet\n",
            ",\n",
            "leading\n",
            "to\n",
            "more\n",
            "effective\n",
            "attacks\n",
            "on\n",
            "a\n",
            "variety\n",
            "of\n",
            "DNN\n",
            "models\n",
            "''\n",
            ".\n",
            "In\n",
            "the\n",
            "method\n",
            "section\n",
            ",\n",
            "the\n",
            "authors\n",
            "step\n",
            "back\n",
            "to\n",
            "the\n",
            "general\n",
            "``\n",
            "composition\n",
            "of\n",
            "matrix\n",
            "multiplication\n",
            "and\n",
            "elementwise\n",
            "nonlinearities\n",
            "''\n",
            "formulation\n",
            "of\n",
            "MLPs\n",
            "and\n",
            "their\n",
            "special\n",
            "case\n",
            "of\n",
            "convolutional\n",
            "networks\n",
            ",\n",
            "and\n",
            "point\n",
            "out\n",
            "that\n",
            "this\n",
            "provides\n",
            "a\n",
            "straightforward\n",
            "view\n",
            "on\n",
            "how\n",
            "one\n",
            "can\n",
            "make\n",
            "a\n",
            "``\n",
            "less\n",
            "nonlinear\n",
            "''\n",
            "network\n",
            "for\n",
            "a\n",
            "constant\n",
            "number\n",
            "of\n",
            "parameters\n",
            ",\n",
            "by\n",
            "simply\n",
            "omitting\n",
            "a\n",
            "choice\n",
            "of\n",
            "nonlinear\n",
            "activation\n",
            "functions\n",
            ".\n",
            "The\n",
            "argument\n",
            "(\n",
            "which\n",
            "I\n",
            "accept\n",
            ")\n",
            "is\n",
            "that\n",
            "this\n",
            "provides\n",
            "a\n",
            "good\n",
            "experimental\n",
            "framework\n",
            "for\n",
            "comparing\n",
            "the\n",
            "success\n",
            "of\n",
            "transfer\n",
            "attacks\n",
            "with\n",
            "respect\n",
            "to\n",
            "the\n",
            "inclusion\n",
            "or\n",
            "exclusion\n",
            "of\n",
            "nonlinear\n",
            "activations\n",
            ",\n",
            "all\n",
            "else\n",
            "equal\n",
            ".\n",
            "The\n",
            "initial\n",
            "experiment\n",
            "uses\n",
            "this\n",
            "framework\n",
            "to\n",
            "compute\n",
            "attacks\n",
            "on\n",
            "a\n",
            "CIFAR-10\n",
            "VGG-19\n",
            "which\n",
            "finishes\n",
            "with\n",
            "fully\n",
            "linearised\n",
            "layers\n",
            ",\n",
            "and\n",
            "transfer\n",
            "them\n",
            "to\n",
            "WRN\n",
            ",\n",
            "ResNeXt\n",
            ",\n",
            "and\n",
            "DenseNet\n",
            ".\n",
            "The\n",
            "partly-linearised\n",
            "VGG-19\n",
            "is\n",
            "also\n",
            "fine-tuned\n",
            "for\n",
            "the\n",
            "original\n",
            "task\n",
            "before\n",
            "being\n",
            "used\n",
            "to\n",
            "compute\n",
            "transfer\n",
            "attacks\n",
            "(\n",
            "via\n",
            "FGSM\n",
            "and\n",
            "I-FGSM\n",
            ")\n",
            ",\n",
            "and\n",
            "the\n",
            "relationship\n",
            "between\n",
            "the\n",
            "number\n",
            "of\n",
            "fine-tuning\n",
            "epochs\n",
            "and\n",
            "transferability\n",
            "is\n",
            "plotted\n",
            ".\n",
            "They\n",
            "note\n",
            "a\n",
            "quick\n",
            "initial\n",
            "improvement\n",
            ",\n",
            "followed\n",
            "by\n",
            "decline\n",
            ",\n",
            "w.r.t\n",
            ".\n",
            "the\n",
            "number\n",
            "of\n",
            "fine-tuning\n",
            "epochs\n",
            ".\n",
            "The\n",
            "key\n",
            "point\n",
            "here\n",
            "is\n",
            "that\n",
            "for\n",
            "a\n",
            "wide\n",
            "range\n",
            "of\n",
            "fine-tuning\n",
            "epochs\n",
            "(\n",
            "which\n",
            "are\n",
            "partly\n",
            "just\n",
            "to\n",
            "repair\n",
            "the\n",
            "hit\n",
            "to\n",
            "standard\n",
            "classification\n",
            "accuracy\n",
            "of\n",
            "the\n",
            "ad-hoc\n",
            "linearised\n",
            "model\n",
            ")\n",
            ",\n",
            "transferability\n",
            "is\n",
            "noticeably\n",
            "increased\n",
            "compared\n",
            "to\n",
            "using\n",
            "the\n",
            "vanilla\n",
            "base\n",
            "model\n",
            ".\n",
            "They\n",
            "repeat\n",
            "the\n",
            "experiment\n",
            "with\n",
            "the\n",
            "same\n",
            "part-linearised\n",
            "architecture\n",
            "trained\n",
            "from\n",
            "scratch\n",
            ",\n",
            "noting\n",
            "that\n",
            "the\n",
            "results\n",
            "are\n",
            "similar\n",
            "for\n",
            "transferring\n",
            "across\n",
            "architectures\n",
            ",\n",
            "but\n",
            "different\n",
            "in\n",
            "that\n",
            "effectiveness\n",
            "is\n",
            "reduced\n",
            "w.r.t\n",
            ".\n",
            "the\n",
            "original\n",
            "f\n",
            "(\n",
            "i.e\n",
            ".\n",
            "that\n",
            "training\n",
            "from\n",
            "scratch\n",
            "appears\n",
            "to\n",
            "make\n",
            "the\n",
            "architecture\n",
            "as\n",
            "difficult\n",
            "to\n",
            "transfer\n",
            "attack\n",
            "as\n",
            "any\n",
            "other\n",
            ",\n",
            "when\n",
            "parameters\n",
            "are\n",
            "not\n",
            "initially\n",
            "shared\n",
            ")\n",
            ".\n",
            "Using\n",
            "the\n",
            "above\n",
            "(\n",
            "``\n",
            "LinS\n",
            "''\n",
            ")\n",
            "as\n",
            "an\n",
            "initial\n",
            "demonstration\n",
            ",\n",
            "they\n",
            "then\n",
            "present\n",
            "their\n",
            "actual\n",
            "proposal\n",
            ",\n",
            "linear\n",
            "backpropagation\n",
            "(\n",
            "LinBP\n",
            ")\n",
            ",\n",
            "in\n",
            "which\n",
            "the\n",
            "fine-tuning\n",
            "is\n",
            "dropped\n",
            "and\n",
            "the\n",
            "scheme\n",
            "of\n",
            "omitting\n",
            "activation\n",
            "functions\n",
            "during\n",
            "backpropagation\n",
            "(\n",
            "alone\n",
            ")\n",
            "is\n",
            "used\n",
            "instead\n",
            ".\n",
            "They\n",
            "compare\n",
            "the\n",
            "proposal\n",
            "to\n",
            "the\n",
            "initial\n",
            "and\n",
            "optimally\n",
            "fine-tuned\n",
            "linearised\n",
            "networks\n",
            "in\n",
            "the\n",
            "previous\n",
            "demonstration\n",
            ",\n",
            "showing\n",
            "that\n",
            "LinBP\n",
            "is\n",
            "on\n",
            "par\n",
            "with\n",
            "the\n",
            "optimal\n",
            "tuning\n",
            "of\n",
            "LinS\n",
            "and\n",
            "far\n",
            "better\n",
            "than\n",
            "either\n",
            "standard\n",
            "transferred\n",
            "FGSM\n",
            "or\n",
            "I-FGSM\n",
            "attacks\n",
            ",\n",
            "or\n",
            "the\n",
            "initial\n",
            "(\n",
            "non-fine-tuned\n",
            ")\n",
            "LinSs\n",
            ".\n",
            "They\n",
            "also\n",
            "demonstrate\n",
            "a\n",
            "simple\n",
            "scheme\n",
            "for\n",
            "normalising\n",
            "the\n",
            "gradient\n",
            "contributions\n",
            "of\n",
            "the\n",
            "main\n",
            "and\n",
            "residual\n",
            "streams\n",
            "in\n",
            "the\n",
            "presence\n",
            "of\n",
            "skip\n",
            "connections\n",
            ".\n",
            "The\n",
            "main\n",
            "results\n",
            "in\n",
            "the\n",
            "paper\n",
            "concern\n",
            "the\n",
            "relative\n",
            "success\n",
            "in\n",
            "transferring\n",
            "I-FGSM\n",
            "attacks\n",
            "under\n",
            "different\n",
            "norm\n",
            "constraints\n",
            "from\n",
            "a\n",
            "CIFAR-10\n",
            "VGG-19\n",
            "and\n",
            "an\n",
            "ImageNet\n",
            "ResNet-50\n",
            "onto\n",
            "a\n",
            "variety\n",
            "of\n",
            "other\n",
            "architectures\n",
            ",\n",
            "against\n",
            "the\n",
            "vanilla\n",
            "approach\n",
            ",\n",
            "TAP\n",
            ",\n",
            "ILA\n",
            ",\n",
            "and\n",
            "SGM\n",
            ".\n",
            "The\n",
            "variation\n",
            "in\n",
            "results\n",
            "with\n",
            "respect\n",
            "to\n",
            "the\n",
            "choice\n",
            "of\n",
            "base\n",
            "attack\n",
            "is\n",
            "handled\n",
            "in\n",
            "the\n",
            "supplementary\n",
            "material\n",
            "(\n",
            "DI^2-FGSM\n",
            ",\n",
            "PGD\n",
            ",\n",
            "ensemble\n",
            "attack\n",
            ")\n",
            ",\n",
            "and\n",
            "is\n",
            "claimed\n",
            "to\n",
            "confirm\n",
            "the\n",
            "results\n",
            "given\n",
            "in\n",
            "the\n",
            "main\n",
            "paper\n",
            "(\n",
            "though\n",
            "I\n",
            "have\n",
            "not\n",
            "yet\n",
            "fully\n",
            "audited\n",
            "this\n",
            "portion\n",
            "of\n",
            "the\n",
            "claim\n",
            "by\n",
            "covering\n",
            "the\n",
            "supplementary\n",
            "material\n",
            "in\n",
            "detail\n",
            ")\n",
            ".\n",
            "They\n",
            "further\n",
            "demonstrate\n",
            "plots\n",
            "of\n",
            "the\n",
            "performance\n",
            "of\n",
            "LinBP\n",
            "vs.\n",
            "ILA\n",
            "as\n",
            "a\n",
            "function\n",
            "of\n",
            "the\n",
            "location\n",
            "parameter\n",
            "in\n",
            "each\n",
            ",\n",
            "and\n",
            "finally\n",
            ",\n",
            "empirically\n",
            "demonstrate\n",
            "the\n",
            "success\n",
            "of\n",
            "combining\n",
            "LinBP\n",
            "with\n",
            "other\n",
            "methods\n",
            "(\n",
            "SGM\n",
            "and\n",
            "ILA\n",
            ")\n",
            ",\n",
            "vs.\n",
            "LinBP\n",
            "or\n",
            "those\n",
            "methods\n",
            "on\n",
            "their\n",
            "own\n",
            ".\n",
            "Strengths\n",
            ":\n",
            "Of\n",
            "course\n",
            ",\n",
            "all\n",
            "first-order\n",
            "attacks\n",
            "inherently\n",
            ",\n",
            "by\n",
            "definition\n",
            ",\n",
            "involve\n",
            "linear\n",
            "approximation\n",
            "of\n",
            "the\n",
            "networks\n",
            "under\n",
            "attack\n",
            ".\n",
            "However\n",
            ",\n",
            "the\n",
            "claim\n",
            "being\n",
            "made\n",
            "here\n",
            "is\n",
            "effectively\n",
            "that\n",
            "attacking\n",
            "a\n",
            "surrogate\n",
            "network\n",
            "whose\n",
            "local\n",
            "linear\n",
            "approximation\n",
            "would\n",
            "differ\n",
            "from\n",
            "that\n",
            "of\n",
            "the\n",
            "original\n",
            "network\n",
            "by\n",
            "``\n",
            "deactivating\n",
            "''\n",
            "ReLUs\n",
            "(\n",
            "i.e\n",
            ".\n",
            "allowing\n",
            "gradients\n",
            "to\n",
            "represent\n",
            "the\n",
            "effect\n",
            "on\n",
            "the\n",
            "output\n",
            "of\n",
            "moving\n",
            "in\n",
            "or\n",
            "out\n",
            "of\n",
            "the\n",
            "negative\n",
            "input\n",
            "half-line\n",
            ")\n",
            "leads\n",
            "to\n",
            "more\n",
            "transferable\n",
            "attacks\n",
            ".\n",
            "Considering\n",
            "that\n",
            "analytical\n",
            "gradients\n",
            ",\n",
            "in\n",
            "the\n",
            "context\n",
            "of\n",
            "optimisation\n",
            ",\n",
            "inherently\n",
            "suffer\n",
            "from\n",
            "the\n",
            "inability\n",
            "to\n",
            "represent\n",
            "nonlinear\n",
            "changes\n",
            "in\n",
            "the\n",
            "functions\n",
            "they\n",
            "describe\n",
            "and\n",
            "ergo\n",
            "do\n",
            "not\n",
            "accurately\n",
            "predict\n",
            "function\n",
            "values\n",
            "away\n",
            "from\n",
            "the\n",
            "point\n",
            "of\n",
            "approximation\n",
            ",\n",
            "and\n",
            "given\n",
            "the\n",
            "nature\n",
            "of\n",
            "ReLUs\n",
            "in\n",
            "the\n",
            "context\n",
            "of\n",
            "this\n",
            "fact\n",
            "(\n",
            "where\n",
            "such\n",
            "mispredictions\n",
            "can\n",
            "be\n",
            "severe\n",
            "when\n",
            "moving\n",
            "from\n",
            "the\n",
            "positive\n",
            "to\n",
            "negative\n",
            "half-line\n",
            "or\n",
            "vice\n",
            "versa\n",
            ")\n",
            ",\n",
            "I\n",
            "consider\n",
            "the\n",
            "claim\n",
            "itself\n",
            "to\n",
            "be\n",
            "sensible\n",
            "enough\n",
            "to\n",
            "warrant\n",
            "investigation\n",
            ".\n",
            "(\n",
            "In\n",
            "the\n",
            "authors\n",
            "'\n",
            "words\n",
            ",\n",
            "``\n",
            "It\n",
            "can\n",
            "be\n",
            "regarded\n",
            "as\n",
            "feeding\n",
            "more\n",
            "gradient\n",
            "into\n",
            "some\n",
            "linear\n",
            "path\n",
            "than\n",
            "the\n",
            "nonlinear\n",
            "path\n",
            "that\n",
            "filters\n",
            "out\n",
            "the\n",
            "gradient\n",
            "of\n",
            "the\n",
            "negative\n",
            "input\n",
            "entries\n",
            ".\n",
            "''\n",
            "Perhaps\n",
            "this\n",
            "wording\n",
            "could\n",
            "be\n",
            "tweaked\n",
            ",\n",
            "but\n",
            "this\n",
            "is\n",
            "the\n",
            "essential\n",
            "point\n",
            ".\n",
            ")\n",
            "Overall\n",
            ",\n",
            "I\n",
            "enjoyed\n",
            "this\n",
            "paper\n",
            ",\n",
            "and\n",
            "have\n",
            "added\n",
            "its\n",
            "results\n",
            "to\n",
            "my\n",
            "bank\n",
            "of\n",
            "knowledge\n",
            "on\n",
            "this\n",
            "topic\n",
            ".\n",
            "It\n",
            "is\n",
            "a\n",
            "good\n",
            "example\n",
            "of\n",
            "elegantly\n",
            "realising\n",
            "a\n",
            "well\n",
            "motivated\n",
            "intuition\n",
            "and\n",
            "providing\n",
            "ample\n",
            "evidence\n",
            "from\n",
            "well\n",
            "designed\n",
            "experiments\n",
            "in\n",
            "support\n",
            "of\n",
            "its\n",
            "hypothesis\n",
            ".\n",
            "I\n",
            "was\n",
            "especially\n",
            "impressed\n",
            "with\n",
            "the\n",
            "rigorous\n",
            "experimental\n",
            "methodology\n",
            ",\n",
            "particularly\n",
            "the\n",
            "plots\n",
            "of\n",
            "LinBP\n",
            "and\n",
            "ILA\n",
            "performance\n",
            "as\n",
            "functions\n",
            "of\n",
            "their\n",
            "respective\n",
            "location\n",
            "parameters\n",
            ",\n",
            "and\n",
            "the\n",
            "evaluation\n",
            "of\n",
            "method\n",
            "combinations\n",
            ".\n",
            "All\n",
            "results\n",
            "are\n",
            "meaningful\n",
            "and\n",
            "convincing\n",
            ".\n",
            "Are\n",
            "the\n",
            "topic\n",
            "and\n",
            "approach\n",
            "relevant\n",
            "to\n",
            "the\n",
            "NeurIPS\n",
            "community\n",
            "?\n",
            "Yes\n",
            ":\n",
            "this\n",
            "is\n",
            "a\n",
            "paper\n",
            "making\n",
            "an\n",
            "observation\n",
            "on\n",
            "the\n",
            "transferability\n",
            "of\n",
            "adversarial\n",
            "examples\n",
            "across\n",
            "models\n",
            ",\n",
            "and\n",
            "the\n",
            "relevance\n",
            "of\n",
            "that\n",
            "topic\n",
            "is\n",
            "not\n",
            "really\n",
            "controversial\n",
            ".\n",
            "I\n",
            "am\n",
            "not\n",
            "predicting\n",
            "an\n",
            "outpouring\n",
            "of\n",
            "wild\n",
            "enthusiasm\n",
            "from\n",
            "said\n",
            "community\n",
            "in\n",
            "response\n",
            "to\n",
            "this\n",
            "paper\n",
            ",\n",
            "but\n",
            "people\n",
            "who\n",
            "care\n",
            "about\n",
            "the\n",
            "details\n",
            "of\n",
            "network\n",
            "analysis\n",
            "would\n",
            "do\n",
            "well\n",
            "to\n",
            "read\n",
            "it\n",
            ".\n",
            "The\n",
            "presentation\n",
            "is\n",
            ",\n",
            "up\n",
            "to\n",
            "minor\n",
            "complaints\n",
            "(\n",
            "given\n",
            "in\n",
            "the\n",
            "``\n",
            "clarity\n",
            "''\n",
            "section\n",
            ")\n",
            ",\n",
            "clear\n",
            "and\n",
            "well\n",
            "organised\n",
            ".\n",
            "I\n",
            "can\n",
            "easily\n",
            "recommend\n",
            "this\n",
            "paper\n",
            "for\n",
            "acceptance\n",
            ".\n",
            "Weaknesses\n",
            ":\n",
            "I\n",
            "note\n",
            "no\n",
            "real\n",
            "weakness\n",
            "outside\n",
            "of\n",
            "the\n",
            "section\n",
            "on\n",
            "clarity\n",
            "of\n",
            "writing\n",
            ",\n",
            "and\n",
            "even\n",
            "this\n",
            "is\n",
            "not\n",
            "a\n",
            "particular\n",
            "weakness\n",
            ".\n",
            "(\n",
            "Again\n",
            ",\n",
            "its\n",
            "appeal\n",
            "will\n",
            "likely\n",
            "be\n",
            "limited\n",
            "to\n",
            "those\n",
            "who\n",
            "care\n",
            "about\n",
            "the\n",
            "non-sensational\n",
            "fine\n",
            "details\n",
            "of\n",
            "network\n",
            "analysis\n",
            "and\n",
            "adversarial\n",
            "vulnerability\n",
            ".\n",
            ")\n",
            "Correctness\n",
            ":\n",
            "As\n",
            "above\n",
            ",\n",
            "they\n",
            "have\n",
            "passed\n",
            "all\n",
            "scrutiny\n",
            "to\n",
            "which\n",
            "I\n",
            "have\n",
            "been\n",
            "capable\n",
            "of\n",
            "subjecting\n",
            "them\n",
            ".\n",
            "The\n",
            "claims\n",
            "and\n",
            "method\n",
            "are\n",
            "straightforward\n",
            ",\n",
            "and\n",
            "I\n",
            "have\n",
            "found\n",
            "no\n",
            "holes\n",
            "in\n",
            "the\n",
            "experimental\n",
            "setup\n",
            "(\n",
            "which\n",
            "I\n",
            "would\n",
            "say\n",
            "has\n",
            "gone\n",
            "beyond\n",
            "the\n",
            "call\n",
            "of\n",
            "duty\n",
            ",\n",
            "if\n",
            "anything\n",
            ")\n",
            ".\n",
            "The\n",
            "only\n",
            "caveat\n",
            "I\n",
            "can\n",
            "offer\n",
            "regarding\n",
            "my\n",
            "judgement\n",
            "(\n",
            "see\n",
            "also\n",
            "``\n",
            "Relation\n",
            "to\n",
            "prior\n",
            "work\n",
            "''\n",
            ")\n",
            "is\n",
            "the\n",
            "fact\n",
            "that\n",
            "while\n",
            "possessing\n",
            "considerable\n",
            "expertise\n",
            "in\n",
            "the\n",
            "subfield\n",
            "of\n",
            "adversarial\n",
            "attacks/vulnerability\n",
            ",\n",
            "I\n",
            "do\n",
            "not\n",
            "specifically\n",
            "study\n",
            "``\n",
            "transfer\n",
            "attacks\n",
            "''\n",
            "in\n",
            "the\n",
            "sense\n",
            "considered\n",
            "here\n",
            "in\n",
            "particular\n",
            "detail\n",
            ".\n",
            "Thus\n",
            ",\n",
            "I\n",
            "can\n",
            "not\n",
            "personally\n",
            "vouch\n",
            "that\n",
            "the\n",
            "experimental\n",
            "framework\n",
            "includes\n",
            "any\n",
            "and\n",
            "all\n",
            "valid\n",
            "``\n",
            "competitors\n",
            "''\n",
            ",\n",
            "only\n",
            "that\n",
            "the\n",
            "framework\n",
            "itself\n",
            "is\n",
            "sound\n",
            ".\n",
            "Having\n",
            "said\n",
            "this\n",
            ",\n",
            "I\n",
            "find\n",
            "these\n",
            "results\n",
            "impressive\n",
            ",\n",
            "well\n",
            "motivated\n",
            "and\n",
            "substantiated\n",
            ",\n",
            "inherently\n",
            "plausible\n",
            ",\n",
            "and\n",
            "interesting\n",
            "in\n",
            "their\n",
            "own\n",
            "right\n",
            ".\n",
            "Clarity\n",
            ":\n",
            "There\n",
            "are\n",
            "general\n",
            "points\n",
            "about\n",
            "English\n",
            "grammar\n",
            "and\n",
            "elegance\n",
            "of\n",
            "phrasing\n",
            "scattered\n",
            "throughout\n",
            "the\n",
            "paper\n",
            "too\n",
            "finely\n",
            "to\n",
            "be\n",
            "worth\n",
            "enumerating\n",
            "exhaustively\n",
            ".\n",
            "I\n",
            "would\n",
            "recommend\n",
            "that\n",
            "the\n",
            "paper\n",
            "be\n",
            "passed\n",
            "over\n",
            "by\n",
            "someone\n",
            "able\n",
            "to\n",
            "improve\n",
            "it\n",
            "in\n",
            "this\n",
            "regard\n",
            ".\n",
            "The\n",
            "paper\n",
            "is\n",
            "not\n",
            "poorly\n",
            "written\n",
            ",\n",
            "but\n",
            "it\n",
            "requires\n",
            "some\n",
            "polishing\n",
            "before\n",
            "publication\n",
            ".\n",
            "Having\n",
            "said\n",
            "that\n",
            ",\n",
            "see\n",
            "the\n",
            "below\n",
            "notes\n",
            ":\n",
            "5\n",
            ":\n",
            "``\n",
            "improving\n",
            "...\n",
            "the\n",
            "linearity\n",
            "''\n",
            ":\n",
            "odd\n",
            "wording/conceptualisation\n",
            "41-42\n",
            ":\n",
            "``\n",
            "Many\n",
            "methods\n",
            "aim\n",
            "to\n",
            "maximize\n",
            "the\n",
            "prediction\n",
            "loss\n",
            "L\n",
            "(\n",
            "x\n",
            "+\n",
            "r\n",
            ";\n",
            "y\n",
            ")\n",
            "with\n",
            "a\n",
            "constraint\n",
            "on\n",
            "its\n",
            "Lp\n",
            "norm\n",
            "...\n",
            "''\n",
            "<\n",
            "-\n",
            "The\n",
            "constraint\n",
            "is\n",
            "on\n",
            "the\n",
            "Lp\n",
            "norm\n",
            "of\n",
            "the\n",
            "perturbation\n",
            "r\n",
            ",\n",
            "not\n",
            "the\n",
            "loss\n",
            "L.\n",
            "This\n",
            "wording\n",
            "needs\n",
            "to\n",
            "be\n",
            "fixed\n",
            ".\n",
            "67\n",
            ":\n",
            "The\n",
            "word\n",
            "``\n",
            "literally\n",
            "''\n",
            "is\n",
            "jarring\n",
            "and\n",
            "not\n",
            "required\n",
            ".\n",
            "121\n",
            ":\n",
            "``\n",
            "decent\n",
            "''\n",
            ",\n",
            "not\n",
            "``\n",
            "descent\n",
            "''\n",
            "137\n",
            ":\n",
            "``\n",
            "unlike\n",
            "''\n",
            ",\n",
            "not\n",
            "``\n",
            "dislike\n",
            "''\n",
            "212\n",
            ":\n",
            "``\n",
            "invoked\n",
            "''\n",
            ",\n",
            "not\n",
            "``\n",
            "evoked\n",
            "''\n",
            "Also\n",
            ",\n",
            "the\n",
            "significance\n",
            "of\n",
            "the\n",
            "asterisk\n",
            "in\n",
            "``\n",
            "VGG-19\n",
            "*\n",
            "''\n",
            "in\n",
            "Figure\n",
            "1\n",
            "is\n",
            "not\n",
            "explained\n",
            "until\n",
            "much\n",
            "later\n",
            ",\n",
            "in\n",
            "the\n",
            "caption\n",
            "of\n",
            "Table\n",
            "3\n",
            ".\n",
            "This\n",
            "statement\n",
            "needs\n",
            "to\n",
            "be\n",
            "made\n",
            "the\n",
            "first\n",
            "time\n",
            "the\n",
            "symbol\n",
            "appears\n",
            ".\n",
            "I\n",
            "spent\n",
            "more\n",
            "time\n",
            "than\n",
            "I\n",
            "should\n",
            "have\n",
            "parsing\n",
            "the\n",
            "first\n",
            "plot\n",
            "because\n",
            "of\n",
            "this\n",
            ".\n",
            "The\n",
            "captions\n",
            "can\n",
            "generally\n",
            "stand\n",
            "to\n",
            "be\n",
            "more\n",
            "detailed\n",
            "and\n",
            "explicit\n",
            ",\n",
            "as\n",
            "this\n",
            "will\n",
            "help\n",
            "readers\n",
            "who\n",
            "are\n",
            "less\n",
            "familiar\n",
            "with\n",
            "this\n",
            "material\n",
            ".\n",
            "Relation\n",
            "to\n",
            "Prior\n",
            "Work\n",
            ":\n",
            "I\n",
            "would\n",
            "have\n",
            "listed\n",
            "[\n",
            "``\n",
            "Simple\n",
            "Black-box\n",
            "Adversarial\n",
            "Attacks\n",
            "''\n",
            ",\n",
            "Guo\n",
            "et\n",
            "al.\n",
            ",\n",
            "ICML\n",
            "2019\n",
            "]\n",
            "as\n",
            "an\n",
            "example\n",
            "of\n",
            "a\n",
            "relatively\n",
            "query-efficient\n",
            "black-box\n",
            "attack\n",
            "(\n",
            "which\n",
            "does\n",
            "not\n",
            "represent\n",
            "an\n",
            "example\n",
            "of\n",
            "a\n",
            "transfer-based\n",
            "method\n",
            ")\n",
            ",\n",
            "in\n",
            "the\n",
            "related\n",
            "work\n",
            ".\n",
            "The\n",
            "LinBP\n",
            "approach\n",
            "can\n",
            "be\n",
            "framed\n",
            "as\n",
            "an\n",
            "instantiation\n",
            "of\n",
            "BPDA\n",
            "[\n",
            "``\n",
            "Obfuscated\n",
            "Gradients\n",
            "Give\n",
            "a\n",
            "False\n",
            "Sense\n",
            "of\n",
            "Security\n",
            ":\n",
            "Circumventing\n",
            "Defenses\n",
            "to\n",
            "Adversarial\n",
            "Examples\n",
            "''\n",
            ",\n",
            "Athalye\n",
            "et\n",
            "al.\n",
            ",\n",
            "ICML\n",
            "2018\n",
            "]\n",
            "in\n",
            "which\n",
            "the\n",
            "approximating\n",
            "network\n",
            "used\n",
            "in\n",
            "the\n",
            "backward\n",
            "pass\n",
            "is\n",
            "the\n",
            "``\n",
            "more\n",
            "linear\n",
            "''\n",
            "variant\n",
            "of\n",
            "the\n",
            "original\n",
            ".\n",
            "I\n",
            "would\n",
            "highly\n",
            "encourage\n",
            "the\n",
            "authors\n",
            "to\n",
            "make\n",
            "this\n",
            "connection\n",
            "explicit\n",
            ".\n",
            "As\n",
            "noted\n",
            "elsewhere\n",
            "regarding\n",
            "my\n",
            "own\n",
            "capacity\n",
            "as\n",
            "a\n",
            "reviewer\n",
            ",\n",
            "as\n",
            "I\n",
            "do\n",
            "not\n",
            "focus\n",
            "specifically\n",
            "on\n",
            "the\n",
            "problem\n",
            "of\n",
            "transfer\n",
            "attacks\n",
            "in\n",
            "my\n",
            "own\n",
            "research\n",
            ",\n",
            "I\n",
            "can\n",
            "not\n",
            "personally\n",
            "verify\n",
            "the\n",
            "claim\n",
            "that\n",
            "the\n",
            "most\n",
            "relevant\n",
            "and\n",
            "recent\n",
            "state-of-the-art\n",
            "methods\n",
            "have\n",
            "been\n",
            "used\n",
            "in\n",
            "comparison\n",
            ".\n",
            "If\n",
            "there\n",
            "is\n",
            "any\n",
            "point\n",
            "of\n",
            "contention\n",
            "here\n",
            "from\n",
            "any\n",
            "other\n",
            "reviewers\n",
            "or\n",
            "meta-reviewers\n",
            ",\n",
            "it\n",
            "should\n",
            "be\n",
            "discussed\n",
            ".\n",
            "Reproducibility\n",
            ":\n",
            "Yes\n",
            "Additional\n",
            "Feedback\n",
            ":\n",
            "18\n",
            ":\n",
            "The\n",
            "``\n",
            "blind\n",
            "spot\n",
            "''\n",
            "model\n",
            "of\n",
            "deep\n",
            "network\n",
            "vulnerability\n",
            "is\n",
            "questionable\n",
            "and\n",
            "arguably\n",
            "misleading\n",
            ",\n",
            "depending\n",
            "on\n",
            "how\n",
            "that\n",
            "statement\n",
            "is\n",
            "interpreted\n",
            ":\n",
            "see\n",
            "e.g\n",
            ".\n",
            "[\n",
            "``\n",
            "With\n",
            "Friends\n",
            "Like\n",
            "These\n",
            ",\n",
            "Who\n",
            "Needs\n",
            "Adversaries\n",
            "?\n",
            "``\n",
            ",\n",
            "Jetley\n",
            "et\n",
            "al.\n",
            ",\n",
            "NeurIPS\n",
            "2018\n",
            ";\n",
            "``\n",
            "Adversarial\n",
            "Examples\n",
            "are\n",
            "not\n",
            "Bugs\n",
            ",\n",
            "they\n",
            "are\n",
            "Features\n",
            "''\n",
            ",\n",
            "Ilyas\n",
            "et\n",
            "al.\n",
            ",\n",
            "NeurIPS\n",
            "2019\n",
            "]\n",
            ".\n",
            "I\n",
            "would\n",
            "discourage\n",
            "casually\n",
            "propagating\n",
            "this\n",
            "view\n",
            "(\n",
            "at\n",
            "least\n",
            "without\n",
            "any\n",
            "clarification\n",
            ")\n",
            ".\n",
            "18-19\n",
            ":\n",
            "``\n",
            "The\n",
            "undesirable\n",
            "phenomenon\n",
            "not\n",
            "only\n",
            "causes\n",
            "a\n",
            "great\n",
            "deal\n",
            "of\n",
            "concern\n",
            "when\n",
            "deploying\n",
            "DNN\n",
            "models\n",
            "in\n",
            "security-sensitive\n",
            "applications\n",
            "''\n",
            ":\n",
            "Well\n",
            ",\n",
            "perhaps\n",
            ",\n",
            "but\n",
            "the\n",
            "general\n",
            "``\n",
            "security\n",
            "concern\n",
            "''\n",
            "statement\n",
            ",\n",
            "in\n",
            "the\n",
            "absence\n",
            "of\n",
            "any\n",
            "more\n",
            "specific\n",
            "example/argument\n",
            ",\n",
            "leaves\n",
            "this\n",
            "reviewer\n",
            ",\n",
            "who\n",
            "currently\n",
            "subscribes\n",
            "to\n",
            "the\n",
            "counterarguments\n",
            "to\n",
            "this\n",
            "point\n",
            "made\n",
            "in\n",
            "[\n",
            "``\n",
            "Motivating\n",
            "the\n",
            "Rules\n",
            "of\n",
            "the\n",
            "Game\n",
            "for\n",
            "Adversarial\n",
            "Example\n",
            "Research\n",
            "''\n",
            ",\n",
            "Gilmer\n",
            "et\n",
            "al\n",
            ".\n",
            "]\n",
            ",\n",
            "cold\n",
            ".\n",
            "I\n",
            "do\n",
            "n't\n",
            "believe\n",
            "that\n",
            "this\n",
            "sort\n",
            "of\n",
            "boilerplate\n",
            "introduction\n",
            "to\n",
            "the\n",
            "problem\n",
            "of\n",
            "adversarial\n",
            "vulnerability\n",
            "is\n",
            "helpful\n",
            "or\n",
            "necessary\n",
            ".\n",
            "If\n",
            "there\n",
            "is\n",
            "a\n",
            "security\n",
            "case\n",
            ",\n",
            "state\n",
            "clearly\n",
            "what\n",
            "it\n",
            "is\n",
            ",\n",
            "else\n",
            ",\n",
            "do\n",
            "n't\n",
            "make\n",
            "this\n",
            "statement\n",
            ".\n",
            "27-28\n",
            ":\n",
            "``\n",
            "In\n",
            "this\n",
            "paper\n",
            ",\n",
            "we\n",
            "revisit\n",
            "the\n",
            "hypothesis\n",
            "of\n",
            "Goodfellow\n",
            "et\n",
            "al.\n",
            "’\n",
            "s\n",
            "[\n",
            "13\n",
            "]\n",
            "that\n",
            "the\n",
            "transferability\n",
            "(\n",
            "or\n",
            "say\n",
            "generalization\n",
            "ability\n",
            ")\n",
            "of\n",
            "adversarial\n",
            "examples\n",
            "comes\n",
            "from\n",
            "the\n",
            "“\n",
            "linear\n",
            "nature\n",
            "”\n",
            "of\n",
            "modern\n",
            "DNNs\n",
            ".\n",
            "''\n",
            "I\n",
            "would\n",
            "n't\n",
            "completely\n",
            "agree\n",
            "that\n",
            "this\n",
            "was\n",
            "the\n",
            "argument\n",
            "in\n",
            "that\n",
            "paper\n",
            ".\n",
            "Those\n",
            "authors\n",
            "were\n",
            ",\n",
            "in\n",
            "my\n",
            "interpretation\n",
            ",\n",
            "arguing\n",
            "that\n",
            "the\n",
            "*\n",
            "existence/effectiveness\n",
            "*\n",
            "of\n",
            "adversarial\n",
            "examples\n",
            "could\n",
            "be\n",
            "explained\n",
            "by\n",
            "``\n",
            "excessive\n",
            "linearity\n",
            "''\n",
            "of\n",
            "networks\n",
            ",\n",
            "and\n",
            "accounted\n",
            "for\n",
            "how\n",
            "transferable\n",
            "perturbations\n",
            "are\n",
            "*\n",
            "between\n",
            "examples\n",
            "on\n",
            "the\n",
            "same\n",
            "network\n",
            "*\n",
            ".\n",
            "That\n",
            "is\n",
            ",\n",
            "they\n",
            "essentially\n",
            "foretold\n",
            "the\n",
            "existence\n",
            "of\n",
            "``\n",
            "universal\n",
            "adversarial\n",
            "perturbations\n",
            "''\n",
            "[\n",
            "Moosavi-Dezfooli\n",
            "et\n",
            "al.\n",
            ",\n",
            "CVPR\n",
            "2017\n",
            "]\n",
            ".\n",
            "They\n",
            "did\n",
            "note\n",
            "inter-network\n",
            "transferability\n",
            ",\n",
            "but\n",
            "noted\n",
            "that\n",
            "that\n",
            "phenomenon\n",
            "depended\n",
            "on\n",
            "different\n",
            "networks\n",
            "learning\n",
            "similar\n",
            "functions\n",
            "when\n",
            "trained\n",
            "to\n",
            "perform\n",
            "the\n",
            "same\n",
            "task\n",
            ",\n",
            "which\n",
            "is\n",
            "a\n",
            "somewhat\n",
            "different\n",
            "matter\n",
            ",\n",
            "even\n",
            "if\n",
            "there\n",
            "is\n",
            "a\n",
            "relationship\n",
            ".\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "Update\n",
            ",\n",
            "following\n",
            "rebuttal\n",
            "and\n",
            "reviewer\n",
            "discussion\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "After\n",
            "conferring\n",
            "with\n",
            "other\n",
            "reviewers\n",
            ",\n",
            "my\n",
            "score\n",
            "and\n",
            "overall\n",
            "opinion\n",
            "of\n",
            "the\n",
            "paper\n",
            "remain\n",
            "unchanged\n",
            ".\n",
            "Because\n",
            "my\n",
            "review\n",
            "was\n",
            "positive\n",
            "aside\n",
            "from\n",
            "specific\n",
            ",\n",
            "easily\n",
            "addressed\n",
            "points\n",
            ",\n",
            "the\n",
            "authors\n",
            "did\n",
            "not\n",
            "have\n",
            "to\n",
            "do\n",
            "much\n",
            "to\n",
            "address\n",
            "me\n",
            "and\n",
            "rightfully\n",
            "focused\n",
            "most\n",
            "of\n",
            "their\n",
            "efforts\n",
            "on\n",
            "R1\n",
            "'s\n",
            "issues\n",
            ".\n",
            "I\n",
            "can\n",
            "concur\n",
            "with\n",
            "R1\n",
            "'s\n",
            "requests\n",
            "for\n",
            "the\n",
            "following\n",
            "(\n",
            "copied\n",
            "verbatim\n",
            "from\n",
            "R1\n",
            "'s\n",
            "updated\n",
            "review\n",
            ")\n",
            ",\n",
            "the\n",
            "first\n",
            "of\n",
            "which\n",
            "I\n",
            "also\n",
            "made\n",
            "myself\n",
            "in\n",
            "my\n",
            "original\n",
            "review\n",
            ":\n",
            "``\n",
            "-\n",
            "[\n",
            "p0\n",
            "]\n",
            "Improved\n",
            "source\n",
            "target\n",
            "transfer\n",
            "notation\n",
            "for\n",
            "clarity\n",
            "-\n",
            "[\n",
            "p0\n",
            "]\n",
            "Move\n",
            "attack\n",
            "results\n",
            "to\n",
            "16/255\n",
            ",\n",
            "8/255\n",
            ",\n",
            "4/255\n",
            "as\n",
            "to\n",
            "be\n",
            "more\n",
            "fairly\n",
            "compared\n",
            "across\n",
            "contemporary\n",
            "works\n",
            ".\n",
            "Also\n",
            ",\n",
            "remove\n",
            "any\n",
            "discussion\n",
            "of\n",
            "eps=0.1\n",
            "as\n",
            "a\n",
            "main\n",
            "result\n",
            ",\n",
            "it\n",
            "is\n",
            "simply\n",
            "too\n",
            "high\n",
            ".\n",
            "[\n",
            "R2\n",
            ":\n",
            "I\n",
            "am\n",
            "agnostic\n",
            "on\n",
            "the\n",
            "point\n",
            "about\n",
            "eps=0.1\n",
            ".\n",
            "]\n",
            "-\n",
            "[\n",
            "p0\n",
            "]\n",
            "Include\n",
            "transfers\n",
            "with\n",
            "other\n",
            "source\n",
            "models\n",
            "for\n",
            "each\n",
            "dataset\n",
            "in\n",
            "the\n",
            "main\n",
            "tables.\n",
            "``\n",
            "I\n",
            "believe\n",
            "these\n",
            "will\n",
            "increase\n",
            "the\n",
            "strength\n",
            "of\n",
            "what\n",
            "is\n",
            "already\n",
            "a\n",
            "strong\n",
            "paper\n",
            ",\n",
            "and\n",
            "so\n",
            "the\n",
            "authors\n",
            "should\n",
            "make\n",
            "an\n",
            "effort\n",
            "to\n",
            "include\n",
            "the\n",
            "results\n",
            "of\n",
            "their\n",
            "rebuttal\n",
            "in\n",
            "the\n",
            "updated\n",
            "text\n",
            ",\n",
            "which\n",
            "I\n",
            "'m\n",
            "sure\n",
            "they\n",
            "will\n",
            "(\n",
            "as\n",
            "they\n",
            "have\n",
            "already\n",
            "done\n",
            "the\n",
            "work\n",
            "and\n",
            ",\n",
            "unsurprisingly\n",
            "to\n",
            "me\n",
            ",\n",
            "realised\n",
            "favourable\n",
            "results\n",
            ")\n",
            ".\n",
            "I\n",
            "would\n",
            "also\n",
            "ask\n",
            "that\n",
            "unless\n",
            "the\n",
            "authors\n",
            "have\n",
            "very\n",
            "strong\n",
            "reasons\n",
            "for\n",
            "overriding\n",
            "the\n",
            "specific\n",
            "objections\n",
            "that\n",
            "I\n",
            "had\n",
            "in\n",
            "the\n",
            "``\n",
            "additional\n",
            "feedback\n",
            "''\n",
            "section\n",
            ",\n",
            "to\n",
            "please\n",
            "take\n",
            "those\n",
            "points\n",
            "into\n",
            "account\n",
            "as\n",
            "well\n",
            "in\n",
            "the\n",
            "camera-ready\n",
            "version\n",
            "(\n",
            "which\n",
            "is\n",
            "more\n",
            "a\n",
            "matter\n",
            "of\n",
            "omission\n",
            "than\n",
            "inclusion\n",
            ")\n",
            ".\n",
            "The\n",
            "same\n",
            "goes\n",
            "for\n",
            "the\n",
            "point\n",
            "about\n",
            "BPDA\n",
            "(\n",
            "though\n",
            "that\n",
            "is\n",
            "a\n",
            "matter\n",
            "of\n",
            "inclusion\n",
            "rather\n",
            "than\n",
            "omission\n",
            ")\n",
            ".\n",
            "This\n",
            "is\n",
            "in\n",
            "addition\n",
            "to\n",
            "having\n",
            "the\n",
            "paper\n",
            "proofed\n",
            "for\n",
            "grammar\n",
            "and\n",
            "style\n",
            "issues\n",
            ".\n",
            "Review\n",
            "3\n",
            "Summary\n",
            "and\n",
            "Contributions\n",
            ":\n",
            "In\n",
            "this\n",
            "paper\n",
            ",\n",
            "the\n",
            "authors\n",
            "propose\n",
            "to\n",
            "enhance\n",
            "the\n",
            "transferability\n",
            "of\n",
            "gradient-based\n",
            "black-box\n",
            "attacks\n",
            "by\n",
            "leveraging\n",
            "the\n",
            "linear\n",
            "nature\n",
            "of\n",
            "deep\n",
            "neural\n",
            "networks\n",
            ".\n",
            "The\n",
            "authors\n",
            "build\n",
            "upon\n",
            "and\n",
            "empirically\n",
            "study\n",
            "a\n",
            "hypothesis\n",
            "put\n",
            "forth\n",
            "by\n",
            "Goodfellow\n",
            "et\n",
            "al\n",
            ".\n",
            "[\n",
            "1\n",
            "]\n",
            ",\n",
            "wherein\n",
            "the\n",
            "high\n",
            "transferability\n",
            "of\n",
            "black-box\n",
            "attacks\n",
            "is\n",
            "attributed\n",
            "to\n",
            "the\n",
            "linearity\n",
            "of\n",
            "networks\n",
            ".\n",
            "The\n",
            "paper\n",
            "proposes\n",
            "LinBP\n",
            ",\n",
            "where\n",
            "the\n",
            "forward\n",
            "pass\n",
            "is\n",
            "unchanged\n",
            ",\n",
            "but\n",
            "the\n",
            "loss\n",
            "is\n",
            "backpropagated\n",
            "linearly\n",
            "as\n",
            "though\n",
            "no\n",
            "non-linear\n",
            "activation\n",
            "function\n",
            "such\n",
            "as\n",
            "ReLU\n",
            "was\n",
            "encountered\n",
            ".\n",
            "Further\n",
            ",\n",
            "the\n",
            "authors\n",
            "demonstrate\n",
            "the\n",
            "improved\n",
            "transferability\n",
            "of\n",
            "different\n",
            "attacks\n",
            "on\n",
            "normally-trained\n",
            "victim\n",
            "models\n",
            "of\n",
            "diverse\n",
            "architectures\n",
            ".\n",
            "[\n",
            "1\n",
            "]\n",
            ":\n",
            "Goodfellow\n",
            ",\n",
            "I.\n",
            "J.\n",
            ",\n",
            "Shlens\n",
            ",\n",
            "J.\n",
            ",\n",
            "and\n",
            "Szegedy\n",
            ",\n",
            "C.\n",
            "Explaining\n",
            "and\n",
            "harnessing\n",
            "adversarial\n",
            "examples\n",
            ".\n",
            "In\n",
            "International\n",
            "Conference\n",
            "on\n",
            "Learning\n",
            "Representations\n",
            "(\n",
            "ICLR\n",
            ")\n",
            ",\n",
            "2015\n",
            "Strengths\n",
            ":\n",
            "1\n",
            ".\n",
            "First\n",
            ",\n",
            "the\n",
            "authors\n",
            "empirically\n",
            "study\n",
            "the\n",
            "hypothesis\n",
            "introduced\n",
            "in\n",
            "Goodfellow\n",
            "et\n",
            "al\n",
            ".\n",
            "[\n",
            "1\n",
            "]\n",
            ",\n",
            "by\n",
            "proposing\n",
            "a\n",
            "method\n",
            "called\n",
            "linear\n",
            "substitution\n",
            "(\n",
            "LinS\n",
            ")\n",
            ",\n",
            "where\n",
            "they\n",
            "fine-tune\n",
            "a\n",
            "normally\n",
            "trained\n",
            "network\n",
            "after\n",
            "removing\n",
            "the\n",
            "non-linear\n",
            "activations\n",
            "in\n",
            "the\n",
            "last\n",
            "few\n",
            "layers\n",
            ".\n",
            "2\n",
            ".\n",
            "They\n",
            "show\n",
            "that\n",
            "both\n",
            "FGSM\n",
            "and\n",
            "IFGSM\n",
            "black-box\n",
            "attacks\n",
            "crafted\n",
            "from\n",
            "this\n",
            "linearised\n",
            "source\n",
            "model\n",
            "achieve\n",
            "a\n",
            "higher\n",
            "success\n",
            "rate\n",
            "in\n",
            "fooling\n",
            "other\n",
            "victim\n",
            "models\n",
            "that\n",
            "are\n",
            "trained\n",
            "with\n",
            "different\n",
            "architectures\n",
            ".\n",
            "3\n",
            ".\n",
            "Motivated\n",
            "by\n",
            "these\n",
            "results\n",
            ",\n",
            "the\n",
            "authors\n",
            "propose\n",
            "a\n",
            "novel\n",
            "technique\n",
            "called\n",
            "linear\n",
            "backpropagation\n",
            "(\n",
            "LinBP\n",
            ")\n",
            ",\n",
            "where\n",
            "the\n",
            "forward\n",
            "pass\n",
            "is\n",
            "unaltered\n",
            ",\n",
            "and\n",
            "the\n",
            "backward\n",
            "pass\n",
            "is\n",
            "performed\n",
            "as\n",
            "though\n",
            "non-linear\n",
            "activations\n",
            "were\n",
            "not\n",
            "encountered\n",
            "in\n",
            "the\n",
            "forward\n",
            "propagation\n",
            ".\n",
            "4\n",
            ".\n",
            "The\n",
            "proposed\n",
            "method\n",
            "shows\n",
            "improved\n",
            "results\n",
            "when\n",
            "compared\n",
            "to\n",
            "previous\n",
            "works\n",
            "on\n",
            "both\n",
            "the\n",
            "CIFAR-10\n",
            "and\n",
            "ImageNet\n",
            "datasets\n",
            ",\n",
            "with\n",
            "no\n",
            "significant\n",
            "additional\n",
            "overhead\n",
            "in\n",
            "computation\n",
            ".\n",
            "5\n",
            ".\n",
            "The\n",
            "authors\n",
            "also\n",
            "demonstrate\n",
            "that\n",
            "their\n",
            "method\n",
            "can\n",
            "be\n",
            "combined\n",
            "with\n",
            "previous\n",
            "works\n",
            "to\n",
            "obtain\n",
            "a\n",
            "further\n",
            "boost\n",
            "in\n",
            "attack\n",
            "transfer\n",
            ".\n",
            "[\n",
            "1\n",
            "]\n",
            ":\n",
            "Goodfellow\n",
            ",\n",
            "I.\n",
            "J.\n",
            ",\n",
            "Shlens\n",
            ",\n",
            "J.\n",
            ",\n",
            "and\n",
            "Szegedy\n",
            ",\n",
            "C.\n",
            "Explaining\n",
            "and\n",
            "harnessing\n",
            "adversarial\n",
            "examples\n",
            ".\n",
            "In\n",
            "International\n",
            "Conference\n",
            "on\n",
            "Learning\n",
            "Representations\n",
            "(\n",
            "ICLR\n",
            ")\n",
            ",\n",
            "2015\n",
            "Weaknesses\n",
            ":\n",
            "1\n",
            ".\n",
            "For\n",
            "secured\n",
            "victim\n",
            "models\n",
            ",\n",
            "evaluations\n",
            "are\n",
            "performed\n",
            "only\n",
            "for\n",
            "a\n",
            "single\n",
            "ensemble\n",
            "adversarially\n",
            "trained\n",
            "Inception\n",
            "model\n",
            ";\n",
            "this\n",
            "is\n",
            "inadequate\n",
            ".\n",
            "2\n",
            ".\n",
            "Could\n",
            "the\n",
            "authors\n",
            "clarify\n",
            "the\n",
            "exact\n",
            "training\n",
            "methodology\n",
            "used\n",
            "for\n",
            "ensemble\n",
            "adversarial\n",
            "training\n",
            ",\n",
            "such\n",
            "as\n",
            "the\n",
            "epsilon\n",
            "constraint\n",
            ",\n",
            "and\n",
            "the\n",
            "fixed\n",
            "source\n",
            "models\n",
            "used\n",
            "to\n",
            "generate\n",
            "the\n",
            "adversaries\n",
            "during\n",
            "training\n",
            ".\n",
            "3\n",
            ".\n",
            "The\n",
            "authors\n",
            "have\n",
            "not\n",
            "included\n",
            "evaluations\n",
            "where\n",
            "the\n",
            "victim\n",
            "model\n",
            "is\n",
            "known\n",
            "to\n",
            "be\n",
            "robust\n",
            ",\n",
            "for\n",
            "example\n",
            ",\n",
            "white-box\n",
            "adversarially\n",
            "trained\n",
            "models\n",
            "using\n",
            "PGD\n",
            "[\n",
            "2\n",
            "]\n",
            ",\n",
            "TRADES\n",
            "[\n",
            "3\n",
            "]\n",
            "or\n",
            "Feature\n",
            "Denoising\n",
            "[\n",
            "4\n",
            "]\n",
            ".\n",
            "[\n",
            "2\n",
            "]\n",
            ":\n",
            "Aleksander\n",
            "Madry\n",
            ",\n",
            "Aleksandar\n",
            "Makelov\n",
            ",\n",
            "Ludwig\n",
            "Schmidt\n",
            ",\n",
            "Tsipras\n",
            "Dimitris\n",
            ",\n",
            "and\n",
            "Adrian\n",
            "Vladu\n",
            ".\n",
            "Towards\n",
            "deep\n",
            "learning\n",
            "models\n",
            "resistant\n",
            "to\n",
            "adversarial\n",
            "attacks\n",
            ".\n",
            "In\n",
            "International\n",
            "Conference\n",
            "on\n",
            "Learning\n",
            "Representations\n",
            "(\n",
            "ICLR\n",
            ")\n",
            ",\n",
            "2018\n",
            "[\n",
            "3\n",
            "]\n",
            ":\n",
            "Zhang\n",
            ",\n",
            "H.\n",
            ",\n",
            "Yu\n",
            ",\n",
            "Y.\n",
            ",\n",
            "Jiao\n",
            ",\n",
            "J.\n",
            ",\n",
            "Xing\n",
            ",\n",
            "E.\n",
            "P.\n",
            ",\n",
            "Ghaoui\n",
            ",\n",
            "L.\n",
            "E.\n",
            ",\n",
            "and\n",
            "Jordan\n",
            ",\n",
            "M.\n",
            "I.\n",
            "Theoretically\n",
            "principled\n",
            "trade-off\n",
            "between\n",
            "robustness\n",
            "and\n",
            "accuracy\n",
            ".\n",
            "In\n",
            "International\n",
            "Conference\n",
            "on\n",
            "Machine\n",
            "Learning\n",
            "(\n",
            "ICML\n",
            ")\n",
            ",\n",
            "2019\n",
            "[\n",
            "4\n",
            "]\n",
            ":\n",
            "Xie\n",
            ",\n",
            "C.\n",
            ",\n",
            "Wu\n",
            ",\n",
            "Y.\n",
            ",\n",
            "van\n",
            "der\n",
            "Maaten\n",
            ",\n",
            "L.\n",
            ",\n",
            "Yuille\n",
            ",\n",
            "A.\n",
            ",\n",
            "and\n",
            "He\n",
            ",\n",
            "K.Feature\n",
            "denoising\n",
            "for\n",
            "improving\n",
            "adversarial\n",
            "robustness\n",
            ",\n",
            "In\n",
            "IEEE\n",
            "Conference\n",
            "on\n",
            "Computer\n",
            "Vision\n",
            "and\n",
            "Pattern\n",
            "Recognition\n",
            "(\n",
            "CVPR\n",
            ")\n",
            ",\n",
            "2019\n",
            "Correctness\n",
            ":\n",
            "Yes\n",
            ",\n",
            "the\n",
            "proposed\n",
            "method\n",
            "appears\n",
            "to\n",
            "be\n",
            "sound\n",
            ",\n",
            "and\n",
            "is\n",
            "adequately\n",
            "backed\n",
            "by\n",
            "valid\n",
            "empirical\n",
            "evaluations\n",
            ".\n",
            "Clarity\n",
            ":\n",
            "Yes\n",
            ",\n",
            "the\n",
            "authors\n",
            "present\n",
            "their\n",
            "ideas\n",
            "in\n",
            "a\n",
            "clear\n",
            ",\n",
            "structured\n",
            "manner\n",
            ".\n",
            "Further\n",
            ",\n",
            "the\n",
            "paper\n",
            "is\n",
            "well\n",
            "written\n",
            ",\n",
            "and\n",
            "is\n",
            "easy\n",
            "to\n",
            "follow\n",
            ".\n",
            "Some\n",
            "minor\n",
            "corrections\n",
            "that\n",
            "can\n",
            "be\n",
            "incorporated\n",
            "have\n",
            "been\n",
            "indicated\n",
            "in\n",
            "the\n",
            "Additional\n",
            "Feedback\n",
            "section\n",
            ".\n",
            "Relation\n",
            "to\n",
            "Prior\n",
            "Work\n",
            ":\n",
            "Yes\n",
            ",\n",
            "the\n",
            "paper\n",
            "does\n",
            "adequately\n",
            "compare\n",
            "and\n",
            "contrast\n",
            "their\n",
            "proposed\n",
            "method\n",
            "with\n",
            "previous\n",
            "published\n",
            "works\n",
            ".\n",
            "The\n",
            "paper\n",
            "expands\n",
            "upon\n",
            "certain\n",
            "ideas\n",
            "proposed\n",
            "in\n",
            "previous\n",
            "works\n",
            ",\n",
            "and\n",
            "presents\n",
            "distinguishing\n",
            "features\n",
            "in\n",
            "enough\n",
            "clarity\n",
            ".\n",
            "Reproducibility\n",
            ":\n",
            "Yes\n",
            "Additional\n",
            "Feedback\n",
            ":\n",
            "L167-169\n",
            ":\n",
            "“\n",
            "In\n",
            "later\n",
            "layers\n",
            "with\n",
            "a\n",
            "relatively\n",
            "large\n",
            "index\n",
            "i\n",
            ",\n",
            "Mi\n",
            "can\n",
            "be\n",
            "very\n",
            "sparse\n",
            "and\n",
            "removing\n",
            "it\n",
            "during\n",
            "backpropagation\n",
            "probably\n",
            "results\n",
            "in\n",
            "less\n",
            "gradient\n",
            "flow\n",
            "through\n",
            "the\n",
            "skip-connections\n",
            "”\n",
            "-\n",
            "Could\n",
            "the\n",
            "authors\n",
            "provide\n",
            "further\n",
            "clarity\n",
            "on\n",
            "this\n",
            "matter\n",
            ",\n",
            "particularly\n",
            "given\n",
            "that\n",
            "it\n",
            "motivates\n",
            "the\n",
            "need\n",
            "for\n",
            "the\n",
            "proposed\n",
            "re-normalisation\n",
            "term\n",
            "?\n",
            "Could\n",
            "the\n",
            "authors\n",
            "clarify\n",
            "how\n",
            "fine-tuning\n",
            "is\n",
            "performed\n",
            "for\n",
            "LinS\n",
            "in\n",
            "terms\n",
            "of\n",
            "the\n",
            "learning\n",
            "rate\n",
            "used\n",
            "etc\n",
            "?\n",
            "Could\n",
            "the\n",
            "authors\n",
            "include\n",
            "evaluations\n",
            "on\n",
            "multi-step\n",
            "adversarially\n",
            "trained\n",
            "models\n",
            "such\n",
            "as\n",
            "PGD\n",
            "[\n",
            "2\n",
            "]\n",
            "or\n",
            "TRADES\n",
            "[\n",
            "3\n",
            "]\n",
            "for\n",
            "CIFAR-10\n",
            "and\n",
            "Feature\n",
            "Denoising\n",
            "[\n",
            "4\n",
            "]\n",
            "for\n",
            "ImageNet\n",
            ".\n",
            "It\n",
            "would\n",
            "be\n",
            "interesting\n",
            "to\n",
            "observe\n",
            "the\n",
            "attack\n",
            "success\n",
            "rates\n",
            "when\n",
            "the\n",
            "epsilon\n",
            "constraint\n",
            "assumed\n",
            "during\n",
            "training\n",
            "is\n",
            "followed/violated\n",
            "during\n",
            "test\n",
            "time\n",
            ".\n",
            "Some\n",
            "suggestions\n",
            "for\n",
            "minor\n",
            "errors\n",
            "in\n",
            "the\n",
            "paper\n",
            ":\n",
            "L93\n",
            ":\n",
            "“\n",
            "there\n",
            "is\n",
            "of\n",
            "yet\n",
            "few\n",
            "empirical\n",
            "evidence\n",
            "”\n",
            "→\n",
            "“\n",
            "there\n",
            "is\n",
            "of\n",
            "yet\n",
            "little\n",
            "empirical\n",
            "evidence\n",
            "”\n",
            "Eqn2\n",
            ":\n",
            "An\n",
            "extra\n",
            "closing\n",
            "parenthesis\n",
            "“\n",
            ")\n",
            "”\n",
            "can\n",
            "be\n",
            "removed\n",
            "L121\n",
            ":\n",
            "“\n",
            "also\n",
            "achieve\n",
            "descent\n",
            "transferability\n",
            "”\n",
            "-\n",
            "perhaps\n",
            "the\n",
            "authors\n",
            "meant\n",
            "“\n",
            "decent\n",
            "”\n",
            "?\n",
            "L160\n",
            ":\n",
            "“\n",
            "In\n",
            "the\n",
            "prequel\n",
            "of\n",
            "this\n",
            "paper\n",
            "”\n",
            "→\n",
            "“\n",
            "In\n",
            "the\n",
            "previous\n",
            "sections\n",
            "of\n",
            "this\n",
            "paper\n",
            "”\n",
            "The\n",
            "legend\n",
            "used\n",
            "in\n",
            "Figures-1\n",
            ",\n",
            "2\n",
            "could\n",
            "be\n",
            "presented\n",
            "with\n",
            "more\n",
            "clarity\n",
            ".\n",
            "For\n",
            "example\n",
            ",\n",
            "“\n",
            "WRN\n",
            "LinS\n",
            "”\n",
            "seems\n",
            "to\n",
            "suggest\n",
            "that\n",
            "the\n",
            "WRN\n",
            "model\n",
            "is\n",
            "linearised\n",
            ",\n",
            "rather\n",
            "than\n",
            "only\n",
            "the\n",
            "source\n",
            "VGG-19\n",
            "model\n",
            "being\n",
            "modified\n",
            ".\n",
            "Table\n",
            "6\n",
            ":\n",
            "If\n",
            "the\n",
            "authors\n",
            "primarily\n",
            "attribute\n",
            "the\n",
            "higher\n",
            "success\n",
            "rate\n",
            "seen\n",
            "for\n",
            "ILA\n",
            "to\n",
            "originate\n",
            "from\n",
            "the\n",
            "use\n",
            "of\n",
            "two-steps\n",
            ",\n",
            "could\n",
            "they\n",
            "include\n",
            "a\n",
            "two-step\n",
            "attack\n",
            "with\n",
            "LinBP\n",
            "for\n",
            "a\n",
            "fair\n",
            "comparison\n",
            "?\n",
            "For\n",
            "table\n",
            "captions\n",
            ",\n",
            "the\n",
            "authors\n",
            "could\n",
            "consider\n",
            "using\n",
            "“\n",
            "Success\n",
            "rates\n",
            "of\n",
            "transfer-based\n",
            "attacks\n",
            "”\n",
            "rather\n",
            "than\n",
            "“\n",
            "Performance\n",
            "of\n",
            "transfer-based\n",
            "attacks\n",
            "”\n",
            ".\n",
            "Could\n",
            "the\n",
            "authors\n",
            "include\n",
            "ablation\n",
            "studies\n",
            "for\n",
            "the\n",
            "re-normalisation\n",
            "factor\n",
            "alpha\n",
            ",\n",
            "such\n",
            "as\n",
            "fixing\n",
            "alpha\n",
            "to\n",
            "be\n",
            "1\n",
            "for\n",
            "all\n",
            "layers\n",
            "?\n",
            "[\n",
            "2\n",
            "]\n",
            ":\n",
            "Aleksander\n",
            "Madry\n",
            ",\n",
            "Aleksandar\n",
            "Makelov\n",
            ",\n",
            "Ludwig\n",
            "Schmidt\n",
            ",\n",
            "Tsipras\n",
            "Dimitris\n",
            ",\n",
            "and\n",
            "Adrian\n",
            "Vladu\n",
            ".\n",
            "Towards\n",
            "deep\n",
            "learning\n",
            "models\n",
            "resistant\n",
            "to\n",
            "adversarial\n",
            "attacks\n",
            ".\n",
            "In\n",
            "International\n",
            "Conference\n",
            "on\n",
            "Learning\n",
            "Representations\n",
            "(\n",
            "ICLR\n",
            ")\n",
            ",\n",
            "2018\n",
            "[\n",
            "3\n",
            "]\n",
            ":\n",
            "Zhang\n",
            ",\n",
            "H.\n",
            ",\n",
            "Yu\n",
            ",\n",
            "Y.\n",
            ",\n",
            "Jiao\n",
            ",\n",
            "J.\n",
            ",\n",
            "Xing\n",
            ",\n",
            "E.\n",
            "P.\n",
            ",\n",
            "Ghaoui\n",
            ",\n",
            "L.\n",
            "E.\n",
            ",\n",
            "and\n",
            "Jordan\n",
            ",\n",
            "M.\n",
            "I.\n",
            "Theoretically\n",
            "principled\n",
            "trade-off\n",
            "between\n",
            "robustness\n",
            "and\n",
            "accuracy\n",
            ".\n",
            "In\n",
            "International\n",
            "Conference\n",
            "on\n",
            "Machine\n",
            "Learning\n",
            "(\n",
            "ICML\n",
            ")\n",
            ",\n",
            "2019\n",
            "[\n",
            "4\n",
            "]\n",
            ":\n",
            "Xie\n",
            ",\n",
            "C.\n",
            ",\n",
            "Wu\n",
            ",\n",
            "Y.\n",
            ",\n",
            "van\n",
            "der\n",
            "Maaten\n",
            ",\n",
            "L.\n",
            ",\n",
            "Yuille\n",
            ",\n",
            "A.\n",
            ",\n",
            "and\n",
            "He\n",
            ",\n",
            "K.Feature\n",
            "denoising\n",
            "for\n",
            "improving\n",
            "adversarial\n",
            "robustness\n",
            ",\n",
            "In\n",
            "IEEE\n",
            "Conference\n",
            "on\n",
            "Computer\n",
            "Vision\n",
            "and\n",
            "Pattern\n",
            "Recognition\n",
            "(\n",
            "CVPR\n",
            ")\n",
            ",\n",
            "2019\n",
            "Post\n",
            "Rebuttal\n",
            ":\n",
            "The\n",
            "authors\n",
            "seem\n",
            "to\n",
            "have\n",
            "adequately\n",
            "addressed\n",
            "the\n",
            "concerns\n",
            "of\n",
            "all\n",
            "four\n",
            "reviewers\n",
            ".\n",
            "The\n",
            "additional\n",
            "results\n",
            "with\n",
            "a\n",
            "robust\n",
            "target\n",
            "model\n",
            "and\n",
            "different\n",
            "source\n",
            "models\n",
            "further\n",
            "highlight\n",
            "the\n",
            "superior\n",
            "performance\n",
            "of\n",
            "the\n",
            "proposed\n",
            "attack\n",
            "compared\n",
            "to\n",
            "previous\n",
            "works\n",
            ".\n",
            "Review\n",
            "4\n",
            "Summary\n",
            "and\n",
            "Contributions\n",
            ":\n",
            "This\n",
            "paper\n",
            "proposes\n",
            "a\n",
            "linear\n",
            "backpropagation\n",
            "(\n",
            "LinBP\n",
            ")\n",
            "technic\n",
            "which\n",
            "backpropagates\n",
            "loss\n",
            "as\n",
            "if\n",
            "there\n",
            "is\n",
            "no\n",
            "non-linear\n",
            "activation\n",
            "between\n",
            "the\n",
            "weight\n",
            "matrix\n",
            ".\n",
            "The\n",
            "proposed\n",
            "method\n",
            "is\n",
            "simple\n",
            "but\n",
            "shows\n",
            "its\n",
            "effectiveness\n",
            "on\n",
            "the\n",
            "transferability\n",
            "of\n",
            "adversarial\n",
            "examples\n",
            ".\n",
            "Strengths\n",
            ":\n",
            "1\n",
            ".\n",
            "The\n",
            "key\n",
            "idea\n",
            "of\n",
            "linear\n",
            "backpropagation\n",
            "seems\n",
            "novel\n",
            "and\n",
            "interesting\n",
            ".\n",
            "2\n",
            ".\n",
            "Empirically\n",
            "validated\n",
            "the\n",
            "effectiveness\n",
            "of\n",
            "linear\n",
            "backpropagation\n",
            "technic\n",
            ".\n",
            "Weaknesses\n",
            ":\n",
            "The\n",
            "linearity\n",
            "hypothesis\n",
            "is\n",
            "validated\n",
            "in\n",
            "an\n",
            "empirical\n",
            "manner\n",
            ",\n",
            "so\n",
            "more\n",
            "solid\n",
            "experiments\n",
            "will\n",
            "make\n",
            "this\n",
            "paper\n",
            "more\n",
            "convincing\n",
            ".\n",
            "1\n",
            ".\n",
            "Can\n",
            "other\n",
            "network\n",
            "architectures\n",
            "(\n",
            "ResNet\n",
            "[\n",
            "1\n",
            "]\n",
            "or\n",
            "DenseNet\n",
            "[\n",
            "2\n",
            "]\n",
            "etc\n",
            ".\n",
            ")\n",
            "also\n",
            "transfer\n",
            "adversarial\n",
            "examples\n",
            "well\n",
            "as\n",
            "in\n",
            "VGG-Net\n",
            "with\n",
            "LinBP\n",
            "?\n",
            "In\n",
            "other\n",
            "words\n",
            ",\n",
            "please\n",
            "show\n",
            "the\n",
            "generalization\n",
            "ability\n",
            "of\n",
            "LinBP\n",
            "method\n",
            ".\n",
            "2\n",
            ".\n",
            "In\n",
            "LinS\n",
            "and\n",
            "LinBP\n",
            ",\n",
            "why\n",
            "only\n",
            "the\n",
            "non-linearity\n",
            "of\n",
            "the\n",
            "two\n",
            "last\n",
            "block\n",
            "of\n",
            "VGG-Net\n",
            "was\n",
            "removed\n",
            "?\n",
            "What\n",
            "if\n",
            "more\n",
            "than\n",
            "two\n",
            "layers\n",
            "are\n",
            "selected\n",
            "?\n",
            "or\n",
            ",\n",
            "why\n",
            "the\n",
            "first\n",
            "blocks\n",
            "can\n",
            "not\n",
            "be\n",
            "selected\n",
            "?\n",
            "If\n",
            "there\n",
            "are\n",
            "some\n",
            "insights\n",
            ",\n",
            "theoritical\n",
            "reason\n",
            ",\n",
            "or\n",
            "empirical\n",
            "results\n",
            ",\n",
            "please\n",
            "provide\n",
            "them\n",
            ".\n",
            "[\n",
            "1\n",
            "]\n",
            "He\n",
            "et\n",
            "al.\n",
            ",\n",
            "``\n",
            "Deep\n",
            "Residual\n",
            "Learning\n",
            "for\n",
            "Image\n",
            "Recognition\n",
            "''\n",
            "[\n",
            "2\n",
            "]\n",
            "Huang\n",
            "et\n",
            "al.\n",
            ",\n",
            "``\n",
            "Densely\n",
            "Connected\n",
            "Convolutional\n",
            "Networks\n",
            "''\n",
            "Correctness\n",
            ":\n",
            "The\n",
            "authors\n",
            "empirically\n",
            "shows\n",
            "the\n",
            "effectiveness\n",
            "of\n",
            "the\n",
            "method\n",
            ".\n",
            "Clarity\n",
            ":\n",
            "Yes\n",
            ".\n",
            "Relation\n",
            "to\n",
            "Prior\n",
            "Work\n",
            ":\n",
            "I\n",
            "guess\n",
            "so\n",
            ".\n",
            "Reproducibility\n",
            ":\n",
            "Yes\n",
            "Book\n",
            "Do\n",
            "not\n",
            "remove\n",
            ":\n",
            "This\n",
            "comment\n",
            "is\n",
            "monitored\n",
            "to\n",
            "verify\n",
            "that\n",
            "the\n",
            "site\n",
            "is\n",
            "working\n",
            "properly\n",
            "Abstract\n",
            "The\n",
            "study\n",
            "of\n",
            "adversarial\n",
            "vulnerabilities\n",
            "of\n",
            "deep\n",
            "neural\n",
            "networks\n",
            "(\n",
            "DNNs\n",
            ")\n",
            "has\n",
            "pro-\n",
            "gressed\n",
            "rapidly\n",
            ".\n",
            "Existing\n",
            "attacks\n",
            "require\n",
            "either\n",
            "internal\n",
            "access\n",
            "(\n",
            "to\n",
            "the\n",
            "architecture\n",
            ",\n",
            "parameters\n",
            ",\n",
            "or\n",
            "training\n",
            "set\n",
            "of\n",
            "the\n",
            "victim\n",
            "model\n",
            ")\n",
            "or\n",
            "external\n",
            "access\n",
            "(\n",
            "to\n",
            "query\n",
            "the\n",
            "model\n",
            ")\n",
            ".\n",
            "However\n",
            ",\n",
            "both\n",
            "the\n",
            "access\n",
            "may\n",
            "be\n",
            "infeasible\n",
            "or\n",
            "expensive\n",
            "in\n",
            "many\n",
            "scenarios\n",
            ".\n",
            "We\n",
            "investigate\n",
            "no-box\n",
            "adversarial\n",
            "examples\n",
            ",\n",
            "where\n",
            "the\n",
            "attacker\n",
            "can\n",
            "neither\n",
            "access\n",
            "the\n",
            "model\n",
            "information\n",
            "or\n",
            "the\n",
            "training\n",
            "set\n",
            "nor\n",
            "query\n",
            "the\n",
            "model\n",
            ".\n",
            "Instead\n",
            ",\n",
            "the\n",
            "attacker\n",
            "can\n",
            "only\n",
            "gather\n",
            "a\n",
            "small\n",
            "number\n",
            "of\n",
            "examples\n",
            "from\n",
            "the\n",
            "same\n",
            "problem\n",
            "domain\n",
            "as\n",
            "that\n",
            "of\n",
            "the\n",
            "victim\n",
            "model\n",
            ".\n",
            "Such\n",
            "a\n",
            "stronger\n",
            "threat\n",
            "model\n",
            "greatly\n",
            "expands\n",
            "the\n",
            "applicability\n",
            "of\n",
            "adversarial\n",
            "attacks\n",
            ".\n",
            "We\n",
            "propose\n",
            "three\n",
            "mechanisms\n",
            "for\n",
            "training\n",
            "with\n",
            "a\n",
            "very\n",
            "small\n",
            "dataset\n",
            "(\n",
            "on\n",
            "the\n",
            "order\n",
            "of\n",
            "tens\n",
            "of\n",
            "examples\n",
            ")\n",
            "and\n",
            "ﬁnd\n",
            "that\n",
            "prototypical\n",
            "reconstruction\n",
            "is\n",
            "the\n",
            "most\n",
            "effective\n",
            ".\n",
            "Our\n",
            "experiments\n",
            "show\n",
            "that\n",
            "adversarial\n",
            "examples\n",
            "crafted\n",
            "on\n",
            "prototypical\n",
            "auto-encoding\n",
            "models\n",
            "transfer\n",
            "well\n",
            "to\n",
            "a\n",
            "variety\n",
            "of\n",
            "image\n",
            "classiﬁcation\n",
            "and\n",
            "face\n",
            "veriﬁcation\n",
            "models\n",
            ".\n",
            "On\n",
            "a\n",
            "commercial\n",
            "celebrity\n",
            "recognition\n",
            "system\n",
            "held\n",
            "by\n",
            "clarifai.com\n",
            ",\n",
            "our\n",
            "approach\n",
            "signiﬁcantly\n",
            "diminishes\n",
            "the\n",
            "average\n",
            "prediction\n",
            "accuracy\n",
            "of\n",
            "the\n",
            "system\n",
            "to\n",
            "only\n",
            "15.40\n",
            "%\n",
            ",\n",
            "which\n",
            "is\n",
            "on\n",
            "par\n",
            "with\n",
            "the\n",
            "attack\n",
            "that\n",
            "trans-\n",
            "fers\n",
            "adversarial\n",
            "examples\n",
            "from\n",
            "a\n",
            "pre-trained\n",
            "Arcface\n",
            "model\n",
            ".\n",
            "Our\n",
            "code\n",
            "is\n",
            "publicly\n",
            "available\n",
            "at\n",
            ":\n",
            "https\n",
            ":\n",
            "//github.com/qizhangli/nobox-attacks\n",
            ".\n",
            "1\n",
            "Abstract\n",
            "We\n",
            "present\n",
            "a\n",
            "causal\n",
            "view\n",
            "on\n",
            "the\n",
            "robustness\n",
            "of\n",
            "neural\n",
            "networks\n",
            "against\n",
            "input\n",
            "manip-\n",
            "ulations\n",
            ",\n",
            "which\n",
            "applies\n",
            "not\n",
            "only\n",
            "to\n",
            "traditional\n",
            "classiﬁcation\n",
            "tasks\n",
            "but\n",
            "also\n",
            "to\n",
            "general\n",
            "measurement\n",
            "data\n",
            ".\n",
            "Based\n",
            "on\n",
            "this\n",
            "view\n",
            ",\n",
            "we\n",
            "design\n",
            "a\n",
            "deep\n",
            "causal\n",
            "manipulation\n",
            "augmented\n",
            "model\n",
            "(\n",
            "deep\n",
            "CAMA\n",
            ")\n",
            "which\n",
            "explicitly\n",
            "models\n",
            "possible\n",
            "manipulations\n",
            "on\n",
            "certain\n",
            "causes\n",
            "leading\n",
            "to\n",
            "changes\n",
            "in\n",
            "the\n",
            "observed\n",
            "effect\n",
            ".\n",
            "We\n",
            "further\n",
            "develop\n",
            "data\n",
            "augmentation\n",
            "and\n",
            "test-time\n",
            "ﬁne-tuning\n",
            "methods\n",
            "to\n",
            "improve\n",
            "deep\n",
            "CAMA\n",
            "’\n",
            "s\n",
            "ro-\n",
            "bustness\n",
            ".\n",
            "When\n",
            "compared\n",
            "with\n",
            "discriminative\n",
            "deep\n",
            "neural\n",
            "networks\n",
            ",\n",
            "our\n",
            "proposed\n",
            "model\n",
            "shows\n",
            "superior\n",
            "robustness\n",
            "against\n",
            "unseen\n",
            "manipulations\n",
            ".\n",
            "As\n",
            "a\n",
            "by-product\n",
            ",\n",
            "our\n",
            "model\n",
            "achieves\n",
            "disentangled\n",
            "representation\n",
            "which\n",
            "separates\n",
            "the\n",
            "representation\n",
            "of\n",
            "manipulations\n",
            "from\n",
            "those\n",
            "of\n",
            "other\n",
            "latent\n",
            "causes\n",
            ".\n",
            "1\n",
            "Abstract\n",
            "We\n",
            "present\n",
            "a\n",
            "method\n",
            "for\n",
            "provably\n",
            "defending\n",
            "any\n",
            "pretrained\n",
            "image\n",
            "classiﬁer\n",
            "against\n",
            "(\n",
            "cid:96\n",
            ")\n",
            "p\n",
            "adversarial\n",
            "attacks\n",
            ".\n",
            "This\n",
            "method\n",
            ",\n",
            "for\n",
            "instance\n",
            ",\n",
            "allows\n",
            "public\n",
            "vision\n",
            "API\n",
            "providers\n",
            "and\n",
            "users\n",
            "to\n",
            "seamlessly\n",
            "convert\n",
            "pretrained\n",
            "non-robust\n",
            "classiﬁcation\n",
            "services\n",
            "into\n",
            "provably\n",
            "robust\n",
            "ones\n",
            ".\n",
            "By\n",
            "prepending\n",
            "a\n",
            "custom-trained\n",
            "denoiser\n",
            "to\n",
            "any\n",
            "off-the-\n",
            "shelf\n",
            "image\n",
            "classiﬁer\n",
            "and\n",
            "using\n",
            "randomized\n",
            "smoothing\n",
            ",\n",
            "we\n",
            "effectively\n",
            "create\n",
            "a\n",
            "new\n",
            "classiﬁer\n",
            "that\n",
            "is\n",
            "guaranteed\n",
            "to\n",
            "be\n",
            "(\n",
            "cid:96\n",
            ")\n",
            "p-robust\n",
            "to\n",
            "adversarial\n",
            "examples\n",
            ",\n",
            "without\n",
            "modifying\n",
            "the\n",
            "pretrained\n",
            "classiﬁer\n",
            ".\n",
            "Our\n",
            "approach\n",
            "applies\n",
            "to\n",
            "both\n",
            "the\n",
            "white-box\n",
            "and\n",
            "the\n",
            "black-box\n",
            "settings\n",
            "of\n",
            "the\n",
            "pretrained\n",
            "classiﬁer\n",
            ".\n",
            "We\n",
            "refer\n",
            "to\n",
            "this\n",
            "defense\n",
            "as\n",
            "denoised\n",
            "smoothing\n",
            ",\n",
            "and\n",
            "we\n",
            "demonstrate\n",
            "its\n",
            "effectiveness\n",
            "through\n",
            "extensive\n",
            "experimentation\n",
            "on\n",
            "ImageNet\n",
            "and\n",
            "CIFAR-10\n",
            ".\n",
            "Finally\n",
            ",\n",
            "we\n",
            "use\n",
            "our\n",
            "approach\n",
            "to\n",
            "provably\n",
            "defend\n",
            "the\n",
            "Azure\n",
            ",\n",
            "Google\n",
            ",\n",
            "AWS\n",
            ",\n",
            "and\n",
            "ClarifAI\n",
            "image\n",
            "classiﬁcation\n",
            "APIs\n",
            ".\n",
            "Our\n",
            "code\n",
            "replicating\n",
            "all\n",
            "the\n",
            "experiments\n",
            "in\n",
            "the\n",
            "paper\n",
            "can\n",
            "be\n",
            "found\n",
            "at\n",
            ":\n",
            "https\n",
            ":\n",
            "//github.com/microsoft/denoised-smoothing1\n",
            ".\n",
            "Abstract\n",
            "Solving\n",
            "optimization\n",
            "problems\n",
            "with\n",
            "unknown\n",
            "parameters\n",
            "often\n",
            "requires\n",
            "learning\n",
            "a\n",
            "predictive\n",
            "model\n",
            "to\n",
            "predict\n",
            "the\n",
            "values\n",
            "of\n",
            "the\n",
            "unknown\n",
            "parameters\n",
            "and\n",
            "then\n",
            "solving\n",
            "the\n",
            "problem\n",
            "using\n",
            "these\n",
            "values\n",
            ".\n",
            "Recent\n",
            "work\n",
            "has\n",
            "shown\n",
            "that\n",
            "including\n",
            "the\n",
            "opti-\n",
            "mization\n",
            "problem\n",
            "as\n",
            "a\n",
            "layer\n",
            "in\n",
            "the\n",
            "model\n",
            "training\n",
            "pipeline\n",
            "results\n",
            "in\n",
            "predictions\n",
            "of\n",
            "the\n",
            "unobserved\n",
            "parameters\n",
            "that\n",
            "lead\n",
            "to\n",
            "higher\n",
            "decision\n",
            "quality\n",
            ".\n",
            "Unfortunately\n",
            ",\n",
            "this\n",
            "process\n",
            "comes\n",
            "at\n",
            "a\n",
            "large\n",
            "computational\n",
            "cost\n",
            "because\n",
            "the\n",
            "optimization\n",
            "problem\n",
            "must\n",
            "be\n",
            "solved\n",
            "and\n",
            "differentiated\n",
            "through\n",
            "in\n",
            "each\n",
            "training\n",
            "iteration\n",
            ";\n",
            "furthermore\n",
            ",\n",
            "it\n",
            "may\n",
            "also\n",
            "sometimes\n",
            "fail\n",
            "to\n",
            "improve\n",
            "solution\n",
            "quality\n",
            "due\n",
            "to\n",
            "non-smoothness\n",
            "issues\n",
            "that\n",
            "arise\n",
            "when\n",
            "training\n",
            "through\n",
            "a\n",
            "complex\n",
            "optimization\n",
            "layer\n",
            ".\n",
            "To\n",
            "address\n",
            "these\n",
            "shortcomings\n",
            ",\n",
            "we\n",
            "learn\n",
            "a\n",
            "low-dimensional\n",
            "surrogate\n",
            "model\n",
            "of\n",
            "a\n",
            "large\n",
            "opti-\n",
            "mization\n",
            "problem\n",
            "by\n",
            "representing\n",
            "the\n",
            "feasible\n",
            "space\n",
            "in\n",
            "terms\n",
            "of\n",
            "meta-variables\n",
            ",\n",
            "each\n",
            "of\n",
            "which\n",
            "is\n",
            "a\n",
            "linear\n",
            "combination\n",
            "of\n",
            "the\n",
            "original\n",
            "variables\n",
            ".\n",
            "By\n",
            "training\n",
            "a\n",
            "low-dimensional\n",
            "surrogate\n",
            "model\n",
            "end-to-end\n",
            ",\n",
            "and\n",
            "jointly\n",
            "with\n",
            "the\n",
            "predictive\n",
            "model\n",
            ",\n",
            "we\n",
            "achieve\n",
            ":\n",
            "i\n",
            ")\n",
            "a\n",
            "large\n",
            "reduction\n",
            "in\n",
            "training\n",
            "and\n",
            "inference\n",
            "time\n",
            ";\n",
            "and\n",
            "ii\n",
            ")\n",
            "improved\n",
            "per-\n",
            "formance\n",
            "by\n",
            "focusing\n",
            "attention\n",
            "on\n",
            "the\n",
            "more\n",
            "important\n",
            "variables\n",
            "in\n",
            "the\n",
            "optimization\n",
            "and\n",
            "learning\n",
            "in\n",
            "a\n",
            "smoother\n",
            "space\n",
            ".\n",
            "Empirically\n",
            ",\n",
            "we\n",
            "demonstrate\n",
            "these\n",
            "improvements\n",
            "on\n",
            "a\n",
            "non-convex\n",
            "adversary\n",
            "modeling\n",
            "task\n",
            ",\n",
            "a\n",
            "submodular\n",
            "recommendation\n",
            "task\n",
            "and\n",
            "a\n",
            "convex\n",
            "portfolio\n",
            "optimization\n",
            "task\n",
            ".\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "df_output                                                 topic  ... rank_lda\n",
            "0              graph similarity deep learning neurips  ...      6.0\n",
            "1              graph similarity deep learning neurips  ...     10.0\n",
            "2              graph similarity deep learning neurips  ...      2.0\n",
            "3              graph similarity deep learning neurips  ...      5.0\n",
            "4              graph similarity deep learning neurips  ...      1.0\n",
            "..                                                ...  ...      ...\n",
            "4   backpropagating linearly improves transferabil...  ...      8.0\n",
            "5   backpropagating linearly improves transferabil...  ...      3.0\n",
            "6   backpropagating linearly improves transferabil...  ...      5.0\n",
            "7   backpropagating linearly improves transferabil...  ...      7.0\n",
            "8   backpropagating linearly improves transferabil...  ...      6.0\n",
            "\n",
            "[67 rows x 8 columns]\n",
            "topic:  pyglove symbolic programming automated machine learning neurips id_= 8\n",
            "1 . PyGlove: Symbolic Programming for Automated Machine Learning https://papers.nips.cc/paper/2020/hash/012a91467f210472fab4e11359bbfef6-Abstract.html\n",
            "**********************************************\n",
            "2 . PyGlove: Symbolic Programming for Automated Machine Learning https://papers.nips.cc/paper/2020/file/012a91467f210472fab4e11359bbfef6-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Neural networks are sensitive to hyper-parameter and architecture choices. Auto-\n",
            "mated Machine Learning (AutoML) is a promising paradigm for automating these\n",
            "choices. Current ML software libraries, however, are quite limited in handling the\n",
            "dynamic interactions among the components of AutoML. For example, efﬁcient\n",
            "NAS algorithms, such as ENAS [1] and DARTS [2], typically require an imple-\n",
            "mentation coupling between the search space and search algorithm, the two key\n",
            "components in AutoML. Furthermore, implementing a complex search ﬂow, such\n",
            "as searching architectures within a loop of searching hardware conﬁgurations, is\n",
            "difﬁcult. To summarize, changing the search space, search algorithm, or search ﬂow\n",
            "in current ML libraries usually requires a signiﬁcant change in the program logic.\n",
            "In this paper, we introduce a new way of programming AutoML based on symbolic\n",
            "programming. Under this paradigm, ML programs are mutable, thus can be\n",
            "manipulated easily by another program. As a result, AutoML can be reformulated\n",
            "as an automated process of symbolic manipulation. With this formulation, we\n",
            "decouple the triangle of the search algorithm, the search space and the child\n",
            "program. This decoupling makes it easy to change the search space and search\n",
            "algorithm (without and with weight sharing), as well as to add search capabilities\n",
            "to existing code and implement complex search ﬂows. We then introduce PyGlove,\n",
            "a new Python library that implements this paradigm. Through case studies on\n",
            "ImageNet and NAS-Bench-101, we show that with PyGlove users can easily\n",
            "convert a static program into a search space, quickly iterate on the search spaces\n",
            "and search algorithms, and craft complex search ﬂows to achieve better results.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "3 . PyGlove: Symbolic Programming for ... - Review for NeurIPS paper https://papers.nips.cc/paper/2020/file/012a91467f210472fab4e11359bbfef6-Review.html\n",
            "**********************************************\n",
            "4 . PyGlove: Symbolic Programming for ... - Review for NeurIPS paper https://papers.nips.cc/paper/2020/file/012a91467f210472fab4e11359bbfef6-MetaReview.html\n",
            "**********************************************\n",
            "5 . Advances in Neural Information Processing Systems 33 (NeurIPS ... https://papers.nips.cc/paper/2020\n",
            "**********************************************\n",
            "data:                                                topic  ...                                                url\n",
            "0  pyglove symbolic programming automated machine...  ...  https://papers.nips.cc/paper/2020/hash/012a914...\n",
            "1  pyglove symbolic programming automated machine...  ...  https://papers.nips.cc/paper/2020/file/012a914...\n",
            "2  pyglove symbolic programming automated machine...  ...  https://papers.nips.cc/paper/2020/file/012a914...\n",
            "3  pyglove symbolic programming automated machine...  ...  https://papers.nips.cc/paper/2020/file/012a914...\n",
            "4  pyglove symbolic programming automated machine...  ...                  https://papers.nips.cc/paper/2020\n",
            "\n",
            "[5 rows x 4 columns]\n",
            "**********************************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                                               topic  ... similarity_score\n",
            "0  pyglove symbolic programming automated machine...  ...         0.963106\n",
            "1  pyglove symbolic programming automated machine...  ...         0.960162\n",
            "2  pyglove symbolic programming automated machine...  ...         0.963674\n",
            "3  pyglove symbolic programming automated machine...  ...         0.959733\n",
            "4  pyglove symbolic programming automated machine...  ...         0.964891\n",
            "\n",
            "[5 rows x 5 columns]\n",
            "df_final after rank=                                                topic  ... rank\n",
            "0  pyglove symbolic programming automated machine...  ...  3.0\n",
            "1  pyglove symbolic programming automated machine...  ...  4.0\n",
            "2  pyglove symbolic programming automated machine...  ...  2.0\n",
            "3  pyglove symbolic programming automated machine...  ...  5.0\n",
            "4  pyglove symbolic programming automated machine...  ...  1.0\n",
            "\n",
            "[5 rows x 6 columns]\n",
            "0    PyGlove: Symbolic Programming for Automated Ma...\n",
            "1    Abstract\\n\\nNeural networks are sensitive to h...\n",
            "2    NeurIPS 2020\\n\\nPyGlove: Symbolic Programming ...\n",
            "3    NeurIPS 2020\\n\\nPyGlove: Symbolic Programming ...\n",
            "4    Book\\n\\nDo not remove: This comment is monitor...\n",
            "Name: text, dtype: object\n",
            "PyGlove\n",
            ":\n",
            "Symbolic\n",
            "Programming\n",
            "for\n",
            "Automated\n",
            "Machine\n",
            "Learning\n",
            "Part\n",
            "of\n",
            "Advances\n",
            "in\n",
            "Neural\n",
            "Information\n",
            "Processing\n",
            "Systems\n",
            "33\n",
            "(\n",
            "NeurIPS\n",
            "2020\n",
            ")\n",
            "Authors\n",
            "Daiyi\n",
            "Peng\n",
            ",\n",
            "Xuanyi\n",
            "Dong\n",
            ",\n",
            "Esteban\n",
            "Real\n",
            ",\n",
            "Mingxing\n",
            "Tan\n",
            ",\n",
            "Yifeng\n",
            "Lu\n",
            ",\n",
            "Gabriel\n",
            "Bender\n",
            ",\n",
            "Hanxiao\n",
            "Liu\n",
            ",\n",
            "Adam\n",
            "Kraft\n",
            ",\n",
            "Chen\n",
            "Liang\n",
            ",\n",
            "Quoc\n",
            "Le\n",
            "Abstract\n",
            "Neural\n",
            "networks\n",
            "are\n",
            "sensitive\n",
            "to\n",
            "hyper-parameter\n",
            "and\n",
            "architecture\n",
            "choices\n",
            ".\n",
            "Automated\n",
            "Machine\n",
            "Learning\n",
            "(\n",
            "AutoML\n",
            ")\n",
            "is\n",
            "a\n",
            "promising\n",
            "paradigm\n",
            "for\n",
            "automating\n",
            "these\n",
            "choices\n",
            ".\n",
            "Current\n",
            "ML\n",
            "software\n",
            "libraries\n",
            ",\n",
            "however\n",
            ",\n",
            "are\n",
            "quite\n",
            "limited\n",
            "in\n",
            "handling\n",
            "the\n",
            "dynamic\n",
            "interactions\n",
            "among\n",
            "the\n",
            "components\n",
            "of\n",
            "AutoML\n",
            ".\n",
            "For\n",
            "example\n",
            ",\n",
            "efficient\n",
            "NAS\n",
            "algorithms\n",
            ",\n",
            "such\n",
            "as\n",
            "ENAS\n",
            "and\n",
            "DARTS\n",
            ",\n",
            "typically\n",
            "require\n",
            "an\n",
            "implementation\n",
            "coupling\n",
            "between\n",
            "the\n",
            "search\n",
            "space\n",
            "and\n",
            "search\n",
            "algorithm\n",
            ",\n",
            "the\n",
            "two\n",
            "key\n",
            "components\n",
            "in\n",
            "AutoML\n",
            ".\n",
            "Furthermore\n",
            ",\n",
            "implementing\n",
            "a\n",
            "complex\n",
            "search\n",
            "flow\n",
            ",\n",
            "such\n",
            "as\n",
            "searching\n",
            "architectures\n",
            "within\n",
            "a\n",
            "loop\n",
            "of\n",
            "searching\n",
            "hardware\n",
            "configurations\n",
            ",\n",
            "is\n",
            "difficult\n",
            ".\n",
            "To\n",
            "summarize\n",
            ",\n",
            "changing\n",
            "the\n",
            "search\n",
            "space\n",
            ",\n",
            "search\n",
            "algorithm\n",
            ",\n",
            "or\n",
            "search\n",
            "flow\n",
            "in\n",
            "current\n",
            "ML\n",
            "libraries\n",
            "usually\n",
            "requires\n",
            "a\n",
            "significant\n",
            "change\n",
            "in\n",
            "the\n",
            "program\n",
            "logic\n",
            ".\n",
            "In\n",
            "this\n",
            "paper\n",
            ",\n",
            "we\n",
            "introduce\n",
            "a\n",
            "new\n",
            "way\n",
            "of\n",
            "programming\n",
            "AutoML\n",
            "based\n",
            "on\n",
            "symbolic\n",
            "programming\n",
            ".\n",
            "Under\n",
            "this\n",
            "paradigm\n",
            ",\n",
            "ML\n",
            "programs\n",
            "are\n",
            "mutable\n",
            ",\n",
            "thus\n",
            "can\n",
            "be\n",
            "manipulated\n",
            "easily\n",
            "by\n",
            "another\n",
            "program\n",
            ".\n",
            "As\n",
            "a\n",
            "result\n",
            ",\n",
            "AutoML\n",
            "can\n",
            "be\n",
            "reformulated\n",
            "as\n",
            "an\n",
            "automated\n",
            "process\n",
            "of\n",
            "symbolic\n",
            "manipulation\n",
            ".\n",
            "With\n",
            "this\n",
            "formulation\n",
            ",\n",
            "we\n",
            "decouple\n",
            "the\n",
            "triangle\n",
            "of\n",
            "the\n",
            "search\n",
            "algorithm\n",
            ",\n",
            "the\n",
            "search\n",
            "space\n",
            "and\n",
            "the\n",
            "child\n",
            "program\n",
            ".\n",
            "This\n",
            "decoupling\n",
            "makes\n",
            "it\n",
            "easy\n",
            "to\n",
            "change\n",
            "the\n",
            "search\n",
            "space\n",
            "and\n",
            "search\n",
            "algorithm\n",
            "(\n",
            "without\n",
            "and\n",
            "with\n",
            "weight\n",
            "sharing\n",
            ")\n",
            ",\n",
            "as\n",
            "well\n",
            "as\n",
            "to\n",
            "add\n",
            "search\n",
            "capabilities\n",
            "to\n",
            "existing\n",
            "code\n",
            "and\n",
            "implement\n",
            "complex\n",
            "search\n",
            "flows\n",
            ".\n",
            "We\n",
            "then\n",
            "introduce\n",
            "PyGlove\n",
            ",\n",
            "a\n",
            "new\n",
            "Python\n",
            "library\n",
            "that\n",
            "implements\n",
            "this\n",
            "paradigm\n",
            ".\n",
            "Through\n",
            "case\n",
            "studies\n",
            "on\n",
            "ImageNet\n",
            "and\n",
            "NAS-Bench-101\n",
            ",\n",
            "we\n",
            "show\n",
            "that\n",
            "with\n",
            "PyGlove\n",
            "users\n",
            "can\n",
            "easily\n",
            "convert\n",
            "a\n",
            "static\n",
            "program\n",
            "into\n",
            "a\n",
            "search\n",
            "space\n",
            ",\n",
            "quickly\n",
            "iterate\n",
            "on\n",
            "the\n",
            "search\n",
            "spaces\n",
            "and\n",
            "search\n",
            "algorithms\n",
            ",\n",
            "and\n",
            "craft\n",
            "complex\n",
            "search\n",
            "flows\n",
            "to\n",
            "achieve\n",
            "better\n",
            "results\n",
            ".\n",
            "Abstract\n",
            "Neural\n",
            "networks\n",
            "are\n",
            "sensitive\n",
            "to\n",
            "hyper-parameter\n",
            "and\n",
            "architecture\n",
            "choices\n",
            ".\n",
            "Auto-\n",
            "mated\n",
            "Machine\n",
            "Learning\n",
            "(\n",
            "AutoML\n",
            ")\n",
            "is\n",
            "a\n",
            "promising\n",
            "paradigm\n",
            "for\n",
            "automating\n",
            "these\n",
            "choices\n",
            ".\n",
            "Current\n",
            "ML\n",
            "software\n",
            "libraries\n",
            ",\n",
            "however\n",
            ",\n",
            "are\n",
            "quite\n",
            "limited\n",
            "in\n",
            "handling\n",
            "the\n",
            "dynamic\n",
            "interactions\n",
            "among\n",
            "the\n",
            "components\n",
            "of\n",
            "AutoML\n",
            ".\n",
            "For\n",
            "example\n",
            ",\n",
            "efﬁcient\n",
            "NAS\n",
            "algorithms\n",
            ",\n",
            "such\n",
            "as\n",
            "ENAS\n",
            "[\n",
            "1\n",
            "]\n",
            "and\n",
            "DARTS\n",
            "[\n",
            "2\n",
            "]\n",
            ",\n",
            "typically\n",
            "require\n",
            "an\n",
            "imple-\n",
            "mentation\n",
            "coupling\n",
            "between\n",
            "the\n",
            "search\n",
            "space\n",
            "and\n",
            "search\n",
            "algorithm\n",
            ",\n",
            "the\n",
            "two\n",
            "key\n",
            "components\n",
            "in\n",
            "AutoML\n",
            ".\n",
            "Furthermore\n",
            ",\n",
            "implementing\n",
            "a\n",
            "complex\n",
            "search\n",
            "ﬂow\n",
            ",\n",
            "such\n",
            "as\n",
            "searching\n",
            "architectures\n",
            "within\n",
            "a\n",
            "loop\n",
            "of\n",
            "searching\n",
            "hardware\n",
            "conﬁgurations\n",
            ",\n",
            "is\n",
            "difﬁcult\n",
            ".\n",
            "To\n",
            "summarize\n",
            ",\n",
            "changing\n",
            "the\n",
            "search\n",
            "space\n",
            ",\n",
            "search\n",
            "algorithm\n",
            ",\n",
            "or\n",
            "search\n",
            "ﬂow\n",
            "in\n",
            "current\n",
            "ML\n",
            "libraries\n",
            "usually\n",
            "requires\n",
            "a\n",
            "signiﬁcant\n",
            "change\n",
            "in\n",
            "the\n",
            "program\n",
            "logic\n",
            ".\n",
            "In\n",
            "this\n",
            "paper\n",
            ",\n",
            "we\n",
            "introduce\n",
            "a\n",
            "new\n",
            "way\n",
            "of\n",
            "programming\n",
            "AutoML\n",
            "based\n",
            "on\n",
            "symbolic\n",
            "programming\n",
            ".\n",
            "Under\n",
            "this\n",
            "paradigm\n",
            ",\n",
            "ML\n",
            "programs\n",
            "are\n",
            "mutable\n",
            ",\n",
            "thus\n",
            "can\n",
            "be\n",
            "manipulated\n",
            "easily\n",
            "by\n",
            "another\n",
            "program\n",
            ".\n",
            "As\n",
            "a\n",
            "result\n",
            ",\n",
            "AutoML\n",
            "can\n",
            "be\n",
            "reformulated\n",
            "as\n",
            "an\n",
            "automated\n",
            "process\n",
            "of\n",
            "symbolic\n",
            "manipulation\n",
            ".\n",
            "With\n",
            "this\n",
            "formulation\n",
            ",\n",
            "we\n",
            "decouple\n",
            "the\n",
            "triangle\n",
            "of\n",
            "the\n",
            "search\n",
            "algorithm\n",
            ",\n",
            "the\n",
            "search\n",
            "space\n",
            "and\n",
            "the\n",
            "child\n",
            "program\n",
            ".\n",
            "This\n",
            "decoupling\n",
            "makes\n",
            "it\n",
            "easy\n",
            "to\n",
            "change\n",
            "the\n",
            "search\n",
            "space\n",
            "and\n",
            "search\n",
            "algorithm\n",
            "(\n",
            "without\n",
            "and\n",
            "with\n",
            "weight\n",
            "sharing\n",
            ")\n",
            ",\n",
            "as\n",
            "well\n",
            "as\n",
            "to\n",
            "add\n",
            "search\n",
            "capabilities\n",
            "to\n",
            "existing\n",
            "code\n",
            "and\n",
            "implement\n",
            "complex\n",
            "search\n",
            "ﬂows\n",
            ".\n",
            "We\n",
            "then\n",
            "introduce\n",
            "PyGlove\n",
            ",\n",
            "a\n",
            "new\n",
            "Python\n",
            "library\n",
            "that\n",
            "implements\n",
            "this\n",
            "paradigm\n",
            ".\n",
            "Through\n",
            "case\n",
            "studies\n",
            "on\n",
            "ImageNet\n",
            "and\n",
            "NAS-Bench-101\n",
            ",\n",
            "we\n",
            "show\n",
            "that\n",
            "with\n",
            "PyGlove\n",
            "users\n",
            "can\n",
            "easily\n",
            "convert\n",
            "a\n",
            "static\n",
            "program\n",
            "into\n",
            "a\n",
            "search\n",
            "space\n",
            ",\n",
            "quickly\n",
            "iterate\n",
            "on\n",
            "the\n",
            "search\n",
            "spaces\n",
            "and\n",
            "search\n",
            "algorithms\n",
            ",\n",
            "and\n",
            "craft\n",
            "complex\n",
            "search\n",
            "ﬂows\n",
            "to\n",
            "achieve\n",
            "better\n",
            "results\n",
            ".\n",
            "1\n",
            "NeurIPS\n",
            "2020\n",
            "PyGlove\n",
            ":\n",
            "Symbolic\n",
            "Programming\n",
            "for\n",
            "Automated\n",
            "Machine\n",
            "Learning\n",
            "Review\n",
            "1\n",
            "Summary\n",
            "and\n",
            "Contributions\n",
            ":\n",
            "This\n",
            "paper\n",
            "introduces\n",
            "PyGlove—a\n",
            "Python\n",
            "library\n",
            "for\n",
            "AutoML\n",
            ".\n",
            "PyGlove\n",
            "makes\n",
            "implementing\n",
            "AutoML\n",
            "easier\n",
            "by\n",
            "decoupling\n",
            "the\n",
            "search\n",
            "space\n",
            ",\n",
            "search\n",
            "algorithm\n",
            ",\n",
            "and\n",
            "child\n",
            "programs\n",
            ".\n",
            "The\n",
            "decoupling\n",
            "is\n",
            "realized\n",
            "by\n",
            "symbolic\n",
            "programming\n",
            ".\n",
            "The\n",
            "search\n",
            "space\n",
            "and\n",
            "programs\n",
            "are\n",
            "represented\n",
            "as\n",
            "symbolic\n",
            "trees\n",
            ",\n",
            "which\n",
            "is\n",
            "manipulated\n",
            "by\n",
            "the\n",
            "search\n",
            "algorithm\n",
            ".\n",
            "The\n",
            "authors\n",
            "present\n",
            "use\n",
            "cases\n",
            "on\n",
            "ImageNet\n",
            "and\n",
            "NAS-Bench-101\n",
            ",\n",
            "demonstrating\n",
            "that\n",
            "users\n",
            "can\n",
            "implement\n",
            "complex\n",
            "search\n",
            "flows\n",
            "easily\n",
            "with\n",
            "PyGlove\n",
            ".\n",
            "Strengths\n",
            ":\n",
            "+\n",
            "The\n",
            "proposed\n",
            "PyGove\n",
            "library\n",
            "could\n",
            "be\n",
            "a\n",
            "useful\n",
            "tool\n",
            "for\n",
            "AutoML\n",
            "researchers\n",
            "and\n",
            "practitioners\n",
            ".\n",
            "In\n",
            "existing\n",
            "tools\n",
            "for\n",
            "AutoML\n",
            ",\n",
            "the\n",
            "search\n",
            "space\n",
            "is\n",
            "often\n",
            "coupled\n",
            "with\n",
            "the\n",
            "search\n",
            "algorithm\n",
            ",\n",
            "making\n",
            "it\n",
            "difficult\n",
            "to\n",
            "change\n",
            "either\n",
            "of\n",
            "them\n",
            ".\n",
            "In\n",
            "contrast\n",
            ",\n",
            "PyGlove\n",
            "uses\n",
            "symbolic\n",
            "programming\n",
            "to\n",
            "decouple\n",
            "the\n",
            "search\n",
            "space\n",
            "and\n",
            "search\n",
            "algorithm\n",
            ",\n",
            "which\n",
            "makes\n",
            "it\n",
            "easier\n",
            "to\n",
            "experiment\n",
            "with\n",
            "different\n",
            "prototypes\n",
            ".\n",
            "+\n",
            "Use\n",
            "cases\n",
            "on\n",
            "ImageNet\n",
            "and\n",
            "NAS-Bench-101\n",
            "demonstrate\n",
            "that\n",
            "we\n",
            "can\n",
            "implement\n",
            "different\n",
            "NAS\n",
            "algorithms\n",
            "in\n",
            "PyGlove\n",
            "easily\n",
            ".\n",
            "The\n",
            "high-level\n",
            "search\n",
            "strategy\n",
            "can\n",
            "be\n",
            "described\n",
            "by\n",
            "only\n",
            "a\n",
            "few\n",
            "lines\n",
            "of\n",
            "code\n",
            ".\n",
            "+\n",
            "The\n",
            "paper\n",
            "is\n",
            "well-written\n",
            "and\n",
            "easy\n",
            "to\n",
            "follow\n",
            ".\n",
            "Weaknesses\n",
            ":\n",
            "-\n",
            "The\n",
            "language\n",
            "for\n",
            "specifying\n",
            "the\n",
            "search\n",
            "space\n",
            "may\n",
            "not\n",
            "be\n",
            "expressive\n",
            "enough\n",
            "to\n",
            "capture\n",
            "a\n",
            "wide\n",
            "range\n",
            "of\n",
            "search\n",
            "space\n",
            "designs\n",
            ".\n",
            "Currently\n",
            ",\n",
            "it\n",
            "has\n",
            "``\n",
            "floatv\n",
            "''\n",
            "for\n",
            "a\n",
            "floating-point\n",
            "range\n",
            ",\n",
            "``\n",
            "intv\n",
            "''\n",
            "for\n",
            "an\n",
            "integer\n",
            "range\n",
            ",\n",
            "``\n",
            "oneof\n",
            "''\n",
            "for\n",
            "choosing\n",
            "one\n",
            "value\n",
            "from\n",
            "a\n",
            "candidate\n",
            "list\n",
            ",\n",
            "and\n",
            "``\n",
            "permutate\n",
            "''\n",
            "for\n",
            "generating\n",
            "permutations\n",
            "of\n",
            "modules\n",
            ".\n",
            "It\n",
            "would\n",
            "be\n",
            "great\n",
            "to\n",
            "discuss\n",
            "whether\n",
            "these\n",
            "primitives\n",
            "can\n",
            "cover\n",
            "search\n",
            "spaces\n",
            "designed\n",
            "in\n",
            "existing\n",
            "NAS\n",
            "literature\n",
            ".\n",
            "-\n",
            "It\n",
            "would\n",
            "be\n",
            "more\n",
            "convincing\n",
            "if\n",
            "the\n",
            "authors\n",
            "include\n",
            "use\n",
            "cases\n",
            "where\n",
            "they\n",
            "replicate\n",
            "prior\n",
            "work\n",
            "in\n",
            "NAS\n",
            "using\n",
            "PyGlove\n",
            ".\n",
            "If\n",
            "it\n",
            "'s\n",
            "possible\n",
            "to\n",
            "do\n",
            "so\n",
            "with\n",
            "very\n",
            "few\n",
            "lines\n",
            "of\n",
            "code\n",
            ",\n",
            "this\n",
            "is\n",
            "strong\n",
            "evidence\n",
            "for\n",
            "the\n",
            "usefulness\n",
            "of\n",
            "PyGlove\n",
            ".\n",
            "Correctness\n",
            ":\n",
            "I\n",
            "do\n",
            "n't\n",
            "see\n",
            "any\n",
            "significant\n",
            "flaws\n",
            "in\n",
            "methodology\n",
            ".\n",
            "Clarity\n",
            ":\n",
            "Yes\n",
            ".\n",
            "Relation\n",
            "to\n",
            "Prior\n",
            "Work\n",
            ":\n",
            "Yes\n",
            ".\n",
            "Reproducibility\n",
            ":\n",
            "Yes\n",
            "Additional\n",
            "Feedback\n",
            ":\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "-\n",
            "Post-rebuttal\n",
            "Update\n",
            "I\n",
            "have\n",
            "read\n",
            "the\n",
            "rebuttal\n",
            "and\n",
            "other\n",
            "reviews\n",
            ".\n",
            "The\n",
            "authors\n",
            "have\n",
            "addressed\n",
            "my\n",
            "questions\n",
            "to\n",
            "a\n",
            "reasonable\n",
            "extent\n",
            ".\n",
            "I\n",
            "would\n",
            "recommend\n",
            "accept\n",
            "for\n",
            "this\n",
            "paper\n",
            ".\n",
            "Review\n",
            "2\n",
            "Summary\n",
            "and\n",
            "Contributions\n",
            ":\n",
            "The\n",
            "paper\n",
            "introduces\n",
            "an\n",
            "AutoML\n",
            "library\n",
            "that\n",
            "tries\n",
            "to\n",
            "find\n",
            "its\n",
            "own\n",
            "sweet\n",
            "spot\n",
            "in\n",
            "the\n",
            "large\n",
            "ecosystem\n",
            "of\n",
            "newly\n",
            "minted\n",
            "AutoML\n",
            "libraries\n",
            ".\n",
            "The\n",
            "paper\n",
            "introduces\n",
            "a\n",
            "symbolic\n",
            "frontend\n",
            "to\n",
            "build\n",
            "neural\n",
            "network\n",
            "models\n",
            ",\n",
            "with\n",
            "simple\n",
            "fundamental\n",
            "constructs\n",
            "that\n",
            "provide\n",
            "choice\n",
            "insertions\n",
            ".\n",
            "Unlike\n",
            "all\n",
            "other\n",
            "packages\n",
            "that\n",
            "I\n",
            "have\n",
            "seen\n",
            "and\n",
            "reviewed\n",
            ",\n",
            "such\n",
            "as\n",
            "Keras\n",
            "Tuner\n",
            ",\n",
            "NNI\n",
            ",\n",
            "AutoGluon\n",
            ",\n",
            "Optuna\n",
            "(\n",
            "btw\n",
            "reference\n",
            "missing\n",
            "to\n",
            "Optuna\n",
            ",\n",
            "you\n",
            "should\n",
            "consider\n",
            "adding\n",
            ")\n",
            ",\n",
            "this\n",
            "paper\n",
            "introduces\n",
            "something\n",
            "innovative\n",
            "and\n",
            "elegant\n",
            ".\n",
            "All\n",
            "these\n",
            "other\n",
            "packages\n",
            "consistently\n",
            "suffer\n",
            "from\n",
            "the\n",
            "code\n",
            "of\n",
            "the\n",
            "model\n",
            "definition\n",
            "getting\n",
            "ugly\n",
            "and\n",
            "unweildy\n",
            "really\n",
            "quickly\n",
            "when\n",
            "you\n",
            "have\n",
            "to\n",
            "introduce\n",
            "model\n",
            "structure\n",
            "searches\n",
            ",\n",
            "and\n",
            "when\n",
            "there\n",
            "'s\n",
            "interaction\n",
            "between\n",
            "structure\n",
            "searches\n",
            "and\n",
            "size\n",
            "searches\n",
            ".\n",
            "In\n",
            "this\n",
            "paper\n",
            ",\n",
            "the\n",
            "authors\n",
            "cleanly\n",
            "separate\n",
            "model\n",
            "structure\n",
            "definitions\n",
            "from\n",
            "each\n",
            "layer\n",
            "'s\n",
            "hyperparameter\n",
            "choices\n",
            ".\n",
            "They\n",
            "do\n",
            "this\n",
            "by\n",
            "introducing\n",
            "their\n",
            "own\n",
            "meta-layers\n",
            "which\n",
            "are\n",
            "put\n",
            "together\n",
            "in\n",
            "a\n",
            "symbolic\n",
            "frontend\n",
            "(\n",
            "ironically\n",
            ",\n",
            "TensorFlow\n",
            "v1\n",
            "would\n",
            "'ve\n",
            "been\n",
            "a\n",
            "good\n",
            "out\n",
            "of\n",
            "the\n",
            "box\n",
            "candidate\n",
            "to\n",
            "be\n",
            "fitting\n",
            "for\n",
            "this\n",
            ",\n",
            "but\n",
            "v2\n",
            "does\n",
            "n't\n",
            "allow\n",
            "the\n",
            "same\n",
            ")\n",
            ".\n",
            "Each\n",
            "of\n",
            "these\n",
            "meta-layers\n",
            "can\n",
            "be\n",
            "structurally\n",
            "permuted\n",
            ",\n",
            "as\n",
            "well\n",
            "as\n",
            "swapped\n",
            "with\n",
            "a\n",
            "dictionary\n",
            "of\n",
            "layers\n",
            ",\n",
            "using\n",
            "a\n",
            "simple\n",
            "meta-programming\n",
            "API\n",
            "that\n",
            "has\n",
            "some\n",
            "convenient\n",
            "pre-defined\n",
            "constructs\n",
            ".\n",
            "The\n",
            "general\n",
            "interface\n",
            "for\n",
            "interacting\n",
            "in\n",
            "different\n",
            "modes\n",
            "of\n",
            "search\n",
            "(\n",
            "weight\n",
            "sharing\n",
            ",\n",
            "layer\n",
            "swapping\n",
            ",\n",
            "width\n",
            "changing\n",
            ",\n",
            "etc\n",
            ".\n",
            ")\n",
            "is\n",
            "convincingly\n",
            "good\n",
            ",\n",
            "and\n",
            "articulated\n",
            "well\n",
            ".\n",
            "The\n",
            "results\n",
            "section\n",
            "of\n",
            "this\n",
            "package\n",
            "is\n",
            "a\n",
            "bit\n",
            "zero-signal\n",
            ",\n",
            "but\n",
            "at\n",
            "the\n",
            "same\n",
            "time\n",
            "it\n",
            "'s\n",
            "really\n",
            "hard\n",
            "to\n",
            "write\n",
            "a\n",
            "convincing\n",
            "results\n",
            "section\n",
            "for\n",
            "frontend\n",
            "innovation\n",
            ".\n",
            "So\n",
            ",\n",
            "I\n",
            "'m\n",
            "completely\n",
            "discounting\n",
            "this\n",
            "as\n",
            "*\n",
            "*\n",
            "not\n",
            "relevant\n",
            "for\n",
            "the\n",
            "type\n",
            "of\n",
            "paper\n",
            "*\n",
            "*\n",
            ".\n",
            "The\n",
            "authors\n",
            "are\n",
            "honest\n",
            "in\n",
            "the\n",
            "broader\n",
            "impact\n",
            "that\n",
            "AutoML\n",
            "is\n",
            "going\n",
            "to\n",
            "release\n",
            "waaaaaay\n",
            "more\n",
            "CO2\n",
            "than\n",
            "traditional\n",
            "hand-optimization\n",
            ".\n",
            "Strengths\n",
            ":\n",
            "Despite\n",
            "entering\n",
            "a\n",
            "crowded\n",
            "space\n",
            ",\n",
            "the\n",
            "paper\n",
            "does\n",
            "a\n",
            "remarkable\n",
            "job\n",
            "of\n",
            "solving\n",
            "a\n",
            "novel\n",
            "problem\n",
            "of\n",
            "releasing\n",
            "the\n",
            "tension\n",
            "between\n",
            "writing\n",
            "the\n",
            "model\n",
            "code\n",
            "in\n",
            "a\n",
            "non-ugly\n",
            "manner\n",
            "and\n",
            "inserting\n",
            "the\n",
            "automl\n",
            "search\n",
            "parameters\n",
            ",\n",
            "especially\n",
            "in\n",
            "the\n",
            "case\n",
            "of\n",
            "searching\n",
            "among\n",
            "new\n",
            "layers\n",
            "and\n",
            "layer\n",
            "orders\n",
            ".\n",
            "Weaknesses\n",
            ":\n",
            "The\n",
            "paper\n",
            "is\n",
            "a\n",
            "software\n",
            "paper\n",
            ",\n",
            "and\n",
            "does\n",
            "n't\n",
            "fit\n",
            "a\n",
            "``\n",
            "traditional\n",
            "''\n",
            "NeurIPS\n",
            "style\n",
            "of\n",
            "``\n",
            "results\n",
            "''\n",
            "section\n",
            "being\n",
            "about\n",
            "how\n",
            "the\n",
            "authors\n",
            "deserve\n",
            "a\n",
            "prize\n",
            "for\n",
            "state\n",
            "of\n",
            "the\n",
            "art\n",
            ".\n",
            "It\n",
            "'s\n",
            "not\n",
            "a\n",
            "weakness\n",
            ",\n",
            "but\n",
            "it\n",
            "can\n",
            "be\n",
            "perceived\n",
            "so\n",
            ".\n",
            "I\n",
            "want\n",
            "to\n",
            "express\n",
            "it\n",
            "as\n",
            "a\n",
            "paper\n",
            "submitted\n",
            "potentially\n",
            "to\n",
            "the\n",
            "limitations\n",
            "of\n",
            "the\n",
            "venue\n",
            "that\n",
            "it\n",
            "'s\n",
            "submitted\n",
            "to\n",
            ".\n",
            "Correctness\n",
            ":\n",
            "The\n",
            "paper\n",
            "seems\n",
            "to\n",
            "be\n",
            "generally\n",
            "correct\n",
            "and\n",
            "the\n",
            "methodology\n",
            "for\n",
            "results\n",
            "seems\n",
            "fine\n",
            ".\n",
            "Clarity\n",
            ":\n",
            "The\n",
            "paper\n",
            "is\n",
            "reasonably\n",
            "well-written\n",
            "and\n",
            "easy\n",
            "to\n",
            "follow\n",
            ".\n",
            "One\n",
            "big\n",
            "gripe\n",
            "I\n",
            "have\n",
            "is\n",
            "that\n",
            "the\n",
            "authors\n",
            "do\n",
            "n't\n",
            "define\n",
            "``\n",
            "cost\n",
            "''\n",
            "in\n",
            "the\n",
            "Results\n",
            "section\n",
            ".\n",
            "I\n",
            "am\n",
            "*\n",
            "*\n",
            "assuming\n",
            "*\n",
            "*\n",
            "that\n",
            "it\n",
            "might\n",
            "be\n",
            "program\n",
            "runtime\n",
            ",\n",
            "but\n",
            "it\n",
            "'s\n",
            "not\n",
            "clear\n",
            ".\n",
            "The\n",
            "line\n",
            "they\n",
            "have\n",
            "is\n",
            ":\n",
            ">\n",
            "The\n",
            "unit\n",
            "cost\n",
            "for\n",
            "search\n",
            "and\n",
            "training\n",
            "is\n",
            "defined\n",
            "as\n",
            "the\n",
            "computation\n",
            "cost\n",
            "to\n",
            "train\n",
            "a\n",
            "MobileNetV2-like\n",
            "model\n",
            "on\n",
            "ImageNet\n",
            "for\n",
            "360\n",
            "epochs\n",
            ".\n",
            "It\n",
            "could\n",
            "literally\n",
            "be\n",
            "anything\n",
            ",\n",
            "like\n",
            "the\n",
            "cost\n",
            "of\n",
            "buying\n",
            "the\n",
            "program\n",
            "from\n",
            "someone\n",
            ",\n",
            "the\n",
            "memory\n",
            "usage\n",
            "of\n",
            "the\n",
            "program\n",
            ",\n",
            "the\n",
            "environmental\n",
            "cost\n",
            "of\n",
            "CO2\n",
            "emissions\n",
            ",\n",
            "and\n",
            "a\n",
            "thousand\n",
            "other\n",
            "things\n",
            "I\n",
            "can\n",
            "make\n",
            "up\n",
            ".\n",
            "Define\n",
            "the\n",
            "cost\n",
            "more\n",
            "precisely\n",
            ".\n",
            "Relation\n",
            "to\n",
            "Prior\n",
            "Work\n",
            ":\n",
            "Prior\n",
            "work\n",
            "is\n",
            "discussed\n",
            "comprehensively\n",
            "and\n",
            "fairly\n",
            ".\n",
            "I\n",
            "went\n",
            "through\n",
            "the\n",
            "documentation\n",
            "of\n",
            "all\n",
            "the\n",
            "discussed\n",
            "prior\n",
            "work\n",
            "(\n",
            "and\n",
            "additional\n",
            "libs\n",
            "such\n",
            "as\n",
            "Optuna\n",
            ")\n",
            "to\n",
            "make\n",
            "sure\n",
            "I\n",
            "understand\n",
            "the\n",
            "fairness\n",
            "of\n",
            "claims\n",
            ".\n",
            "Reproducibility\n",
            ":\n",
            "Yes\n",
            "Additional\n",
            "Feedback\n",
            ":\n",
            "Review\n",
            "3\n",
            "Summary\n",
            "and\n",
            "Contributions\n",
            ":\n",
            "This\n",
            "paper\n",
            "presents\n",
            "PyGlove\n",
            ",\n",
            "a\n",
            "Python\n",
            "library\n",
            "for\n",
            "AutoML\n",
            ".\n",
            "The\n",
            "problem\n",
            "PyGlove\n",
            "aims\n",
            "to\n",
            "solve\n",
            "is\n",
            "managing\n",
            "inconsistencies\n",
            "between\n",
            "the\n",
            "search\n",
            "space\n",
            "and\n",
            "search\n",
            "algorithm\n",
            "in\n",
            "AutoML\n",
            "when\n",
            "one\n",
            "or\n",
            "the\n",
            "other\n",
            "is\n",
            "modified\n",
            ".\n",
            "It\n",
            "introduces\n",
            "a\n",
            "symbolic\n",
            "representation\n",
            "of\n",
            "Python\n",
            "objects\n",
            "that\n",
            "is\n",
            "able\n",
            "to\n",
            "express\n",
            "neural\n",
            "architectures\n",
            "and\n",
            "training\n",
            "procedures\n",
            ".\n",
            "These\n",
            "representations\n",
            "can\n",
            "be\n",
            "searched\n",
            "and\n",
            "modified\n",
            "automatically\n",
            ",\n",
            "making\n",
            "it\n",
            "easier\n",
            "to\n",
            "decouple\n",
            "the\n",
            "search\n",
            "space\n",
            "and\n",
            "search\n",
            "algorithm\n",
            ".\n",
            "Strengths\n",
            ":\n",
            "The\n",
            "primary\n",
            "strength\n",
            "is\n",
            "that\n",
            "’\n",
            "s\n",
            "they\n",
            "have\n",
            "developed\n",
            "a\n",
            "useful\n",
            "tool\n",
            "that\n",
            "hits\n",
            "a\n",
            "sweet\n",
            "spot\n",
            "in\n",
            "the\n",
            "design\n",
            "space\n",
            "of\n",
            "random\n",
            "search\n",
            "based\n",
            "program\n",
            "synthesis\n",
            "methods\n",
            "for\n",
            "machine\n",
            "learning\n",
            ".\n",
            "Their\n",
            "approach\n",
            "can\n",
            "be\n",
            "applied\n",
            "to\n",
            "essentially\n",
            "parameterize\n",
            "existing\n",
            "deep\n",
            "network\n",
            "architectures\n",
            ",\n",
            "since\n",
            "introducing\n",
            "a\n",
            "choice\n",
            "amounts\n",
            "to\n",
            "only\n",
            "adding\n",
            "small\n",
            "annotations\n",
            "to\n",
            "existing\n",
            "python\n",
            "code\n",
            ".\n",
            "Ultimately\n",
            ",\n",
            "changes\n",
            "to\n",
            "the\n",
            "search\n",
            "space\n",
            "or\n",
            "search\n",
            "algorithm\n",
            "can\n",
            "be\n",
            "done\n",
            "with\n",
            "small\n",
            "modifications\n",
            "to\n",
            "the\n",
            "existing\n",
            "code\n",
            ".\n",
            "Weaknesses\n",
            ":\n",
            "One\n",
            "weakness\n",
            "is\n",
            "the\n",
            "exposition\n",
            "and\n",
            "relation\n",
            "to\n",
            "prior\n",
            "work\n",
            ".\n",
            "Either\n",
            "the\n",
            "authors\n",
            "are\n",
            "not\n",
            "aware\n",
            "of\n",
            "how\n",
            "their\n",
            "approach\n",
            "sits\n",
            "within\n",
            "the\n",
            "broader\n",
            "framework\n",
            "of\n",
            "programming\n",
            "languages\n",
            "or\n",
            "synthesis\n",
            ",\n",
            "or\n",
            "they\n",
            "have\n",
            "chosen\n",
            "their\n",
            "language\n",
            "to\n",
            "hide\n",
            "it\n",
            "to\n",
            "make\n",
            "the\n",
            "work\n",
            "more\n",
            "approachable\n",
            ".\n",
            "For\n",
            "instance\n",
            ",\n",
            "they\n",
            "introduce\n",
            "their\n",
            "objects\n",
            "as\n",
            "symbolic\n",
            "trees\n",
            ",\n",
            "which\n",
            "are\n",
            "simply\n",
            "abstract\n",
            "syntax\n",
            "trees\n",
            ".\n",
            "In\n",
            "fact\n",
            ",\n",
            "all\n",
            "programs\n",
            "are\n",
            "represented\n",
            "at\n",
            "some\n",
            "point\n",
            "as\n",
            "syntax\n",
            "trees\n",
            ".\n",
            "Second\n",
            ",\n",
            "most\n",
            "of\n",
            "their\n",
            "tool/language\n",
            "design\n",
            "could\n",
            "be\n",
            "summarized\n",
            "as\n",
            "adding\n",
            "some\n",
            "kind\n",
            "of\n",
            "non\n",
            "deterministic/parametric\n",
            "choice\n",
            "into\n",
            "the\n",
            "programming\n",
            "language\n",
            ",\n",
            "so\n",
            "that\n",
            "the\n",
            "search\n",
            "mechanism\n",
            ",\n",
            "for\n",
            "instance\n",
            ",\n",
            "can\n",
            "choose\n",
            "between\n",
            "16\n",
            "or\n",
            "32\n",
            "layers\n",
            ".\n",
            "This\n",
            "has\n",
            "been\n",
            "explored\n",
            "in\n",
            "many\n",
            "areas\n",
            "in\n",
            "PL\n",
            ".\n",
            "It\n",
            "’\n",
            "s\n",
            "extension\n",
            "to\n",
            "ML\n",
            "does\n",
            "not\n",
            "introduce\n",
            "anything\n",
            "particularly\n",
            "new\n",
            ",\n",
            "but\n",
            "that\n",
            "it\n",
            "is\n",
            "not\n",
            "to\n",
            "say\n",
            "it\n",
            "is\n",
            "not\n",
            "useful\n",
            ".\n",
            "The\n",
            "evaluation\n",
            "is\n",
            "mostly\n",
            "not\n",
            "inline\n",
            "with\n",
            "the\n",
            "objectives\n",
            "of\n",
            "the\n",
            "paper\n",
            ".\n",
            "The\n",
            "paper\n",
            "does\n",
            "not\n",
            "suggest\n",
            "new\n",
            "ways\n",
            "of\n",
            "searching\n",
            "for\n",
            "programs\n",
            ",\n",
            "it\n",
            "is\n",
            "a\n",
            "tool\n",
            "designed\n",
            "to\n",
            "make\n",
            "it\n",
            "easier\n",
            "to\n",
            "change\n",
            "search\n",
            "space\n",
            "algorithms\n",
            "independently\n",
            "from\n",
            "changes\n",
            "to\n",
            "the\n",
            "search\n",
            "spaces\n",
            "themselves\n",
            ".\n",
            "Consequently\n",
            ",\n",
            "the\n",
            "performance\n",
            "of\n",
            "the\n",
            "resulting\n",
            "searches\n",
            "is\n",
            "not\n",
            "really\n",
            "relevant\n",
            ",\n",
            "and\n",
            "the\n",
            "paper\n",
            "should\n",
            "spend\n",
            "much\n",
            "more\n",
            "ink\n",
            "expanding\n",
            "on\n",
            "the\n",
            "how\n",
            "easy\n",
            "it\n",
            "is\n",
            "to\n",
            "do\n",
            "these\n",
            "search\n",
            "space\n",
            "/\n",
            "search\n",
            "algorithm\n",
            "changes\n",
            "compared\n",
            "to\n",
            "other\n",
            "approaches\n",
            ".\n",
            "Correctness\n",
            ":\n",
            "There\n",
            "are\n",
            "few\n",
            "claims\n",
            "to\n",
            "be\n",
            "assessed\n",
            "for\n",
            "correctness\n",
            ",\n",
            "but\n",
            "the\n",
            "method\n",
            "appears\n",
            "sound\n",
            ".\n",
            "Clarity\n",
            ":\n",
            "Clear\n",
            ".\n",
            "Relation\n",
            "to\n",
            "Prior\n",
            "Work\n",
            ":\n",
            "Relation\n",
            "to\n",
            "existing\n",
            "AutoML\n",
            "work\n",
            "is\n",
            "clear\n",
            ",\n",
            "but\n",
            "severely\n",
            "lacking\n",
            "in\n",
            "connections\n",
            "to\n",
            "PL\n",
            "methods\n",
            ",\n",
            "which\n",
            "have\n",
            "long\n",
            "explored\n",
            "this\n",
            ".\n",
            "Reproducibility\n",
            ":\n",
            "Yes\n",
            "NeurIPS\n",
            "2020\n",
            "PyGlove\n",
            ":\n",
            "Symbolic\n",
            "Programming\n",
            "for\n",
            "Automated\n",
            "Machine\n",
            "Learning\n",
            "Meta\n",
            "Review\n",
            "The\n",
            "reviewers\n",
            "generally\n",
            "agree\n",
            "that\n",
            "the\n",
            "design\n",
            "choices\n",
            "of\n",
            "this\n",
            "framework\n",
            "for\n",
            "AutoML\n",
            "are\n",
            "judicious\n",
            "and\n",
            "hit\n",
            "a\n",
            "``\n",
            "sweet\n",
            "spot\n",
            "''\n",
            ".\n",
            "This\n",
            "combination\n",
            "of\n",
            "language/tooling\n",
            "design\n",
            "is\n",
            "of\n",
            "great\n",
            "value\n",
            "to\n",
            "expose\n",
            "to\n",
            "large\n",
            "swathes\n",
            "of\n",
            "the\n",
            "NeurIPS\n",
            "community\n",
            ".\n",
            "The\n",
            "rebuttal\n",
            "persuasively\n",
            "addresses\n",
            "the\n",
            "reviewers\n",
            "'\n",
            "concerns\n",
            "about\n",
            "the\n",
            "evaluation\n",
            "and\n",
            "utility\n",
            "of\n",
            "this\n",
            "proposal\n",
            ",\n",
            "and\n",
            "the\n",
            "response\n",
            "to\n",
            "R4\n",
            "is\n",
            "also\n",
            "reassuring\n",
            ".\n",
            "We\n",
            "look\n",
            "forward\n",
            "to\n",
            "the\n",
            "authors\n",
            "'\n",
            "final\n",
            "version\n",
            "of\n",
            "the\n",
            "paper\n",
            ",\n",
            "incorporating\n",
            "the\n",
            "proposed\n",
            "improvements\n",
            ".\n",
            "Book\n",
            "Do\n",
            "not\n",
            "remove\n",
            ":\n",
            "This\n",
            "comment\n",
            "is\n",
            "monitored\n",
            "to\n",
            "verify\n",
            "that\n",
            "the\n",
            "site\n",
            "is\n",
            "working\n",
            "properly\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "df_output                                                 topic  ... rank_lda\n",
            "0              graph similarity deep learning neurips  ...      6.0\n",
            "1              graph similarity deep learning neurips  ...     10.0\n",
            "2              graph similarity deep learning neurips  ...      2.0\n",
            "3              graph similarity deep learning neurips  ...      5.0\n",
            "4              graph similarity deep learning neurips  ...      1.0\n",
            "..                                                ...  ...      ...\n",
            "0   pyglove symbolic programming automated machine...  ...      2.0\n",
            "1   pyglove symbolic programming automated machine...  ...      5.0\n",
            "2   pyglove symbolic programming automated machine...  ...      4.0\n",
            "3   pyglove symbolic programming automated machine...  ...      3.0\n",
            "4   pyglove symbolic programming automated machine...  ...      1.0\n",
            "\n",
            "[72 rows x 8 columns]\n",
            "topic:  fourier sparse leverage scores approximate kernel learning neurips id_= 9\n",
            "1 . Fourier Sparse Leverage Scores and Approximate Kernel Learning https://papers.nips.cc/paper/2020/hash/012d9fe15b2493f21902cd55603382ec-Abstract.html\n",
            "**********************************************\n",
            "2 . Fourier Sparse Leverage Scores and Approximate Kernel Learning https://papers.nips.cc/paper/2020/file/012d9fe15b2493f21902cd55603382ec-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Neural networks are sensitive to hyper-parameter and architecture choices. Auto-\n",
            "mated Machine Learning (AutoML) is a promising paradigm for automating these\n",
            "choices. Current ML software libraries, however, are quite limited in handling the\n",
            "dynamic interactions among the components of AutoML. For example, efﬁcient\n",
            "NAS algorithms, such as ENAS [1] and DARTS [2], typically require an imple-\n",
            "mentation coupling between the search space and search algorithm, the two key\n",
            "components in AutoML. Furthermore, implementing a complex search ﬂow, such\n",
            "as searching architectures within a loop of searching hardware conﬁgurations, is\n",
            "difﬁcult. To summarize, changing the search space, search algorithm, or search ﬂow\n",
            "in current ML libraries usually requires a signiﬁcant change in the program logic.\n",
            "In this paper, we introduce a new way of programming AutoML based on symbolic\n",
            "programming. Under this paradigm, ML programs are mutable, thus can be\n",
            "manipulated easily by another program. As a result, AutoML can be reformulated\n",
            "as an automated process of symbolic manipulation. With this formulation, we\n",
            "decouple the triangle of the search algorithm, the search space and the child\n",
            "program. This decoupling makes it easy to change the search space and search\n",
            "algorithm (without and with weight sharing), as well as to add search capabilities\n",
            "to existing code and implement complex search ﬂows. We then introduce PyGlove,\n",
            "a new Python library that implements this paradigm. Through case studies on\n",
            "ImageNet and NAS-Bench-101, we show that with PyGlove users can easily\n",
            "convert a static program into a search space, quickly iterate on the search spaces\n",
            "and search algorithms, and craft complex search ﬂows to achieve better results.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "3 . Fourier Sparse Leverage Scores and ... - Review for NeurIPS paper https://papers.nips.cc/paper/2020/file/012d9fe15b2493f21902cd55603382ec-Review.html\n",
            "**********************************************\n",
            "4 . Review for NeurIPS paper: Fourier Sparse Leverage Scores and ... https://papers.nips.cc/paper/2020/file/012d9fe15b2493f21902cd55603382ec-MetaReview.html\n",
            "**********************************************\n",
            "5 . Fourier Sparse Leverage Scores and Approximate Kernel Learning https://papers.nips.cc/paper/2020/file/012d9fe15b2493f21902cd55603382ec-Supplemental.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Neural networks are sensitive to hyper-parameter and architecture choices. Auto-\n",
            "mated Machine Learning (AutoML) is a promising paradigm for automating these\n",
            "choices. Current ML software libraries, however, are quite limited in handling the\n",
            "dynamic interactions among the components of AutoML. For example, efﬁcient\n",
            "NAS algorithms, such as ENAS [1] and DARTS [2], typically require an imple-\n",
            "mentation coupling between the search space and search algorithm, the two key\n",
            "components in AutoML. Furthermore, implementing a complex search ﬂow, such\n",
            "as searching architectures within a loop of searching hardware conﬁgurations, is\n",
            "difﬁcult. To summarize, changing the search space, search algorithm, or search ﬂow\n",
            "in current ML libraries usually requires a signiﬁcant change in the program logic.\n",
            "In this paper, we introduce a new way of programming AutoML based on symbolic\n",
            "programming. Under this paradigm, ML programs are mutable, thus can be\n",
            "manipulated easily by another program. As a result, AutoML can be reformulated\n",
            "as an automated process of symbolic manipulation. With this formulation, we\n",
            "decouple the triangle of the search algorithm, the search space and the child\n",
            "program. This decoupling makes it easy to change the search space and search\n",
            "algorithm (without and with weight sharing), as well as to add search capabilities\n",
            "to existing code and implement complex search ﬂows. We then introduce PyGlove,\n",
            "a new Python library that implements this paradigm. Through case studies on\n",
            "ImageNet and NAS-Bench-101, we show that with PyGlove users can easily\n",
            "convert a static program into a search space, quickly iterate on the search spaces\n",
            "and search algorithms, and craft complex search ﬂows to achieve better results.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "6 . Advances in Neural Information Processing Systems 33 (NeurIPS ... https://papers.nips.cc/paper/2020\n",
            "**********************************************\n",
            "7 . Generalized Leverage Score Sampling for Neural Networks https://papers.nips.cc/paper/2020/file/7a22c0c0a4515485e31f95fd372050c9-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Leverage score sampling is a powerful technique that originates from theoretical\n",
            "computer science, which can be used to speed up a large number of fundamental\n",
            "questions, e.g. linear regression, linear programming, semi-deﬁnite programming,\n",
            "cutting plane method, graph sparsiﬁcation, maximum matching and max-ﬂow. Re-\n",
            "cently, it has been shown that leverage score sampling helps to accelerate kernel\n",
            "methods [Avron, Kapralov, Musco, Musco, Velingker and Zandieh 17].\n",
            "In this work, we generalize the results in [Avron, Kapralov, Musco, Musco, Vel-\n",
            "ingker and Zandieh 17] to a broader class of kernels. We further bring the leverage\n",
            "score sampling into the ﬁeld of deep learning theory.\n",
            "\n",
            "• We show the connection between the initialization for neural network train-\n",
            "\n",
            "ing and approximating the neural tangent kernel with random features.\n",
            "\n",
            "• We prove the equivalence between regularized neural network and neural tan-\n",
            "gent kernel ridge regression under the initialization of both classical random\n",
            "Gaussian and leverage score sampling.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "8 . Learning with Optimized Random Features: Exponential Speedup ... https://papers.nips.cc/paper/2020/file/9ddb9dd5d8aee9a76bf217a2a3c54833-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Kernel methods augmented with random features give scalable algorithms for\n",
            "learning from big data. But it has been computationally hard to sample random\n",
            "features according to a probability distribution that is optimized for the data, so as\n",
            "to minimize the required number of features for achieving the learning to a desired\n",
            "accuracy. Here, we develop a quantum algorithm for sampling from this optimized\n",
            "distribution over features, in runtime O(D) that is linear in the dimension D of\n",
            "the input data. Our algorithm achieves an exponential speedup in D compared\n",
            "to any known classical algorithm for this sampling task. In contrast to existing\n",
            "quantum machine learning algorithms, our algorithm circumvents sparsity and\n",
            "low-rank assumptions and thus has wide applicability. We also show that the\n",
            "sampled features can be combined with regression by stochastic gradient descent to\n",
            "achieve the learning without canceling out our exponential speedup. Our algorithm\n",
            "based on sampling optimized random features leads to an accelerated framework\n",
            "for machine learning that takes advantage of quantum computers.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "9 . The Statistical Cost of Robust Kernel Hyperparameter Tuning https://papers.nips.cc/paper/2020/file/f4661398cb1a3abd3ffe58600bf11322-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "This paper studies the statistical complexity of kernel hyperparameter tuning in the\n",
            "setting of active regression under adversarial noise. We consider the problem of\n",
            "ﬁnding the best interpolant from a class of kernels with unknown hyperparameters,\n",
            "assuming only that the noise is square-integrable. We provide ﬁnite-sample guaran-\n",
            "tees for the problem, characterizing how increasing the complexity of the kernel\n",
            "class increases the complexity of learning kernel hyperparameters. For common\n",
            "kernel classes (e.g. squared-exponential kernels with unknown lengthscale), our\n",
            "results show that hyperparameter optimization increases sample complexity by\n",
            "just a logarithmic factor, in comparison to the setting where optimal parameters\n",
            "are known in advance. Our result is based on a subsampling guarantee for linear\n",
            "regression under multiple design matrices which may be of independent interest.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "10 . Supplemental https://papers.nips.cc/paper/2020/file/18a411989b47ed75a60ac69d9da05aa5-Supplemental.pdf\n",
            "example.pdf\n",
            "\n",
            "data:                                                topic  ...                                                url\n",
            "0  fourier sparse leverage scores approximate ker...  ...  https://papers.nips.cc/paper/2020/hash/012d9fe...\n",
            "1  fourier sparse leverage scores approximate ker...  ...  https://papers.nips.cc/paper/2020/file/012d9fe...\n",
            "2  fourier sparse leverage scores approximate ker...  ...  https://papers.nips.cc/paper/2020/file/012d9fe...\n",
            "3  fourier sparse leverage scores approximate ker...  ...  https://papers.nips.cc/paper/2020/file/012d9fe...\n",
            "4  fourier sparse leverage scores approximate ker...  ...  https://papers.nips.cc/paper/2020/file/012d9fe...\n",
            "5  fourier sparse leverage scores approximate ker...  ...                  https://papers.nips.cc/paper/2020\n",
            "6  fourier sparse leverage scores approximate ker...  ...  https://papers.nips.cc/paper/2020/file/7a22c0c...\n",
            "7  fourier sparse leverage scores approximate ker...  ...  https://papers.nips.cc/paper/2020/file/9ddb9dd...\n",
            "8  fourier sparse leverage scores approximate ker...  ...  https://papers.nips.cc/paper/2020/file/f466139...\n",
            "\n",
            "[9 rows x 4 columns]\n",
            "**********************************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                                               topic  ... similarity_score\n",
            "0  fourier sparse leverage scores approximate ker...  ...         0.967066\n",
            "1  fourier sparse leverage scores approximate ker...  ...         0.961896\n",
            "2  fourier sparse leverage scores approximate ker...  ...         0.948122\n",
            "3  fourier sparse leverage scores approximate ker...  ...         0.966170\n",
            "4  fourier sparse leverage scores approximate ker...  ...         0.961896\n",
            "5  fourier sparse leverage scores approximate ker...  ...         0.965745\n",
            "6  fourier sparse leverage scores approximate ker...  ...         0.961819\n",
            "7  fourier sparse leverage scores approximate ker...  ...         0.961877\n",
            "8  fourier sparse leverage scores approximate ker...  ...         0.964693\n",
            "\n",
            "[9 rows x 5 columns]\n",
            "df_final after rank=                                                topic  ... rank\n",
            "0  fourier sparse leverage scores approximate ker...  ...  1.0\n",
            "1  fourier sparse leverage scores approximate ker...  ...  6.0\n",
            "2  fourier sparse leverage scores approximate ker...  ...  9.0\n",
            "3  fourier sparse leverage scores approximate ker...  ...  2.0\n",
            "4  fourier sparse leverage scores approximate ker...  ...  6.0\n",
            "5  fourier sparse leverage scores approximate ker...  ...  3.0\n",
            "6  fourier sparse leverage scores approximate ker...  ...  8.0\n",
            "7  fourier sparse leverage scores approximate ker...  ...  7.0\n",
            "8  fourier sparse leverage scores approximate ker...  ...  4.0\n",
            "\n",
            "[9 rows x 6 columns]\n",
            "0    Fourier Sparse Leverage Scores and Approximate...\n",
            "1    Abstract\\n\\nNeural networks are sensitive to h...\n",
            "2    NeurIPS 2020\\n\\nFourier Sparse Leverage Scores...\n",
            "3    NeurIPS 2020\\n\\nFourier Sparse Leverage Scores...\n",
            "4    Abstract\\n\\nNeural networks are sensitive to h...\n",
            "5    Book\\n\\nDo not remove: This comment is monitor...\n",
            "6    Abstract\\n\\nLeverage score sampling is a power...\n",
            "7    Abstract\\n\\nKernel methods augmented with rand...\n",
            "8    Abstract\\n\\nThis paper studies the statistical...\n",
            "Name: text, dtype: object\n",
            "Fourier\n",
            "Sparse\n",
            "Leverage\n",
            "Scores\n",
            "and\n",
            "Approximate\n",
            "Kernel\n",
            "Learning\n",
            "Part\n",
            "of\n",
            "Advances\n",
            "in\n",
            "Neural\n",
            "Information\n",
            "Processing\n",
            "Systems\n",
            "33\n",
            "(\n",
            "NeurIPS\n",
            "2020\n",
            ")\n",
            "Authors\n",
            "Tamas\n",
            "Erdelyi\n",
            ",\n",
            "Cameron\n",
            "Musco\n",
            ",\n",
            "Christopher\n",
            "Musco\n",
            "Abstract\n",
            "We\n",
            "prove\n",
            "new\n",
            "explicit\n",
            "upper\n",
            "bounds\n",
            "on\n",
            "the\n",
            "leverage\n",
            "scores\n",
            "of\n",
            "Fourier\n",
            "sparse\n",
            "functions\n",
            "under\n",
            "both\n",
            "the\n",
            "Gaussian\n",
            "and\n",
            "Laplace\n",
            "measures\n",
            ".\n",
            "In\n",
            "particular\n",
            ",\n",
            "we\n",
            "study\n",
            "s-sparse\n",
            "functions\n",
            "of\n",
            "the\n",
            "form\n",
            "$\n",
            "f\n",
            "(\n",
            "x\n",
            ")\n",
            "=\n",
            "\\sum_\n",
            "{\n",
            "j=1\n",
            "}\n",
            "^s\n",
            "a_j\n",
            "e^\n",
            "{\n",
            "i\n",
            "\\lambda_j\n",
            "x\n",
            "}\n",
            "$\n",
            "for\n",
            "coefficients\n",
            "$\n",
            "a_j\n",
            "\\in\n",
            "C\n",
            "$\n",
            "and\n",
            "frequencies\n",
            "$\n",
            "\\lambda_j\n",
            "\\in\n",
            "R\n",
            "$\n",
            ".\n",
            "Bounding\n",
            "Fourier\n",
            "sparse\n",
            "leverage\n",
            "scores\n",
            "under\n",
            "various\n",
            "measures\n",
            "is\n",
            "of\n",
            "pure\n",
            "mathematical\n",
            "interest\n",
            "in\n",
            "approximation\n",
            "theory\n",
            ",\n",
            "and\n",
            "our\n",
            "work\n",
            "extends\n",
            "existing\n",
            "results\n",
            "for\n",
            "the\n",
            "uniform\n",
            "measure\n",
            "[\n",
            "Erd17\n",
            ",\n",
            "CP19a\n",
            "]\n",
            ".\n",
            "Practically\n",
            ",\n",
            "our\n",
            "bounds\n",
            "are\n",
            "motivated\n",
            "by\n",
            "two\n",
            "important\n",
            "applications\n",
            "in\n",
            "machine\n",
            "learning\n",
            ":\n",
            "1\n",
            ".\n",
            "Kernel\n",
            "Approximation\n",
            ".\n",
            "They\n",
            "yield\n",
            "a\n",
            "new\n",
            "random\n",
            "Fourier\n",
            "features\n",
            "algorithm\n",
            "for\n",
            "approximating\n",
            "Gaussian\n",
            "and\n",
            "Cauchy\n",
            "(\n",
            "rational\n",
            "quadratic\n",
            ")\n",
            "kernel\n",
            "matrices\n",
            ".\n",
            "For\n",
            "low-dimensional\n",
            "data\n",
            ",\n",
            "our\n",
            "method\n",
            "uses\n",
            "a\n",
            "near\n",
            "optimal\n",
            "number\n",
            "of\n",
            "features\n",
            ",\n",
            "and\n",
            "its\n",
            "runtime\n",
            "is\n",
            "polynomial\n",
            "in\n",
            "the\n",
            "*\n",
            "statistical\n",
            "dimension\n",
            "*\n",
            "of\n",
            "the\n",
            "approximated\n",
            "kernel\n",
            "matrix\n",
            ".\n",
            "It\n",
            "is\n",
            "the\n",
            "first\n",
            "``\n",
            "oblivious\n",
            "sketching\n",
            "method\n",
            "''\n",
            "with\n",
            "this\n",
            "property\n",
            "for\n",
            "any\n",
            "kernel\n",
            "besides\n",
            "the\n",
            "polynomial\n",
            "kernel\n",
            ",\n",
            "resolving\n",
            "an\n",
            "open\n",
            "question\n",
            "of\n",
            "[\n",
            "AKM+17\n",
            ",\n",
            "AKK+20b\n",
            "]\n",
            ".\n",
            "2\n",
            ".\n",
            "Active\n",
            "Learning\n",
            ".\n",
            "They\n",
            "can\n",
            "be\n",
            "used\n",
            "as\n",
            "non-uniform\n",
            "sampling\n",
            "distributions\n",
            "for\n",
            "robust\n",
            "active\n",
            "learning\n",
            "when\n",
            "data\n",
            "follows\n",
            "a\n",
            "Gaussian\n",
            "or\n",
            "Laplace\n",
            "distribution\n",
            ".\n",
            "Using\n",
            "the\n",
            "framework\n",
            "of\n",
            "[\n",
            "AKM+19\n",
            "]\n",
            ",\n",
            "we\n",
            "provide\n",
            "essentially\n",
            "optimal\n",
            "results\n",
            "for\n",
            "bandlimited\n",
            "and\n",
            "multiband\n",
            "interpolation\n",
            ",\n",
            "and\n",
            "Gaussian\n",
            "process\n",
            "regression\n",
            ".\n",
            "These\n",
            "results\n",
            "generalize\n",
            "existing\n",
            "work\n",
            "that\n",
            "only\n",
            "applies\n",
            "to\n",
            "uniformly\n",
            "distributed\n",
            "data\n",
            ".\n",
            "Abstract\n",
            "Neural\n",
            "networks\n",
            "are\n",
            "sensitive\n",
            "to\n",
            "hyper-parameter\n",
            "and\n",
            "architecture\n",
            "choices\n",
            ".\n",
            "Auto-\n",
            "mated\n",
            "Machine\n",
            "Learning\n",
            "(\n",
            "AutoML\n",
            ")\n",
            "is\n",
            "a\n",
            "promising\n",
            "paradigm\n",
            "for\n",
            "automating\n",
            "these\n",
            "choices\n",
            ".\n",
            "Current\n",
            "ML\n",
            "software\n",
            "libraries\n",
            ",\n",
            "however\n",
            ",\n",
            "are\n",
            "quite\n",
            "limited\n",
            "in\n",
            "handling\n",
            "the\n",
            "dynamic\n",
            "interactions\n",
            "among\n",
            "the\n",
            "components\n",
            "of\n",
            "AutoML\n",
            ".\n",
            "For\n",
            "example\n",
            ",\n",
            "efﬁcient\n",
            "NAS\n",
            "algorithms\n",
            ",\n",
            "such\n",
            "as\n",
            "ENAS\n",
            "[\n",
            "1\n",
            "]\n",
            "and\n",
            "DARTS\n",
            "[\n",
            "2\n",
            "]\n",
            ",\n",
            "typically\n",
            "require\n",
            "an\n",
            "imple-\n",
            "mentation\n",
            "coupling\n",
            "between\n",
            "the\n",
            "search\n",
            "space\n",
            "and\n",
            "search\n",
            "algorithm\n",
            ",\n",
            "the\n",
            "two\n",
            "key\n",
            "components\n",
            "in\n",
            "AutoML\n",
            ".\n",
            "Furthermore\n",
            ",\n",
            "implementing\n",
            "a\n",
            "complex\n",
            "search\n",
            "ﬂow\n",
            ",\n",
            "such\n",
            "as\n",
            "searching\n",
            "architectures\n",
            "within\n",
            "a\n",
            "loop\n",
            "of\n",
            "searching\n",
            "hardware\n",
            "conﬁgurations\n",
            ",\n",
            "is\n",
            "difﬁcult\n",
            ".\n",
            "To\n",
            "summarize\n",
            ",\n",
            "changing\n",
            "the\n",
            "search\n",
            "space\n",
            ",\n",
            "search\n",
            "algorithm\n",
            ",\n",
            "or\n",
            "search\n",
            "ﬂow\n",
            "in\n",
            "current\n",
            "ML\n",
            "libraries\n",
            "usually\n",
            "requires\n",
            "a\n",
            "signiﬁcant\n",
            "change\n",
            "in\n",
            "the\n",
            "program\n",
            "logic\n",
            ".\n",
            "In\n",
            "this\n",
            "paper\n",
            ",\n",
            "we\n",
            "introduce\n",
            "a\n",
            "new\n",
            "way\n",
            "of\n",
            "programming\n",
            "AutoML\n",
            "based\n",
            "on\n",
            "symbolic\n",
            "programming\n",
            ".\n",
            "Under\n",
            "this\n",
            "paradigm\n",
            ",\n",
            "ML\n",
            "programs\n",
            "are\n",
            "mutable\n",
            ",\n",
            "thus\n",
            "can\n",
            "be\n",
            "manipulated\n",
            "easily\n",
            "by\n",
            "another\n",
            "program\n",
            ".\n",
            "As\n",
            "a\n",
            "result\n",
            ",\n",
            "AutoML\n",
            "can\n",
            "be\n",
            "reformulated\n",
            "as\n",
            "an\n",
            "automated\n",
            "process\n",
            "of\n",
            "symbolic\n",
            "manipulation\n",
            ".\n",
            "With\n",
            "this\n",
            "formulation\n",
            ",\n",
            "we\n",
            "decouple\n",
            "the\n",
            "triangle\n",
            "of\n",
            "the\n",
            "search\n",
            "algorithm\n",
            ",\n",
            "the\n",
            "search\n",
            "space\n",
            "and\n",
            "the\n",
            "child\n",
            "program\n",
            ".\n",
            "This\n",
            "decoupling\n",
            "makes\n",
            "it\n",
            "easy\n",
            "to\n",
            "change\n",
            "the\n",
            "search\n",
            "space\n",
            "and\n",
            "search\n",
            "algorithm\n",
            "(\n",
            "without\n",
            "and\n",
            "with\n",
            "weight\n",
            "sharing\n",
            ")\n",
            ",\n",
            "as\n",
            "well\n",
            "as\n",
            "to\n",
            "add\n",
            "search\n",
            "capabilities\n",
            "to\n",
            "existing\n",
            "code\n",
            "and\n",
            "implement\n",
            "complex\n",
            "search\n",
            "ﬂows\n",
            ".\n",
            "We\n",
            "then\n",
            "introduce\n",
            "PyGlove\n",
            ",\n",
            "a\n",
            "new\n",
            "Python\n",
            "library\n",
            "that\n",
            "implements\n",
            "this\n",
            "paradigm\n",
            ".\n",
            "Through\n",
            "case\n",
            "studies\n",
            "on\n",
            "ImageNet\n",
            "and\n",
            "NAS-Bench-101\n",
            ",\n",
            "we\n",
            "show\n",
            "that\n",
            "with\n",
            "PyGlove\n",
            "users\n",
            "can\n",
            "easily\n",
            "convert\n",
            "a\n",
            "static\n",
            "program\n",
            "into\n",
            "a\n",
            "search\n",
            "space\n",
            ",\n",
            "quickly\n",
            "iterate\n",
            "on\n",
            "the\n",
            "search\n",
            "spaces\n",
            "and\n",
            "search\n",
            "algorithms\n",
            ",\n",
            "and\n",
            "craft\n",
            "complex\n",
            "search\n",
            "ﬂows\n",
            "to\n",
            "achieve\n",
            "better\n",
            "results\n",
            ".\n",
            "1\n",
            "NeurIPS\n",
            "2020\n",
            "Fourier\n",
            "Sparse\n",
            "Leverage\n",
            "Scores\n",
            "and\n",
            "Approximate\n",
            "Kernel\n",
            "Learning\n",
            "Review\n",
            "1\n",
            "Summary\n",
            "and\n",
            "Contributions\n",
            ":\n",
            "This\n",
            "submission\n",
            "concerns\n",
            "kernel-based\n",
            "learning\n",
            "methods\n",
            ",\n",
            "which\n",
            "have\n",
            "been\n",
            "well\n",
            "studied\n",
            "in\n",
            "machine\n",
            "learning\n",
            ".\n",
            "Methods\n",
            "such\n",
            "as\n",
            "Random\n",
            "Fourier\n",
            "Features\n",
            "and\n",
            "the\n",
            "Nystrom\n",
            "method\n",
            "have\n",
            "been\n",
            "used\n",
            "to\n",
            "scale\n",
            "up\n",
            "kernel\n",
            "methods\n",
            "by\n",
            "computing\n",
            "kernel\n",
            "approximations\n",
            ".\n",
            "Such\n",
            "methods\n",
            "generally\n",
            "fall\n",
            "into\n",
            "two\n",
            "categories\n",
            ",\n",
            "namely\n",
            ",\n",
            "oblivious\n",
            "methods\n",
            "(\n",
            "e.g.\n",
            ",\n",
            "RFF\n",
            ",\n",
            "Tensor\n",
            "Sketch\n",
            "variant\n",
            ")\n",
            "and\n",
            "data-adaptive\n",
            "methods\n",
            "(\n",
            "Nystrom\n",
            "method\n",
            ")\n",
            ".\n",
            "While\n",
            "the\n",
            "former\n",
            "have\n",
            "the\n",
            "advantage\n",
            "of\n",
            "parallelizability\n",
            "(\n",
            "in\n",
            "settings\n",
            "where\n",
            "data\n",
            "is\n",
            "distributed\n",
            "across\n",
            "different\n",
            "machines\n",
            ")\n",
            ",\n",
            "the\n",
            "latter\n",
            "have\n",
            "generally\n",
            "given\n",
            "better\n",
            "kernel\n",
            "approximations\n",
            "until\n",
            "now\n",
            ".\n",
            "This\n",
            "work\n",
            "closes\n",
            "this\n",
            "gap\n",
            "between\n",
            "the\n",
            "two\n",
            "classes\n",
            "of\n",
            "methods\n",
            "by\n",
            "advancing\n",
            "an\n",
            "oblivious\n",
            "sketching\n",
            "method\n",
            "with\n",
            "better\n",
            "approimation\n",
            ",\n",
            "based\n",
            "on\n",
            "statistical\n",
            "leverage\n",
            "scores\n",
            ".\n",
            "The\n",
            "authors\n",
            "also\n",
            "show\n",
            "how\n",
            "to\n",
            "use\n",
            "the\n",
            "method\n",
            "in\n",
            "an\n",
            "active\n",
            "learning\n",
            "setting\n",
            ".\n",
            "Statistical\n",
            "leverage\n",
            "scores\n",
            "have\n",
            "gained\n",
            "increasing\n",
            "importance\n",
            "in\n",
            "literature\n",
            "on\n",
            "kernel\n",
            "methods\n",
            ".\n",
            "For\n",
            "instance\n",
            ",\n",
            "Avron\n",
            "et\n",
            "al\n",
            ".\n",
            "(\n",
            "ICML'17\n",
            ")\n",
            "were\n",
            "able\n",
            "to\n",
            "upper\n",
            "bound\n",
            "leverage\n",
            "scores\n",
            "in\n",
            "the\n",
            "case\n",
            "of\n",
            "the\n",
            "RBF\n",
            "Gaussian\n",
            "kernel\n",
            "on\n",
            "bounded\n",
            "data\n",
            "sets\n",
            "in\n",
            "low\n",
            "dimension\n",
            ";\n",
            "they\n",
            "showed\n",
            "that\n",
            "this\n",
            "is\n",
            "enough\n",
            "to\n",
            "obtain\n",
            "better\n",
            "kernel\n",
            "approximations\n",
            "for\n",
            "problems\n",
            "such\n",
            "as\n",
            "ridge\n",
            "regression\n",
            "with\n",
            "sample\n",
            "dependence\n",
            "polynomial\n",
            "in\n",
            "the\n",
            "statistical\n",
            "dimension\n",
            ".\n",
            "This\n",
            "work\n",
            "roughly\n",
            "follows\n",
            "this\n",
            "line\n",
            "of\n",
            "thought\n",
            ",\n",
            "except\n",
            "that\n",
            "tighter\n",
            "upper\n",
            "bounds\n",
            "on\n",
            "the\n",
            "leverage\n",
            "score\n",
            "are\n",
            "produced\n",
            "without\n",
            "the\n",
            "assumption\n",
            "of\n",
            "bounded\n",
            "data\n",
            "sets\n",
            ".\n",
            "Furthermore\n",
            ",\n",
            "experiments\n",
            "are\n",
            "provided\n",
            "on\n",
            "a\n",
            "GIS\n",
            "dataset\n",
            ",\n",
            "for\n",
            "which\n",
            "a\n",
            "comparison\n",
            "of\n",
            "the\n",
            "modified\n",
            "random\n",
            "Fourier\n",
            "features\n",
            "method\n",
            "(\n",
            "via\n",
            "statistical\n",
            "leverage\n",
            "score\n",
            "sampling\n",
            "according\n",
            "to\n",
            "the\n",
            "theory\n",
            "in\n",
            "this\n",
            "paper\n",
            ")\n",
            "to\n",
            "the\n",
            "classical\n",
            "RFF\n",
            "method\n",
            "is\n",
            "provided\n",
            ".\n",
            "While\n",
            "classical\n",
            "RFF\n",
            "has\n",
            "better\n",
            "error\n",
            ",\n",
            "the\n",
            "new\n",
            "RFF\n",
            "is\n",
            "shown\n",
            "to\n",
            "approximate\n",
            "small\n",
            "eigenvalues\n",
            "of\n",
            "the\n",
            "kernel\n",
            "matrix\n",
            "better\n",
            ".\n",
            "Strengths\n",
            ":\n",
            "The\n",
            "problem\n",
            "is\n",
            "well\n",
            "motivated\n",
            "--\n",
            "finding\n",
            "optimal\n",
            "oblivious\n",
            "sketches\n",
            "has\n",
            "appeared\n",
            "as\n",
            "an\n",
            "important\n",
            "open\n",
            "question\n",
            "in\n",
            "works\n",
            "such\n",
            "as\n",
            "Avron\n",
            "et\n",
            "al\n",
            ".\n",
            "(\n",
            "ICML'17\n",
            ")\n",
            "and\n",
            "Ahle\n",
            "et\n",
            "al\n",
            ".\n",
            "(\n",
            "SODA'20\n",
            ")\n",
            ".\n",
            "The\n",
            "authors\n",
            "seemingly\n",
            "make\n",
            "progress\n",
            "toward\n",
            "this\n",
            "important\n",
            "problem\n",
            "for\n",
            "Gaussian\n",
            "and\n",
            "Laplace\n",
            "kernels\n",
            ".\n",
            "In\n",
            "the\n",
            "case\n",
            "of\n",
            "Gaussian\n",
            "kernels\n",
            ",\n",
            "this\n",
            "work\n",
            "has\n",
            "the\n",
            "added\n",
            "advantage\n",
            "over\n",
            "the\n",
            "aforementioned\n",
            "works\n",
            "of\n",
            "not\n",
            "requiring\n",
            "an\n",
            "assumption\n",
            "on\n",
            "boundedness\n",
            "of\n",
            "the\n",
            "data\n",
            ".\n",
            "The\n",
            "work\n",
            "has\n",
            "solid\n",
            "theoretical\n",
            "grounding\n",
            "(\n",
            "though\n",
            "there\n",
            "are\n",
            "some\n",
            "questions\n",
            "I\n",
            "have\n",
            ",\n",
            "see\n",
            "below\n",
            "section\n",
            ")\n",
            ",\n",
            "and\n",
            "the\n",
            "theory\n",
            "is\n",
            "supplemented\n",
            "by\n",
            "reasonable\n",
            "experiments\n",
            "on\n",
            "a\n",
            "real-world\n",
            "GIS\n",
            "dataset\n",
            ".\n",
            "Weaknesses\n",
            ":\n",
            "Unlike\n",
            "the\n",
            "work\n",
            "of\n",
            "Ahle\n",
            "et\n",
            "al\n",
            ".\n",
            "(\n",
            "which\n",
            "gives\n",
            "polynomial\n",
            "dependences\n",
            "for\n",
            "high-dim\n",
            "poly\n",
            "and\n",
            "Gaussian\n",
            "kernels\n",
            ")\n",
            ",\n",
            "the\n",
            "work\n",
            "only\n",
            "seems\n",
            "to\n",
            "apply\n",
            "to\n",
            "the\n",
            "case\n",
            "of\n",
            "data\n",
            "with\n",
            "low\n",
            "ambient\n",
            "dimension\n",
            ".\n",
            "It\n",
            "would\n",
            "be\n",
            "good\n",
            "to\n",
            "give\n",
            "some\n",
            "more\n",
            "intuition\n",
            "as\n",
            "to\n",
            "why\n",
            "this\n",
            "is\n",
            "the\n",
            "case\n",
            ".\n",
            "Moreover\n",
            "there\n",
            "are\n",
            "some\n",
            "questions\n",
            "about\n",
            "the\n",
            "theory\n",
            "that\n",
            "are\n",
            "unclear\n",
            "(\n",
            "see\n",
            "questions\n",
            "below\n",
            ")\n",
            ".\n",
            "The\n",
            "experiments\n",
            "display\n",
            "a\n",
            "tradeoff\n",
            "between\n",
            "error\n",
            "and\n",
            "approximation\n",
            "of\n",
            "small\n",
            "eigenvalues\n",
            ".\n",
            "The\n",
            "normal\n",
            "RFF\n",
            "method\n",
            "does\n",
            "better\n",
            "in\n",
            "the\n",
            "former\n",
            ".\n",
            "It\n",
            "'s\n",
            "not\n",
            "clear\n",
            "to\n",
            "me\n",
            "why\n",
            "better\n",
            "approximation\n",
            "of\n",
            "small\n",
            "eigenvalues\n",
            "at\n",
            "the\n",
            "expense\n",
            "of\n",
            "overall\n",
            "error\n",
            "is\n",
            "a\n",
            "suitable\n",
            "tradoeff\n",
            ".\n",
            "The\n",
            "authors\n",
            "mention\n",
            "preconditioning/spectral\n",
            "approximation\n",
            "as\n",
            "a\n",
            "motivation\n",
            ",\n",
            "but\n",
            "it\n",
            "is\n",
            "not\n",
            "clear\n",
            "to\n",
            "me\n",
            "how\n",
            "much\n",
            "this\n",
            "matters\n",
            "in\n",
            "practice\n",
            ".\n",
            "Some\n",
            "experiments\n",
            "that\n",
            "perform\n",
            "linear\n",
            "algebra\n",
            "based\n",
            "on\n",
            "preconditioning\n",
            "methods\n",
            "would\n",
            "offer\n",
            "more\n",
            "convincing\n",
            "evidence\n",
            "of\n",
            "the\n",
            "superiority\n",
            "of\n",
            "the\n",
            "authors\n",
            "'\n",
            "approach\n",
            ".\n",
            "Correctness\n",
            ":\n",
            "There\n",
            "are\n",
            "a\n",
            "few\n",
            "claims\n",
            "and\n",
            "applications\n",
            "of\n",
            "theorems\n",
            "that\n",
            "I\n",
            "could\n",
            "not\n",
            "follow\n",
            ",\n",
            "but\n",
            "it\n",
            "is\n",
            "possible\n",
            "I\n",
            "am\n",
            "missing\n",
            "some\n",
            "insight\n",
            "here\n",
            "(\n",
            "see\n",
            "below\n",
            "questions\n",
            ")\n",
            ".\n",
            "Clarity\n",
            ":\n",
            "Yes\n",
            ",\n",
            "the\n",
            "paper\n",
            "is\n",
            "written\n",
            "in\n",
            "a\n",
            "clear\n",
            ",\n",
            "easy-to-read\n",
            "fashion\n",
            ".\n",
            "Relation\n",
            "to\n",
            "Prior\n",
            "Work\n",
            ":\n",
            "Yes\n",
            ",\n",
            "the\n",
            "work\n",
            "does\n",
            "a\n",
            "good\n",
            "job\n",
            "of\n",
            "motivating\n",
            "the\n",
            "work\n",
            "in\n",
            "the\n",
            "context\n",
            "of\n",
            "previous\n",
            "literature\n",
            ".\n",
            "Reproducibility\n",
            ":\n",
            "Yes\n",
            "Additional\n",
            "Feedback\n",
            ":\n",
            "I\n",
            "have\n",
            "some\n",
            "questions\n",
            "regarding\n",
            "some\n",
            "of\n",
            "the\n",
            "proofs\n",
            ",\n",
            "which\n",
            "impact\n",
            "correctness\n",
            "of\n",
            "the\n",
            "paper\n",
            "'s\n",
            "main\n",
            "theoretical\n",
            "contributions\n",
            ".\n",
            "I\n",
            "am\n",
            "willing\n",
            "to\n",
            "upgrade\n",
            "my\n",
            "overall\n",
            "score\n",
            "for\n",
            "the\n",
            "paper\n",
            "subject\n",
            "to\n",
            "satisfactory\n",
            "responses\n",
            "to\n",
            "these\n",
            "questions\n",
            ".\n",
            "(\n",
            "1\n",
            ")\n",
            "How\n",
            "does\n",
            "the\n",
            "equation\n",
            "after\n",
            "line\n",
            "518\n",
            "follow\n",
            "?\n",
            "Lemma\n",
            "7\n",
            "bounds\n",
            "the\n",
            "L2\n",
            "norm\n",
            "on\n",
            "a\n",
            "smaller\n",
            "interval\n",
            ",\n",
            "whereas\n",
            "the\n",
            "equation\n",
            "is\n",
            "trying\n",
            "to\n",
            "upper\n",
            "bound\n",
            "the\n",
            "L-infinity\n",
            "norm\n",
            ".\n",
            "In\n",
            "general\n",
            ",\n",
            "it\n",
            "is\n",
            "not\n",
            "the\n",
            "case\n",
            "that\n",
            "the\n",
            "L-infinity\n",
            "norm\n",
            "of\n",
            "f\n",
            "is\n",
            "upper\n",
            "bounded\n",
            "by\n",
            "the\n",
            "L2\n",
            "norm\n",
            "on\n",
            "the\n",
            "described\n",
            "interval\n",
            "(\n",
            "i.e.\n",
            ",\n",
            "|f\n",
            "(\n",
            "x\n",
            ")\n",
            "|\n",
            "<\n",
            "=\n",
            "||f||_\n",
            "[\n",
            "a-delta\n",
            ",\n",
            "b+delta\n",
            "]\n",
            ")\n",
            ",\n",
            "so\n",
            "the\n",
            "logic\n",
            "seems\n",
            "incorrect\n",
            ".\n",
            "(\n",
            "The\n",
            "same\n",
            "appears\n",
            "to\n",
            "be\n",
            "true\n",
            "for\n",
            "the\n",
            "logic\n",
            "in\n",
            "the\n",
            "equation\n",
            "following\n",
            "line\n",
            "519\n",
            ",\n",
            "which\n",
            "is\n",
            "symmetric\n",
            ".\n",
            ")\n",
            "(\n",
            "2\n",
            ")\n",
            "I\n",
            "could\n",
            "not\n",
            "find\n",
            "Lemma\n",
            "7\n",
            "in\n",
            "[\n",
            "BE06\n",
            "]\n",
            ".\n",
            "Again\n",
            ",\n",
            "there\n",
            "appears\n",
            "to\n",
            "be\n",
            "a\n",
            "mismatch\n",
            "between\n",
            "L2\n",
            "and\n",
            "L-inf\n",
            "norms\n",
            ".\n",
            "Do\n",
            "the\n",
            "authors\n",
            "have\n",
            "a\n",
            "specific\n",
            "citation\n",
            "?\n",
            "[\n",
            "UPDATE\n",
            ":\n",
            "POST-REBUTTAL\n",
            "]\n",
            "Thanks\n",
            "for\n",
            "the\n",
            "detailed\n",
            "responses\n",
            "to\n",
            "my\n",
            "questions\n",
            ".\n",
            "I\n",
            "am\n",
            "convinced\n",
            "of\n",
            "the\n",
            "correctness\n",
            "now\n",
            "and\n",
            "am\n",
            "willing\n",
            "to\n",
            "upgrade\n",
            "the\n",
            "review\n",
            "to\n",
            "a\n",
            "7\n",
            ".\n",
            "This\n",
            "is\n",
            "a\n",
            "good\n",
            "submission\n",
            ".\n",
            "Review\n",
            "2\n",
            "Summary\n",
            "and\n",
            "Contributions\n",
            ":\n",
            "This\n",
            "paper\n",
            "provides\n",
            "an\n",
            "improved\n",
            "theoretical\n",
            "bound\n",
            "for\n",
            "upper\n",
            "bounding\n",
            "leverage\n",
            "scores\n",
            "conditioned\n",
            "on\n",
            "representing\n",
            "s-sparse\n",
            "Fourier\n",
            "functions\n",
            ".\n",
            "This\n",
            "is\n",
            "particular\n",
            "relevant\n",
            "for\n",
            "various\n",
            "kernel\n",
            "learning\n",
            "applications\n",
            ".\n",
            "The\n",
            "paper\n",
            "describes\n",
            "how\n",
            "these\n",
            "result\n",
            "in\n",
            "improved\n",
            "results\n",
            "for\n",
            "kernel\n",
            "learning\n",
            "applications\n",
            "(\n",
            "e.g.\n",
            ",\n",
            "kernel\n",
            "regression\n",
            ")\n",
            "when\n",
            "the\n",
            "bound\n",
            "depends\n",
            "on\n",
            "the\n",
            "statistical\n",
            "dimension\n",
            ",\n",
            "and\n",
            "the\n",
            "sketches\n",
            "are\n",
            "oblivious\n",
            ".\n",
            "In\n",
            "this\n",
            "case\n",
            ",\n",
            "the\n",
            "dimension\n",
            "of\n",
            "an\n",
            "approximate\n",
            "lifting\n",
            "map\n",
            "(\n",
            "e.g.\n",
            ",\n",
            "like\n",
            "Rahimi-Recht\n",
            "Random\n",
            "Fourier\n",
            "Features\n",
            ")\n",
            "can\n",
            "achieve\n",
            "*\n",
            "relative\n",
            "*\n",
            "error\n",
            "in\n",
            "the\n",
            "kernel-ridge\n",
            "problem\n",
            ",\n",
            "using\n",
            "dimensions\n",
            "only\n",
            "depending\n",
            "on\n",
            "the\n",
            "relative\n",
            "error\n",
            "parameter\n",
            "and\n",
            "the\n",
            "statistical\n",
            "dimension\n",
            ".\n",
            "This\n",
            "is\n",
            "for\n",
            "instance\n",
            "what\n",
            "is\n",
            "required\n",
            "for\n",
            "approximate\n",
            "versions\n",
            "of\n",
            "kernel\n",
            "ridge\n",
            "regression\n",
            ".\n",
            "Strengths\n",
            ":\n",
            "These\n",
            "are\n",
            "important\n",
            "theoretical\n",
            "results\n",
            ",\n",
            "for\n",
            "problems\n",
            "quite\n",
            "central\n",
            "to\n",
            "NeurIPS\n",
            ",\n",
            "and\n",
            "thus\n",
            "should\n",
            "be\n",
            "accepted\n",
            ".\n",
            "The\n",
            "paper\n",
            "also\n",
            "provides\n",
            "a\n",
            "nice\n",
            "array\n",
            "of\n",
            "empirical\n",
            "uses\n",
            "cases\n",
            ".\n",
            "These\n",
            "basically\n",
            "are\n",
            "the\n",
            "same\n",
            "as\n",
            "recent\n",
            "non-oblivious\n",
            "ways\n",
            "to\n",
            "featurize\n",
            "the\n",
            "data\n",
            "(\n",
            "beyond\n",
            "Rahimi-Recht\n",
            "RFFs\n",
            ")\n",
            ",\n",
            "and\n",
            "they\n",
            "show\n",
            "clear\n",
            "improvement\n",
            ".\n",
            "This\n",
            "paper\n",
            "shows\n",
            "these\n",
            "results\n",
            "are\n",
            "oblivious\n",
            "to\n",
            "the\n",
            "data\n",
            "(\n",
            "like\n",
            "RR\n",
            "RFFs\n",
            ")\n",
            ",\n",
            "which\n",
            "is\n",
            "important\n",
            "for\n",
            "big\n",
            "data\n",
            "settings\n",
            ".\n",
            "Weaknesses\n",
            ":\n",
            "The\n",
            "only\n",
            "complaint\n",
            "is\n",
            "there\n",
            "is\n",
            "still\n",
            "a\n",
            "sqrt\n",
            "{\n",
            "s\n",
            "}\n",
            "gap\n",
            "in\n",
            "the\n",
            "leverage\n",
            "score\n",
            "bound\n",
            "for\n",
            "Gaussian\n",
            "densities\n",
            ",\n",
            "that\n",
            "seems\n",
            "significant\n",
            "(\n",
            "upper\n",
            "bound\n",
            "is\n",
            "Omega\n",
            "(\n",
            "s^\n",
            "{\n",
            "3/2\n",
            "}\n",
            ")\n",
            ",\n",
            "lower\n",
            "bound\n",
            "is\n",
            "s\n",
            ")\n",
            ".\n",
            "The\n",
            "experiments\n",
            "mentions\n",
            "that\n",
            "in\n",
            "practice\n",
            "the\n",
            "algorithm\n",
            "(\n",
            "from\n",
            "how\n",
            "it\n",
            "is\n",
            "implemented\n",
            "is\n",
            "not\n",
            "really\n",
            "new\n",
            ")\n",
            ",\n",
            "but\n",
            "that\n",
            "is\n",
            "fine\n",
            ",\n",
            "as\n",
            "the\n",
            "main\n",
            "importance\n",
            "of\n",
            "this\n",
            "work\n",
            "is\n",
            "showing\n",
            "theoretical\n",
            "result\n",
            "and\n",
            "obliviousness\n",
            ".\n",
            "Correctness\n",
            ":\n",
            "It\n",
            "all\n",
            "seems\n",
            "correct\n",
            ".\n",
            "Proofs\n",
            "are\n",
            "all\n",
            "sketched\n",
            "in\n",
            "main\n",
            "8\n",
            "pages\n",
            ".\n",
            "Clarity\n",
            ":\n",
            "Yes\n",
            "!\n",
            "Relation\n",
            "to\n",
            "Prior\n",
            "Work\n",
            ":\n",
            "Note\n",
            ":\n",
            "The\n",
            "formulation\n",
            "of\n",
            "leverage\n",
            "scores\n",
            "(\n",
            "in\n",
            "equation\n",
            "(\n",
            "1\n",
            ")\n",
            ")\n",
            "is\n",
            "indeed\n",
            "a\n",
            "nice\n",
            "general\n",
            "view\n",
            ".\n",
            "In\n",
            "fact\n",
            ",\n",
            "it\n",
            "basically\n",
            "appears\n",
            "like\n",
            "the\n",
            "notion\n",
            "of\n",
            "total\n",
            "sensitivity\n",
            "(\n",
            "https\n",
            ":\n",
            "//doi.org/10.1137/1.9781611973075.50\n",
            ")\n",
            ";\n",
            "these\n",
            "concepts\n",
            "are\n",
            "known\n",
            "to\n",
            "be\n",
            "the\n",
            "same\n",
            "in\n",
            "many\n",
            "cases\n",
            ",\n",
            "so\n",
            "it\n",
            "may\n",
            "be\n",
            "useful\n",
            "to\n",
            "make\n",
            "this\n",
            "connection\n",
            "explicit\n",
            ".\n",
            "Reproducibility\n",
            ":\n",
            "Yes\n",
            "Additional\n",
            "Feedback\n",
            ":\n",
            "Review\n",
            "3\n",
            "Summary\n",
            "and\n",
            "Contributions\n",
            ":\n",
            "The\n",
            "authors\n",
            "derive\n",
            "a\n",
            "computationally\n",
            "tractable\n",
            "upper-bound\n",
            "on\n",
            "the\n",
            "leverage\n",
            "score\n",
            "function\n",
            "when\n",
            "the\n",
            "function\n",
            "class\n",
            "is\n",
            "that\n",
            "of\n",
            "Fourier\n",
            "sparse\n",
            "functions\n",
            "with\n",
            "s\n",
            "spectrums\n",
            "and\n",
            "the\n",
            "probability\n",
            "density\n",
            "is\n",
            "that\n",
            "of\n",
            "Gaussian\n",
            "or\n",
            "Cauchy\n",
            ",\n",
            "in\n",
            "the\n",
            "univariate\n",
            "setting\n",
            ".\n",
            "They\n",
            "use\n",
            "the\n",
            "derived\n",
            "bound\n",
            "in\n",
            "two\n",
            "applications\n",
            ":\n",
            "random\n",
            "features\n",
            "for\n",
            "kernel\n",
            "approximation\n",
            "and\n",
            "active\n",
            "sampling\n",
            ".\n",
            "Strengths\n",
            ":\n",
            "-\n",
            "The\n",
            "paper\n",
            "contains\n",
            "a\n",
            "lot\n",
            "of\n",
            "interesting\n",
            "theoretical\n",
            "results\n",
            ".\n",
            "I\n",
            "found\n",
            "in\n",
            "particular\n",
            "Theorem\n",
            "5\n",
            "is\n",
            "interesting\n",
            ",\n",
            "as\n",
            "it\n",
            "connects\n",
            "the\n",
            "\\lambda-ridge\n",
            "leverage\n",
            "score\n",
            "in\n",
            "Def\n",
            "4\n",
            "to\n",
            "the\n",
            "leverage\n",
            "score\n",
            "function\n",
            "in\n",
            "Eq.1\n",
            "defined\n",
            "with\n",
            "the\n",
            "Fourier-sparse\n",
            "function\n",
            "class\n",
            "and\n",
            "the\n",
            "spectral\n",
            "density\n",
            "of\n",
            "the\n",
            "kernel\n",
            ".\n",
            "This\n",
            "is\n",
            "an\n",
            "interesting\n",
            "result\n",
            "in\n",
            "its\n",
            "own\n",
            "right\n",
            ".\n",
            "Comined\n",
            "with\n",
            "the\n",
            "computationally\n",
            "tractable\n",
            "upper\n",
            "bound\n",
            "in\n",
            "Theorem\n",
            "1\n",
            "or\n",
            "Theorem\n",
            "2\n",
            ",\n",
            "this\n",
            "leads\n",
            "to\n",
            "a\n",
            "tractable\n",
            "approximation\n",
            "to\n",
            "the\n",
            "\\lambda-ridge\n",
            "score\n",
            "for\n",
            "sampling\n",
            "random\n",
            "features\n",
            ".\n",
            "-\n",
            "The\n",
            "presentation\n",
            "is\n",
            "good\n",
            ",\n",
            "as\n",
            "there\n",
            "is\n",
            "a\n",
            "coherent\n",
            "story\n",
            ".\n",
            "I\n",
            "enjoyed\n",
            "reading\n",
            "it\n",
            ".\n",
            "-\n",
            "The\n",
            "theoretical\n",
            "results\n",
            "would\n",
            "be\n",
            "interesting\n",
            "to\n",
            "kernel\n",
            "folks\n",
            ".\n",
            "Weaknesses\n",
            ":\n",
            "-\n",
            "The\n",
            "theoretical\n",
            "results\n",
            "only\n",
            "hold\n",
            "for\n",
            "the\n",
            "univariate\n",
            "case\n",
            "with\n",
            "Gaussian\n",
            "or\n",
            "Cauchy\n",
            "densities\n",
            ".\n",
            "-\n",
            "The\n",
            "proposed\n",
            "approach\n",
            "to\n",
            "sampling\n",
            "random\n",
            "features\n",
            "implicitly\n",
            "assumes\n",
            "that\n",
            "the\n",
            "\\lambda-statistical\n",
            "dimension\n",
            "in\n",
            "Def\n",
            "2\n",
            "is\n",
            "known\n",
            ".\n",
            "This\n",
            "can\n",
            "be\n",
            "seen\n",
            "from\n",
            "Theorem\n",
            "5\n",
            ",\n",
            "whose\n",
            "upper-bound\n",
            "includes\n",
            "the\n",
            "statistical\n",
            "dimension\n",
            ".\n",
            "Since\n",
            "the\n",
            "statistical\n",
            "dimension\n",
            "requires\n",
            "the\n",
            "computation\n",
            "of\n",
            "the\n",
            "eigenvalues\n",
            "of\n",
            "the\n",
            "kernel\n",
            "matrix\n",
            ",\n",
            "this\n",
            "requires\n",
            "O\n",
            "(\n",
            "n^3\n",
            ")\n",
            "computational\n",
            "cost\n",
            ",\n",
            "if\n",
            "exactly\n",
            "computed\n",
            ".\n",
            "Since\n",
            "this\n",
            "cost\n",
            "is\n",
            "what\n",
            "we\n",
            "want\n",
            "to\n",
            "avoid\n",
            "(\n",
            "that\n",
            "'s\n",
            "why\n",
            "we\n",
            "use\n",
            "random\n",
            "features\n",
            ")\n",
            ",\n",
            "this\n",
            "makes\n",
            "the\n",
            "proposed\n",
            "approach\n",
            "practically\n",
            "useless\n",
            ".\n",
            "Therefore\n",
            "the\n",
            "authors\n",
            "should\n",
            "discuss\n",
            "this\n",
            "point\n",
            "and\n",
            "explain\n",
            "if\n",
            "there\n",
            "is\n",
            "any\n",
            "computationally\n",
            "efficient\n",
            "way\n",
            "of\n",
            "approximating\n",
            "the\n",
            "statistical\n",
            "dimension\n",
            ".\n",
            "-\n",
            "The\n",
            "experimental\n",
            "setting\n",
            "is\n",
            "not\n",
            "explained\n",
            "in\n",
            "detail\n",
            ",\n",
            "and\n",
            "the\n",
            "experiments\n",
            "may\n",
            "not\n",
            "be\n",
            "perfomed\n",
            "systematically\n",
            ".\n",
            "Regarding\n",
            "the\n",
            "former\n",
            ",\n",
            "the\n",
            "authors\n",
            "do\n",
            "not\n",
            "explain\n",
            "how\n",
            "the\n",
            "number\n",
            "of\n",
            "spectrum\n",
            "s\n",
            "(\n",
            "or\n",
            "the\n",
            "corresponding\n",
            "statistical\n",
            "dimension\n",
            "s_\\lambda\n",
            ")\n",
            "is\n",
            "specified\n",
            "and\n",
            "computed\n",
            ",\n",
            "for\n",
            "instance\n",
            ".\n",
            "Regarding\n",
            "the\n",
            "latter\n",
            ",\n",
            "the\n",
            "results\n",
            "do\n",
            "not\n",
            "have\n",
            "error\n",
            "bars\n",
            ",\n",
            "i.e.\n",
            ",\n",
            "standard\n",
            "deviations\n",
            "obtained\n",
            "from\n",
            "independent\n",
            "experiments\n",
            ".\n",
            "Correctness\n",
            ":\n",
            "I\n",
            "have\n",
            "not\n",
            "checked\n",
            "the\n",
            "proofs\n",
            "in\n",
            "the\n",
            "supplementary\n",
            ".\n",
            "Some\n",
            "important\n",
            "details\n",
            "are\n",
            "missing\n",
            "in\n",
            "the\n",
            "experimental\n",
            "results\n",
            "(\n",
            "see\n",
            "Weaknesses\n",
            "above\n",
            ")\n",
            ".\n",
            "Clarity\n",
            ":\n",
            "Yes\n",
            ",\n",
            "the\n",
            "paper\n",
            "is\n",
            "clearly\n",
            "written\n",
            "in\n",
            "general\n",
            ".\n",
            "However\n",
            ",\n",
            "there\n",
            "are\n",
            "some\n",
            "places\n",
            "where\n",
            "the\n",
            "explanations\n",
            "are\n",
            "not\n",
            "so\n",
            "clear\n",
            ".\n",
            "-\n",
            "Theorem\n",
            "3\n",
            ":\n",
            "what\n",
            "is\n",
            "the\n",
            "form\n",
            "of\n",
            "the\n",
            "embedding\n",
            "?\n",
            "The\n",
            "theorem\n",
            "only\n",
            "claims\n",
            "its\n",
            "existence\n",
            ".\n",
            "This\n",
            "is\n",
            "important\n",
            "as\n",
            "this\n",
            "embedding\n",
            "is\n",
            "used\n",
            "as\n",
            "a\n",
            "proposed\n",
            "method\n",
            "(\n",
            "lines\n",
            "251-252\n",
            ")\n",
            "-\n",
            "Line\n",
            "197\n",
            ":\n",
            "what\n",
            "is\n",
            "q\n",
            "?\n",
            "-\n",
            "Lines\n",
            "251-252\n",
            ":\n",
            "``\n",
            "To\n",
            "achieve\n",
            "the\n",
            "linear\n",
            "dependence\n",
            "on\n",
            "s_\\lambda\n",
            "in\n",
            "Theorem\n",
            "3\n",
            "we\n",
            "argue\n",
            "that\n",
            "it\n",
            "suffices\n",
            "to\n",
            "post-process\n",
            "the\n",
            "modified\n",
            "RFF\n",
            "embedding\n",
            "g\n",
            "with\n",
            "a\n",
            "standard\n",
            "random\n",
            "projection\n",
            "method\n",
            "''\n",
            ".\n",
            "It\n",
            "is\n",
            "not\n",
            "very\n",
            "clear\n",
            "from\n",
            "the\n",
            "text\n",
            "what\n",
            "this\n",
            "means\n",
            ".\n",
            "Do\n",
            "you\n",
            "have\n",
            "any\n",
            "formal\n",
            "statement\n",
            "of\n",
            "this\n",
            "and\n",
            "a\n",
            "formal\n",
            "theoretical\n",
            "justification\n",
            "for\n",
            "it\n",
            "?\n",
            "Relation\n",
            "to\n",
            "Prior\n",
            "Work\n",
            ":\n",
            "Yes\n",
            "One\n",
            "paper\n",
            "to\n",
            "be\n",
            "discussed\n",
            ":\n",
            "the\n",
            "following\n",
            "paper\n",
            "seems\n",
            "closely\n",
            "related\n",
            "to\n",
            "this\n",
            "paper\n",
            ".\n",
            "Please\n",
            "discuss\n",
            "how\n",
            "your\n",
            "work\n",
            "is\n",
            "related\n",
            "to\n",
            "their\n",
            "analysis\n",
            ".\n",
            "Z.\n",
            "Li\n",
            ",\n",
            "J.-F\n",
            ".\n",
            "Ton\n",
            ",\n",
            "D.\n",
            "Oglic\n",
            ",\n",
            "and\n",
            "D.\n",
            "Sejdinovic\n",
            ",\n",
            "Towards\n",
            "A\n",
            "Unified\n",
            "Analysis\n",
            "of\n",
            "Random\n",
            "Fourier\n",
            "Features\n",
            ",\n",
            "in\n",
            "International\n",
            "Conference\n",
            "on\n",
            "Machine\n",
            "Learning\n",
            "(\n",
            "ICML\n",
            ")\n",
            ",\n",
            "2019\n",
            ",\n",
            "PMLR\n",
            "97:3905–3914\n",
            "Reproducibility\n",
            ":\n",
            "No\n",
            "Additional\n",
            "Feedback\n",
            ":\n",
            "*\n",
            "*\n",
            "*\n",
            "Post\n",
            "rebuttal\n",
            "*\n",
            "*\n",
            "*\n",
            "Thanks\n",
            "for\n",
            "your\n",
            "feedback\n",
            "!\n",
            "Review\n",
            "4\n",
            "Summary\n",
            "and\n",
            "Contributions\n",
            ":\n",
            "This\n",
            "paper\n",
            "first\n",
            "provides\n",
            "two\n",
            "upper\n",
            "bounds\n",
            "on\n",
            "the\n",
            "leverage\n",
            "scores\n",
            "of\n",
            "Fourier\n",
            "sparse\n",
            "functions\n",
            "under\n",
            "Gaussian\n",
            "and\n",
            "Laplace\n",
            "measures\n",
            ".\n",
            "The\n",
            "authors\n",
            "motivate\n",
            "computing\n",
            "these\n",
            "upper\n",
            "bounds\n",
            "by\n",
            "the\n",
            "fact\n",
            "that\n",
            "for\n",
            "these\n",
            "functions\n",
            ",\n",
            "it\n",
            "is\n",
            "difficult\n",
            "to\n",
            "compute\n",
            "the\n",
            "leverage\n",
            "score\n",
            "over\n",
            "all\n",
            "x\n",
            "in\n",
            "the\n",
            "domain\n",
            ".\n",
            "To\n",
            "demonstrate\n",
            "usefulness\n",
            "of\n",
            "the\n",
            "obtained\n",
            "bounds\n",
            ",\n",
            "the\n",
            "authors\n",
            "talk\n",
            "about\n",
            "two\n",
            "ML\n",
            "applications\n",
            ".\n",
            "First\n",
            ",\n",
            "they\n",
            "show\n",
            "that\n",
            "the\n",
            "bounds\n",
            "yield\n",
            "a\n",
            "modified\n",
            "random\n",
            "Fourier\n",
            "features\n",
            "algorithm\n",
            "that\n",
            "can\n",
            "approximate\n",
            "Gaussian\n",
            "and\n",
            "Cauchy\n",
            "kernel\n",
            "matrices\n",
            ".\n",
            "Specifically\n",
            ",\n",
            "they\n",
            "show\n",
            "that\n",
            "for\n",
            "low\n",
            "dimensional\n",
            "data\n",
            ",\n",
            "a\n",
            "data\n",
            "oblivious\n",
            "kernel\n",
            "approximation\n",
            "method\n",
            "can\n",
            "be\n",
            "used\n",
            "that\n",
            "nearly\n",
            "matches\n",
            "best\n",
            "adaptive\n",
            "methods\n",
            "in\n",
            "speed\n",
            "and\n",
            "approximation\n",
            "quality\n",
            ".\n",
            "Second\n",
            ",\n",
            "they\n",
            "show\n",
            "that\n",
            "the\n",
            "bounds\n",
            "can\n",
            "be\n",
            "used\n",
            "as\n",
            "non-uniform\n",
            "sampling\n",
            "distributions\n",
            "for\n",
            "active\n",
            "learning\n",
            ".\n",
            "Specifically\n",
            ",\n",
            "they\n",
            "obtain\n",
            "active\n",
            "sampling\n",
            "results\n",
            "for\n",
            "regression\n",
            "problems\n",
            "involving\n",
            "s\n",
            "arbitrary\n",
            "complex\n",
            "exponentials\n",
            "when\n",
            "the\n",
            "data\n",
            "follows\n",
            "a\n",
            "Gaussian\n",
            "or\n",
            "Laplacian\n",
            "distribution\n",
            ".\n",
            "Finally\n",
            ",\n",
            "to\n",
            "show\n",
            "the\n",
            "potential\n",
            "of\n",
            "Fourier\n",
            "sparse\n",
            "leverage\n",
            "score\n",
            "bounds\n",
            ",\n",
            "the\n",
            "proposed\n",
            "modified\n",
            "RFF\n",
            "method\n",
            "is\n",
            "empirically\n",
            "evaluated\n",
            "and\n",
            "compared\n",
            "with\n",
            "classical\n",
            "RFF\n",
            "on\n",
            "a\n",
            "kernel\n",
            "ridge\n",
            "regression\n",
            "problem\n",
            ".\n",
            "They\n",
            "show\n",
            "that\n",
            "their\n",
            "method\n",
            "leads\n",
            "to\n",
            "faster\n",
            "convergence\n",
            "and\n",
            "better\n",
            "prediction\n",
            "error\n",
            ".\n",
            "Strengths\n",
            ":\n",
            "The\n",
            "authors\n",
            "highlight\n",
            "the\n",
            "importance\n",
            "of\n",
            "their\n",
            "work\n",
            ",\n",
            "their\n",
            "contributions\n",
            ",\n",
            "and\n",
            "relation\n",
            "to\n",
            "prior\n",
            "work\n",
            "well\n",
            ".\n",
            "Their\n",
            "numerical\n",
            "section\n",
            "is\n",
            "also\n",
            "detailed\n",
            ".\n",
            "Weaknesses\n",
            ":\n",
            "In\n",
            "general\n",
            ",\n",
            "while\n",
            "the\n",
            "authors\n",
            "make\n",
            "interesting\n",
            "claims\n",
            ",\n",
            "there\n",
            "are\n",
            "some\n",
            "issues\n",
            "with\n",
            "the\n",
            "work\n",
            ":\n",
            "Section\n",
            "2\n",
            ":\n",
            "After\n",
            "both\n",
            "Theorem\n",
            "stating\n",
            "the\n",
            "leverage\n",
            "scores\n",
            "upper\n",
            "bounds\n",
            ",\n",
            "the\n",
            "authors\n",
            "mention\n",
            "that\n",
            "there\n",
            "may\n",
            "be\n",
            "a\n",
            "gap\n",
            "and\n",
            "elude\n",
            "to\n",
            "the\n",
            "fact\n",
            "that\n",
            "a\n",
            "tighter\n",
            "upper\n",
            "bound\n",
            "may\n",
            "be\n",
            "obtained\n",
            "by\n",
            "strengthening\n",
            "Theorem\n",
            "1\n",
            "and\n",
            "2\n",
            ".\n",
            "Do\n",
            "the\n",
            "authors\n",
            "have\n",
            "any\n",
            "ideas\n",
            "of\n",
            "how\n",
            "their\n",
            "Theorems\n",
            "can\n",
            "be\n",
            "strengthened\n",
            "?\n",
            "O\n",
            "(\n",
            "\\sqrt\n",
            "(\n",
            "s\n",
            ")\n",
            ")\n",
            "does\n",
            "seem\n",
            "to\n",
            "be\n",
            "a\n",
            "large\n",
            "gap\n",
            "in\n",
            "Theorem\n",
            "1\n",
            ".\n",
            "I\n",
            "saw\n",
            "in\n",
            "the\n",
            "Appendix\n",
            "that\n",
            "the\n",
            "authors\n",
            "do\n",
            "give\n",
            "a\n",
            "tight\n",
            "bound\n",
            "for\n",
            "a\n",
            "special\n",
            "case\n",
            ".\n",
            "This\n",
            "should\n",
            "be\n",
            "called\n",
            "out\n",
            "in\n",
            "the\n",
            "main\n",
            "text\n",
            "and\n",
            "more\n",
            "explanations\n",
            "have\n",
            "to\n",
            "be\n",
            "given\n",
            "there\n",
            ".\n",
            "I\n",
            "found\n",
            "the\n",
            "fact\n",
            "that\n",
            "illustrated\n",
            "plots\n",
            "related\n",
            "to\n",
            "these\n",
            "upper\n",
            "bounds\n",
            "were\n",
            "also\n",
            "“\n",
            "tighter\n",
            "”\n",
            "than\n",
            "what\n",
            "authors\n",
            "can\n",
            "prove\n",
            "a\n",
            "bit\n",
            "misleading\n",
            ".\n",
            "I\n",
            "think\n",
            "it\n",
            "’\n",
            "s\n",
            "better\n",
            "to\n",
            "plot\n",
            "the\n",
            "actual\n",
            "obtained\n",
            "upper\n",
            "bound\n",
            ".\n",
            "Page\n",
            "3\n",
            "line\n",
            "122\n",
            "an\n",
            "“\n",
            "=\n",
            "”\n",
            "is\n",
            "missing\n",
            "?\n",
            "Section\n",
            "3\n",
            ":\n",
            "The\n",
            "authors\n",
            "mention\n",
            "“\n",
            "low\n",
            "dimensional\n",
            "data\n",
            "”\n",
            "here\n",
            "and\n",
            "in\n",
            "abstract\n",
            ".\n",
            "I\n",
            "think\n",
            "it\n",
            "’\n",
            "s\n",
            "better\n",
            "if\n",
            "that\n",
            "is\n",
            "quantified\n",
            "orderwise\n",
            ".\n",
            "Also\n",
            "the\n",
            "naming\n",
            "of\n",
            "subsections\n",
            "3.1\n",
            "and\n",
            "3.2\n",
            "is\n",
            "misleading\n",
            ".\n",
            "Theorem\n",
            "3\n",
            "is\n",
            "the\n",
            "authors\n",
            "contribution\n",
            "in\n",
            "subsection\n",
            "3.1\n",
            "(\n",
            "Formal\n",
            "results\n",
            ")\n",
            ".\n",
            "The\n",
            "next\n",
            "subsection\n",
            "is\n",
            "named\n",
            "“\n",
            "Our\n",
            "approach\n",
            "”\n",
            "which\n",
            "usually\n",
            "means\n",
            "that\n",
            "the\n",
            "previous\n",
            "subsection\n",
            "was\n",
            "prior\n",
            "work\n",
            ".\n",
            "Section\n",
            "4\n",
            ":\n",
            "The\n",
            "authors\n",
            "mention\n",
            "that\n",
            "they\n",
            "use\n",
            "kernel\n",
            "approximation\n",
            "as\n",
            "a\n",
            "preconditioner\n",
            "to\n",
            "accelerate\n",
            "the\n",
            "iterative\n",
            "solution\n",
            "of\n",
            "the\n",
            "original\n",
            "problem\n",
            ".\n",
            "They\n",
            "say\n",
            "that\n",
            "they\n",
            "get\n",
            "similar\n",
            "empirical\n",
            "results\n",
            "as\n",
            "[\n",
            "AKM+17\n",
            "]\n",
            "did\n",
            "by\n",
            "using\n",
            "approximation\n",
            "in\n",
            "place\n",
            "of\n",
            "K.\n",
            "Is\n",
            "this\n",
            "similarity\n",
            "in\n",
            "terms\n",
            "of\n",
            "accuracy\n",
            "or\n",
            "speed\n",
            "?\n",
            "If\n",
            "both\n",
            ",\n",
            "it\n",
            "’\n",
            "s\n",
            "not\n",
            "clear\n",
            "what\n",
            "makes\n",
            "this\n",
            "algorithm\n",
            "interesting\n",
            "for\n",
            "this\n",
            "use-case\n",
            ".\n",
            "Update\n",
            ":\n",
            "The\n",
            "authors\n",
            "did\n",
            "address\n",
            "this\n",
            "point\n",
            "in\n",
            "rebuttal\n",
            ".\n",
            "Correctness\n",
            ":\n",
            "I\n",
            "did\n",
            "not\n",
            "check\n",
            "the\n",
            "proofs\n",
            "of\n",
            "Theorems\n",
            ".\n",
            "Empirical\n",
            "methodology\n",
            "looks\n",
            "correct\n",
            ".\n",
            "Clarity\n",
            ":\n",
            "Overall\n",
            "the\n",
            "paper\n",
            "is\n",
            "well\n",
            "written\n",
            ".\n",
            "The\n",
            "flow\n",
            "can\n",
            "be\n",
            "improved\n",
            ".\n",
            "I\n",
            "found\n",
            "myself\n",
            "reading\n",
            "parts\n",
            "more\n",
            "than\n",
            "once\n",
            "and\n",
            "going\n",
            "back\n",
            "and\n",
            "forth\n",
            "between\n",
            "Theorems\n",
            ".\n",
            "Relation\n",
            "to\n",
            "Prior\n",
            "Work\n",
            ":\n",
            "The\n",
            "authors\n",
            "do\n",
            "make\n",
            "distinctions\n",
            "between\n",
            "their\n",
            "contributions\n",
            "and\n",
            "prior\n",
            "work\n",
            "throughout\n",
            "the\n",
            "paper\n",
            ".\n",
            "Reproducibility\n",
            ":\n",
            "Yes\n",
            "NeurIPS\n",
            "2020\n",
            "Fourier\n",
            "Sparse\n",
            "Leverage\n",
            "Scores\n",
            "and\n",
            "Approximate\n",
            "Kernel\n",
            "Learning\n",
            "Meta\n",
            "Review\n",
            "Four\n",
            "knowledgeable\n",
            "reviewers\n",
            "recommend\n",
            "to\n",
            "accept\n",
            "the\n",
            "paper\n",
            "based\n",
            "on\n",
            "the\n",
            "progress\n",
            "it\n",
            "has\n",
            "made\n",
            "toward\n",
            "understanding\n",
            "and\n",
            "improving\n",
            "the\n",
            "accuracy\n",
            "of\n",
            "kernel\n",
            "approximations\n",
            "made\n",
            "using\n",
            "leverage\n",
            "scores\n",
            ".\n",
            "On\n",
            "this\n",
            "basis\n",
            "the\n",
            "paper\n",
            "is\n",
            "accepted\n",
            ".\n",
            "We\n",
            "ask\n",
            "that\n",
            "the\n",
            "authors\n",
            "implement\n",
            "the\n",
            "edits\n",
            "proposed\n",
            "in\n",
            "their\n",
            "rebuttal\n",
            ":\n",
            "to\n",
            "clarify\n",
            "the\n",
            "justification\n",
            "for\n",
            "the\n",
            "equation\n",
            "after\n",
            "line\n",
            "518\n",
            ",\n",
            "and\n",
            "to\n",
            "expand\n",
            "on\n",
            "the\n",
            "discussion\n",
            "of\n",
            "Theorem\n",
            "3\n",
            ".\n",
            "Abstract\n",
            "Neural\n",
            "networks\n",
            "are\n",
            "sensitive\n",
            "to\n",
            "hyper-parameter\n",
            "and\n",
            "architecture\n",
            "choices\n",
            ".\n",
            "Auto-\n",
            "mated\n",
            "Machine\n",
            "Learning\n",
            "(\n",
            "AutoML\n",
            ")\n",
            "is\n",
            "a\n",
            "promising\n",
            "paradigm\n",
            "for\n",
            "automating\n",
            "these\n",
            "choices\n",
            ".\n",
            "Current\n",
            "ML\n",
            "software\n",
            "libraries\n",
            ",\n",
            "however\n",
            ",\n",
            "are\n",
            "quite\n",
            "limited\n",
            "in\n",
            "handling\n",
            "the\n",
            "dynamic\n",
            "interactions\n",
            "among\n",
            "the\n",
            "components\n",
            "of\n",
            "AutoML\n",
            ".\n",
            "For\n",
            "example\n",
            ",\n",
            "efﬁcient\n",
            "NAS\n",
            "algorithms\n",
            ",\n",
            "such\n",
            "as\n",
            "ENAS\n",
            "[\n",
            "1\n",
            "]\n",
            "and\n",
            "DARTS\n",
            "[\n",
            "2\n",
            "]\n",
            ",\n",
            "typically\n",
            "require\n",
            "an\n",
            "imple-\n",
            "mentation\n",
            "coupling\n",
            "between\n",
            "the\n",
            "search\n",
            "space\n",
            "and\n",
            "search\n",
            "algorithm\n",
            ",\n",
            "the\n",
            "two\n",
            "key\n",
            "components\n",
            "in\n",
            "AutoML\n",
            ".\n",
            "Furthermore\n",
            ",\n",
            "implementing\n",
            "a\n",
            "complex\n",
            "search\n",
            "ﬂow\n",
            ",\n",
            "such\n",
            "as\n",
            "searching\n",
            "architectures\n",
            "within\n",
            "a\n",
            "loop\n",
            "of\n",
            "searching\n",
            "hardware\n",
            "conﬁgurations\n",
            ",\n",
            "is\n",
            "difﬁcult\n",
            ".\n",
            "To\n",
            "summarize\n",
            ",\n",
            "changing\n",
            "the\n",
            "search\n",
            "space\n",
            ",\n",
            "search\n",
            "algorithm\n",
            ",\n",
            "or\n",
            "search\n",
            "ﬂow\n",
            "in\n",
            "current\n",
            "ML\n",
            "libraries\n",
            "usually\n",
            "requires\n",
            "a\n",
            "signiﬁcant\n",
            "change\n",
            "in\n",
            "the\n",
            "program\n",
            "logic\n",
            ".\n",
            "In\n",
            "this\n",
            "paper\n",
            ",\n",
            "we\n",
            "introduce\n",
            "a\n",
            "new\n",
            "way\n",
            "of\n",
            "programming\n",
            "AutoML\n",
            "based\n",
            "on\n",
            "symbolic\n",
            "programming\n",
            ".\n",
            "Under\n",
            "this\n",
            "paradigm\n",
            ",\n",
            "ML\n",
            "programs\n",
            "are\n",
            "mutable\n",
            ",\n",
            "thus\n",
            "can\n",
            "be\n",
            "manipulated\n",
            "easily\n",
            "by\n",
            "another\n",
            "program\n",
            ".\n",
            "As\n",
            "a\n",
            "result\n",
            ",\n",
            "AutoML\n",
            "can\n",
            "be\n",
            "reformulated\n",
            "as\n",
            "an\n",
            "automated\n",
            "process\n",
            "of\n",
            "symbolic\n",
            "manipulation\n",
            ".\n",
            "With\n",
            "this\n",
            "formulation\n",
            ",\n",
            "we\n",
            "decouple\n",
            "the\n",
            "triangle\n",
            "of\n",
            "the\n",
            "search\n",
            "algorithm\n",
            ",\n",
            "the\n",
            "search\n",
            "space\n",
            "and\n",
            "the\n",
            "child\n",
            "program\n",
            ".\n",
            "This\n",
            "decoupling\n",
            "makes\n",
            "it\n",
            "easy\n",
            "to\n",
            "change\n",
            "the\n",
            "search\n",
            "space\n",
            "and\n",
            "search\n",
            "algorithm\n",
            "(\n",
            "without\n",
            "and\n",
            "with\n",
            "weight\n",
            "sharing\n",
            ")\n",
            ",\n",
            "as\n",
            "well\n",
            "as\n",
            "to\n",
            "add\n",
            "search\n",
            "capabilities\n",
            "to\n",
            "existing\n",
            "code\n",
            "and\n",
            "implement\n",
            "complex\n",
            "search\n",
            "ﬂows\n",
            ".\n",
            "We\n",
            "then\n",
            "introduce\n",
            "PyGlove\n",
            ",\n",
            "a\n",
            "new\n",
            "Python\n",
            "library\n",
            "that\n",
            "implements\n",
            "this\n",
            "paradigm\n",
            ".\n",
            "Through\n",
            "case\n",
            "studies\n",
            "on\n",
            "ImageNet\n",
            "and\n",
            "NAS-Bench-101\n",
            ",\n",
            "we\n",
            "show\n",
            "that\n",
            "with\n",
            "PyGlove\n",
            "users\n",
            "can\n",
            "easily\n",
            "convert\n",
            "a\n",
            "static\n",
            "program\n",
            "into\n",
            "a\n",
            "search\n",
            "space\n",
            ",\n",
            "quickly\n",
            "iterate\n",
            "on\n",
            "the\n",
            "search\n",
            "spaces\n",
            "and\n",
            "search\n",
            "algorithms\n",
            ",\n",
            "and\n",
            "craft\n",
            "complex\n",
            "search\n",
            "ﬂows\n",
            "to\n",
            "achieve\n",
            "better\n",
            "results\n",
            ".\n",
            "1\n",
            "Book\n",
            "Do\n",
            "not\n",
            "remove\n",
            ":\n",
            "This\n",
            "comment\n",
            "is\n",
            "monitored\n",
            "to\n",
            "verify\n",
            "that\n",
            "the\n",
            "site\n",
            "is\n",
            "working\n",
            "properly\n",
            "Abstract\n",
            "Leverage\n",
            "score\n",
            "sampling\n",
            "is\n",
            "a\n",
            "powerful\n",
            "technique\n",
            "that\n",
            "originates\n",
            "from\n",
            "theoretical\n",
            "computer\n",
            "science\n",
            ",\n",
            "which\n",
            "can\n",
            "be\n",
            "used\n",
            "to\n",
            "speed\n",
            "up\n",
            "a\n",
            "large\n",
            "number\n",
            "of\n",
            "fundamental\n",
            "questions\n",
            ",\n",
            "e.g\n",
            ".\n",
            "linear\n",
            "regression\n",
            ",\n",
            "linear\n",
            "programming\n",
            ",\n",
            "semi-deﬁnite\n",
            "programming\n",
            ",\n",
            "cutting\n",
            "plane\n",
            "method\n",
            ",\n",
            "graph\n",
            "sparsiﬁcation\n",
            ",\n",
            "maximum\n",
            "matching\n",
            "and\n",
            "max-ﬂow\n",
            ".\n",
            "Re-\n",
            "cently\n",
            ",\n",
            "it\n",
            "has\n",
            "been\n",
            "shown\n",
            "that\n",
            "leverage\n",
            "score\n",
            "sampling\n",
            "helps\n",
            "to\n",
            "accelerate\n",
            "kernel\n",
            "methods\n",
            "[\n",
            "Avron\n",
            ",\n",
            "Kapralov\n",
            ",\n",
            "Musco\n",
            ",\n",
            "Musco\n",
            ",\n",
            "Velingker\n",
            "and\n",
            "Zandieh\n",
            "17\n",
            "]\n",
            ".\n",
            "In\n",
            "this\n",
            "work\n",
            ",\n",
            "we\n",
            "generalize\n",
            "the\n",
            "results\n",
            "in\n",
            "[\n",
            "Avron\n",
            ",\n",
            "Kapralov\n",
            ",\n",
            "Musco\n",
            ",\n",
            "Musco\n",
            ",\n",
            "Vel-\n",
            "ingker\n",
            "and\n",
            "Zandieh\n",
            "17\n",
            "]\n",
            "to\n",
            "a\n",
            "broader\n",
            "class\n",
            "of\n",
            "kernels\n",
            ".\n",
            "We\n",
            "further\n",
            "bring\n",
            "the\n",
            "leverage\n",
            "score\n",
            "sampling\n",
            "into\n",
            "the\n",
            "ﬁeld\n",
            "of\n",
            "deep\n",
            "learning\n",
            "theory\n",
            ".\n",
            "•\n",
            "We\n",
            "show\n",
            "the\n",
            "connection\n",
            "between\n",
            "the\n",
            "initialization\n",
            "for\n",
            "neural\n",
            "network\n",
            "train-\n",
            "ing\n",
            "and\n",
            "approximating\n",
            "the\n",
            "neural\n",
            "tangent\n",
            "kernel\n",
            "with\n",
            "random\n",
            "features\n",
            ".\n",
            "•\n",
            "We\n",
            "prove\n",
            "the\n",
            "equivalence\n",
            "between\n",
            "regularized\n",
            "neural\n",
            "network\n",
            "and\n",
            "neural\n",
            "tan-\n",
            "gent\n",
            "kernel\n",
            "ridge\n",
            "regression\n",
            "under\n",
            "the\n",
            "initialization\n",
            "of\n",
            "both\n",
            "classical\n",
            "random\n",
            "Gaussian\n",
            "and\n",
            "leverage\n",
            "score\n",
            "sampling\n",
            ".\n",
            "1\n",
            "Abstract\n",
            "Kernel\n",
            "methods\n",
            "augmented\n",
            "with\n",
            "random\n",
            "features\n",
            "give\n",
            "scalable\n",
            "algorithms\n",
            "for\n",
            "learning\n",
            "from\n",
            "big\n",
            "data\n",
            ".\n",
            "But\n",
            "it\n",
            "has\n",
            "been\n",
            "computationally\n",
            "hard\n",
            "to\n",
            "sample\n",
            "random\n",
            "features\n",
            "according\n",
            "to\n",
            "a\n",
            "probability\n",
            "distribution\n",
            "that\n",
            "is\n",
            "optimized\n",
            "for\n",
            "the\n",
            "data\n",
            ",\n",
            "so\n",
            "as\n",
            "to\n",
            "minimize\n",
            "the\n",
            "required\n",
            "number\n",
            "of\n",
            "features\n",
            "for\n",
            "achieving\n",
            "the\n",
            "learning\n",
            "to\n",
            "a\n",
            "desired\n",
            "accuracy\n",
            ".\n",
            "Here\n",
            ",\n",
            "we\n",
            "develop\n",
            "a\n",
            "quantum\n",
            "algorithm\n",
            "for\n",
            "sampling\n",
            "from\n",
            "this\n",
            "optimized\n",
            "distribution\n",
            "over\n",
            "features\n",
            ",\n",
            "in\n",
            "runtime\n",
            "O\n",
            "(\n",
            "D\n",
            ")\n",
            "that\n",
            "is\n",
            "linear\n",
            "in\n",
            "the\n",
            "dimension\n",
            "D\n",
            "of\n",
            "the\n",
            "input\n",
            "data\n",
            ".\n",
            "Our\n",
            "algorithm\n",
            "achieves\n",
            "an\n",
            "exponential\n",
            "speedup\n",
            "in\n",
            "D\n",
            "compared\n",
            "to\n",
            "any\n",
            "known\n",
            "classical\n",
            "algorithm\n",
            "for\n",
            "this\n",
            "sampling\n",
            "task\n",
            ".\n",
            "In\n",
            "contrast\n",
            "to\n",
            "existing\n",
            "quantum\n",
            "machine\n",
            "learning\n",
            "algorithms\n",
            ",\n",
            "our\n",
            "algorithm\n",
            "circumvents\n",
            "sparsity\n",
            "and\n",
            "low-rank\n",
            "assumptions\n",
            "and\n",
            "thus\n",
            "has\n",
            "wide\n",
            "applicability\n",
            ".\n",
            "We\n",
            "also\n",
            "show\n",
            "that\n",
            "the\n",
            "sampled\n",
            "features\n",
            "can\n",
            "be\n",
            "combined\n",
            "with\n",
            "regression\n",
            "by\n",
            "stochastic\n",
            "gradient\n",
            "descent\n",
            "to\n",
            "achieve\n",
            "the\n",
            "learning\n",
            "without\n",
            "canceling\n",
            "out\n",
            "our\n",
            "exponential\n",
            "speedup\n",
            ".\n",
            "Our\n",
            "algorithm\n",
            "based\n",
            "on\n",
            "sampling\n",
            "optimized\n",
            "random\n",
            "features\n",
            "leads\n",
            "to\n",
            "an\n",
            "accelerated\n",
            "framework\n",
            "for\n",
            "machine\n",
            "learning\n",
            "that\n",
            "takes\n",
            "advantage\n",
            "of\n",
            "quantum\n",
            "computers\n",
            ".\n",
            "1\n",
            "Abstract\n",
            "This\n",
            "paper\n",
            "studies\n",
            "the\n",
            "statistical\n",
            "complexity\n",
            "of\n",
            "kernel\n",
            "hyperparameter\n",
            "tuning\n",
            "in\n",
            "the\n",
            "setting\n",
            "of\n",
            "active\n",
            "regression\n",
            "under\n",
            "adversarial\n",
            "noise\n",
            ".\n",
            "We\n",
            "consider\n",
            "the\n",
            "problem\n",
            "of\n",
            "ﬁnding\n",
            "the\n",
            "best\n",
            "interpolant\n",
            "from\n",
            "a\n",
            "class\n",
            "of\n",
            "kernels\n",
            "with\n",
            "unknown\n",
            "hyperparameters\n",
            ",\n",
            "assuming\n",
            "only\n",
            "that\n",
            "the\n",
            "noise\n",
            "is\n",
            "square-integrable\n",
            ".\n",
            "We\n",
            "provide\n",
            "ﬁnite-sample\n",
            "guaran-\n",
            "tees\n",
            "for\n",
            "the\n",
            "problem\n",
            ",\n",
            "characterizing\n",
            "how\n",
            "increasing\n",
            "the\n",
            "complexity\n",
            "of\n",
            "the\n",
            "kernel\n",
            "class\n",
            "increases\n",
            "the\n",
            "complexity\n",
            "of\n",
            "learning\n",
            "kernel\n",
            "hyperparameters\n",
            ".\n",
            "For\n",
            "common\n",
            "kernel\n",
            "classes\n",
            "(\n",
            "e.g\n",
            ".\n",
            "squared-exponential\n",
            "kernels\n",
            "with\n",
            "unknown\n",
            "lengthscale\n",
            ")\n",
            ",\n",
            "our\n",
            "results\n",
            "show\n",
            "that\n",
            "hyperparameter\n",
            "optimization\n",
            "increases\n",
            "sample\n",
            "complexity\n",
            "by\n",
            "just\n",
            "a\n",
            "logarithmic\n",
            "factor\n",
            ",\n",
            "in\n",
            "comparison\n",
            "to\n",
            "the\n",
            "setting\n",
            "where\n",
            "optimal\n",
            "parameters\n",
            "are\n",
            "known\n",
            "in\n",
            "advance\n",
            ".\n",
            "Our\n",
            "result\n",
            "is\n",
            "based\n",
            "on\n",
            "a\n",
            "subsampling\n",
            "guarantee\n",
            "for\n",
            "linear\n",
            "regression\n",
            "under\n",
            "multiple\n",
            "design\n",
            "matrices\n",
            "which\n",
            "may\n",
            "be\n",
            "of\n",
            "independent\n",
            "interest\n",
            ".\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "df_output                                                 topic  ... rank_lda\n",
            "0              graph similarity deep learning neurips  ...      6.0\n",
            "1              graph similarity deep learning neurips  ...     10.0\n",
            "2              graph similarity deep learning neurips  ...      2.0\n",
            "3              graph similarity deep learning neurips  ...      5.0\n",
            "4              graph similarity deep learning neurips  ...      1.0\n",
            "..                                                ...  ...      ...\n",
            "4   fourier sparse leverage scores approximate ker...  ...      2.0\n",
            "5   fourier sparse leverage scores approximate ker...  ...      8.0\n",
            "6   fourier sparse leverage scores approximate ker...  ...      1.0\n",
            "7   fourier sparse leverage scores approximate ker...  ...      5.0\n",
            "8   fourier sparse leverage scores approximate ker...  ...      3.0\n",
            "\n",
            "[81 rows x 8 columns]\n",
            "topic:  improved algorithms online submodular maximization via first order regret bounds neurips id_= 10\n",
            "1 . Improved Algorithms for Online Submodular Maximization via First ... https://papers.nips.cc/paper/2020/hash/0163cceb20f5ca7b313419c068abd9dc-Abstract.html\n",
            "**********************************************\n",
            "2 . Improved Algorithms for Online Submodular Maximization via First ... https://papers.nips.cc/paper/2020/file/0163cceb20f5ca7b313419c068abd9dc-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "We consider the problem of nonnegative submodular maximization in the online\n",
            "setting. At time step t, an algorithm selects a set St ∈ C ⊆ 2V where C is a feasible\n",
            "family of sets. An adversary then reveals a submodular function ft. The goal is to\n",
            "design an efﬁcient algorithm for minimizing the expected approximate regret.\n",
            "In this work, we give a general approach for improving regret bounds in online\n",
            "submodular maximization by exploiting “ﬁrst-order” regret bounds for online\n",
            "linear optimization.\n",
            "• For monotone submodular maximization subject to a matroid, we give an efﬁcient\n",
            "\n",
            "algorithm which achieves a (1 − c/e − ε)-regret of O((cid:112)kT ln(n/k)) where n\n",
            "\n",
            "is the size of the ground set, k is the rank of the matroid, ε > 0 is a constant,\n",
            "and c is the average curvature. Even without assuming any curvature (i.e., taking\n",
            "c = 1), this regret bound improves on previous results of Streeter et al. (2009)\n",
            "and Golovin et al. (2014).\n",
            "\n",
            "√\n",
            "• For nonmonotone, unconstrained submodular functions, we give an algorithm\n",
            "with 1/2-regret O(\n",
            "nT ), improving on the results of Roughgarden and Wang\n",
            "(2018). Our approach is based on Blackwell approachability; in particular, we\n",
            "give a novel ﬁrst-order regret bound for the Blackwell instances that arise in this\n",
            "setting.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "3 . Review for NeurIPS paper: Improved Algorithms for Online ... https://papers.nips.cc/paper/2020/file/0163cceb20f5ca7b313419c068abd9dc-MetaReview.html\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-33c69df03483>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'pdf'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'link'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'pptx'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'link'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'info'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'link'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'tfhub'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'link'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'link'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0marticle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfulltext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'link'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;31m#print(article)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/newspaper/api.py\u001b[0m in \u001b[0;36mfulltext\u001b[0;34m(html, language)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mtop_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_best_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mtop_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marticle_html\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_formatted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/newspaper/extractors.py\u001b[0m in \u001b[0;36mpost_cleanup\u001b[0;34m(self, top_node)\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0;32mor\u001b[0m \u001b[0mparas\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mno\u001b[0m \u001b[0mgusto\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0madd\u001b[0m \u001b[0madjacent\u001b[0m \u001b[0mnodes\u001b[0m \u001b[0mwhich\u001b[0m \u001b[0mlook\u001b[0m \u001b[0mcontenty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \"\"\"\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_siblings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetChildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m             \u001b[0me_tag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetTag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/newspaper/extractors.py\u001b[0m in \u001b[0;36madd_siblings\u001b[0;34m(self, top_node)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_siblings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 869\u001b[0;31m         \u001b[0mbaseline_score_siblings_para\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_siblings_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk_siblings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcurrent_node\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/newspaper/extractors.py\u001b[0m in \u001b[0;36mget_siblings_score\u001b[0;34m(self, top_node)\u001b[0m\n\u001b[1;32m    924\u001b[0m         \u001b[0mparagraphs_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[0mparagraphs_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m         \u001b[0mnodes_to_check\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetElementsByTag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'p'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnodes_to_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/newspaper/parsers.py\u001b[0m in \u001b[0;36mgetElementsByTag\u001b[0;34m(cls, node, tag, attr, value, childs, use_regex)\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0mtrans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'translate(@%s, \"%s\", \"%s\")'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mascii_uppercase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mascii_lowercase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0mselector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'%s[contains(%s, \"%s\")]'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mselector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0melems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespaces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;31m# remove the root node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# if we have a selection tag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'xpath'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYhkCvVIJYQa"
      },
      "source": [
        "df_output.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mf5XuJwa2JG0"
      },
      "source": [
        "# To CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MVbUuRX2Ift"
      },
      "source": [
        "file_path = '/content/drive/Shared drives/1DeepContextGraph/1DeepContextGraph/code/data/'\n",
        "\n",
        "df_output.to_csv(file_path+file_name+str(ngramsCount)+'grams.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}