{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrendDetection_pipeline_cloud_version.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "environment": {
      "name": "common-cpu.m75",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/base-cpu:m75"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d51b511c737b41ab846a167d5e934f34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4e5202df885444e6b3126703b8140348",
              "IPY_MODEL_f3d891c0ac3347a69785c86c716b1f1b"
            ],
            "layout": "IPY_MODEL_c22662fda94f4efd92ae372e39a71687"
          }
        },
        "c22662fda94f4efd92ae372e39a71687": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e5202df885444e6b3126703b8140348": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "Downloading: 100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8966ddf543f8496eb11b96acf7ca83a6",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b9188ac63634b9dae09fba87c866254",
            "value": 231508
          }
        },
        "f3d891c0ac3347a69785c86c716b1f1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d54004f9bec42bf8386c72509d61fde",
            "placeholder": "​",
            "style": "IPY_MODEL_4fa7e53049d9418e97dee36155893f33",
            "value": " 232k/232k [00:00&lt;00:00, 414kB/s]"
          }
        },
        "5b9188ac63634b9dae09fba87c866254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "8966ddf543f8496eb11b96acf7ca83a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fa7e53049d9418e97dee36155893f33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d54004f9bec42bf8386c72509d61fde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72778c0f871d46ae8beb512a91b98c38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a129ae5021364fc684759fbb7479e44e",
              "IPY_MODEL_fd5da834d2da45a5bfb4af01bde800ed"
            ],
            "layout": "IPY_MODEL_c3446589739e4ae2828d1b11ae28cd9f"
          }
        },
        "c3446589739e4ae2828d1b11ae28cd9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a129ae5021364fc684759fbb7479e44e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "Downloading: 100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6af320a038b04e728a11fa4fd674f55a",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3eb0fa2c12474cc18b50c7cf70953916",
            "value": 28
          }
        },
        "fd5da834d2da45a5bfb4af01bde800ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c159eea4fa90426a921df7d3c3d718e2",
            "placeholder": "​",
            "style": "IPY_MODEL_8821650883e245018bce02b7ff4f3ed8",
            "value": " 28.0/28.0 [00:00&lt;00:00, 222B/s]"
          }
        },
        "3eb0fa2c12474cc18b50c7cf70953916": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "6af320a038b04e728a11fa4fd674f55a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8821650883e245018bce02b7ff4f3ed8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c159eea4fa90426a921df7d3c3d718e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fc8279aadd94c07aa910a675a7bc1b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_10bc6b2da9ad44239f2b9edad12d7031",
              "IPY_MODEL_0b39a048235a419d9626d2aed8a9addd"
            ],
            "layout": "IPY_MODEL_77819468aa694b05b5dd25b0ae852ed4"
          }
        },
        "77819468aa694b05b5dd25b0ae852ed4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10bc6b2da9ad44239f2b9edad12d7031": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "Downloading: 100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b03595f6c594725ac159d2034114c3e",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_164be9b1b41b422aa788fdbe8965f68c",
            "value": 466062
          }
        },
        "0b39a048235a419d9626d2aed8a9addd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_167b764c57a54841823f8c163939b4f6",
            "placeholder": "​",
            "style": "IPY_MODEL_1c1affee94054a63a6c43be9f48bd355",
            "value": " 466k/466k [00:00&lt;00:00, 1.83MB/s]"
          }
        },
        "164be9b1b41b422aa788fdbe8965f68c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "0b03595f6c594725ac159d2034114c3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c1affee94054a63a6c43be9f48bd355": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "167b764c57a54841823f8c163939b4f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7e37c4e13d14672b930d61a86650299": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5e12f9cfc8a343ddb60f50c6de3275ed",
              "IPY_MODEL_6faee1983f564d5993aee157c9deccc6"
            ],
            "layout": "IPY_MODEL_32a132887f5f427ebd89d39bd2ddc56c"
          }
        },
        "32a132887f5f427ebd89d39bd2ddc56c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e12f9cfc8a343ddb60f50c6de3275ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "Downloading: 100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d96cf7785c304b2d97aed740e9a0dffe",
            "max": 442,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0728253c9a0c44959e491c5d59061a72",
            "value": 442
          }
        },
        "6faee1983f564d5993aee157c9deccc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ef86a3bd09143d897b6aed270c9f4bc",
            "placeholder": "​",
            "style": "IPY_MODEL_70769eb544f84c5fb688859594f2c635",
            "value": " 442/442 [00:00&lt;00:00, 4.47kB/s]"
          }
        },
        "0728253c9a0c44959e491c5d59061a72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "d96cf7785c304b2d97aed740e9a0dffe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70769eb544f84c5fb688859594f2c635": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ef86a3bd09143d897b6aed270c9f4bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbeeed0f42b44431b2ae60f49526f4cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_502ed2954ecd4b4e8716749994f80a26",
              "IPY_MODEL_ad5a760951964a1caa1a9ebdb5382df5"
            ],
            "layout": "IPY_MODEL_daf66f65ae614e3b8883b36ed0a2dce2"
          }
        },
        "daf66f65ae614e3b8883b36ed0a2dce2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "502ed2954ecd4b4e8716749994f80a26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "Downloading: 100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0db0184f95a426eac7b42d5d1654208",
            "max": 267967963,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_62aa5006f8ac4876a918f2e7bd34d234",
            "value": 267967963
          }
        },
        "ad5a760951964a1caa1a9ebdb5382df5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d69df1e63804d55965233b99a2ffdf4",
            "placeholder": "​",
            "style": "IPY_MODEL_d47392e81951406495627a879bc16911",
            "value": " 268M/268M [00:07&lt;00:00, 37.9MB/s]"
          }
        },
        "62aa5006f8ac4876a918f2e7bd34d234": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "a0db0184f95a426eac7b42d5d1654208": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d47392e81951406495627a879bc16911": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d69df1e63804d55965233b99a2ffdf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s-c-soma/deep_context_graph/blob/main/code/TrendDetection_pipeline_cloud_version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOwqe1yW8_NX"
      },
      "source": [
        "# Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rM1DyIDL8_Nl"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwWqkEx78_Nm",
        "outputId": "bc5f8e8b-623e-4294-cfa9-1e055a899c09"
      },
      "source": [
        "!pip install dateparser\n",
        "!pip install bs4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dateparser in /opt/conda/lib/python3.7/site-packages (1.0.0)\n",
            "Requirement already satisfied: regex!=2019.02.19 in /opt/conda/lib/python3.7/site-packages (from dateparser) (2019.8.19)\n",
            "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from dateparser) (2021.1)\n",
            "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.7/site-packages (from dateparser) (2.8.1)\n",
            "Requirement already satisfied: tzlocal in /opt/conda/lib/python3.7/site-packages (from dateparser) (2.1)\n",
            "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil->dateparser) (1.16.0)\n",
            "Requirement already satisfied: bs4 in /opt/conda/lib/python3.7/site-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.7/site-packages (from bs4) (4.9.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4->bs4) (2.2.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0Bw88v98_No"
      },
      "source": [
        "#Import the dependencies\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import requests\n",
        "import urllib.request\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from dateparser.search import search_dates\n",
        "import re\n",
        "from abc import ABC, abstractmethod\n",
        "from typing import List"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEzmGbhSIa7f"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fonNa_5IgVh"
      },
      "source": [
        "URL = 'https://papers.nips.cc/paper/2020' ## conference paper link\n",
        "topic_count = 10 ## topic count for passing to the custom query enginine; must stay in limit (<50) for free service\n",
        "ngramsCount =5 ##no of n grams\n",
        "\n",
        "conf_name = 'neurips' ## required for api search\n",
        "topic_file_name = 'neurips_topics_2020_' # to store the result in a csv file\n",
        "file_name = 'neurips_trend_withRanking_2020_' # to store the result in a csv file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBa76Iuo8_Np"
      },
      "source": [
        "## Init"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7UHYkbG8_Nq"
      },
      "source": [
        "#Create lists to store the scraped data\n",
        "#type\ttitle\tauthors\tabstract\tcategory\tkeywords\turl\n",
        "\n",
        "sources = []\n",
        "urls = []\n",
        "titles = []\n",
        "summaries = []\n",
        "dates = []\n",
        "ratings = []\n",
        "bodies = []\n",
        "authors= []\n",
        "publishdate = []\n",
        "relatedlinks = []\n",
        "claims = []\n",
        "abstracts = []\n",
        "type_ = []\n",
        "MATCH_ALL = r'.*'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EF9qGTV8_Nq"
      },
      "source": [
        "## Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoGyXHnK8_Nr"
      },
      "source": [
        "def like(string):\n",
        "    \"\"\"\n",
        "    Return a compiled regular expression that matches the given\n",
        "    string with any prefix and postfix, e.g. if string = \"hello\",\n",
        "    the returned regex matches r\".*hello.*\"\n",
        "    \"\"\"\n",
        "    string_ = string\n",
        "    if not isinstance(string_, str):\n",
        "        string_ = str(string_)\n",
        "    regex = MATCH_ALL + re.escape(string_) + MATCH_ALL\n",
        "    return re.compile(regex, flags=re.DOTALL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snIYiBD28_Ns"
      },
      "source": [
        "def find_by_text(soup, text, tag, **kwargs):\n",
        "    \"\"\"\n",
        "    Find the tag in soup that matches all provided kwargs, and contains the\n",
        "    text.\n",
        "\n",
        "    If no match is found, return None.\n",
        "    If more than one match is found, raise ValueError.\n",
        "    \"\"\"\n",
        "    elements = soup.find_all(tag, **kwargs)\n",
        "    matches = []\n",
        "    for element in elements:\n",
        "        if element.find(text=like(text)):\n",
        "            matches.append(element)\n",
        "    if len(matches) == 0:\n",
        "        return None\n",
        "\n",
        "    return matches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2WsDarM8_Nt"
      },
      "source": [
        "def extract_claim_and_review(parsed_claim_review_page, url):\n",
        "        urls.append(url)\n",
        "        sources.append(\"washingtonpost\")\n",
        "\n",
        "        \n",
        "        # title\n",
        "        title = parsed_claim_review_page.find(\"h1\", {\"class\": \" font--headline gray-darkest pb-sm null \"})\n",
        "        #print(\"title\", title.text)\n",
        "        #soup = BeautifulSoup(title.text)\n",
        "        #print(\"title\", soup.text)\n",
        "        titles.append(title.text)\n",
        "        \n",
        "\n",
        "        # date\n",
        "        date_ = parsed_claim_review_page.find('div', {\"class\": \"display-date \"})#.find(\"p\")\n",
        "        #print(\"date_\", date_)\n",
        "        if date_:\n",
        "            date_str = search_dates(date_.text)[0][1].strftime(\"%Y-%m-%d\")\n",
        "            #print(\"url_date\", url_date)\n",
        "            dates.append(date_str)\n",
        "\n",
        "        # body\n",
        "        body = parsed_claim_review_page.find(\"div\", {\"class\": \"article-body\"})\n",
        "        #print(\"body=\", body.get_text())\n",
        "        #claim.set_body(body.get_text())\n",
        "        bodies.append(body.get_text())\n",
        "        \n",
        "\n",
        "        # related links\n",
        "        divTag = parsed_claim_review_page.find(\"div\", {\"class\": \"article-body\"})\n",
        "        related_links = []\n",
        "        for link in divTag.findAll('a', href=True):\n",
        "            related_links.append(link['href'])\n",
        "        relatedlinks.append(related_links)\n",
        "\n",
        "     \n",
        "        #claims\n",
        "        tags = []\n",
        "        for tag in parsed_claim_review_page.findAll('meta', {\"property\": \"article:tag\"}):\n",
        "            tags.append(tag[\"content\"])\n",
        "        claims.append(\", \".join(tags))\n",
        "       \n",
        "        return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNpm-NLV8_Ns"
      },
      "source": [
        " def extract_urls(parsed_listing_page):\n",
        "        urls = list()\n",
        "        titles = list()\n",
        "        authors = list()\n",
        "        # links = parsed_listing_page.find('ui').findAll('a', href=True)\n",
        "        # finding all li tags in ul and printing the text within it\n",
        "        body = parsed_listing_page.find(\"div\", {\"class\": \"col\"})\n",
        "        data1 = body.find('ul')\n",
        "        #print(data1)\n",
        "        for li in data1.findAll('a', href=True): \n",
        "            url = \"https://papers.nips.cc\" + str(li['href'])\n",
        "            max_claims = 0\n",
        "            if 0 < max_claims <= len(urls):\n",
        "                break\n",
        "            #if url not in self.configuration.avoid_urls:\n",
        "            urls.append(url)\n",
        "            titles.append(li.text)\n",
        "        soup = ''\n",
        "        for li in data1.findAll('i'): \n",
        "            #print(li)\n",
        "            soup = BeautifulSoup(li.text)\n",
        "            #print(soup.text)\n",
        "            authors.append(soup.text)\n",
        "            #break\n",
        "        return urls,titles,authors  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bj9_dMJA1Eqv"
      },
      "source": [
        "def extract_abstract(parsed_listing_page):\n",
        "    sources.append(\"neurips\")\n",
        "    type_.append(\"conference\")\n",
        "\n",
        "    abstracts = list()\n",
        "    body = parsed_listing_page.find(\"div\", {\"class\": \"col\"})\n",
        "    p_tags = body.find_all([\"p\"])\n",
        "    \n",
        "    if len(p_tags)>3:\n",
        "      #print(p_tags[3].text)\n",
        "      abstracts.append(p_tags[3].text)\n",
        "    else: \n",
        "      #print(p_tags)\n",
        "      abstracts.append(p_tags.text)\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhRPZCRTBRkL"
      },
      "source": [
        "abstracts = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9j7JjVMP7EpZ"
      },
      "source": [
        "def extract_abstract2(soup):\n",
        "    sources.append(\"neurips\")\n",
        "    type_.append(\"conference\")\n",
        "\n",
        "    #abstracts = list()\n",
        "    body = soup.find(\"div\", {\"class\": \"col\"})\n",
        "    p_tags = body.find_all([\"p\"])\n",
        "    \n",
        "    body = soup.find(\"div\", {\"class\": \"col\"})\n",
        "    #body\n",
        "    p_tags = body.find_all([\"p\"])\n",
        "\n",
        "    soup1=''\n",
        "    if len(p_tags)>=3:\n",
        "          #print(p_tags)\n",
        "          soup1 = BeautifulSoup(p_tags[2].text)\n",
        "          #print(soup1.text)\n",
        "          abstracts.append(soup1.text)\n",
        "    else: \n",
        "          #print(p_tags)\n",
        "          soup1 = BeautifulSoup(p_tags.text)\n",
        "          #print(soup1.text)\n",
        "          abstracts.append(soup1.text)\n",
        "          #print(p_tags)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqRHdbwu8_Nt"
      },
      "source": [
        "## 1.Scrape Urls [.scrapeURLs()]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQIm4l6-ujcE",
        "outputId": "a324c380-4e4f-437c-8a59-da8617336904"
      },
      "source": [
        "page_number = 2\n",
        "URL = 'https://papers.nips.cc/paper/2020'\n",
        "webpage = requests.get(URL)  #Make a request to the website\n",
        "soup = BeautifulSoup(webpage.text, \"html.parser\")\n",
        "#print(soup.prettify())\n",
        "\n",
        "extract_url,titles, authors = extract_urls(soup)\n",
        "extract_url"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['https://papers.nips.cc/paper/2020/hash/0004d0b59e19461ff126e3a08a814c33-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/00482b9bed15a272730fcb590ffebddd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0060ef47b12160b9198302ebdb144dcf-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/007ff380ee5ac49ffc34442f5c2a2b86-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0084ae4bc24c0795d1e6a4f58444d39b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/00a03ec6533ca7f5c644d198d815329c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/00ac8ed3b4327bdd4ebbebcb2ba10a00-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/00e26af6ac3b1c1c49d7c3d79c60d000-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/012a91467f210472fab4e11359bbfef6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/012d9fe15b2493f21902cd55603382ec-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0163cceb20f5ca7b313419c068abd9dc-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0169cf885f882efd795951253db5cdfb-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0172d289da48c48de8c5ebf3de9f7ee1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/019fa4fdf1c04cf73ba25aa2223769cd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/01a0683665f38d8e5e567b3b15ca98bf-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/01c9d2c5b3ff5cbba349ec39a570b5e3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/01e00f2f4bfcbb7505cb641066f2859b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/021bbc7ee20b71134d53e20206bd6feb-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/021f6dd88a11ca489936ae770e4634ad-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/022e0ee5162c13d9a7bb3bd00fb032ce-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/023d0a5671efd29e80b4deef8262e297-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/024d2d699e6c1a82c9ba986386f4d824-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/02a3c7fb3f489288ae6942498498db20-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/02e74f10e0327ad868d138f2b4fdd6f0-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/02ed812220b0705fabb868ddbf17ea20-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/02f657d55eaf1c4840ce8d66fcdaf90c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/03255088ed63354a54e0e5ed957e9008-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/03287fcce194dbd958c2ec5b33705912-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0332d694daab22e0e0eaf7a5e88433f9-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/033cc385728c51d97360020ed57776f0-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/03593ce517feac573fdaafa6dcedef61-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/03793ef7d06ffd63d34ade9d091f1ced-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/03fa2f7502f5f6b9169e67d17cbf51bb-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0415740eaa4d9decbc8da001d3fd805f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/045117b0e0a11a242b9765e79cbf113f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/04ecb1fa28506ccb6f72b12c0245ddbc-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/05128e44e27c36bdba71221bfccf735d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/051928341be67dcba03f0e04104d9047-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0561bc7ecba98e39ca7994f93311ba23-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/05a624166c8eb8273b8464e8d9cb5bd9-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/05e2a0647e260c355dd2b2175edb45b8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/05ee45de8d877c3949760a94fa691533-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/05f971b5ec196b8c65b75d2ef8267331-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0607f4c705595b911a4f3e7a127b44e0-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/061412e4a03c02f9902576ec55ebbe77-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0660895c22f8a14eb039bfb9beb0778f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0663a4ddceacb40b095eda264a85f15c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/066ca7bf90807fcd8e4f1eaef4e4e8f7-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/066f182b787111ed4cb65ed437f0855b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0678ca2eae02d542cc931e81b74de122-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/06964dce9addb1c5cb5d6e3d9838f733-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/06a9d51e04213572ef0720dd27a84792-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/06d5ae105ea1bea4d800bc96491876e9-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/070dbb6024b5ef93784428afc71f2146-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/07168af6cb0ef9f78dae15739dd73255-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/07211688a0869d995947a8fb11b215d6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/07217414eb3fbe24d4e5b6cafb91ca18-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0740bb92e583cd2b88ec7c59f985cb41-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/074177d3eb6371e32c16c55a3b8f706b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/075b051ec3d22dac7b33f788da631fd4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/07cb5f86508f146774a2fac4373a8e50-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/07fc15c9d169ee48573edd749d25945d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/08058bf500242562c0d031ff830ad094-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/08425b881bcde94a383cd258cea331be-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0887f1a5b9970ad13f46b8c1485f7900-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/08e5d8066881eab185d0de9db3b36c7f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/08f38e0434442128fab5ead6217ca759-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/08fa43588c2571ade19bc0fa5936e028-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/08fb104b0f2f838f3ce2d2b3741a12c2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0912d0f15f1394268c66639e39b26215-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/093b60fd0557804c8ba0cbf1453da22f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/093f65e080a295f8076b1c5722a46aa2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0987b8b338d6c90bbedd8631bc499221-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/098d86c982354a96556bd861823ebfbd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/099fe6b0b444c23836c4a5d07346082b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/09ccf3183d9e90e5ae1f425d5f9b2c00-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0a2298a72858d90d5c4b4fee954b6896-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0a3b6f64f0523984e51323fe53b8c504-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0a4dc6dae338c9cb08947c07581f77a2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0a5052334511e344f15ae0bfafd47a67-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0a656cc19f3f5b41530182a9e03982a4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0a716fe8c7745e51a3185fc8be6ca23a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0a73de68f10e15626eb98701ecf03adb-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0a93091da5efb0d9d5649e7f6b2ad9d7-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0afe095e81a6ac76ff3f69975cb3e7ae-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0b1ec366924b26fc98fa7b71a9c249cf-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0b5e29aa1acf8bdc5d8935d7036fa4f5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0b6ace9e8971cf36f1782aa982a708db-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0b8aff0438617c055eb55f0ba5d226fa-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0b96d81f0494fde5428c7aea243c9157-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0baf163c24ed14b515aaf57a9de5501c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0c0a7566915f4f24853fc4192689aa7e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0c7119e3a6a2209da6a5b90e5b5b75bd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0c72cb7ee1512f800abe27823a792d03-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0cb5ebb1b34ec343dfe135db691e4a85-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0cbc5671ae26f67871cb914d81ef8fc1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0cc24cb7c26586310cc95c8cb1a81cbc-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0cc6928e741d75e7a92396317522069e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0cc6ee01c82fc49c28706e0918f57e2d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0d2b2061826a5df3221116a5085a6052-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0d352b4d3a317e3eae221199fdb49651-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0d5501edb21a59a43435efa67f200828-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0d5bd023a3ee11c7abca5b42a93c4866-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0d770c496aa3da6d2c3f2bd19e7b9d6b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0d82627e10660af39ea7eb69c3568955-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0d85eb24e2add96ff1a7021f83c1abc9-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0dc23b6a0e4abc39904388dd3ffadcd1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0dd1bc593a91620daecf7723d2235624-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0e1bacf07b14673fcdb553da51b999a5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0e1ebad68af7f0ae4830b7ac92bc3c6f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0e230b1a582d76526b7ad7fc62ae937d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0e4ceef65add6cf21c0f3f9da53b71c0-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0e900ad84f63618452210ab8baae0218-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0ea6f098a59fcf2462afc50d130ff034-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0eac690d7059a8de4b48e90f14510391-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0ec96be397dd6d3cf2fecb4a2d627c1c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0ed9422357395a0d4879191c66f4faa2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0f0e13216262f4a201bec128044dd30f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0f34132b15dd02f282a11ea1e322a96d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0f34314d2dd0c1b9311cb8f40eb4f255-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0ff8033cf9437c213ee13937b1c4c455-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/0ffaca95e3e5242ba1097ad8a9a6e95d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1006ff12c465532f8c574aeaa4461b16-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1010cedf85f6a7e24b087e63235dc12e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/102f0bb6efb3a6128a3c750dd16729be-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/103303dd56a731e377d01f6a37badae3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1068bceb19323fe72b2b344ccf85c254-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1091660f3dff84fd648efe31391c5524-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/10c72a9d42dd07a028ee910f7854da5d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/10eb6500bd1e4a3704818012a1593cc3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/10fb6cfa4c990d2bad5ddef4f70e8ba2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1102a326d5f7c9e04fc3c89d0ede88c9-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/11348e03e23b137d55d94464250a67a2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1160453108d3e537255e9f7b931f4e90-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/118bd558033a1016fcc82560c65cca5f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/11953163dd7fb12669b41a48f78a29b6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/11958dfee29b6709f48a9ba0387a2431-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/11f38f8ecd71867b42433548d1078e38-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/122e27d57ae8ecb37f3f1da67abb33cb-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/123650dd0560587918b3d771cf0c0171-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/123b7f02433572a0a560e620311a469c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/12780ea688a71dabc284b064add459a4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/12b1e42dc0746f22cf361267de07073f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/12bcd658ef0a540cabc36cdf2b1046fd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/12d16adf4a9355513f9d574b76087a08-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/12ffb0968f2f56e51a59a6beb37b2859-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1325cdae3b6f0f91a1b629307bf2d498-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1349b36b01e0e804a6c2909a6d0ec72a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1359aa933b48b754a2f54adb688bfa77-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1373b284bc381890049e92d324f56de0-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1385974ed5904a438616ff7bdb3f7439-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/13b919438259814cd5be8cb45877d577-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/13d4635deccc230c944e4ff6e03404b5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/13e36f06c66134ad65f532e90d898545-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/13ec9935e17e00bed6ec8f06230e33a9-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/13f320e7b5ead1024ac95c3b208610db-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/13f3cf8c531952d72e5847c4183e6910-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/13fe9d84310e77f13a6d184dbf1232f3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/146f7dd4c91bc9d80cf4458ad6d6cd1b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1487987e862c44b91a0296cf3866387e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/149ef6419512be56a93169cd5e6fa8fd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/14da15db887a4b50efe5c1bc66537089-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/14faf969228fc18fcd4fcf59437b0c97-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/151d21647527d1079781ba6ae6571ffd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/15231a7ce4ba789d13b722cc5c955834-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1534b76d325a8f591b52d302e7181331-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/155fa09596c7e18e50b58eb7e0c6ccb4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/15825aee15eb335cc13f9b559f166ee8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/15ae3b9d6286f1b2a489ea4f3f4abaed-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/15bb63b28926cd083b15e3b97567bbea-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/16002f7a455a94aa4e91cc34ebdb9f2d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/165a59f7cf3b5c4396ba65953d679f17-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/16837163fee34175358a47e0b51485ff-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/168efc366c449fab9c2843e9b54e2a18-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/169806bb68ccbf5e6f96ddc60c40a044-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/16f8e136ee5693823268874e58795216-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/170f6aa36530c364b77ddf83a84e7351-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/171ae1bbb81475eb96287dd78565b38b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/17256f049f1e3fede17c7a313f7657f4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/17257e81a344982579af1ae6415a7b8c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/172ef5a94b4dd0aa120c6878fc29f70c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1730f69e6f66d5f0c741799e82351f81-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1731592aca5fb4d789c4119c65c10b4b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/174f8f613332b27e9e8a5138adb7e920-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1763ea5a7e72dd7ee64073c2dda7a7a8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1764183ef03fc7324eb58c3842bd9a57-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/176bf6219855a6eb1f3a30903e34b6fb-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/17b3c7061788dbe82de5abe9f6fe22b3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/17f98ddf040204eda0af36a108cbdea4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/18064d61b6f93dab8681a460779b8429-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1819020b02e926785cf3be594d957696-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/186b690e29892f137b4c34cfa40a3a4d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/187acf7982f3c169b3075132380986e4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1896a3bf730516dd643ba67b4c447d36-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/18a010d2a9813e91907ce88cd9143fdf-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/18a411989b47ed75a60ac69d9da05aa5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/18df51b97ccd68128e994804f3eccc87-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/18fc72d8b8aba03a4d84f66efabce82e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/191595dc11b4d6e54f01504e3aa92f96-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/192fc044e74dffea144f9ac5dc9f3395-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/193002e668758ea9762904da1a22337c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1943102704f8f8f3302c2b730728e023-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1959eb9d5a0f7ebc58ebde81d5df400d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1963bd5135521d623f6c29e6b1174975-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/196f5641aa9dc87067da4ff90fd81e7b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/19aa6c6fb4ba9fcf39e893ff1fd5b5bd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/19eca5979ccbb752778e6c5f090dc9b6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1a669e81c8093745261889539694be7f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1a77befc3b608d6ed363567685f70e1e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1aa3d9c6ce672447e1e5d0f1b5207e85-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1abb1e1ea5f481b589da52303b091cbb-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1ac978c8020be6d7212aa71d4f040fc3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1ae6464c6b5d51b363d7d96f97132c75-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1b0251ccb8bd5f9ccf444e4bda7713e3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1b113258af3968aaf3969ca67e744ff8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1b33d16fc562464579b7199ca3114982-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1b69ebedb522700034547abc5652ffac-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1b742ae215adf18b75449c6e272fd92d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1b84c4cee2b8b3d823b30e2d604b1878-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1b9a80606d74d3da6db2f1274557e644-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1ba922ac006a8e5f2b123684c2f4d65f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1bd413de70f32142f4a33a94134c5690-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1bd69c7df3112fb9a584fbd9edfc6c90-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1bda4c789c38754f639a376716c5859f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1c104b9c0accfca52ef21728eaf01453-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1c336b8080f82bcc2cd2499b4c57261d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1c383cd30b7c298ab50293adfecb7b18-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1cb524b5a3f3f82be4a7d954063c07e2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1cc8a8ea51cd0adddf5dab504a285915-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1cd138d0499a68f4bb72bee04bbec2d7-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1cdf14d1e3699d61d237cf76ce1c2dca-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1cf44d7975e6c86cffa70cae95b5fbb2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1cfa81af29c6f2d8cacb44921722e753-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1d8d70dddf147d2d92a634817f01b239-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1da546f25222c1ee710cf7e2f7a3ff0c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1dc3a89d0d440ba31729b0ba74b93a33-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1de7d2b90d554be9f0db1c338e80197d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1def1713ebf17722cbe300cfc1c88558-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1e04b969bf040acd252e1faafb51f829-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1e0b802d5c0e1e8434a771ba7ff2c301-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1e14bfe2714193e7af5abc64ecbd6b46-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1e591403ff232de0f0f139ac51d99295-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1e6e25d952a0d639b676ee20d0519ee2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1e7875cf32d306989d80c14308f3a099-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1e9491470749d5b0e361ce4f0b24d037-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1ea97de85eb634d580161c603422437f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1ee942c6b182d0f041a2312947385b23-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1ef91c212e30e14bf125e9374262401f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1f10c3650a3aa5912dccc5789fd515e8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1f1baa5b8edac74eb4eaa329f14a0361-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1f47cef5e38c952f94c5d61726027439-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1f89885d556929e98d3ef9b86448f951-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1f8d87e1161af68b81bace188a1ec624-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1fc214004c9481e4c8073e85323bfd4b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1fc30b9d4319760b04fab735fbfed9a9-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1fd09c5f59a8ff35d499c0ee25a1d47e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1fd6c4e41e2c6a6b092eb13ee72bce95-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/1fdc0ee9d95c71d73df82ac8f0721459-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2000f6325dfc4fc3201fc45ed01c7a5d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/20125fd9b2d43e340a35fb0278da235d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/201d7288b4c18a679e48b31c72c30ded-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/20479c788fb27378c2c99eadcf207e7f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2051bd70fc110a2208bdbd4a743e7f79-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/205e73579f21c2ed134dbd6ce7e4a1ea-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/20b02dc95171540bc52912baf3aa709d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/20b5e1cf8694af7a3c1ba4a87f073021-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/20c86a628232a67e7bd46f76fba7ce12-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/20d749bc05f47d2bd3026ce457dcfd8e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2109737282d2c2de4fc5534be26c9bb6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/211b39255232ab59ce78f2e28cd0292b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/212ab20dbdf4191cbcdcf015511783f4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/21327ba33b3689e713cdff1641128004-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/216f44e2d28d4e175a194492bde9148f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2172fde49301047270b2897085e4319d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/217eedd1ba8c592db97d0dbe54c7adfc-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/219e052492f4008818b8adb6366c7ed6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/21d144c75af2c3a1cb90441bbb7d8b40-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/222afbe0d68c61de60374b96f1d86715-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/227f6afd3b7f89b96c4bb91f95d50f6d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/228669109aa3ab1b4ec06b7722efb105-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2288f691b58edecadcc9a8691762b4fd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2290a7385ed77cc5592dc2153229f082-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/229aeb9e2ae66f2fac1149e5240b2fdd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/22bb543b251c39ccdad8063d486987bb-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/22eda830d1051274a2581d6466c06e6c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/22f791da07b0d8a2504c2537c560001c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/23378a2d0a25c6ade2c1da1c06c5213f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/234833147b97bb6aed53a8f4f1c7a7d8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/234b941e88b755b7a72a1c1dd5022f30-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/234e691320c0ad5b45ee3c96d0d7b8f8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/23685a2431acad7789c1e3d43ea1522c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/236f119f58f5fd102c5a2ca609fdcbd8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/23937b42f9273974570fb5a56a6652ee-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/23ad3e314e2a2b43b4c720507cec0723-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/23af4b45f1e166141a790d1a3126e77a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/240ac9371ec2671ae99847c3ae2e6384-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/24357dd085d2c4b1a88a7e0692e60294-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/24368c745de15b3d2d6279667debcba3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/24389bfe4fe2eba8bf9aa9203a44cdad-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/243be2818a23c980ad664f30f48e5d19-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/244edd7e85dc81602b7615cd705545f5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/24aef8cb3281a2422a59b51659f1ad2e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/24bcb4d0caa4120575bb45c8a156b651-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/24bea84d52e6a1f8025e313c2ffff50a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/24f2f931f12a4d9149876a5bef93e96a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2517756c5a9be6ac007fe9bb7fb92611-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/258be18e31c8188555c2ff05b4d542c3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/25ddc0f8c9d3e22e03d3076f98d83cb2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/26178fc759d2b89c45dd31962f81dc61-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/26588e932c7ccfa1df309280702fe1b5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/26b58a41da329e0cbde0cbf956640a58-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/26d88423fc6da243ffddf161ca712757-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/26ed695e9b7b9f6463ef4bc1fd74fc87-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/27059a11c58ade9b03bde05c2ca7c285-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/272e11700558e27be60f7489d2d782e7-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/274e6fcf4a583de4a81c6376f17673e7-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/275d7fb2fd45098ad5c3ece2ed4a2824-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2779fda014fbadb761f67dd708c1325e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2794f6a20ee0685f4006210f40799acd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/27b587bbe83aecf9a98c8fe6ab48cacc-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/27d8d40b22f812a1ba6c26f8ef7df480-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/27e9661e033a73a6ad8cefcde965c54d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/28538c394c36e4d5ea8ff5ad60562a93-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/285baacbdf8fda1de94b19282acd23e2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/285f89b802bcb2651801455c86d78f2a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/288cd2567953f06e460a33951f55daaf-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/28a7602724ba16600d5ccc644c19bf18-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/28e209b61a52482a0ae1cb9f5959c792-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/28f248e9279ac845995c4e9f8af35c2b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/291597a100aadd814d197af4f4bab3a7-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/291dbc18539ba7e19b8abb7d85aa204e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/293835c2cc75b585649498ee74b395f5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/29405e2a4c22866a205f557559c7fa4b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/294e09f267683c7ddc6cc5134a7e68a8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2952351097998ac1240cb2ab7333a3d2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/29539ed932d32f1c56324cded92c07c2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/29586cb449c90e249f1f09a0a4ee245a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2974788b53f73e7950e8aa49f3a306db-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/299dc35e747eb77177d9cea10a802da2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/29a6aa8af3c942a277478a90aa4cae21-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/29c0605a3bab4229e46723f89cf59d83-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/29e48b79ae6fc68e9b6480b677453586-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2a084e55c87b1ebcdaad1f62fdbbac8e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2a27b8144ac02f67687f76782a3b5d8f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2adcfc3929e7c03fac3100d3ad51da26-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2adee8815dd939548ee6b2772524b6f2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2b346a0aa375a07f5a90a344a61416c4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2b64c2f19d868305aa8bbc2d72902cc5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2ba596643cbbbc20318224181fa46b28-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2ba61cc3a8f44143e1f2f13b2b729ab3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2bba9f4124283edd644799e0cecd45ca-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2be5f9c2e3620eb73c2972d7552b6cb5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2c29d89cc56cdb191c60db2f0bae796b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2c5201a7391fedbc40c3cc6aa057a029-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2c6a0bae0f071cbbf0bb3d5b11d90a82-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2c75cf2681788adaca63aa95ae028b22-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2cb274e6ce940f47beb8011d8ecb1462-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2cd2915e69546904e4e5d4a2ac9e1652-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2cd4e8a2ce081c3d7c32c3cde4312ef7-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2cfa3753d6a524711acb5fce38eeca1a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2cfa8f9e50e0f510ede9d12338a5f564-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2d16ad1968844a4300e9a490588ff9f8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2df45244f09369e16ea3f9117ca45157-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2dfe1946b3003933b7f8ddd71f24dbb1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2e1b24a664f5e9c18f407b2f9c73e821-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2e255d2d6bf9bb33030246d31f1a79ca-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2e2c4bf7ceaa4712a72dd5ee136dc9a8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2e6d9c6052e99fcdfa61d9b9da273ca2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2e85d72295b67c5b649290dfbf019285-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2f10c1578a0706e06b6d7db6f0b4a6af-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2f2b265625d76a6704b08093c652fd79-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2f380b99d45812a211da102c04dc1ddb-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2f3bbb9730639e9ea48f309d9a79ff01-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2f73168bf3656f697507752ec592c437-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/2fd5d41ec6cfab47e32164d5624269b1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3000311ca56a1cb93397bc676c0b7fff-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/300891a62162b960cf02ce3827bb363c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/305ddad049f65a2c241dbb6e6f746c54-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/309fee4e541e51de2e41f21bebb342aa-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/30da227c6b5b9e2482b6b221c711edfd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/30de24287a6d8f07b37c716ad51623a7-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/30de9ece7cf3790c8c39ccff1a044209-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/30ee748d38e21392de740e2f9dc686b6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/30f0641c041f03d94e95a76b9d8bd58f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/310614fca8fb8e5491295336298c340f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/310cc7ca5a76a446f85c1a0d641ba96d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/313f422ac583444ba6045cd122653b0e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/31784d9fc1fa0d25d04eae50ac9bf787-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3181d59d19e76e902666df5c7821259a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/31fefc0e570cb3860f2a6d4b38c6490d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3202111cf90e7c816a472aaceb72b0df-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3214a6d842cc69597f9edf26df552e43-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/322f62469c5e3c7dc3e58f5a4d1ea399-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/32508f53f24c46f685870a075eaaa29c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3261769be720b0fefbfffec05e9d9202-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/328e5d4c166bb340b314d457a208dc83-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3295c76acbf4caaed33c36b1b5fc2cb1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/32bb90e8976aab5298d5da10fe66f21d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/32cfdce9631d8c7906e8e9d6e68b514b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/32e54441e6382a7fbacbbbaf3c450059-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/32fcc8cfe1fa4c77b5c58dafd36d1a98-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/331316d4efb44682092a006307b9ae3a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3341f6f048384ec73a7ba2e77d2db48b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/335cd1b90bfa4ee70b39d08a4ae0cf2d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/339a18def9898dd60a634b2ad8fbbd58-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/33a5435d4f945aa6154b31a73bab3b73-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/33a854e247155d590883b93bca53848a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/33c5f5bff65aa05a8cd3e5d2597f44ae-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/33cc2b872dfe481abef0f61af181dfcf-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/33cf42b38bbcf1dd6ba6b0f0cd005328-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/33d3b157ddc0896addfb22fa2a519097-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/33dd6dba1d56e826aac1cbf23cdcca87-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/33e75ff09dd601bbe69f351039152189-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/342285bb2a8cadef22f667eeb6a63732-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/342c472b95d00421be10e9512b532866-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3430095c577593aad3c39c701712bcfe-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/34609bdc08a07ace4e1526bbb1777673-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3465ab6e0c21086020e382f09a482ced-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3472ab80b6dff70c54758fd6dfc800c2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3493894fa4ea036cfc6433c3e2ee63b0-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3501672ebc68a5524629080e3ef60aef-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/350a7f5ee27d22dbe36698b10930ff96-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/35464c848f410e55a13bb9d78e7fddd0-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/354ac345fd8c6d7ef634d9a8e3d47b83-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/356dc40642abeb3a437e7e06f178701c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/357a6fdf7642bf815a88822c447d9dc4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/35adf1ae7eb5734122c84b7a9ea5cc13-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/36ac8e558ac7690b6f44e2cb5ef93322-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/36dcd524971019336af02550264b8a08-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/373e4c5d8edfa8b74fd4b6791d0cf6dc-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/37693cfc748049e45d87b8c7d8b9aacd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/37740d59bb0eb7b4493725b2e0e5289b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/37aa5dfc44dddd0d19d4311e2c7a0240-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/37bc5e7fb6931a50b3464ec66179085f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/37d097caf1299d9aa79c2c2b843d2d78-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/37e7897f62e8d91b1ce60515829ca282-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/37e79373884f0f0b70b5cb91fb947148-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/37f76c6fe3ab45e0cd7ecb176b5a046d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3812f9a59b634c2a9c574610eaba5bed-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/385822e359afa26d52b5b286226f2cea-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/386854131f58a556343e056f03626e00-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/38a77aa456fc813af07bb428f2363c8d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/38a8e18d75e95ca619af8df0da1417f2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/39016cfe079db1bfb359ca72fcba3fd8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3948ead63a9f2944218de038d8934305-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/397d6b4c83c91021fe928a8c4220386b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/39d0a8908fbe6c18039ea8227f827023-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/39d4b545fb02556829aab1db805021c3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3a01fc0853ebeba94fde4d1cc6fb842a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3a029f04d76d32e79367c4b3255dda4d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3a0772443a0739141292a5429b952fe6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3a077e8acfc4a2b463c47f2125fdfac5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3a30be93eb45566a90f4e95ee72a089a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3a37abdeefe1dab1b30f7c5c7e581b93-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3a4496776767aaa99f9804d0905fe584-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3a61ed715ee66c48bacf237fa7bb5289-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3a93a609b97ec0ab0ff5539eb79ef33a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3ab6be46e1d6b21d59a3c3a0b9d0f6ef-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3ac48664b7886cf4e4ab4aba7e6b6bc9-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3acb2a202ae4bea8840224e6fce16fd0-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3ad7c2ebb96fcba7cda0cf54a2e802f5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3b13b1eb44b05f57735764786fab9c2c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3b2acfe2e38102074656ed938abf4ac3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3bb585ea00014b0e3ebe4c6dd165a358-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3be0214185d6177a9aa6adea5a720b09-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3c09bb10e2189124fdd8f467cc8b55a7-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3c0de3fec9ab8a3df01109251f137119-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3c56fe2f24038c4d22b9eb0aca78f590-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3c8f9a173f749710d6377d3150cf90da-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3cc697419ea18cc98d525999665cb94a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3ce3bd7d63a2c9c81983cc8e9bd02ae5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3d2d8ccb37df977cb6d9da15b76c3f3a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3d8e03e8b133b16f13a586f0c01b6866-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3d9dabe52805a1ea21864b09f3397593-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3db54f5573cd617a0112d35dd1e6b1ef-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3def184ad8f4755ff269862ea77393dd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3df80af53dce8435cf9ad6c3e7a403fd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3e5190eeb51ebe6c5bbc54ee8950c548-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3e91970f771a2c473ae36b60d1146068-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3eb46aa5d93b7a5939616af91addfa88-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3f13cf4ddf6fc50c0d39a1d5aeb57dd8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3f1656d9668dffcf8119e3ecff873558-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3f2dff7862a70f97a59a1fa02c3ec110-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3f8b2a81da929223ae025fcec26dde0d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3fb04953d95a94367bb133f862402bce-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3fe230348e9a12c13120749e3f9fa4cd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3fe78a8acf5fda99de95303940a2420c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/3fe94a002317b5f9259f82690aeea4cd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/405075699f065e43581f27d67bb68478-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/412604be30f701b1b1e3124c252065e6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/415e1af7ea95f89f4e375162b21ae38c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4175a4b46a45813fccf4bd34c779d817-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/417fbbf2e9d5a28a855a11894b2e795a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/418db2ea5d227a9ea8db8e5357ca2084-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/41c542dfe6e4fc3deb251d64cf6ed2e4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/41d80bfc327ef980528426fc810a6d7a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/41e7637e7b6a9f27a98b84d3a185c7c0-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/42299f06ee419aa5d9d07798b56779e2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/426f990b332ef8193a61cc90516c1245-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/42ae1544956fbe6e09242e6cd752444c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/42cd63cb189c30ed03e42ce2c069566c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4311359ed4969e8401880e3c1836fbe1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/43207fd5e34f87c48d584fc5c11befb8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4324e8d0d37b110ee1a4f1633ac52df5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4379cf00e1a95a97a33dac10ce454ca4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/438124b4c06f3a5caffab2c07863b617-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/439d8c975f26e5005dcdbf41b0d84161-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/439fca360bc99c315c5882c4432ae7a4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/43a7c24e2d1fe375ce60d84ac901819f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/43bb733c1b62a5e374c63cb22fa457b4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/43e4e6a6f341e00671e123714de019a8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/440924c5948e05070663f88e69e8242b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/440e7c3eb9bbcd4c33c3535354a51605-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/443dec3062d0286986e21dc0631734c9-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/445e1050156c6ae8c082a8422bb7dfc0-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/448d5eda79895153938a8431919f4c9f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4491777b1aa8b5b32c2e8666dbe1a495-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4496bf24afe7fab6f046bf4923da8de6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/44bf89b63173d40fb39f9842e308b3f9-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/44e76e99b5e194377e955b13fb12f630-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/44ece762ae7e41e3a0b1301488907eaa-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/44f683a84163b3523afe57c2e008bc8c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/44feb0096faa8326192570788b38c1d1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/456048afb7253926e1fbb7486e699180-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/45713f6ff2041d3fdfae927b82488db8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/45c166d697d65080d54501403b433256-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/45f31d16b1058d586fc3be7207b58053-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/45fbc6d3e05ebd93369ce542e8f2322d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/460191c72f67e90150a093b4585e7eb4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4607f7fff0dce694258e1c637512aa9d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/464074179972cbbd75a39abc6954cd12-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/46489c17893dfdcf028883202cefd6d1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/46a4378f835dc8040c8057beb6a2da52-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/473803f0f2ebd77d83ee60daaa61f381-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/475d66314dc56a0df8fb8f7c5dbbaf78-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/477bdb55b231264bb53a7942fd84254d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/47951a40efc0d2f7da8ff1ecbfde80f4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/47a3893cc405396a5c30d91320572d6d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/47a658229eb2368a99f1d032c8848542-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/47ce0875420b2dbacfc5535f94e68433-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/47d40767c7e9df50249ebfd9c7cfff77-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/47fd3c87f42f55d4b233417d49c34783-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/481d462e46c2ab976294271a175b8929-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/481fbfa59da2581098e841b7afc122f1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/48237d9f2dea8c74c2a72126cf63d933-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/483101a6bc4e6c46a86222eb65fbcb6a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/488e4104520c6aab692863cc1dba45af-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/48db71587df6c7c442e5b76cc723169a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/48e59000d7dfcf6c1d96ce4a603ed738-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/48f7d3043bc03e6c48a6f0ebc0f258a8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/490640b43519c77281cb2f8471e61a71-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/492114f6915a69aa3dd005aa4233ef51-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/49562478de4c54fafd4ec46fdb297de5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/497476fe61816251905e8baafdf54c23-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/49856ed476ad01fcff881d57e161d73f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/49ca03822497d26a3943d5084ed59130-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/49f85a9ed090b20c8bed85a5923c669f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4a4526b1ec301744aba9526d78fcb2a6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4a46fbfca3f1465a27b210f4bdfe6ab3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4a5876b450b45371f6cfe5047ac8cd45-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4a5cfa9281924139db466a8a19291aff-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4aaa76178f8567e05c8e8295c96171d8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4afd521d77158e02aed37e2274b90c9c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4b0091f82f50ff7095647fe893580d60-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4b21cf96d4cf612f239a6c322b10c8fe-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4b29fa4efe4fb7bc667c7b301b74d52d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4b86ca48d90bd5f0978afa3a012503a4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4bb236de7787ceedafdff83bb8ea4710-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4be2c8f27b8a420492f2d44463933eb6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4bfbd52f4e8466dc12aaf30b7e057b66-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4c2e5eaae9152079b9e95845750bb9ab-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4c5bcfec8584af0d967f1ab10179ca4b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4cc05b35c2f937c5bd9e7d41d3686fff-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4cc5400e63624c44fadeda99f57588a6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4cea2358d3cc5f8cd32397ca9bc51b94-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4d410063822cd9be28f86701c0bc3a31-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4d771504ddcd28037b4199740df767e6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4d7e0d72898ae7ea3593eb5ebf20c744-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4d95d05a4fc4eadbc3b9dde67afdca39-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4db73860ecb5533b5a6c710341d5bbec-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4dbf29d90d5780cab50897fb955e4373-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4dc3ed26a29c9c3df3ec373524377a5b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4dd9cec1c21bc54eecb53786a2c5fa09-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4dea382d82666332fb564f2e711cbc71-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4df5bde009073d3ef60da64d736724d6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4e0928de075538c593fbdabb0c5ef2c3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4e668929edb3bf915e1a3a9d96c3c97e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4eab60e55fe4c7dd567a0be28016bff3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4eb7d41ae6005f60fe401e56277ebd4e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4ebd440d99504722d80de606ea8507da-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4ecb679fd35dcfd0f0894c399590be1a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4ee78d4122ef8503fe01cdad3e9ea4ee-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4ef2f8259495563cb3a8ea4449ec4f9f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4ef42b32bccc9485b10b8183507e5d82-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4eff0720836a198b6174eecf02cbfdbf-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4f00921114932db3f8662a41b44ee68f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4f20f7f5d2e7a1b640ebc8244428558c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4f87658ef0de194413056248a00ce009-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4fbe073f17f161810fdf3dab1307b30f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/4fc28b7093b135c21c7183ac07e928a6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5034a5d62f91942d2a7aeaf527dfe111-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/50905d7b2216bfeccb5b41016357176b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/50c1f44e426560f3f2cdcb3e19e39903-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/50cf0fe63e0ff857e1c9d01d827267ca-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/510f2318f324cf07fce24c3a4b89c771-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/51200d29d1fc15f5a71c1dab4bb54f7c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/512c5cad6c37edb98ae91c8a76c3a291-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/51311013e51adebc3c34d2cc591fefee-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5133aa1d673894d5a05b9d83809b9dbe-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/517f24c02e620d5a4dac1db388664a63-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/518a38cc9a0173d0b2dc088166981cf8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/51cdbd2611e844ece5d80878eb770436-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/51f4efbfb3e18f4ea053c4d3d282c4e2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5227fa9a19dce7ba113f50a405dcaf09-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/524f141e189d2a00968c3d48cadd4159-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5265d33c184af566aeb7ef8afd0b9b03-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/52aaa62e71f829d41d74892a18a11d59-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/52cf49fea5ff66588408852f65cf8272-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/52d2752b150f9c35ccb6869cbf074e48-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/52f4691a4de70b3c441bca6c546979d9-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5301c4d888f5204274439e6dcf5fdb54-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/531d29a813ef9471aad0a5558d449a73-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/537d9b6c927223c796cac288cced29df-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/53c04118df112c13a8c34b38343b9c10-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/53c5b2affa12eed84dfec9bfd83550b1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/54391c872fe1c8b4f98095c5d6ec7ec7-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/543e83748234f7cbab21aa0ade66565f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/54e0e46b6647aa736c13ef9d09eab432-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/54f3bc04830d762a3b56a789b6ff62df-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/55053683268957697aa39fba6f231c68-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/551fdbb810aff145c114b93867dd8bfd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/55479c55ebd1efd3ff125f1337100388-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/555d6702c950ecb729a966504af0a635-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/55d491cf951b1b920900684d71419282-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5607fe8879e4fd269e88387e8cb30b7e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/564127c03caab942e503ee6f810f54fd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/56577889b3c1cd083b6d7b32d32f99d5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/565e8a413d0562de9ee4378402d2b481-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/566f0ea4f6c2e947f36795c8f58ba901-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/567b8f5f423af15818a068235807edc0-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/569ff987c643b4bedf504efda8f786c2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/56dc0997d871e9177069bb472574eb29-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/56f9f88906aebf4ad985aaec7fa01313-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/572201a4497b0b9f02d4f279b09ec30d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5763abe87ed1938799203fb6e8650025-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5781a2637b476d781eb3134581b32044-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/57cd30d9088b0185cf0ebca1a472ff1d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/57e5cb96e22546001f1d6520ff11d9ba-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/588cb956d6bbe67078f29f8de420a13d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5898d8095428ee310bf7fa3da1864ff7-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/58ae23d878a47004366189884c2f8440-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/58c54802a9fb9526cd0923353a34a7ae-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5938b4d054136e5d59ada6ec9c295d7a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/593906af0d138e69f49d251d3e7cbed0-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/595373f017b659cb7743291e920a8857-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/59587bffec1c7846f3e34230141556ae-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/597c7b407a02cc0a92167e7a371eca25-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/59a3adea76fadcb6dd9e54c96fc155d1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/59accb9fe696ce55e28b7d23a009e2d1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5a01f0597ac4bdf35c24846734ee9a76-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5a16bce575f3ddce9c819de125ba0029-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5a29503a4909fcade36b1823e7cebcf5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5a378f8490c8d6af8647a753812f6e31-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5a5eab21ca2a8fef4af5e35709ecca15-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5a66b9200f29ac3fa0ae244cc2a51b39-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5a751d6a0b6ef05cfe51b86e5d1458e6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5a7b238ba0f6502e5d6be14424b20ded-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5b0fa0e4c041548bb6289e15d865a696-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5b8e9841e87fb8fc590434f5d933c92c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5bca8566db79f3788be9efd96c9ed70d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5bce843dd76db8c939d5323dd3e54ec9-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5bd844f11fa520d54fa5edec06ea2507-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5bf8aaef51c6e0d363cbe554acaf3f20-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5c3b99e8f92532e5ad1556e53ceea00c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5c528e25e1fdeaf9d8160dc24dbf4d60-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5c9452254bccd24b8ad0bb1ab4408ad1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5ca359ab1e9e3b9c478459944a2d9ca5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5ca41a86596a5ed567d15af0be224952-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5cb0e249689cd6d8369c4885435a56c2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5cc3749a6e56ef6d656735dff9176074-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5cc4bb753030a3d804351b2dfec0d8b5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5cd5058bca53951ffa7801bcdf421651-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5d0cb12f8c9ad6845110317afc6e2183-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5d0d5594d24f0f955548f0fc0ff83d10-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5d151d1059a6281335a10732fc49620e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5d40954183d62a82257835477ccad3d2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5d44ee6f2c3f71b73125876103c8f6c4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5d79099fcdf499f12b79770834c0164a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5d97f4dd7c44b2905c799db681b80ce0-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5dbc8390f17e019d300d5a162c3ce3bc-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5de8a36008b04a6167761fa19b61aa6c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5df0385cba256a135be596dbe28fa7aa-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5e1b18c4c6a6d31695acbae3fd70ecc6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5e5dd00d770ef3e9154a4257edcb80b8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5e98d23afe19a774d1b2dcbefd5103eb-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5ef20b89bab8fed38253e98a12f26316-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5f0ad4db43d8723d18169b2e4817a160-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5f14615696649541a025d3d0f8e0447f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5f268dfb0fbef44de0f668a022707b86-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5f7695debd8cde8db5abcb9f161b49ea-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5f8b73c0d4b1bf60dd7173b660b87c29-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/5fb37d5bbdbbae16dea2f3104d7f9439-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/60495b4e033e9f60b32a6607b587aadd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/604b37ea63ea51fa5fb3d8a89ec056e6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/604f2c31e67034642b288d76a8df11d5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/607bc9ebe4abfcd65181bfbef6252830-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/609a199881ca4ba9c95688235cd6ac5c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/609c5e5089a9aa967232aba2a4d03114-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/609e9d4bcc8157c00808993f612f1acd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/60a70bb05b08d6cd95deb3bdb750dce8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/60cb558c40e4f18479664069d9642d5a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/60e1deb043af37db5ea4ce9ae8d2c9ea-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6101903146e4bbf4999c449d78441606-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/618491e20a9b686b79e158c293ab4f91-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/618790ae971abb5610b16c826fb72d01-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/61a10e6abb1149ad9d08f303267f9bc4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/61c66a2f4e6e10dc9c16ddf9d19745d6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/61d77652c97ef636343742fc3dcf3ba9-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/62000dee5a05a6a71de3a6127a68778a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6217b2f7e4634fa665d31d3b4df81b56-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/62326dc7c4f7b849d6f013ba46489d6c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6244b2ba957c48bc64582cf2bcec3d04-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6271faadeedd7626d661856b7a004e27-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6275d7071d005260ab9d0766d6df1145-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/62d75fb2e3075506e8837d8f55021ab1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/62da5a6d47be0029801ba74a17e47e1a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/62db9e3397c76207a687c360e0243317-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/630eff1b380505a67570dff952ce4ad7-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/631e9c01c190fc1515b9fe3865abbb15-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/634841a6831464b64c072c8510c7f35c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/636efd4f9aeb5781e9ea815cdd633e52-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/63c17d596f401acb520efe4a2a7a01ee-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/63c3ddcc7b23daa1e42dc41f9a44a873-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/63d5fb54a858dd033fe90e6e4a74b0f0-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/63f44623dd8686aba388944c8810087f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/641d77dd5271fca28764612a028d9c8e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/645e6bfdd05d1a69c5e47b20f0a91d46-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/64714a86909d401f8feb83e8c2d94b23-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6495cf7ca745a9443508b86951b8e33a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/64986d86a17424eeac96b08a6d519059-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/649d45bf179296e31731adfd4df25588-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/64a08e5f1e6c39faeb90108c430eb120-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/64dcf3c521a00dbb4d2a10a27a95a9d8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/652c208b21f13f6e995bfc1154a1a2e5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6547884cea64550284728eb26b0947ef-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/65586803f1435736f42a541d3a924595-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/657b96f0592803e25a4f07166fff289a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/65a99bb7a3115fdede20da98b08a370f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/65ae450c5536606c266f49f1c08321f2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/65cf25ef90de99d93fa96dc49d0d8b3c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/66121d1f782d29b62a286909165517bc-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/661b1e76b95cc50a7a11a85619a67d95-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/662a2e96162905620397b19c9d249781-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6646b06b90bd13dabc11ddba01270d23-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/665d5cbb82b5785d9f344c46417c6c36-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/66de6afdfb5fb3c21d0e3b5c3226bf00-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/670c26185a3783678135b4697f7dbd1a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/672cf3025399742b1a047c8dc6b1e992-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6734fa703f6633ab896eecbdfad8953a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/673de96b04fa3adcae1aacda704217ef-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6740526b78c0b230e41ae61d8ca07cf5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6754e06e46dfa419d5afe3c9781cecad-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/67d16d00201083a2b118dd5128dd6f59-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/67e235e7f2fa8800d8375409b566e6b6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/67ff32d40fb51f1a2fd2c4f1b1019785-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/680390c55bbd9ce416d1d69a9ab4760d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6811f9b2bf86bf64e3f320973119b959-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6822951732be44edf818dc5a97d32ca6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/685ac8cadc1be5ac98da9556bc1c8d9e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/685bfde03eb646c27ed565881917c71c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/68a9750337a418a86fe06c1991a1d64c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/68ce199ec2c5517597ce0a4d89620f55-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/68d3743587f71fbaa5062152985aff40-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/68dd09b9ff11f0df5624a690fe0f6729-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/690d83983a63aa1818423fd6edd3bfdb-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/690f44c8c2b7ded579d01abe8fdb6110-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/691dcb1d65f31967a874d18383b9da75-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6925f2a16026e36e4fc112f82dd79406-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6933b5648c59d618bbb30986c84080fe-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6950aa02ae8613af620668146dd11840-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/69bfa2aa2b7b139ff581a806abf0a886-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/69d1fc78dbda242c43ad6590368912d4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/69eba34671b3ef1ef38ee85caae6b2a1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6a508a60aa3bf9510ea6acb021c94b48-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6a61d423d02a1c56250dc23ae7ff12f3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6aaba9a124857622930ca4e50f5afed2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6abba5d8ab1f4f32243e174beb754661-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6ad4174eba19ecb5fed17411a34ff5e6-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6affee954d76859baa2800e1c49e2c5d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6b39183e7053a0106e4376f4e9c5c74d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6b493230205f780e1bc26945df7481e5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6b5617315c9ac918215fc7514bef514b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6b8b8e3bd6ad94b985c1b1f1b7a94cb2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6ba3af5d7b2790e73f0de32e5c8c1798-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6bb56208f672af0dd65451f869fedfd9-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6c1e55ec7c43dc51a37472ddcbd756fb-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6c250b592dc94d4de38a79db4d2b18f2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6c81c83c4bd0b58850495f603ab45a93-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6cd9313ed34ef58bad3fdd504355e72c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6ce8d8f3b038f737cefcdafcf3752452-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6cfe0e6127fa25df2a0ef2ae1067d915-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6d0c932802f6953f70eb20931645fa40-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6d34d468ac8876333c4d7173b85efed9-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6d70cb65d15211726dcce4c0e971e21c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6d79e030371e47e6231337805a7a2685-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6d7d394c9d0c886e9247542e06ebb705-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6dbbe6abe5f14af882ff977fc3f35501-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6dd4e10e3296fa63738371ec0d5df818-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6df182582740607da754e4515b70e32d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6dfe08eda761bd321f8a9b239f6f4ec3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6e01383fd96a17ae51cc3e15447e7533-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6e17a5fd135fcaf4b49f2860c2474c7c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6e69ebbfad976d4637bb4b39de261bf7-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6ef1173b096aa200158bfbc8af3ae8e3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6f1d0705c91c2145201df18a1a0c7345-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6f2268bd1d3d3ebaabb04d6b5d099425-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6f3a770e5af1fd4cadc5f004b81e1040-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6f5216f8d89b086c18298e043bfe48ed-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6f5e4e86a87220e5d361ad82f1ebc335-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6fbd841e2e4b2938351a4f9b68f12e6b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6fd86e0ad726b778e37cf270fa0247d7-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6fd9a99a5abed788d9afc9d52d54e91b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6fe43269967adbb64ec6149852b5cc3e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/6fec24eac8f18ed793f5eaad3dd7977c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/703957b6dd9e3a7980e040bee50ded65-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/70431e77d378d760c3c5456519f06efe-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7078971350bcefbc6ec2779c9b84a9bd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/70d85f35a1fdc0ab701ff78779306407-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/70feb62b69f16e0238f741fab228fec2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/712a3c9878efeae8ff06d57432016ceb-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7137debd45ae4d0ab9aa953017286b20-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/713fd63d76c8a57b16fc433fb4ae718a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7183145a2a3e0ce2b68cd3735186b1d5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/71a58e8cb75904f24cde464161c3e766-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/71c1806ca28b555c76650f52bb0d2810-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/71e9c6620d381d60196ebe694840aaaa-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7212a6567c8a6c513f33b858d868ff80-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7221e5c8ec6b08ef6d3f9ff3ce6eb1d1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/722caafb4825ef5d8670710fa29087cf-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/723e8f97fde15f7a8d5ff8d558ea3f16-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7250eb93b3c18cc9daa29cf58af7a004-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7261925973c9bf0a74d85ae968a57e5f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7288251b27c8f0e73f4d7f483b06a785-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/72ab54f9b8c11fae5b923d7f854ef06a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/72b32a1f754ba1c09b3695e0cb6cde7f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/72e6d3238361fe70f22fb0ac624a7072-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/731309c4bb223491a9f67eac5214fb2e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/731c83db8d2ff01bdc000083fd3c3740-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/735ddec196a9ca5745c05bec0eaa4bf9-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/73634c1dcbe056c1f7dcf5969da406c8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/73740ea85c4ec25f00f9acbd859f861d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/738a6457be8432bab553e21b4235dd97-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/73a427badebe0e32caa2e1fc7530b7f3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/73b817090081cef1bca77232f4532c5d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/73d02e4344f71a0b0d51a925246990e7-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/73f95ee473881dea4afd89c06165fa66-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/747c1bcceb6109a4ef936bc70cfe67de-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/747d3443e319a22747fbb873e8b2f9f2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/747e32ab0fea7fbd2ad9ec03daa3f840-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/74dbd1111727a31a2b825d615d80b2e7-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/74de5f915765ea59816e770a8e686f38-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7503cfacd12053d309b6bed5c89de212-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7504adad8bb96320eb3afdd4df6e1f60-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/751d51528afe5e6f7fe95dece4ed32ba-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/751f6b6b02bf39c41025f3bcfd9948ad-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7520fa31d14f45add6d61e52df5a03ff-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/753a043674f0193523abc1bbce678686-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/75800f73fa80f935216b8cfbedf77bfa-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/75877cb75154206c4e65e76b88a12712-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/75a7c30fc0063c4952d7eb044a3c0897-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/75c58d36157505a600e0695ed0b3a22d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/75df63609809c7a2052fdffe5c00a84e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/75ebb02f92fc30a8040bbd625af999f1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7612936dcc85282c6fa4dd9d4ffe57f1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/766d856ef1a6b02f93d894415e6bfa0e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/766e428d1e232bbdd58664b41346196c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/768e78024aa8fdb9b8fe87be86f64745-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/769c3bce651ce5feaa01ce3b75986420-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/76cf99d3614e23eabab16fb27e944bf9-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/76dc611d6ebaafc66cc0879c71b5db5c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/770f8e448d07586afbf77bb59f698587-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/77133be2e96a577bd4794928976d2ae2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/77305c2f862ad1d353f55bf38e5a5183-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/77330e1330ae2b086e5bfcae50d9ffae-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/774412967f19ea61d448977ad9749078-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/778609db5dc7e1a8315717a9cdd8fd6f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/780261c4b9a55cd803080619d0cc3e11-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/781397bc0630d47ab531ea850bddcf63-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/781877bda0783aac5f1cf765c128b437-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/786ab8c4d7ee758f80d57e65582e609d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/78719f11fa2df9917de3110133506521-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7880d7226e872b776d8b9f23975e2a3d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/788d986905533aba051261497ecffcbb-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/789ba2ae4d335e8a2ad283a3f7effced-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/78f7d96ea21ccae89a7b581295f34135-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7967cc8e3ab559e68cc944c44b1cf3e8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/798d1c2813cbdf8bcdb388db0e32d496-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/79a3308b13cd31f096d8a4a34f96b66b-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/79f56e5e3e0e999b3c139f225838d41f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7a006957be65e608e863301eb98e1808-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7a1d9028a78f418cb8f01909a348d9b2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7a22c0c0a4515485e31f95fd372050c9-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7a43ed4e82d06a1e6b2e88518fb8c2b0-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7a53928fa4dd31e82c6ef826f341daec-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7a674153c63cff1ad7f0e261c369ab2c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7a677bb4477ae2dd371add568dd19e23-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7a685d9edd95508471a9d3d6fcace432-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7a6a74cbe87bc60030a4bd041dd47b78-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7a8b8402b2f0fc78cf726ee484a0a2b7-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7a9a322cbe0d06a98667fdc5160dc6f8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7ac52e3f2729d1b3f6d2b7e8f6467226-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7b41bfa5085806dfa24b8c9de0ce567f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7b497aa1b2a83ec63d1777a88676b0c2-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7ba0691b7777b6581397456412a41390-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7bab7650be60b0738e22c3b8745f937d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7bcdf75ad237b8e02e301f4091fb6bc8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7bd28f15a49d5e5848d6ec70e584e625-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7cac11e2f46ed46c339ec3d569853759-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7cc538b1337957dae283c30ad46def38-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7cc980b0f894bd0cf05c37c246f215f3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7d265aa7147bd3913fb84c7963a209d1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7d3d5bcad324d3edc08e40738e663554-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7d420e2b2939762031eed0447a9be19f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7d97667a3e056acab9aaf653807b4a03-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7e05d6f828574fbc975a896b25bb011e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7e0a0209b929d097bd3e8ef30567a5c1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7ec0dbeee45813422897e04ad8424a5e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7ec2442aa04c157590b2fa1a7d093a33-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7f141cf8e7136ce8701dc6636c2a6fe4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7f2be1b45d278ac18804b79207a24c53-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7f2cba89a7116c7c6b0a769572d5fad9-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7f6caf1f0ba788cd7953d817724c2b6e-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7fa215c9efebb3811a7ef58409907899-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7fc63ff01769c4fa7d9279e97e307829-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/7fd3b80fb1884e2927df46a7139bb8bf-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/803ef56843860e4a48fc4cdb3065e8ce-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/804741413d7fe0e515b19a7ffc7b3027-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/806beafe154032a5b818e97b4420ad98-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/80b618ebcac7aa97a6dac2ba65cb7e36-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/8169e05e2a0debcb15458f2cc1eff0ea-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/8171ac2c5544a5cb54ac0f38bf477af4-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/819f46e52c25763a55cc642422644317-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/81e3225c6ad49623167a4309eb4b2e75-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/81e793dc8317a3dbc3534ed3f242c418-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/81f7acabd411274fcf65ce2070ed568a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/82039d16dce0aab3913b6a7ac73deff7-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/821fa74b50ba3f7cba1e6c53e8fa6845-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/8248a99e81e752cb9b41da3fc43fbe7f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/82674fc29bc0d9895cee346548c2cb5c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/8289889263db4a40463e3f358bb7c7a1-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/82b04cd5aa016d979fe048f3ddf0e8d3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/82e9e7a12665240d13d0b928be28f230-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/83004190b1793d7aa15f8d0d49a13eba-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/837a7924b8c0aa866e41b2721f66135c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/8396b14c5dff55d13eea57487bf8ed26-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/83adc9225e4deb67d7ce42d58fe5157c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/83d3d4b6c9579515e1679aca8cbc8033-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/83eaa6722798a773dd55e8fc7443aa09-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/83fa5a432ae55c253d0e60dbfa716723-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/8493eeaccb772c0878f99d60a0bd2bb3-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/84c230a5b1bc3495046ef916957c7238-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/84c578f202616448a2f80e6f56d5f16d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/84ddfb34126fc3a48ee38d7044e87276-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/84fec9a8e45846340fdf5c7c9f7ed66c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/8511df98c02ab60aea1b2356c013bc0f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/85690f81aadc1749175c187784afc9ee-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/858e47701162578e5e627cd93ab0938a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/85934679f30131d812a8c7475a7d0f74-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/85b42dd8aae56e01379be5736db5b496-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/85b9a5ac91cd629bd3afe396ec07270a-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/85c9f9efab89cee90a95cb98f15feacd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/85fc37b18c57097425b52fc7afbb6969-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/8606bdb6f1fa707fc6ca309943eea443-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/860b37e28ec7ba614f00f9246949561d-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/861637a425ef06e6d539aaaff113d1d5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/865dfbde8a344b44095495f3591f7407-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/866d90e0921ac7b024b47d672445a086-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/8682cc30db9c025ecd3fee433f8ab54c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/86b94dae7c6517ec1ac767fd2c136580-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/86c51678350f656dcc7f490a43946ee5-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/86d7c8a08b4aaa1bc7c599473f5dddda-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/8763d72bba4a7ade23f9ae1f09f4efc7-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/8767bccb1ff4231a9962e3914f4f1f8f-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/87736972ed2fb48230f1052699dedbe7-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/884d247c6f65a96a7da4d1105d584ddd-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/885b2c7a6deb4fea10f319c4ce993e02-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/887caadc3642e304ede659b734f79b00-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/88855547570f7ff053fff7c54e5148cc-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/8929c70f8d710e412d38da624b21c3c8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/89562dccfeb1d0394b9ae7e09544dc70-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/8965f76632d7672e7d3cf29c87ecaa0c-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/8977ecbb8cb82d77fb091c7a7f186163-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/8989e07fc124e7a9bcbdebcc8ace2bc0-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/89ae0fe22c47d374bc9350ef99e01685-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/89b9e0a6f6d1505fe13dea0f18a2dcfa-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/8a1276c25f5efe85f0fc4020fbf5b4f8-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/8a50bae297807da9e97722a0b3fd8f27-Abstract.html',\n",
              " 'https://papers.nips.cc/paper/2020/hash/8a7129b8f3edd95b7d969dfc2c8e9d9d-Abstract.html',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxZ3884S8_Nv"
      },
      "source": [
        "## 2.Scrape Abstracts from 1st Level Urls [scrapeDetails()]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BnnMzgi3TcI",
        "outputId": "dc59e741-c76d-4da2-dd34-2ed389abf031"
      },
      "source": [
        "print(len(extract_url))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1898\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIMLDN-d8_Nv"
      },
      "source": [
        "\n",
        "#extract_url = ['https://papers.nips.cc/paper/2020/hash/012d9fe15b2493f21902cd55603382ec-Abstract.html']\n",
        "for URL in extract_url:\n",
        "  #print(URL)\n",
        "  webpage = requests.get(URL)\n",
        "  soup = BeautifulSoup(webpage.text, \"html.parser\") #Parse the text from the website\n",
        "  #print(soup.prettify())\n",
        "  extract_abstract2(soup)\n",
        "  #print(\"****************************\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eccdyGoR8_Nw"
      },
      "source": [
        "### Building Dataframe From Extracted URLs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-DxrF6egM89",
        "outputId": "3c677dab-367d-4046-f5db-c7174a017c8d"
      },
      "source": [
        "len(titles)\n",
        "print(len(abstracts))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1898\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfpgJUchG4UX",
        "outputId": "0f60fe9b-a712-478b-8c1c-1c9a71113304"
      },
      "source": [
        "authors[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Seongmin Ok'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkqX8Mtt8_Nw",
        "outputId": "a09eb354-9c6f-4162-bd40-4ee8df8819e6"
      },
      "source": [
        "#Create a new dataFrame \n",
        "data = pd.DataFrame(columns = ['type', 'sources', 'titles', 'authors', 'abstract', 'urls']) \n",
        "data['type'] = type_\n",
        "data['sources'] = sources\n",
        "data['titles'] = titles\n",
        "data['authors'] = authors\n",
        "data['abstract'] = abstracts\n",
        "data['urls'] = extract_url\n",
        "\n",
        "#Show the data set\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>sources</th>\n",
              "      <th>titles</th>\n",
              "      <th>authors</th>\n",
              "      <th>abstract</th>\n",
              "      <th>urls</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>conference</td>\n",
              "      <td>neurips</td>\n",
              "      <td>A graph similarity for deep learning</td>\n",
              "      <td>Seongmin Ok</td>\n",
              "      <td>Graph neural networks (GNNs) have been success...</td>\n",
              "      <td>https://papers.nips.cc/paper/2020/hash/0004d0b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>conference</td>\n",
              "      <td>neurips</td>\n",
              "      <td>An Unsupervised Information-Theoretic Perceptu...</td>\n",
              "      <td>Sangnie Bhardwaj, Ian Fischer, Johannes Ballé,...</td>\n",
              "      <td>Tractable models of human perception have prov...</td>\n",
              "      <td>https://papers.nips.cc/paper/2020/hash/00482b9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>conference</td>\n",
              "      <td>neurips</td>\n",
              "      <td>Self-Supervised MultiModal Versatile Networks</td>\n",
              "      <td>Jean-Baptiste Alayrac, Adria Recasens, Rosalia...</td>\n",
              "      <td>Videos are a rich source of multi-modal superv...</td>\n",
              "      <td>https://papers.nips.cc/paper/2020/hash/0060ef4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>conference</td>\n",
              "      <td>neurips</td>\n",
              "      <td>Benchmarking Deep Inverse Models over time, an...</td>\n",
              "      <td>Simiao Ren, Willie Padilla, Jordan Malof</td>\n",
              "      <td>We consider the task of solving generic invers...</td>\n",
              "      <td>https://papers.nips.cc/paper/2020/hash/007ff38...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>conference</td>\n",
              "      <td>neurips</td>\n",
              "      <td>Off-Policy Evaluation and Learning for Externa...</td>\n",
              "      <td>Masatoshi Uehara, Masahiro Kato, Shota Yasui</td>\n",
              "      <td>We consider the evaluation and training of a n...</td>\n",
              "      <td>https://papers.nips.cc/paper/2020/hash/0084ae4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1893</th>\n",
              "      <td>conference</td>\n",
              "      <td>neurips</td>\n",
              "      <td>Distributed Distillation for On-Device Learning</td>\n",
              "      <td>Ilai Bistritz, Ariana Mann, Nicholas Bambos</td>\n",
              "      <td>On-device learning promises collaborative trai...</td>\n",
              "      <td>https://papers.nips.cc/paper/2020/hash/fef6f97...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1894</th>\n",
              "      <td>conference</td>\n",
              "      <td>neurips</td>\n",
              "      <td>COOT: Cooperative Hierarchical Transformer for...</td>\n",
              "      <td>Simon Ging, Mohammadreza Zolfaghari, Hamed Pir...</td>\n",
              "      <td>Many real-world video-text tasks involve diffe...</td>\n",
              "      <td>https://papers.nips.cc/paper/2020/hash/ff0abbc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1895</th>\n",
              "      <td>conference</td>\n",
              "      <td>neurips</td>\n",
              "      <td>Passport-aware Normalization for Deep Model Pr...</td>\n",
              "      <td>Jie Zhang, Dongdong Chen, Jing Liao, Weiming Z...</td>\n",
              "      <td>Despite tremendous success in many application...</td>\n",
              "      <td>https://papers.nips.cc/paper/2020/hash/ff1418e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1896</th>\n",
              "      <td>conference</td>\n",
              "      <td>neurips</td>\n",
              "      <td>Sampling-Decomposable Generative Adversarial R...</td>\n",
              "      <td>Binbin Jin, Defu Lian, Zheng Liu, Qi Liu, Jian...</td>\n",
              "      <td>Recommendation techniques are important approa...</td>\n",
              "      <td>https://papers.nips.cc/paper/2020/hash/ff42b03...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1897</th>\n",
              "      <td>conference</td>\n",
              "      <td>neurips</td>\n",
              "      <td>Limits to Depth Efficiencies of Self-Attention</td>\n",
              "      <td>Yoav Levine, Noam Wies, Or Sharir, Hofit Bata,...</td>\n",
              "      <td>Self-attention architectures, which are rapidl...</td>\n",
              "      <td>https://papers.nips.cc/paper/2020/hash/ff4dfdf...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1898 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            type  sources                                             titles  \\\n",
              "0     conference  neurips               A graph similarity for deep learning   \n",
              "1     conference  neurips  An Unsupervised Information-Theoretic Perceptu...   \n",
              "2     conference  neurips      Self-Supervised MultiModal Versatile Networks   \n",
              "3     conference  neurips  Benchmarking Deep Inverse Models over time, an...   \n",
              "4     conference  neurips  Off-Policy Evaluation and Learning for Externa...   \n",
              "...          ...      ...                                                ...   \n",
              "1893  conference  neurips    Distributed Distillation for On-Device Learning   \n",
              "1894  conference  neurips  COOT: Cooperative Hierarchical Transformer for...   \n",
              "1895  conference  neurips  Passport-aware Normalization for Deep Model Pr...   \n",
              "1896  conference  neurips  Sampling-Decomposable Generative Adversarial R...   \n",
              "1897  conference  neurips     Limits to Depth Efficiencies of Self-Attention   \n",
              "\n",
              "                                                authors  \\\n",
              "0                                           Seongmin Ok   \n",
              "1     Sangnie Bhardwaj, Ian Fischer, Johannes Ballé,...   \n",
              "2     Jean-Baptiste Alayrac, Adria Recasens, Rosalia...   \n",
              "3              Simiao Ren, Willie Padilla, Jordan Malof   \n",
              "4          Masatoshi Uehara, Masahiro Kato, Shota Yasui   \n",
              "...                                                 ...   \n",
              "1893        Ilai Bistritz, Ariana Mann, Nicholas Bambos   \n",
              "1894  Simon Ging, Mohammadreza Zolfaghari, Hamed Pir...   \n",
              "1895  Jie Zhang, Dongdong Chen, Jing Liao, Weiming Z...   \n",
              "1896  Binbin Jin, Defu Lian, Zheng Liu, Qi Liu, Jian...   \n",
              "1897  Yoav Levine, Noam Wies, Or Sharir, Hofit Bata,...   \n",
              "\n",
              "                                               abstract  \\\n",
              "0     Graph neural networks (GNNs) have been success...   \n",
              "1     Tractable models of human perception have prov...   \n",
              "2     Videos are a rich source of multi-modal superv...   \n",
              "3     We consider the task of solving generic invers...   \n",
              "4     We consider the evaluation and training of a n...   \n",
              "...                                                 ...   \n",
              "1893  On-device learning promises collaborative trai...   \n",
              "1894  Many real-world video-text tasks involve diffe...   \n",
              "1895  Despite tremendous success in many application...   \n",
              "1896  Recommendation techniques are important approa...   \n",
              "1897  Self-attention architectures, which are rapidl...   \n",
              "\n",
              "                                                   urls  \n",
              "0     https://papers.nips.cc/paper/2020/hash/0004d0b...  \n",
              "1     https://papers.nips.cc/paper/2020/hash/00482b9...  \n",
              "2     https://papers.nips.cc/paper/2020/hash/0060ef4...  \n",
              "3     https://papers.nips.cc/paper/2020/hash/007ff38...  \n",
              "4     https://papers.nips.cc/paper/2020/hash/0084ae4...  \n",
              "...                                                 ...  \n",
              "1893  https://papers.nips.cc/paper/2020/hash/fef6f97...  \n",
              "1894  https://papers.nips.cc/paper/2020/hash/ff0abbc...  \n",
              "1895  https://papers.nips.cc/paper/2020/hash/ff1418e...  \n",
              "1896  https://papers.nips.cc/paper/2020/hash/ff42b03...  \n",
              "1897  https://papers.nips.cc/paper/2020/hash/ff4dfdf...  \n",
              "\n",
              "[1898 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gh94MkmACBy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2GajxlfAMaZ"
      },
      "source": [
        "file_path = '/content/drive/Shared drives/1DeepContextGraph/1DeepContextGraph/code/data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhgVVkK3AZvS"
      },
      "source": [
        "#data.to_csv(file_path+'neurips_data_2020.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGCnlmjmJBiX"
      },
      "source": [
        "## 3.Transitive Topic Extraction from N-grams [.extractTopic()]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4ybI8yjgBNJ"
      },
      "source": [
        "# import pandas as pd\n",
        "# file_path = '/content/drive/Shared drives/1DeepContextGraph/1DeepContextGraph/code/data/'\n",
        "# data=pd.read_csv(file_path+\"neurips_data_2020.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "id": "RcocyKVCpHOq",
        "outputId": "9e8baa8d-4884-4656-f4d6-f88291f979bf"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>sources</th>\n",
              "      <th>titles</th>\n",
              "      <th>authors</th>\n",
              "      <th>abstract</th>\n",
              "      <th>urls</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>conference</td>\n",
              "      <td>neurips</td>\n",
              "      <td>A graph similarity for deep learning</td>\n",
              "      <td>Seongmin Ok</td>\n",
              "      <td>Graph neural networks (GNNs) have been success...</td>\n",
              "      <td>https://papers.nips.cc/paper/2020/hash/0004d0b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>conference</td>\n",
              "      <td>neurips</td>\n",
              "      <td>An Unsupervised Information-Theoretic Perceptu...</td>\n",
              "      <td>Sangnie Bhardwaj, Ian Fischer, Johannes Ballé,...</td>\n",
              "      <td>Tractable models of human perception have prov...</td>\n",
              "      <td>https://papers.nips.cc/paper/2020/hash/00482b9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>conference</td>\n",
              "      <td>neurips</td>\n",
              "      <td>Self-Supervised MultiModal Versatile Networks</td>\n",
              "      <td>Jean-Baptiste Alayrac, Adria Recasens, Rosalia...</td>\n",
              "      <td>Videos are a rich source of multi-modal superv...</td>\n",
              "      <td>https://papers.nips.cc/paper/2020/hash/0060ef4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>conference</td>\n",
              "      <td>neurips</td>\n",
              "      <td>Benchmarking Deep Inverse Models over time, an...</td>\n",
              "      <td>Simiao Ren, Willie Padilla, Jordan Malof</td>\n",
              "      <td>We consider the task of solving generic invers...</td>\n",
              "      <td>https://papers.nips.cc/paper/2020/hash/007ff38...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>conference</td>\n",
              "      <td>neurips</td>\n",
              "      <td>Off-Policy Evaluation and Learning for Externa...</td>\n",
              "      <td>Masatoshi Uehara, Masahiro Kato, Shota Yasui</td>\n",
              "      <td>We consider the evaluation and training of a n...</td>\n",
              "      <td>https://papers.nips.cc/paper/2020/hash/0084ae4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1893</th>\n",
              "      <td>conference</td>\n",
              "      <td>neurips</td>\n",
              "      <td>Distributed Distillation for On-Device Learning</td>\n",
              "      <td>Ilai Bistritz, Ariana Mann, Nicholas Bambos</td>\n",
              "      <td>On-device learning promises collaborative trai...</td>\n",
              "      <td>https://papers.nips.cc/paper/2020/hash/fef6f97...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1894</th>\n",
              "      <td>conference</td>\n",
              "      <td>neurips</td>\n",
              "      <td>COOT: Cooperative Hierarchical Transformer for...</td>\n",
              "      <td>Simon Ging, Mohammadreza Zolfaghari, Hamed Pir...</td>\n",
              "      <td>Many real-world video-text tasks involve diffe...</td>\n",
              "      <td>https://papers.nips.cc/paper/2020/hash/ff0abbc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1895</th>\n",
              "      <td>conference</td>\n",
              "      <td>neurips</td>\n",
              "      <td>Passport-aware Normalization for Deep Model Pr...</td>\n",
              "      <td>Jie Zhang, Dongdong Chen, Jing Liao, Weiming Z...</td>\n",
              "      <td>Despite tremendous success in many application...</td>\n",
              "      <td>https://papers.nips.cc/paper/2020/hash/ff1418e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1896</th>\n",
              "      <td>conference</td>\n",
              "      <td>neurips</td>\n",
              "      <td>Sampling-Decomposable Generative Adversarial R...</td>\n",
              "      <td>Binbin Jin, Defu Lian, Zheng Liu, Qi Liu, Jian...</td>\n",
              "      <td>Recommendation techniques are important approa...</td>\n",
              "      <td>https://papers.nips.cc/paper/2020/hash/ff42b03...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1897</th>\n",
              "      <td>conference</td>\n",
              "      <td>neurips</td>\n",
              "      <td>Limits to Depth Efficiencies of Self-Attention</td>\n",
              "      <td>Yoav Levine, Noam Wies, Or Sharir, Hofit Bata,...</td>\n",
              "      <td>Self-attention architectures, which are rapidl...</td>\n",
              "      <td>https://papers.nips.cc/paper/2020/hash/ff4dfdf...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1898 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            type  sources                                             titles  \\\n",
              "0     conference  neurips               A graph similarity for deep learning   \n",
              "1     conference  neurips  An Unsupervised Information-Theoretic Perceptu...   \n",
              "2     conference  neurips      Self-Supervised MultiModal Versatile Networks   \n",
              "3     conference  neurips  Benchmarking Deep Inverse Models over time, an...   \n",
              "4     conference  neurips  Off-Policy Evaluation and Learning for Externa...   \n",
              "...          ...      ...                                                ...   \n",
              "1893  conference  neurips    Distributed Distillation for On-Device Learning   \n",
              "1894  conference  neurips  COOT: Cooperative Hierarchical Transformer for...   \n",
              "1895  conference  neurips  Passport-aware Normalization for Deep Model Pr...   \n",
              "1896  conference  neurips  Sampling-Decomposable Generative Adversarial R...   \n",
              "1897  conference  neurips     Limits to Depth Efficiencies of Self-Attention   \n",
              "\n",
              "                                                authors  \\\n",
              "0                                           Seongmin Ok   \n",
              "1     Sangnie Bhardwaj, Ian Fischer, Johannes Ballé,...   \n",
              "2     Jean-Baptiste Alayrac, Adria Recasens, Rosalia...   \n",
              "3              Simiao Ren, Willie Padilla, Jordan Malof   \n",
              "4          Masatoshi Uehara, Masahiro Kato, Shota Yasui   \n",
              "...                                                 ...   \n",
              "1893        Ilai Bistritz, Ariana Mann, Nicholas Bambos   \n",
              "1894  Simon Ging, Mohammadreza Zolfaghari, Hamed Pir...   \n",
              "1895  Jie Zhang, Dongdong Chen, Jing Liao, Weiming Z...   \n",
              "1896  Binbin Jin, Defu Lian, Zheng Liu, Qi Liu, Jian...   \n",
              "1897  Yoav Levine, Noam Wies, Or Sharir, Hofit Bata,...   \n",
              "\n",
              "                                               abstract  \\\n",
              "0     Graph neural networks (GNNs) have been success...   \n",
              "1     Tractable models of human perception have prov...   \n",
              "2     Videos are a rich source of multi-modal superv...   \n",
              "3     We consider the task of solving generic invers...   \n",
              "4     We consider the evaluation and training of a n...   \n",
              "...                                                 ...   \n",
              "1893  On-device learning promises collaborative trai...   \n",
              "1894  Many real-world video-text tasks involve diffe...   \n",
              "1895  Despite tremendous success in many application...   \n",
              "1896  Recommendation techniques are important approa...   \n",
              "1897  Self-attention architectures, which are rapidl...   \n",
              "\n",
              "                                                   urls  \n",
              "0     https://papers.nips.cc/paper/2020/hash/0004d0b...  \n",
              "1     https://papers.nips.cc/paper/2020/hash/00482b9...  \n",
              "2     https://papers.nips.cc/paper/2020/hash/0060ef4...  \n",
              "3     https://papers.nips.cc/paper/2020/hash/007ff38...  \n",
              "4     https://papers.nips.cc/paper/2020/hash/0084ae4...  \n",
              "...                                                 ...  \n",
              "1893  https://papers.nips.cc/paper/2020/hash/fef6f97...  \n",
              "1894  https://papers.nips.cc/paper/2020/hash/ff0abbc...  \n",
              "1895  https://papers.nips.cc/paper/2020/hash/ff1418e...  \n",
              "1896  https://papers.nips.cc/paper/2020/hash/ff42b03...  \n",
              "1897  https://papers.nips.cc/paper/2020/hash/ff4dfdf...  \n",
              "\n",
              "[1898 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYyfrRXcJKsu"
      },
      "source": [
        "### Set-up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGH2_FKWJMtK",
        "outputId": "84aa7963-160f-4694-9385-0261bceb34e6"
      },
      "source": [
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install stop_words\n",
        "!pip install nlpretext"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: stop_words in /opt/conda/lib/python3.7/site-packages (2018.7.23)\n",
            "Requirement already satisfied: nlpretext in /opt/conda/lib/python3.7/site-packages (1.0.4)\n",
            "Requirement already satisfied: emoji>=0.5.2 in /opt/conda/lib/python3.7/site-packages (from nlpretext) (1.4.1)\n",
            "Requirement already satisfied: nlpaug==1.0.1 in /opt/conda/lib/python3.7/site-packages (from nlpretext) (1.0.1)\n",
            "Requirement already satisfied: chardet==3.0.4 in /opt/conda/lib/python3.7/site-packages (from nlpretext) (3.0.4)\n",
            "Requirement already satisfied: nltk>=3.4.5 in /opt/conda/lib/python3.7/site-packages (from nlpretext) (3.6.2)\n",
            "Requirement already satisfied: spacy==2.3.4 in /opt/conda/lib/python3.7/site-packages (from nlpretext) (2.3.4)\n",
            "Requirement already satisfied: ftfy<5.0.0,>=4.2.0 in /opt/conda/lib/python3.7/site-packages (from nlpretext) (4.4.3)\n",
            "Requirement already satisfied: scikit-learn==0.23.2 in /opt/conda/lib/python3.7/site-packages (from nlpretext) (0.23.2)\n",
            "Requirement already satisfied: mosestokenizer==1.1.0 in /opt/conda/lib/python3.7/site-packages (from nlpretext) (1.1.0)\n",
            "Requirement already satisfied: sacremoses==0.0.13 in /opt/conda/lib/python3.7/site-packages (from nlpretext) (0.0.13)\n",
            "Requirement already satisfied: numpy>1.15.4 in /opt/conda/lib/python3.7/site-packages (from nlpretext) (1.19.5)\n",
            "Requirement already satisfied: regex==2019.8.19 in /opt/conda/lib/python3.7/site-packages (from nlpretext) (2019.8.19)\n",
            "Requirement already satisfied: stop-words==2018.7.23 in /opt/conda/lib/python3.7/site-packages (from nlpretext) (2018.7.23)\n",
            "Requirement already satisfied: flashtext==2.7 in /opt/conda/lib/python3.7/site-packages (from nlpretext) (2.7)\n",
            "Requirement already satisfied: phonenumbers==8.10.12 in /opt/conda/lib/python3.7/site-packages (from nlpretext) (8.10.12)\n",
            "Requirement already satisfied: uctools in /opt/conda/lib/python3.7/site-packages (from mosestokenizer==1.1.0->nlpretext) (1.3.0)\n",
            "Requirement already satisfied: docopt in /opt/conda/lib/python3.7/site-packages (from mosestokenizer==1.1.0->nlpretext) (0.6.2)\n",
            "Requirement already satisfied: openfile in /opt/conda/lib/python3.7/site-packages (from mosestokenizer==1.1.0->nlpretext) (0.0.7)\n",
            "Requirement already satisfied: toolwrapper in /opt/conda/lib/python3.7/site-packages (from mosestokenizer==1.1.0->nlpretext) (2.1.0)\n",
            "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from sacremoses==0.0.13->nlpretext) (4.61.2)\n",
            "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses==0.0.13->nlpretext) (1.0.1)\n",
            "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses==0.0.13->nlpretext) (1.16.0)\n",
            "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses==0.0.13->nlpretext) (8.0.1)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from scikit-learn==0.23.2->nlpretext) (1.7.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn==0.23.2->nlpretext) (2.2.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy==2.3.4->nlpretext) (1.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy==2.3.4->nlpretext) (2.25.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/conda/lib/python3.7/site-packages (from spacy==2.3.4->nlpretext) (1.1.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy==2.3.4->nlpretext) (0.7.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/conda/lib/python3.7/site-packages (from spacy==2.3.4->nlpretext) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy==2.3.4->nlpretext) (0.8.2)\n",
            "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy==2.3.4->nlpretext) (49.6.0.post20210108)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy==2.3.4->nlpretext) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy==2.3.4->nlpretext) (3.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy==2.3.4->nlpretext) (2.0.5)\n",
            "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy==2.3.4->nlpretext) (7.4.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /opt/conda/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy==2.3.4->nlpretext) (3.10.1)\n",
            "Requirement already satisfied: html5lib in /opt/conda/lib/python3.7/site-packages (from ftfy<5.0.0,>=4.2.0->nlpretext) (1.1)\n",
            "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from ftfy<5.0.0,>=4.2.0->nlpretext) (0.2.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy==2.3.4->nlpretext) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy==2.3.4->nlpretext) (3.10.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.4->nlpretext) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.4->nlpretext) (2021.5.30)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.4->nlpretext) (1.26.6)\n",
            "Requirement already satisfied: webencodings in /opt/conda/lib/python3.7/site-packages (from html5lib->ftfy<5.0.0,>=4.2.0->nlpretext) (0.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7aRFnffJP_m"
      },
      "source": [
        "import requests\n",
        "import nlpretext as nlp\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9VTLl8nKt5P"
      },
      "source": [
        "### Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-12-17T02:03:33.356005Z",
          "start_time": "2019-12-17T02:03:33.336089Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOH8A6emDoZj",
        "outputId": "07369b9e-4979-41b1-af83-ea592a6f0309"
      },
      "source": [
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stopwords = stopwords.words('english')\n",
        "\n",
        "def join_tokens(list_of_tokens):\n",
        "    outstr = TreebankWordDetokenizer().detokenize(list_of_tokens)\n",
        "    return outstr\n",
        "\n",
        "def filter_stopwords_from_list(titles):\n",
        "    word_list = titles\n",
        "    title_list = []\n",
        "    new_word_list = []\n",
        "    new_title_list= []\n",
        "    for title in titles:\n",
        "            #print (title)\n",
        "            title_list =  nltk.word_tokenize(title)\n",
        "            #print (words)\n",
        "            for word in title_list:\n",
        "                print (word)\n",
        "                if word.lower() not in stopwords:\n",
        "                    new_word_list.append(word)\n",
        "                    #print(\"joined {} :\".format(word))\n",
        "            #print (\"new title list :\",new_word_list)\n",
        "            new_title = join_tokens(new_word_list)\n",
        "            #print (\"\\n New title : \", new_title)\n",
        "            new_word_list =[]\n",
        "            # print (\"old : {}  \\n -----> new : {}\\n\\n\".format(title, new_title))\n",
        "            new_title_list.append(new_title)\n",
        "    # print (\"========================\\n\")\n",
        "    # print (\"new list of titles: \\n: ===> \",new_title_list )\n",
        "    return new_title_list\n",
        "        #print (new_line)\n",
        "        #filtered_words = [word for word in words if word.lower() not in stopwords]\n",
        "        #print (words)\n",
        "\n",
        "# receives a list of texts and creates n-grams for each of the text as well as for the entire corpus\n",
        "def getNGramsConcat(lstText, ngramsCount):\n",
        "  import re\n",
        "  from nltk.util import ngrams\n",
        "  s = \" \".join(lstText) # this may be needed to crea\n",
        "  s = s.lower()\n",
        "  s = re.sub(r'[^a-zA-Z0-9\\s]', ' ', s)\n",
        "  tokens = [token for token in s.split(\" \") if token != \"\"]\n",
        "  corpusNGrams = list(ngrams(tokens, ngramsCount))\n",
        "  corpusNGramsConcat = [\"-\".join(e) for e in corpusNGrams]\n",
        "\n",
        "  txtNGrams = []\n",
        "  txtNGramsConcat = []\n",
        "  for t in lstText:\n",
        "    t2 = t.lower()\n",
        "    t2 = re.sub(r'[^a-zA-Z0-9\\s]', ' ', t2)\n",
        "    tokens2 = [token2 for token2 in t2.split(\" \") if token2 != \"\"]\n",
        "    ng = list(ngrams(tokens2, ngramsCount))\n",
        "    txtNGrams.append(ng)\n",
        "    txtNGramsConcat.append( [\"-\".join(e) for e in ng])\n",
        "\n",
        "  return (txtNGramsConcat, corpusNGramsConcat)\n",
        "\n",
        "# titles = dfEvents[\"title\"]\n",
        "# filteredTitles = filter_stopwords_from_list(titles)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/jupyter/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxJw0wAAKyjQ"
      },
      "source": [
        "### Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dm62M4NgD7Kq"
      },
      "source": [
        "df = data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BImt3QuCD7D"
      },
      "source": [
        "df= df.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBqDAF11K9PR"
      },
      "source": [
        "### Remove small words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MENnkjEMCD7E"
      },
      "source": [
        "import nlpretext as nlp\n",
        "from nlpretext.token.preprocess import remove_smallwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZzLfhFfNiv_"
      },
      "source": [
        "### Compute N-Gram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4oEBqvPXVBlz",
        "outputId": "16227f3c-ddea-4ae0-ad24-654ec7a26f49"
      },
      "source": [
        "df[\"titles\"][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A graph similarity for deep learning'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4RiuD6ANk6R",
        "outputId": "3adac607-5736-415c-da4c-a31b977cb256"
      },
      "source": [
        "texts = df[\"titles\"] #+ \". \" + df[\"abstract\"]\n",
        "texts"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                    A graph similarity for deep learning\n",
              "1       An Unsupervised Information-Theoretic Perceptu...\n",
              "2           Self-Supervised MultiModal Versatile Networks\n",
              "3       Benchmarking Deep Inverse Models over time, an...\n",
              "4       Off-Policy Evaluation and Learning for Externa...\n",
              "                              ...                        \n",
              "1893      Distributed Distillation for On-Device Learning\n",
              "1894    COOT: Cooperative Hierarchical Transformer for...\n",
              "1895    Passport-aware Normalization for Deep Model Pr...\n",
              "1896    Sampling-Decomposable Generative Adversarial R...\n",
              "1897       Limits to Depth Efficiencies of Self-Attention\n",
              "Name: titles, Length: 1898, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxbsMKZYU7Vr",
        "outputId": "5b68b74b-788b-4be7-a496-1552125e41f7"
      },
      "source": [
        "filteredTexts = filter_stopwords_from_list(texts)\n",
        "(lstNGrams, corpusNGrams) = getNGramsConcat(filteredTexts, ngramsCount = ngramsCount)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A\n",
            "graph\n",
            "similarity\n",
            "for\n",
            "deep\n",
            "learning\n",
            "An\n",
            "Unsupervised\n",
            "Information-Theoretic\n",
            "Perceptual\n",
            "Quality\n",
            "Metric\n",
            "Self-Supervised\n",
            "MultiModal\n",
            "Versatile\n",
            "Networks\n",
            "Benchmarking\n",
            "Deep\n",
            "Inverse\n",
            "Models\n",
            "over\n",
            "time\n",
            ",\n",
            "and\n",
            "the\n",
            "Neural-Adjoint\n",
            "method\n",
            "Off-Policy\n",
            "Evaluation\n",
            "and\n",
            "Learning\n",
            "for\n",
            "External\n",
            "Validity\n",
            "under\n",
            "a\n",
            "Covariate\n",
            "Shift\n",
            "Neural\n",
            "Methods\n",
            "for\n",
            "Point-wise\n",
            "Dependency\n",
            "Estimation\n",
            "Fast\n",
            "and\n",
            "Flexible\n",
            "Temporal\n",
            "Point\n",
            "Processes\n",
            "with\n",
            "Triangular\n",
            "Maps\n",
            "Backpropagating\n",
            "Linearly\n",
            "Improves\n",
            "Transferability\n",
            "of\n",
            "Adversarial\n",
            "Examples\n",
            "PyGlove\n",
            ":\n",
            "Symbolic\n",
            "Programming\n",
            "for\n",
            "Automated\n",
            "Machine\n",
            "Learning\n",
            "Fourier\n",
            "Sparse\n",
            "Leverage\n",
            "Scores\n",
            "and\n",
            "Approximate\n",
            "Kernel\n",
            "Learning\n",
            "Improved\n",
            "Algorithms\n",
            "for\n",
            "Online\n",
            "Submodular\n",
            "Maximization\n",
            "via\n",
            "First-order\n",
            "Regret\n",
            "Bounds\n",
            "Synbols\n",
            ":\n",
            "Probing\n",
            "Learning\n",
            "Algorithms\n",
            "with\n",
            "Synthetic\n",
            "Datasets\n",
            "Adversarially\n",
            "Robust\n",
            "Streaming\n",
            "Algorithms\n",
            "via\n",
            "Differential\n",
            "Privacy\n",
            "Trading\n",
            "Personalization\n",
            "for\n",
            "Accuracy\n",
            ":\n",
            "Data\n",
            "Debugging\n",
            "in\n",
            "Collaborative\n",
            "Filtering\n",
            "Cascaded\n",
            "Text\n",
            "Generation\n",
            "with\n",
            "Markov\n",
            "Transformers\n",
            "Improving\n",
            "Local\n",
            "Identifiability\n",
            "in\n",
            "Probabilistic\n",
            "Box\n",
            "Embeddings\n",
            "Permute-and-Flip\n",
            ":\n",
            "A\n",
            "new\n",
            "mechanism\n",
            "for\n",
            "differentially\n",
            "private\n",
            "selection\n",
            "Deep\n",
            "reconstruction\n",
            "of\n",
            "strange\n",
            "attractors\n",
            "from\n",
            "time\n",
            "series\n",
            "Reciprocal\n",
            "Adversarial\n",
            "Learning\n",
            "via\n",
            "Characteristic\n",
            "Functions\n",
            "Statistical\n",
            "Guarantees\n",
            "of\n",
            "Distributed\n",
            "Nearest\n",
            "Neighbor\n",
            "Classification\n",
            "Stein\n",
            "Self-Repulsive\n",
            "Dynamics\n",
            ":\n",
            "Benefits\n",
            "From\n",
            "Past\n",
            "Samples\n",
            "The\n",
            "Statistical\n",
            "Complexity\n",
            "of\n",
            "Early-Stopped\n",
            "Mirror\n",
            "Descent\n",
            "Algorithmic\n",
            "recourse\n",
            "under\n",
            "imperfect\n",
            "causal\n",
            "knowledge\n",
            ":\n",
            "a\n",
            "probabilistic\n",
            "approach\n",
            "Quantitative\n",
            "Propagation\n",
            "of\n",
            "Chaos\n",
            "for\n",
            "SGD\n",
            "in\n",
            "Wide\n",
            "Neural\n",
            "Networks\n",
            "A\n",
            "Causal\n",
            "View\n",
            "on\n",
            "Robustness\n",
            "of\n",
            "Neural\n",
            "Networks\n",
            "Minimax\n",
            "Classification\n",
            "with\n",
            "0-1\n",
            "Loss\n",
            "and\n",
            "Performance\n",
            "Guarantees\n",
            "How\n",
            "to\n",
            "Learn\n",
            "a\n",
            "Useful\n",
            "Critic\n",
            "?\n",
            "Model-based\n",
            "Action-Gradient-Estimator\n",
            "Policy\n",
            "Optimization\n",
            "Coresets\n",
            "for\n",
            "Regressions\n",
            "with\n",
            "Panel\n",
            "Data\n",
            "Learning\n",
            "Composable\n",
            "Energy\n",
            "Surrogates\n",
            "for\n",
            "PDE\n",
            "Order\n",
            "Reduction\n",
            "Efficient\n",
            "Contextual\n",
            "Bandits\n",
            "with\n",
            "Continuous\n",
            "Actions\n",
            "Achieving\n",
            "Equalized\n",
            "Odds\n",
            "by\n",
            "Resampling\n",
            "Sensitive\n",
            "Attributes\n",
            "Multi-Robot\n",
            "Collision\n",
            "Avoidance\n",
            "under\n",
            "Uncertainty\n",
            "with\n",
            "Probabilistic\n",
            "Safety\n",
            "Barrier\n",
            "Certificates\n",
            "Hard\n",
            "Shape-Constrained\n",
            "Kernel\n",
            "Machines\n",
            "A\n",
            "Closer\n",
            "Look\n",
            "at\n",
            "the\n",
            "Training\n",
            "Strategy\n",
            "for\n",
            "Modern\n",
            "Meta-Learning\n",
            "On\n",
            "the\n",
            "Value\n",
            "of\n",
            "Out-of-Distribution\n",
            "Testing\n",
            ":\n",
            "An\n",
            "Example\n",
            "of\n",
            "Goodhart\n",
            "'s\n",
            "Law\n",
            "Generalised\n",
            "Bayesian\n",
            "Filtering\n",
            "via\n",
            "Sequential\n",
            "Monte\n",
            "Carlo\n",
            "Deterministic\n",
            "Approximation\n",
            "for\n",
            "Submodular\n",
            "Maximization\n",
            "over\n",
            "a\n",
            "Matroid\n",
            "in\n",
            "Nearly\n",
            "Linear\n",
            "Time\n",
            "Flows\n",
            "for\n",
            "simultaneous\n",
            "manifold\n",
            "learning\n",
            "and\n",
            "density\n",
            "estimation\n",
            "Simultaneous\n",
            "Preference\n",
            "and\n",
            "Metric\n",
            "Learning\n",
            "from\n",
            "Paired\n",
            "Comparisons\n",
            "Efficient\n",
            "Variational\n",
            "Inference\n",
            "for\n",
            "Sparse\n",
            "Deep\n",
            "Learning\n",
            "with\n",
            "Theoretical\n",
            "Guarantee\n",
            "Learning\n",
            "Manifold\n",
            "Implicitly\n",
            "via\n",
            "Explicit\n",
            "Heat-Kernel\n",
            "Learning\n",
            "Deep\n",
            "Relational\n",
            "Topic\n",
            "Modeling\n",
            "via\n",
            "Graph\n",
            "Poisson\n",
            "Gamma\n",
            "Belief\n",
            "Network\n",
            "One-bit\n",
            "Supervision\n",
            "for\n",
            "Image\n",
            "Classification\n",
            "What\n",
            "is\n",
            "being\n",
            "transferred\n",
            "in\n",
            "transfer\n",
            "learning\n",
            "?\n",
            "Submodular\n",
            "Maximization\n",
            "Through\n",
            "Barrier\n",
            "Functions\n",
            "Neural\n",
            "Networks\n",
            "with\n",
            "Recurrent\n",
            "Generative\n",
            "Feedback\n",
            "Learning\n",
            "to\n",
            "Extrapolate\n",
            "Knowledge\n",
            ":\n",
            "Transductive\n",
            "Few-shot\n",
            "Out-of-Graph\n",
            "Link\n",
            "Prediction\n",
            "Exploiting\n",
            "weakly\n",
            "supervised\n",
            "visual\n",
            "patterns\n",
            "to\n",
            "learn\n",
            "from\n",
            "partial\n",
            "annotations\n",
            "Improving\n",
            "Inference\n",
            "for\n",
            "Neural\n",
            "Image\n",
            "Compression\n",
            "Neuron\n",
            "Merging\n",
            ":\n",
            "Compensating\n",
            "for\n",
            "Pruned\n",
            "Neurons\n",
            "FixMatch\n",
            ":\n",
            "Simplifying\n",
            "Semi-Supervised\n",
            "Learning\n",
            "with\n",
            "Consistency\n",
            "and\n",
            "Confidence\n",
            "Reinforcement\n",
            "Learning\n",
            "with\n",
            "Combinatorial\n",
            "Actions\n",
            ":\n",
            "An\n",
            "Application\n",
            "to\n",
            "Vehicle\n",
            "Routing\n",
            "Towards\n",
            "Playing\n",
            "Full\n",
            "MOBA\n",
            "Games\n",
            "with\n",
            "Deep\n",
            "Reinforcement\n",
            "Learning\n",
            "Rankmax\n",
            ":\n",
            "An\n",
            "Adaptive\n",
            "Projection\n",
            "Alternative\n",
            "to\n",
            "the\n",
            "Softmax\n",
            "Function\n",
            "Online\n",
            "Agnostic\n",
            "Boosting\n",
            "via\n",
            "Regret\n",
            "Minimization\n",
            "Causal\n",
            "Intervention\n",
            "for\n",
            "Weakly-Supervised\n",
            "Semantic\n",
            "Segmentation\n",
            "Belief\n",
            "Propagation\n",
            "Neural\n",
            "Networks\n",
            "Over-parameterized\n",
            "Adversarial\n",
            "Training\n",
            ":\n",
            "An\n",
            "Analysis\n",
            "Overcoming\n",
            "the\n",
            "Curse\n",
            "of\n",
            "Dimensionality\n",
            "Post-training\n",
            "Iterative\n",
            "Hierarchical\n",
            "Data\n",
            "Augmentation\n",
            "for\n",
            "Deep\n",
            "Networks\n",
            "Debugging\n",
            "Tests\n",
            "for\n",
            "Model\n",
            "Explanations\n",
            "Robust\n",
            "compressed\n",
            "sensing\n",
            "using\n",
            "generative\n",
            "models\n",
            "Fairness\n",
            "without\n",
            "Demographics\n",
            "through\n",
            "Adversarially\n",
            "Reweighted\n",
            "Learning\n",
            "Stochastic\n",
            "Latent\n",
            "Actor-Critic\n",
            ":\n",
            "Deep\n",
            "Reinforcement\n",
            "Learning\n",
            "with\n",
            "a\n",
            "Latent\n",
            "Variable\n",
            "Model\n",
            "Ridge\n",
            "Rider\n",
            ":\n",
            "Finding\n",
            "Diverse\n",
            "Solutions\n",
            "by\n",
            "Following\n",
            "Eigenvectors\n",
            "of\n",
            "the\n",
            "Hessian\n",
            "The\n",
            "route\n",
            "to\n",
            "chaos\n",
            "in\n",
            "routing\n",
            "games\n",
            ":\n",
            "When\n",
            "is\n",
            "price\n",
            "of\n",
            "anarchy\n",
            "too\n",
            "optimistic\n",
            "?\n",
            "Online\n",
            "Algorithm\n",
            "for\n",
            "Unsupervised\n",
            "Sequential\n",
            "Selection\n",
            "with\n",
            "Contextual\n",
            "Information\n",
            "Adapting\n",
            "Neural\n",
            "Architectures\n",
            "Between\n",
            "Domains\n",
            "What\n",
            "went\n",
            "wrong\n",
            "and\n",
            "when\n",
            "?\n",
            "Instance-wise\n",
            "feature\n",
            "importance\n",
            "for\n",
            "time-series\n",
            "black-box\n",
            "models\n",
            "Towards\n",
            "Better\n",
            "Generalization\n",
            "of\n",
            "Adaptive\n",
            "Gradient\n",
            "Methods\n",
            "Learning\n",
            "Guidance\n",
            "Rewards\n",
            "with\n",
            "Trajectory-space\n",
            "Smoothing\n",
            "Variance\n",
            "Reduction\n",
            "via\n",
            "Accelerated\n",
            "Dual\n",
            "Averaging\n",
            "for\n",
            "Finite-Sum\n",
            "Optimization\n",
            "Tree\n",
            "!\n",
            "I\n",
            "am\n",
            "no\n",
            "Tree\n",
            "!\n",
            "I\n",
            "am\n",
            "a\n",
            "low\n",
            "dimensional\n",
            "Hyperbolic\n",
            "Embedding\n",
            "Deep\n",
            "Structural\n",
            "Causal\n",
            "Models\n",
            "for\n",
            "Tractable\n",
            "Counterfactual\n",
            "Inference\n",
            "Convolutional\n",
            "Generation\n",
            "of\n",
            "Textured\n",
            "3D\n",
            "Meshes\n",
            "A\n",
            "Statistical\n",
            "Framework\n",
            "for\n",
            "Low-bitwidth\n",
            "Training\n",
            "of\n",
            "Deep\n",
            "Neural\n",
            "Networks\n",
            "Better\n",
            "Set\n",
            "Representations\n",
            "For\n",
            "Relational\n",
            "Reasoning\n",
            "AutoSync\n",
            ":\n",
            "Learning\n",
            "to\n",
            "Synchronize\n",
            "for\n",
            "Data-Parallel\n",
            "Distributed\n",
            "Deep\n",
            "Learning\n",
            "A\n",
            "Combinatorial\n",
            "Perspective\n",
            "on\n",
            "Transfer\n",
            "Learning\n",
            "Hardness\n",
            "of\n",
            "Learning\n",
            "Neural\n",
            "Networks\n",
            "with\n",
            "Natural\n",
            "Weights\n",
            "Higher-Order\n",
            "Spectral\n",
            "Clustering\n",
            "of\n",
            "Directed\n",
            "Graphs\n",
            "Primal-Dual\n",
            "Mesh\n",
            "Convolutional\n",
            "Neural\n",
            "Networks\n",
            "The\n",
            "Advantage\n",
            "of\n",
            "Conditional\n",
            "Meta-Learning\n",
            "for\n",
            "Biased\n",
            "Regularization\n",
            "and\n",
            "Fine\n",
            "Tuning\n",
            "Watch\n",
            "out\n",
            "!\n",
            "Motion\n",
            "is\n",
            "Blurring\n",
            "the\n",
            "Vision\n",
            "of\n",
            "Your\n",
            "Deep\n",
            "Neural\n",
            "Networks\n",
            "Sinkhorn\n",
            "Barycenter\n",
            "via\n",
            "Functional\n",
            "Gradient\n",
            "Descent\n",
            "Coresets\n",
            "for\n",
            "Near-Convex\n",
            "Functions\n",
            "Bayesian\n",
            "Deep\n",
            "Ensembles\n",
            "via\n",
            "the\n",
            "Neural\n",
            "Tangent\n",
            "Kernel\n",
            "Improved\n",
            "Schemes\n",
            "for\n",
            "Episodic\n",
            "Memory-based\n",
            "Lifelong\n",
            "Learning\n",
            "Adaptive\n",
            "Sampling\n",
            "for\n",
            "Stochastic\n",
            "Risk-Averse\n",
            "Learning\n",
            "Deep\n",
            "Wiener\n",
            "Deconvolution\n",
            ":\n",
            "Wiener\n",
            "Meets\n",
            "Deep\n",
            "Learning\n",
            "for\n",
            "Image\n",
            "Deblurring\n",
            "Discovering\n",
            "Reinforcement\n",
            "Learning\n",
            "Algorithms\n",
            "Taming\n",
            "Discrete\n",
            "Integration\n",
            "via\n",
            "the\n",
            "Boon\n",
            "of\n",
            "Dimensionality\n",
            "Blind\n",
            "Video\n",
            "Temporal\n",
            "Consistency\n",
            "via\n",
            "Deep\n",
            "Video\n",
            "Prior\n",
            "Simplify\n",
            "and\n",
            "Robustify\n",
            "Negative\n",
            "Sampling\n",
            "for\n",
            "Implicit\n",
            "Collaborative\n",
            "Filtering\n",
            "Model\n",
            "Selection\n",
            "for\n",
            "Production\n",
            "System\n",
            "via\n",
            "Automated\n",
            "Online\n",
            "Experiments\n",
            "On\n",
            "the\n",
            "Almost\n",
            "Sure\n",
            "Convergence\n",
            "of\n",
            "Stochastic\n",
            "Gradient\n",
            "Descent\n",
            "in\n",
            "Non-Convex\n",
            "Problems\n",
            "Automatic\n",
            "Perturbation\n",
            "Analysis\n",
            "for\n",
            "Scalable\n",
            "Certified\n",
            "Robustness\n",
            "and\n",
            "Beyond\n",
            "Adaptation\n",
            "Properties\n",
            "Allow\n",
            "Identification\n",
            "of\n",
            "Optimized\n",
            "Neural\n",
            "Codes\n",
            "Global\n",
            "Convergence\n",
            "and\n",
            "Variance\n",
            "Reduction\n",
            "for\n",
            "a\n",
            "Class\n",
            "of\n",
            "Nonconvex-Nonconcave\n",
            "Minimax\n",
            "Problems\n",
            "Model-Based\n",
            "Multi-Agent\n",
            "RL\n",
            "in\n",
            "Zero-Sum\n",
            "Markov\n",
            "Games\n",
            "with\n",
            "Near-Optimal\n",
            "Sample\n",
            "Complexity\n",
            "Conservative\n",
            "Q-Learning\n",
            "for\n",
            "Offline\n",
            "Reinforcement\n",
            "Learning\n",
            "Online\n",
            "Influence\n",
            "Maximization\n",
            "under\n",
            "Linear\n",
            "Threshold\n",
            "Model\n",
            "Ensembling\n",
            "geophysical\n",
            "models\n",
            "with\n",
            "Bayesian\n",
            "Neural\n",
            "Networks\n",
            "Delving\n",
            "into\n",
            "the\n",
            "Cyclic\n",
            "Mechanism\n",
            "in\n",
            "Semi-supervised\n",
            "Video\n",
            "Object\n",
            "Segmentation\n",
            "Asymmetric\n",
            "Shapley\n",
            "values\n",
            ":\n",
            "incorporating\n",
            "causal\n",
            "knowledge\n",
            "into\n",
            "model-agnostic\n",
            "explainability\n",
            "Understanding\n",
            "Deep\n",
            "Architecture\n",
            "with\n",
            "Reasoning\n",
            "Layer\n",
            "Planning\n",
            "in\n",
            "Markov\n",
            "Decision\n",
            "Processes\n",
            "with\n",
            "Gap-Dependent\n",
            "Sample\n",
            "Complexity\n",
            "Provably\n",
            "Good\n",
            "Batch\n",
            "Off-Policy\n",
            "Reinforcement\n",
            "Learning\n",
            "Without\n",
            "Great\n",
            "Exploration\n",
            "Detection\n",
            "as\n",
            "Regression\n",
            ":\n",
            "Certified\n",
            "Object\n",
            "Detection\n",
            "with\n",
            "Median\n",
            "Smoothing\n",
            "Contextual\n",
            "Reserve\n",
            "Price\n",
            "Optimization\n",
            "in\n",
            "Auctions\n",
            "via\n",
            "Mixed\n",
            "Integer\n",
            "Programming\n",
            "ExpandNets\n",
            ":\n",
            "Linear\n",
            "Over-parameterization\n",
            "to\n",
            "Train\n",
            "Compact\n",
            "Convolutional\n",
            "Networks\n",
            "FleXOR\n",
            ":\n",
            "Trainable\n",
            "Fractional\n",
            "Quantization\n",
            "The\n",
            "Implications\n",
            "of\n",
            "Local\n",
            "Correlation\n",
            "on\n",
            "Learning\n",
            "Some\n",
            "Deep\n",
            "Functions\n",
            "Learning\n",
            "to\n",
            "search\n",
            "efficiently\n",
            "for\n",
            "causally\n",
            "near-optimal\n",
            "treatments\n",
            "A\n",
            "Game\n",
            "Theoretic\n",
            "Analysis\n",
            "of\n",
            "Additive\n",
            "Adversarial\n",
            "Attacks\n",
            "and\n",
            "Defenses\n",
            "Posterior\n",
            "Network\n",
            ":\n",
            "Uncertainty\n",
            "Estimation\n",
            "without\n",
            "OOD\n",
            "Samples\n",
            "via\n",
            "Density-Based\n",
            "Pseudo-Counts\n",
            "Recurrent\n",
            "Quantum\n",
            "Neural\n",
            "Networks\n",
            "No-Regret\n",
            "Learning\n",
            "and\n",
            "Mixed\n",
            "Nash\n",
            "Equilibria\n",
            ":\n",
            "They\n",
            "Do\n",
            "Not\n",
            "Mix\n",
            "A\n",
            "Unifying\n",
            "View\n",
            "of\n",
            "Optimism\n",
            "in\n",
            "Episodic\n",
            "Reinforcement\n",
            "Learning\n",
            "Continuous\n",
            "Submodular\n",
            "Maximization\n",
            ":\n",
            "Beyond\n",
            "DR-Submodularity\n",
            "An\n",
            "Asymptotically\n",
            "Optimal\n",
            "Primal-Dual\n",
            "Incremental\n",
            "Algorithm\n",
            "for\n",
            "Contextual\n",
            "Linear\n",
            "Bandits\n",
            "Assessing\n",
            "SATNet\n",
            "'s\n",
            "Ability\n",
            "to\n",
            "Solve\n",
            "the\n",
            "Symbol\n",
            "Grounding\n",
            "Problem\n",
            "A\n",
            "Bayesian\n",
            "Nonparametrics\n",
            "View\n",
            "into\n",
            "Deep\n",
            "Representations\n",
            "On\n",
            "the\n",
            "Similarity\n",
            "between\n",
            "the\n",
            "Laplace\n",
            "and\n",
            "Neural\n",
            "Tangent\n",
            "Kernels\n",
            "A\n",
            "causal\n",
            "view\n",
            "of\n",
            "compositional\n",
            "zero-shot\n",
            "recognition\n",
            "HiPPO\n",
            ":\n",
            "Recurrent\n",
            "Memory\n",
            "with\n",
            "Optimal\n",
            "Polynomial\n",
            "Projections\n",
            "Auto\n",
            "Learning\n",
            "Attention\n",
            "CASTLE\n",
            ":\n",
            "Regularization\n",
            "via\n",
            "Auxiliary\n",
            "Causal\n",
            "Graph\n",
            "Discovery\n",
            "Long-Tailed\n",
            "Classification\n",
            "by\n",
            "Keeping\n",
            "the\n",
            "Good\n",
            "and\n",
            "Removing\n",
            "the\n",
            "Bad\n",
            "Momentum\n",
            "Causal\n",
            "Effect\n",
            "Explainable\n",
            "Voting\n",
            "Deep\n",
            "Archimedean\n",
            "Copulas\n",
            "Re-Examining\n",
            "Linear\n",
            "Embeddings\n",
            "for\n",
            "High-Dimensional\n",
            "Bayesian\n",
            "Optimization\n",
            "UnModNet\n",
            ":\n",
            "Learning\n",
            "to\n",
            "Unwrap\n",
            "a\n",
            "Modulo\n",
            "Image\n",
            "for\n",
            "High\n",
            "Dynamic\n",
            "Range\n",
            "Imaging\n",
            "Thunder\n",
            ":\n",
            "a\n",
            "Fast\n",
            "Coordinate\n",
            "Selection\n",
            "Solver\n",
            "for\n",
            "Sparse\n",
            "Learning\n",
            "Neural\n",
            "Networks\n",
            "Fail\n",
            "to\n",
            "Learn\n",
            "Periodic\n",
            "Functions\n",
            "and\n",
            "How\n",
            "to\n",
            "Fix\n",
            "It\n",
            "Distribution\n",
            "Matching\n",
            "for\n",
            "Crowd\n",
            "Counting\n",
            "Correspondence\n",
            "learning\n",
            "via\n",
            "linearly-invariant\n",
            "embedding\n",
            "Learning\n",
            "to\n",
            "Dispatch\n",
            "for\n",
            "Job\n",
            "Shop\n",
            "Scheduling\n",
            "via\n",
            "Deep\n",
            "Reinforcement\n",
            "Learning\n",
            "On\n",
            "Adaptive\n",
            "Attacks\n",
            "to\n",
            "Adversarial\n",
            "Example\n",
            "Defenses\n",
            "Sinkhorn\n",
            "Natural\n",
            "Gradient\n",
            "for\n",
            "Generative\n",
            "Models\n",
            "Online\n",
            "Sinkhorn\n",
            ":\n",
            "Optimal\n",
            "Transport\n",
            "distances\n",
            "from\n",
            "sample\n",
            "streams\n",
            "Ultrahyperbolic\n",
            "Representation\n",
            "Learning\n",
            "Locally-Adaptive\n",
            "Nonparametric\n",
            "Online\n",
            "Learning\n",
            "Compositional\n",
            "Generalization\n",
            "via\n",
            "Neural-Symbolic\n",
            "Stack\n",
            "Machines\n",
            "Graphon\n",
            "Neural\n",
            "Networks\n",
            "and\n",
            "the\n",
            "Transferability\n",
            "of\n",
            "Graph\n",
            "Neural\n",
            "Networks\n",
            "Unreasonable\n",
            "Effectiveness\n",
            "of\n",
            "Greedy\n",
            "Algorithms\n",
            "in\n",
            "Multi-Armed\n",
            "Bandit\n",
            "with\n",
            "Many\n",
            "Arms\n",
            "Gamma-Models\n",
            ":\n",
            "Generative\n",
            "Temporal\n",
            "Difference\n",
            "Learning\n",
            "for\n",
            "Infinite-Horizon\n",
            "Prediction\n",
            "Deep\n",
            "Transformers\n",
            "with\n",
            "Latent\n",
            "Depth\n",
            "Neural\n",
            "Mesh\n",
            "Flow\n",
            ":\n",
            "3D\n",
            "Manifold\n",
            "Mesh\n",
            "Generation\n",
            "via\n",
            "Diffeomorphic\n",
            "Flows\n",
            "Statistical\n",
            "control\n",
            "for\n",
            "spatio-temporal\n",
            "MEG/EEG\n",
            "source\n",
            "imaging\n",
            "with\n",
            "desparsified\n",
            "mutli-task\n",
            "Lasso\n",
            "A\n",
            "Scalable\n",
            "MIP-based\n",
            "Method\n",
            "for\n",
            "Learning\n",
            "Optimal\n",
            "Multivariate\n",
            "Decision\n",
            "Trees\n",
            "Efficient\n",
            "Exact\n",
            "Verification\n",
            "of\n",
            "Binarized\n",
            "Neural\n",
            "Networks\n",
            "Ultra-Low\n",
            "Precision\n",
            "4-bit\n",
            "Training\n",
            "of\n",
            "Deep\n",
            "Neural\n",
            "Networks\n",
            "Bridging\n",
            "the\n",
            "Gap\n",
            "between\n",
            "Sample-based\n",
            "and\n",
            "One-shot\n",
            "Neural\n",
            "Architecture\n",
            "Search\n",
            "with\n",
            "BONAS\n",
            "On\n",
            "Numerosity\n",
            "of\n",
            "Deep\n",
            "Neural\n",
            "Networks\n",
            "Outlier\n",
            "Robust\n",
            "Mean\n",
            "Estimation\n",
            "with\n",
            "Subgaussian\n",
            "Rates\n",
            "via\n",
            "Stability\n",
            "Self-Supervised\n",
            "Relationship\n",
            "Probing\n",
            "Information\n",
            "Theoretic\n",
            "Counterfactual\n",
            "Learning\n",
            "from\n",
            "Missing-Not-At-Random\n",
            "Feedback\n",
            "Prophet\n",
            "Attention\n",
            ":\n",
            "Predicting\n",
            "Attention\n",
            "with\n",
            "Future\n",
            "Attention\n",
            "Language\n",
            "Models\n",
            "are\n",
            "Few-Shot\n",
            "Learners\n",
            "Margins\n",
            "are\n",
            "Insufficient\n",
            "for\n",
            "Explaining\n",
            "Gradient\n",
            "Boosting\n",
            "Fourier-transform-based\n",
            "attribution\n",
            "priors\n",
            "improve\n",
            "the\n",
            "interpretability\n",
            "and\n",
            "stability\n",
            "of\n",
            "deep\n",
            "learning\n",
            "models\n",
            "for\n",
            "genomics\n",
            "MomentumRNN\n",
            ":\n",
            "Integrating\n",
            "Momentum\n",
            "into\n",
            "Recurrent\n",
            "Neural\n",
            "Networks\n",
            "Marginal\n",
            "Utility\n",
            "for\n",
            "Planning\n",
            "in\n",
            "Continuous\n",
            "or\n",
            "Large\n",
            "Discrete\n",
            "Action\n",
            "Spaces\n",
            "Projected\n",
            "Stein\n",
            "Variational\n",
            "Gradient\n",
            "Descent\n",
            "Minimax\n",
            "Lower\n",
            "Bounds\n",
            "for\n",
            "Transfer\n",
            "Learning\n",
            "with\n",
            "Linear\n",
            "and\n",
            "One-hidden\n",
            "Layer\n",
            "Neural\n",
            "Networks\n",
            "SE\n",
            "(\n",
            "3\n",
            ")\n",
            "-Transformers\n",
            ":\n",
            "3D\n",
            "Roto-Translation\n",
            "Equivariant\n",
            "Attention\n",
            "Networks\n",
            "On\n",
            "the\n",
            "equivalence\n",
            "of\n",
            "molecular\n",
            "graph\n",
            "convolution\n",
            "and\n",
            "molecular\n",
            "wave\n",
            "function\n",
            "with\n",
            "poor\n",
            "basis\n",
            "set\n",
            "The\n",
            "Power\n",
            "of\n",
            "Predictions\n",
            "in\n",
            "Online\n",
            "Control\n",
            "Learning\n",
            "Affordance\n",
            "Landscapes\n",
            "for\n",
            "Interaction\n",
            "Exploration\n",
            "in\n",
            "3D\n",
            "Environments\n",
            "Cooperative\n",
            "Multi-player\n",
            "Bandit\n",
            "Optimization\n",
            "Tight\n",
            "First-\n",
            "and\n",
            "Second-Order\n",
            "Regret\n",
            "Bounds\n",
            "for\n",
            "Adversarial\n",
            "Linear\n",
            "Bandits\n",
            "Just\n",
            "Pick\n",
            "a\n",
            "Sign\n",
            ":\n",
            "Optimizing\n",
            "Deep\n",
            "Multitask\n",
            "Models\n",
            "with\n",
            "Gradient\n",
            "Sign\n",
            "Dropout\n",
            "A\n",
            "Loss\n",
            "Function\n",
            "for\n",
            "Generative\n",
            "Neural\n",
            "Networks\n",
            "Based\n",
            "on\n",
            "Watson\n",
            "’\n",
            "s\n",
            "Perceptual\n",
            "Model\n",
            "Dynamic\n",
            "Fusion\n",
            "of\n",
            "Eye\n",
            "Movement\n",
            "Data\n",
            "and\n",
            "Verbal\n",
            "Narrations\n",
            "in\n",
            "Knowledge-rich\n",
            "Domains\n",
            "Scalable\n",
            "Multi-Agent\n",
            "Reinforcement\n",
            "Learning\n",
            "for\n",
            "Networked\n",
            "Systems\n",
            "with\n",
            "Average\n",
            "Reward\n",
            "Optimizing\n",
            "Neural\n",
            "Networks\n",
            "via\n",
            "Koopman\n",
            "Operator\n",
            "Theory\n",
            "SVGD\n",
            "as\n",
            "a\n",
            "kernelized\n",
            "Wasserstein\n",
            "gradient\n",
            "flow\n",
            "of\n",
            "the\n",
            "chi-squared\n",
            "divergence\n",
            "Adversarial\n",
            "Robustness\n",
            "of\n",
            "Supervised\n",
            "Sparse\n",
            "Coding\n",
            "Differentiable\n",
            "Meta-Learning\n",
            "of\n",
            "Bandit\n",
            "Policies\n",
            "Biologically\n",
            "Inspired\n",
            "Mechanisms\n",
            "for\n",
            "Adversarial\n",
            "Robustness\n",
            "Statistical-Query\n",
            "Lower\n",
            "Bounds\n",
            "via\n",
            "Functional\n",
            "Gradients\n",
            "Near-Optimal\n",
            "Reinforcement\n",
            "Learning\n",
            "with\n",
            "Self-Play\n",
            "Network\n",
            "Diffusions\n",
            "via\n",
            "Neural\n",
            "Mean-Field\n",
            "Dynamics\n",
            "Self-Distillation\n",
            "as\n",
            "Instance-Specific\n",
            "Label\n",
            "Smoothing\n",
            "Towards\n",
            "Problem-dependent\n",
            "Optimal\n",
            "Learning\n",
            "Rates\n",
            "Cross-lingual\n",
            "Retrieval\n",
            "for\n",
            "Iterative\n",
            "Self-Supervised\n",
            "Training\n",
            "Rethinking\n",
            "pooling\n",
            "in\n",
            "graph\n",
            "neural\n",
            "networks\n",
            "Pointer\n",
            "Graph\n",
            "Networks\n",
            "Gradient\n",
            "Regularized\n",
            "V-Learning\n",
            "for\n",
            "Dynamic\n",
            "Treatment\n",
            "Regimes\n",
            "Faster\n",
            "Wasserstein\n",
            "Distance\n",
            "Estimation\n",
            "with\n",
            "the\n",
            "Sinkhorn\n",
            "Divergence\n",
            "Forethought\n",
            "and\n",
            "Hindsight\n",
            "in\n",
            "Credit\n",
            "Assignment\n",
            "Robust\n",
            "Recursive\n",
            "Partitioning\n",
            "for\n",
            "Heterogeneous\n",
            "Treatment\n",
            "Effects\n",
            "with\n",
            "Uncertainty\n",
            "Quantification\n",
            "Rescuing\n",
            "neural\n",
            "spike\n",
            "train\n",
            "models\n",
            "from\n",
            "bad\n",
            "MLE\n",
            "Lower\n",
            "Bounds\n",
            "and\n",
            "Optimal\n",
            "Algorithms\n",
            "for\n",
            "Personalized\n",
            "Federated\n",
            "Learning\n",
            "Black-Box\n",
            "Certification\n",
            "with\n",
            "Randomized\n",
            "Smoothing\n",
            ":\n",
            "A\n",
            "Functional\n",
            "Optimization\n",
            "Based\n",
            "Framework\n",
            "Deep\n",
            "Imitation\n",
            "Learning\n",
            "for\n",
            "Bimanual\n",
            "Robotic\n",
            "Manipulation\n",
            "Stationary\n",
            "Activations\n",
            "for\n",
            "Uncertainty\n",
            "Calibration\n",
            "in\n",
            "Deep\n",
            "Learning\n",
            "Ensemble\n",
            "Distillation\n",
            "for\n",
            "Robust\n",
            "Model\n",
            "Fusion\n",
            "in\n",
            "Federated\n",
            "Learning\n",
            "Falcon\n",
            ":\n",
            "Fast\n",
            "Spectral\n",
            "Inference\n",
            "on\n",
            "Encrypted\n",
            "Data\n",
            "On\n",
            "Power\n",
            "Laws\n",
            "in\n",
            "Deep\n",
            "Ensembles\n",
            "Practical\n",
            "Quasi-Newton\n",
            "Methods\n",
            "for\n",
            "Training\n",
            "Deep\n",
            "Neural\n",
            "Networks\n",
            "Approximation\n",
            "Based\n",
            "Variance\n",
            "Reduction\n",
            "for\n",
            "Reparameterization\n",
            "Gradients\n",
            "Inference\n",
            "Stage\n",
            "Optimization\n",
            "for\n",
            "Cross-scenario\n",
            "3D\n",
            "Human\n",
            "Pose\n",
            "Estimation\n",
            "Consistent\n",
            "feature\n",
            "selection\n",
            "for\n",
            "analytic\n",
            "deep\n",
            "neural\n",
            "networks\n",
            "Glance\n",
            "and\n",
            "Focus\n",
            ":\n",
            "a\n",
            "Dynamic\n",
            "Approach\n",
            "to\n",
            "Reducing\n",
            "Spatial\n",
            "Redundancy\n",
            "in\n",
            "Image\n",
            "Classification\n",
            "Information\n",
            "Maximization\n",
            "for\n",
            "Few-Shot\n",
            "Learning\n",
            "Inverse\n",
            "Reinforcement\n",
            "Learning\n",
            "from\n",
            "a\n",
            "Gradient-based\n",
            "Learner\n",
            "Bayesian\n",
            "Multi-type\n",
            "Mean\n",
            "Field\n",
            "Multi-agent\n",
            "Imitation\n",
            "Learning\n",
            "Bayesian\n",
            "Robust\n",
            "Optimization\n",
            "for\n",
            "Imitation\n",
            "Learning\n",
            "Multiview\n",
            "Neural\n",
            "Surface\n",
            "Reconstruction\n",
            "by\n",
            "Disentangling\n",
            "Geometry\n",
            "and\n",
            "Appearance\n",
            "Riemannian\n",
            "Continuous\n",
            "Normalizing\n",
            "Flows\n",
            "Attention-Gated\n",
            "Brain\n",
            "Propagation\n",
            ":\n",
            "How\n",
            "the\n",
            "brain\n",
            "can\n",
            "implement\n",
            "reward-based\n",
            "error\n",
            "backpropagation\n",
            "Asymptotic\n",
            "Guarantees\n",
            "for\n",
            "Generative\n",
            "Modeling\n",
            "Based\n",
            "on\n",
            "the\n",
            "Smooth\n",
            "Wasserstein\n",
            "Distance\n",
            "Online\n",
            "Robust\n",
            "Regression\n",
            "via\n",
            "SGD\n",
            "on\n",
            "the\n",
            "l1\n",
            "loss\n",
            "PRANK\n",
            ":\n",
            "motion\n",
            "Prediction\n",
            "based\n",
            "on\n",
            "RANKing\n",
            "Fighting\n",
            "Copycat\n",
            "Agents\n",
            "in\n",
            "Behavioral\n",
            "Cloning\n",
            "from\n",
            "Observation\n",
            "Histories\n",
            "Tight\n",
            "Nonparametric\n",
            "Convergence\n",
            "Rates\n",
            "for\n",
            "Stochastic\n",
            "Gradient\n",
            "Descent\n",
            "under\n",
            "the\n",
            "Noiseless\n",
            "Linear\n",
            "Model\n",
            "Structured\n",
            "Prediction\n",
            "for\n",
            "Conditional\n",
            "Meta-Learning\n",
            "Optimal\n",
            "Lottery\n",
            "Tickets\n",
            "via\n",
            "Subset\n",
            "Sum\n",
            ":\n",
            "Logarithmic\n",
            "Over-Parameterization\n",
            "is\n",
            "Sufficient\n",
            "The\n",
            "Hateful\n",
            "Memes\n",
            "Challenge\n",
            ":\n",
            "Detecting\n",
            "Hate\n",
            "Speech\n",
            "in\n",
            "Multimodal\n",
            "Memes\n",
            "Stochasticity\n",
            "of\n",
            "Deterministic\n",
            "Gradient\n",
            "Descent\n",
            ":\n",
            "Large\n",
            "Learning\n",
            "Rate\n",
            "for\n",
            "Multiscale\n",
            "Objective\n",
            "Function\n",
            "Identifying\n",
            "Learning\n",
            "Rules\n",
            "From\n",
            "Neural\n",
            "Network\n",
            "Observables\n",
            "Optimal\n",
            "Approximation\n",
            "-\n",
            "Smoothness\n",
            "Tradeoffs\n",
            "for\n",
            "Soft-Max\n",
            "Functions\n",
            "Weakly-Supervised\n",
            "Reinforcement\n",
            "Learning\n",
            "for\n",
            "Controllable\n",
            "Behavior\n",
            "Improving\n",
            "Policy-Constrained\n",
            "Kidney\n",
            "Exchange\n",
            "via\n",
            "Pre-Screening\n",
            "Learning\n",
            "abstract\n",
            "structure\n",
            "for\n",
            "drawing\n",
            "by\n",
            "efficient\n",
            "motor\n",
            "program\n",
            "induction\n",
            "Why\n",
            "Do\n",
            "Deep\n",
            "Residual\n",
            "Networks\n",
            "Generalize\n",
            "Better\n",
            "than\n",
            "Deep\n",
            "Feedforward\n",
            "Networks\n",
            "?\n",
            "--\n",
            "-\n",
            "A\n",
            "Neural\n",
            "Tangent\n",
            "Kernel\n",
            "Perspective\n",
            "Dual\n",
            "Instrumental\n",
            "Variable\n",
            "Regression\n",
            "Stochastic\n",
            "Gradient\n",
            "Descent\n",
            "in\n",
            "Correlated\n",
            "Settings\n",
            ":\n",
            "A\n",
            "Study\n",
            "on\n",
            "Gaussian\n",
            "Processes\n",
            "Interventional\n",
            "Few-Shot\n",
            "Learning\n",
            "Minimax\n",
            "Value\n",
            "Interval\n",
            "for\n",
            "Off-Policy\n",
            "Evaluation\n",
            "and\n",
            "Policy\n",
            "Optimization\n",
            "Biased\n",
            "Stochastic\n",
            "First-Order\n",
            "Methods\n",
            "for\n",
            "Conditional\n",
            "Stochastic\n",
            "Optimization\n",
            "and\n",
            "Applications\n",
            "in\n",
            "Meta\n",
            "Learning\n",
            "ShiftAddNet\n",
            ":\n",
            "A\n",
            "Hardware-Inspired\n",
            "Deep\n",
            "Network\n",
            "Network-to-Network\n",
            "Translation\n",
            "with\n",
            "Conditional\n",
            "Invertible\n",
            "Neural\n",
            "Networks\n",
            "Intra-Processing\n",
            "Methods\n",
            "for\n",
            "Debiasing\n",
            "Neural\n",
            "Networks\n",
            "Finding\n",
            "Second-Order\n",
            "Stationary\n",
            "Points\n",
            "Efficiently\n",
            "in\n",
            "Smooth\n",
            "Nonconvex\n",
            "Linearly\n",
            "Constrained\n",
            "Optimization\n",
            "Problems\n",
            "Model-based\n",
            "Policy\n",
            "Optimization\n",
            "with\n",
            "Unsupervised\n",
            "Model\n",
            "Adaptation\n",
            "Implicit\n",
            "Regularization\n",
            "and\n",
            "Convergence\n",
            "for\n",
            "Weight\n",
            "Normalization\n",
            "Geometric\n",
            "All-way\n",
            "Boolean\n",
            "Tensor\n",
            "Decomposition\n",
            "Modular\n",
            "Meta-Learning\n",
            "with\n",
            "Shrinkage\n",
            "A/B\n",
            "Testing\n",
            "in\n",
            "Dense\n",
            "Large-Scale\n",
            "Networks\n",
            ":\n",
            "Design\n",
            "and\n",
            "Inference\n",
            "What\n",
            "Neural\n",
            "Networks\n",
            "Memorize\n",
            "and\n",
            "Why\n",
            ":\n",
            "Discovering\n",
            "the\n",
            "Long\n",
            "Tail\n",
            "via\n",
            "Influence\n",
            "Estimation\n",
            "Partially\n",
            "View-aligned\n",
            "Clustering\n",
            "Partial\n",
            "Optimal\n",
            "Tranport\n",
            "with\n",
            "applications\n",
            "on\n",
            "Positive-Unlabeled\n",
            "Learning\n",
            "Toward\n",
            "the\n",
            "Fundamental\n",
            "Limits\n",
            "of\n",
            "Imitation\n",
            "Learning\n",
            "Logarithmic\n",
            "Pruning\n",
            "is\n",
            "All\n",
            "You\n",
            "Need\n",
            "Hold\n",
            "me\n",
            "tight\n",
            "!\n",
            "Influence\n",
            "of\n",
            "discriminative\n",
            "features\n",
            "on\n",
            "deep\n",
            "network\n",
            "boundaries\n",
            "Learning\n",
            "from\n",
            "Mixtures\n",
            "of\n",
            "Private\n",
            "and\n",
            "Public\n",
            "Populations\n",
            "Adversarial\n",
            "Weight\n",
            "Perturbation\n",
            "Helps\n",
            "Robust\n",
            "Generalization\n",
            "Stateful\n",
            "Posted\n",
            "Pricing\n",
            "with\n",
            "Vanishing\n",
            "Regret\n",
            "via\n",
            "Dynamic\n",
            "Deterministic\n",
            "Markov\n",
            "Decision\n",
            "Processes\n",
            "Adversarial\n",
            "Self-Supervised\n",
            "Contrastive\n",
            "Learning\n",
            "Normalizing\n",
            "Kalman\n",
            "Filters\n",
            "for\n",
            "Multivariate\n",
            "Time\n",
            "Series\n",
            "Analysis\n",
            "Learning\n",
            "to\n",
            "summarize\n",
            "with\n",
            "human\n",
            "feedback\n",
            "Fourier\n",
            "Spectrum\n",
            "Discrepancies\n",
            "in\n",
            "Deep\n",
            "Network\n",
            "Generated\n",
            "Images\n",
            "Lamina-specific\n",
            "neuronal\n",
            "properties\n",
            "promote\n",
            "robust\n",
            ",\n",
            "stable\n",
            "signal\n",
            "propagation\n",
            "in\n",
            "feedforward\n",
            "networks\n",
            "Learning\n",
            "Dynamic\n",
            "Belief\n",
            "Graphs\n",
            "to\n",
            "Generalize\n",
            "on\n",
            "Text-Based\n",
            "Games\n",
            "Triple\n",
            "descent\n",
            "and\n",
            "the\n",
            "two\n",
            "kinds\n",
            "of\n",
            "overfitting\n",
            ":\n",
            "where\n",
            "&\n",
            "why\n",
            "do\n",
            "they\n",
            "appear\n",
            "?\n",
            "Multimodal\n",
            "Graph\n",
            "Networks\n",
            "for\n",
            "Compositional\n",
            "Generalization\n",
            "in\n",
            "Visual\n",
            "Question\n",
            "Answering\n",
            "Learning\n",
            "Graph\n",
            "Structure\n",
            "With\n",
            "A\n",
            "Finite-State\n",
            "Automaton\n",
            "Layer\n",
            "A\n",
            "Universal\n",
            "Approximation\n",
            "Theorem\n",
            "of\n",
            "Deep\n",
            "Neural\n",
            "Networks\n",
            "for\n",
            "Expressing\n",
            "Probability\n",
            "Distributions\n",
            "Unsupervised\n",
            "object-centric\n",
            "video\n",
            "generation\n",
            "and\n",
            "decomposition\n",
            "in\n",
            "3D\n",
            "Domain\n",
            "Generalization\n",
            "for\n",
            "Medical\n",
            "Imaging\n",
            "Classification\n",
            "with\n",
            "Linear-Dependency\n",
            "Regularization\n",
            "Multi-label\n",
            "classification\n",
            ":\n",
            "do\n",
            "Hamming\n",
            "loss\n",
            "and\n",
            "subset\n",
            "accuracy\n",
            "really\n",
            "conflict\n",
            "with\n",
            "each\n",
            "other\n",
            "?\n",
            "A\n",
            "Novel\n",
            "Automated\n",
            "Curriculum\n",
            "Strategy\n",
            "to\n",
            "Solve\n",
            "Hard\n",
            "Sokoban\n",
            "Planning\n",
            "Instances\n",
            "Causal\n",
            "analysis\n",
            "of\n",
            "Covid-19\n",
            "Spread\n",
            "in\n",
            "Germany\n",
            "Locally\n",
            "private\n",
            "non-asymptotic\n",
            "testing\n",
            "of\n",
            "discrete\n",
            "distributions\n",
            "is\n",
            "faster\n",
            "using\n",
            "interactive\n",
            "mechanisms\n",
            "Adaptive\n",
            "Gradient\n",
            "Quantization\n",
            "for\n",
            "Data-Parallel\n",
            "SGD\n",
            "Finite\n",
            "Continuum-Armed\n",
            "Bandits\n",
            "Removing\n",
            "Bias\n",
            "in\n",
            "Multi-modal\n",
            "Classifiers\n",
            ":\n",
            "Regularization\n",
            "by\n",
            "Maximizing\n",
            "Functional\n",
            "Entropies\n",
            "Compact\n",
            "task\n",
            "representations\n",
            "as\n",
            "a\n",
            "normative\n",
            "model\n",
            "for\n",
            "higher-order\n",
            "brain\n",
            "activity\n",
            "Robust-Adaptive\n",
            "Control\n",
            "of\n",
            "Linear\n",
            "Systems\n",
            ":\n",
            "beyond\n",
            "Quadratic\n",
            "Costs\n",
            "Co-exposure\n",
            "Maximization\n",
            "in\n",
            "Online\n",
            "Social\n",
            "Networks\n",
            "UCLID-Net\n",
            ":\n",
            "Single\n",
            "View\n",
            "Reconstruction\n",
            "in\n",
            "Object\n",
            "Space\n",
            "Reinforcement\n",
            "Learning\n",
            "for\n",
            "Control\n",
            "with\n",
            "Multiple\n",
            "Frequencies\n",
            "Complex\n",
            "Dynamics\n",
            "in\n",
            "Simple\n",
            "Neural\n",
            "Networks\n",
            ":\n",
            "Understanding\n",
            "Gradient\n",
            "Flow\n",
            "in\n",
            "Phase\n",
            "Retrieval\n",
            "Neural\n",
            "Message\n",
            "Passing\n",
            "for\n",
            "Multi-Relational\n",
            "Ordered\n",
            "and\n",
            "Recursive\n",
            "Hypergraphs\n",
            "A\n",
            "Unified\n",
            "View\n",
            "of\n",
            "Label\n",
            "Shift\n",
            "Estimation\n",
            "Optimal\n",
            "Private\n",
            "Median\n",
            "Estimation\n",
            "under\n",
            "Minimal\n",
            "Distributional\n",
            "Assumptions\n",
            "Breaking\n",
            "the\n",
            "Communication-Privacy-Accuracy\n",
            "Trilemma\n",
            "Audeo\n",
            ":\n",
            "Audio\n",
            "Generation\n",
            "for\n",
            "a\n",
            "Silent\n",
            "Performance\n",
            "Video\n",
            "Ode\n",
            "to\n",
            "an\n",
            "ODE\n",
            "Self-Distillation\n",
            "Amplifies\n",
            "Regularization\n",
            "in\n",
            "Hilbert\n",
            "Space\n",
            "Coupling-based\n",
            "Invertible\n",
            "Neural\n",
            "Networks\n",
            "Are\n",
            "Universal\n",
            "Diffeomorphism\n",
            "Approximators\n",
            "Community\n",
            "detection\n",
            "using\n",
            "fast\n",
            "low-cardinality\n",
            "semidefinite\n",
            "programming\n",
            "Modeling\n",
            "Noisy\n",
            "Annotations\n",
            "for\n",
            "Crowd\n",
            "Counting\n",
            "An\n",
            "operator\n",
            "view\n",
            "of\n",
            "policy\n",
            "gradient\n",
            "methods\n",
            "Demystifying\n",
            "Contrastive\n",
            "Self-Supervised\n",
            "Learning\n",
            ":\n",
            "Invariances\n",
            ",\n",
            "Augmentations\n",
            "and\n",
            "Dataset\n",
            "Biases\n",
            "Online\n",
            "MAP\n",
            "Inference\n",
            "of\n",
            "Determinantal\n",
            "Point\n",
            "Processes\n",
            "Video\n",
            "Object\n",
            "Segmentation\n",
            "with\n",
            "Adaptive\n",
            "Feature\n",
            "Bank\n",
            "and\n",
            "Uncertain-Region\n",
            "Refinement\n",
            "Inferring\n",
            "learning\n",
            "rules\n",
            "from\n",
            "animal\n",
            "decision-making\n",
            "Input-Aware\n",
            "Dynamic\n",
            "Backdoor\n",
            "Attack\n",
            "How\n",
            "hard\n",
            "is\n",
            "to\n",
            "distinguish\n",
            "graphs\n",
            "with\n",
            "graph\n",
            "neural\n",
            "networks\n",
            "?\n",
            "Minimax\n",
            "Regret\n",
            "of\n",
            "Switching-Constrained\n",
            "Online\n",
            "Convex\n",
            "Optimization\n",
            ":\n",
            "No\n",
            "Phase\n",
            "Transition\n",
            "Dual\n",
            "Manifold\n",
            "Adversarial\n",
            "Robustness\n",
            ":\n",
            "Defense\n",
            "against\n",
            "Lp\n",
            "and\n",
            "non-Lp\n",
            "Adversarial\n",
            "Attacks\n",
            "Cross-Scale\n",
            "Internal\n",
            "Graph\n",
            "Neural\n",
            "Network\n",
            "for\n",
            "Image\n",
            "Super-Resolution\n",
            "Unsupervised\n",
            "Representation\n",
            "Learning\n",
            "by\n",
            "Invariance\n",
            "Propagation\n",
            "Restoring\n",
            "Negative\n",
            "Information\n",
            "in\n",
            "Few-Shot\n",
            "Object\n",
            "Detection\n",
            "Do\n",
            "Adversarially\n",
            "Robust\n",
            "ImageNet\n",
            "Models\n",
            "Transfer\n",
            "Better\n",
            "?\n",
            "Robust\n",
            "Correction\n",
            "of\n",
            "Sampling\n",
            "Bias\n",
            "using\n",
            "Cumulative\n",
            "Distribution\n",
            "Functions\n",
            "Personalized\n",
            "Federated\n",
            "Learning\n",
            "with\n",
            "Theoretical\n",
            "Guarantees\n",
            ":\n",
            "A\n",
            "Model-Agnostic\n",
            "Meta-Learning\n",
            "Approach\n",
            "Pixel-Level\n",
            "Cycle\n",
            "Association\n",
            ":\n",
            "A\n",
            "New\n",
            "Perspective\n",
            "for\n",
            "Domain\n",
            "Adaptive\n",
            "Semantic\n",
            "Segmentation\n",
            "Classification\n",
            "with\n",
            "Valid\n",
            "and\n",
            "Adaptive\n",
            "Coverage\n",
            "Learning\n",
            "Global\n",
            "Transparent\n",
            "Models\n",
            "consistent\n",
            "with\n",
            "Local\n",
            "Contrastive\n",
            "Explanations\n",
            "Learning\n",
            "to\n",
            "Approximate\n",
            "a\n",
            "Bregman\n",
            "Divergence\n",
            "Diverse\n",
            "Image\n",
            "Captioning\n",
            "with\n",
            "Context-Object\n",
            "Split\n",
            "Latent\n",
            "Spaces\n",
            "Learning\n",
            "Disentangled\n",
            "Representations\n",
            "of\n",
            "Videos\n",
            "with\n",
            "Missing\n",
            "Data\n",
            "Natural\n",
            "Graph\n",
            "Networks\n",
            "Continual\n",
            "Learning\n",
            "with\n",
            "Node-Importance\n",
            "based\n",
            "Adaptive\n",
            "Group\n",
            "Sparse\n",
            "Regularization\n",
            "Towards\n",
            "Crowdsourced\n",
            "Training\n",
            "of\n",
            "Large\n",
            "Neural\n",
            "Networks\n",
            "using\n",
            "Decentralized\n",
            "Mixture-of-Experts\n",
            "Bidirectional\n",
            "Convolutional\n",
            "Poisson\n",
            "Gamma\n",
            "Dynamical\n",
            "Systems\n",
            "Deep\n",
            "Reinforcement\n",
            "and\n",
            "InfoMax\n",
            "Learning\n",
            "On\n",
            "ranking\n",
            "via\n",
            "sorting\n",
            "by\n",
            "estimated\n",
            "expected\n",
            "utility\n",
            "Distribution-free\n",
            "binary\n",
            "classification\n",
            ":\n",
            "prediction\n",
            "sets\n",
            ",\n",
            "confidence\n",
            "intervals\n",
            "and\n",
            "calibration\n",
            "Closing\n",
            "the\n",
            "Dequantization\n",
            "Gap\n",
            ":\n",
            "PixelCNN\n",
            "as\n",
            "a\n",
            "Single-Layer\n",
            "Flow\n",
            "Sequence\n",
            "to\n",
            "Multi-Sequence\n",
            "Learning\n",
            "via\n",
            "Conditional\n",
            "Chain\n",
            "Mapping\n",
            "for\n",
            "Mixture\n",
            "Signals\n",
            "Variance\n",
            "reduction\n",
            "for\n",
            "Random\n",
            "Coordinate\n",
            "Descent-Langevin\n",
            "Monte\n",
            "Carlo\n",
            "Language\n",
            "as\n",
            "a\n",
            "Cognitive\n",
            "Tool\n",
            "to\n",
            "Imagine\n",
            "Goals\n",
            "in\n",
            "Curiosity\n",
            "Driven\n",
            "Exploration\n",
            "All\n",
            "Word\n",
            "Embeddings\n",
            "from\n",
            "One\n",
            "Embedding\n",
            "Primal\n",
            "Dual\n",
            "Interpretation\n",
            "of\n",
            "the\n",
            "Proximal\n",
            "Stochastic\n",
            "Gradient\n",
            "Langevin\n",
            "Algorithm\n",
            "How\n",
            "to\n",
            "Characterize\n",
            "The\n",
            "Landscape\n",
            "of\n",
            "Overparameterized\n",
            "Convolutional\n",
            "Neural\n",
            "Networks\n",
            "On\n",
            "the\n",
            "Tightness\n",
            "of\n",
            "Semidefinite\n",
            "Relaxations\n",
            "for\n",
            "Certifying\n",
            "Robustness\n",
            "to\n",
            "Adversarial\n",
            "Examples\n",
            "Submodular\n",
            "Meta-Learning\n",
            "Rethinking\n",
            "Pre-training\n",
            "and\n",
            "Self-training\n",
            "Unsupervised\n",
            "Sound\n",
            "Separation\n",
            "Using\n",
            "Mixture\n",
            "Invariant\n",
            "Training\n",
            "Adaptive\n",
            "Discretization\n",
            "for\n",
            "Model-Based\n",
            "Reinforcement\n",
            "Learning\n",
            "CodeCMR\n",
            ":\n",
            "Cross-Modal\n",
            "Retrieval\n",
            "For\n",
            "Function-Level\n",
            "Binary\n",
            "Source\n",
            "Code\n",
            "Matching\n",
            "On\n",
            "Warm-Starting\n",
            "Neural\n",
            "Network\n",
            "Training\n",
            "DAGs\n",
            "with\n",
            "No\n",
            "Fears\n",
            ":\n",
            "A\n",
            "Closer\n",
            "Look\n",
            "at\n",
            "Continuous\n",
            "Optimization\n",
            "for\n",
            "Learning\n",
            "Bayesian\n",
            "Networks\n",
            "OOD-MAML\n",
            ":\n",
            "Meta-Learning\n",
            "for\n",
            "Few-Shot\n",
            "Out-of-Distribution\n",
            "Detection\n",
            "and\n",
            "Classification\n",
            "An\n",
            "Imitation\n",
            "from\n",
            "Observation\n",
            "Approach\n",
            "to\n",
            "Transfer\n",
            "Learning\n",
            "with\n",
            "Dynamics\n",
            "Mismatch\n",
            "Learning\n",
            "About\n",
            "Objects\n",
            "by\n",
            "Learning\n",
            "to\n",
            "Interact\n",
            "with\n",
            "Them\n",
            "Learning\n",
            "discrete\n",
            "distributions\n",
            "with\n",
            "infinite\n",
            "support\n",
            "Dissecting\n",
            "Neural\n",
            "ODEs\n",
            "Teaching\n",
            "a\n",
            "GAN\n",
            "What\n",
            "Not\n",
            "to\n",
            "Learn\n",
            "Counterfactual\n",
            "Data\n",
            "Augmentation\n",
            "using\n",
            "Locally\n",
            "Factored\n",
            "Dynamics\n",
            "Rethinking\n",
            "Learnable\n",
            "Tree\n",
            "Filter\n",
            "for\n",
            "Generic\n",
            "Feature\n",
            "Transform\n",
            "Self-Supervised\n",
            "Relational\n",
            "Reasoning\n",
            "for\n",
            "Representation\n",
            "Learning\n",
            "Sufficient\n",
            "dimension\n",
            "reduction\n",
            "for\n",
            "classification\n",
            "using\n",
            "principal\n",
            "optimal\n",
            "transport\n",
            "direction\n",
            "Fast\n",
            "Epigraphical\n",
            "Projection-based\n",
            "Incremental\n",
            "Algorithms\n",
            "for\n",
            "Wasserstein\n",
            "Distributionally\n",
            "Robust\n",
            "Support\n",
            "Vector\n",
            "Machine\n",
            "Differentially\n",
            "Private\n",
            "Clustering\n",
            ":\n",
            "Tight\n",
            "Approximation\n",
            "Ratios\n",
            "On\n",
            "the\n",
            "Power\n",
            "of\n",
            "Louvain\n",
            "in\n",
            "the\n",
            "Stochastic\n",
            "Block\n",
            "Model\n",
            "Fairness\n",
            "with\n",
            "Overlapping\n",
            "Groups\n",
            ";\n",
            "a\n",
            "Probabilistic\n",
            "Perspective\n",
            "AttendLight\n",
            ":\n",
            "Universal\n",
            "Attention-Based\n",
            "Reinforcement\n",
            "Learning\n",
            "Model\n",
            "for\n",
            "Traffic\n",
            "Signal\n",
            "Control\n",
            "Searching\n",
            "for\n",
            "Low-Bit\n",
            "Weights\n",
            "in\n",
            "Quantized\n",
            "Neural\n",
            "Networks\n",
            "Adaptive\n",
            "Reduced\n",
            "Rank\n",
            "Regression\n",
            "From\n",
            "Predictions\n",
            "to\n",
            "Decisions\n",
            ":\n",
            "Using\n",
            "Lookahead\n",
            "Regularization\n",
            "Sequential\n",
            "Bayesian\n",
            "Experimental\n",
            "Design\n",
            "with\n",
            "Variable\n",
            "Cost\n",
            "Structure\n",
            "Predictive\n",
            "inference\n",
            "is\n",
            "free\n",
            "with\n",
            "the\n",
            "jackknife+-after-bootstrap\n",
            "Counterfactual\n",
            "Predictions\n",
            "under\n",
            "Runtime\n",
            "Confounding\n",
            "Learning\n",
            "Loss\n",
            "for\n",
            "Test-Time\n",
            "Augmentation\n",
            "Balanced\n",
            "Meta-Softmax\n",
            "for\n",
            "Long-Tailed\n",
            "Visual\n",
            "Recognition\n",
            "Efficient\n",
            "Exploration\n",
            "of\n",
            "Reward\n",
            "Functions\n",
            "in\n",
            "Inverse\n",
            "Reinforcement\n",
            "Learning\n",
            "via\n",
            "Bayesian\n",
            "Optimization\n",
            "MDP\n",
            "Homomorphic\n",
            "Networks\n",
            ":\n",
            "Group\n",
            "Symmetries\n",
            "in\n",
            "Reinforcement\n",
            "Learning\n",
            "How\n",
            "Can\n",
            "I\n",
            "Explain\n",
            "This\n",
            "to\n",
            "You\n",
            "?\n",
            "An\n",
            "Empirical\n",
            "Study\n",
            "of\n",
            "Deep\n",
            "Neural\n",
            "Network\n",
            "Explanation\n",
            "Methods\n",
            "On\n",
            "the\n",
            "Error\n",
            "Resistance\n",
            "of\n",
            "Hinge-Loss\n",
            "Minimization\n",
            "Munchausen\n",
            "Reinforcement\n",
            "Learning\n",
            "Object\n",
            "Goal\n",
            "Navigation\n",
            "using\n",
            "Goal-Oriented\n",
            "Semantic\n",
            "Exploration\n",
            "Efficient\n",
            "semidefinite-programming-based\n",
            "inference\n",
            "for\n",
            "binary\n",
            "and\n",
            "multi-class\n",
            "MRFs\n",
            "Funnel-Transformer\n",
            ":\n",
            "Filtering\n",
            "out\n",
            "Sequential\n",
            "Redundancy\n",
            "for\n",
            "Efficient\n",
            "Language\n",
            "Processing\n",
            "Semantic\n",
            "Visual\n",
            "Navigation\n",
            "by\n",
            "Watching\n",
            "YouTube\n",
            "Videos\n",
            "Heavy-tailed\n",
            "Representations\n",
            ",\n",
            "Text\n",
            "Polarity\n",
            "Classification\n",
            "&\n",
            "Data\n",
            "Augmentation\n",
            "SuperLoss\n",
            ":\n",
            "A\n",
            "Generic\n",
            "Loss\n",
            "for\n",
            "Robust\n",
            "Curriculum\n",
            "Learning\n",
            "CogMol\n",
            ":\n",
            "Target-Specific\n",
            "and\n",
            "Selective\n",
            "Drug\n",
            "Design\n",
            "for\n",
            "COVID-19\n",
            "Using\n",
            "Deep\n",
            "Generative\n",
            "Models\n",
            "Memory\n",
            "Based\n",
            "Trajectory-conditioned\n",
            "Policies\n",
            "for\n",
            "Learning\n",
            "from\n",
            "Sparse\n",
            "Rewards\n",
            "Liberty\n",
            "or\n",
            "Depth\n",
            ":\n",
            "Deep\n",
            "Bayesian\n",
            "Neural\n",
            "Nets\n",
            "Do\n",
            "Not\n",
            "Need\n",
            "Complex\n",
            "Weight\n",
            "Posterior\n",
            "Approximations\n",
            "Improving\n",
            "Sample\n",
            "Complexity\n",
            "Bounds\n",
            "for\n",
            "(\n",
            "Natural\n",
            ")\n",
            "Actor-Critic\n",
            "Algorithms\n",
            "Learning\n",
            "Differential\n",
            "Equations\n",
            "that\n",
            "are\n",
            "Easy\n",
            "to\n",
            "Solve\n",
            "Stability\n",
            "of\n",
            "Stochastic\n",
            "Gradient\n",
            "Descent\n",
            "on\n",
            "Nonsmooth\n",
            "Convex\n",
            "Losses\n",
            "Influence-Augmented\n",
            "Online\n",
            "Planning\n",
            "for\n",
            "Complex\n",
            "Environments\n",
            "PAC-Bayes\n",
            "Learning\n",
            "Bounds\n",
            "for\n",
            "Sample-Dependent\n",
            "Priors\n",
            "Reward-rational\n",
            "(\n",
            "implicit\n",
            ")\n",
            "choice\n",
            ":\n",
            "A\n",
            "unifying\n",
            "formalism\n",
            "for\n",
            "reward\n",
            "learning\n",
            "Probabilistic\n",
            "Time\n",
            "Series\n",
            "Forecasting\n",
            "with\n",
            "Shape\n",
            "and\n",
            "Temporal\n",
            "Diversity\n",
            "Low\n",
            "Distortion\n",
            "Block-Resampling\n",
            "with\n",
            "Spatially\n",
            "Stochastic\n",
            "Networks\n",
            "Continual\n",
            "Deep\n",
            "Learning\n",
            "by\n",
            "Functional\n",
            "Regularisation\n",
            "of\n",
            "Memorable\n",
            "Past\n",
            "Distance\n",
            "Encoding\n",
            ":\n",
            "Design\n",
            "Provably\n",
            "More\n",
            "Powerful\n",
            "Neural\n",
            "Networks\n",
            "for\n",
            "Graph\n",
            "Representation\n",
            "Learning\n",
            "Fast\n",
            "Fourier\n",
            "Convolution\n",
            "Unsupervised\n",
            "Learning\n",
            "of\n",
            "Dense\n",
            "Visual\n",
            "Representations\n",
            "Higher-Order\n",
            "Certification\n",
            "For\n",
            "Randomized\n",
            "Smoothing\n",
            "Learning\n",
            "Structured\n",
            "Distributions\n",
            "From\n",
            "Untrusted\n",
            "Batches\n",
            ":\n",
            "Faster\n",
            "and\n",
            "Simpler\n",
            "Hierarchical\n",
            "Quantized\n",
            "Autoencoders\n",
            "Diversity\n",
            "can\n",
            "be\n",
            "Transferred\n",
            ":\n",
            "Output\n",
            "Diversification\n",
            "for\n",
            "White-\n",
            "and\n",
            "Black-box\n",
            "Attacks\n",
            "POLY-HOOT\n",
            ":\n",
            "Monte-Carlo\n",
            "Planning\n",
            "in\n",
            "Continuous\n",
            "Space\n",
            "MDPs\n",
            "with\n",
            "Non-Asymptotic\n",
            "Analysis\n",
            "AvE\n",
            ":\n",
            "Assistance\n",
            "via\n",
            "Empowerment\n",
            "Variational\n",
            "Policy\n",
            "Gradient\n",
            "Method\n",
            "for\n",
            "Reinforcement\n",
            "Learning\n",
            "with\n",
            "General\n",
            "Utilities\n",
            "Reverse-engineering\n",
            "recurrent\n",
            "neural\n",
            "network\n",
            "solutions\n",
            "to\n",
            "a\n",
            "hierarchical\n",
            "inference\n",
            "task\n",
            "for\n",
            "mice\n",
            "Temporal\n",
            "Positive-unlabeled\n",
            "Learning\n",
            "for\n",
            "Biomedical\n",
            "Hypothesis\n",
            "Generation\n",
            "via\n",
            "Risk\n",
            "Estimation\n",
            "Efficient\n",
            "Low\n",
            "Rank\n",
            "Gaussian\n",
            "Variational\n",
            "Inference\n",
            "for\n",
            "Neural\n",
            "Networks\n",
            "Privacy\n",
            "Amplification\n",
            "via\n",
            "Random\n",
            "Check-Ins\n",
            "Probabilistic\n",
            "Circuits\n",
            "for\n",
            "Variational\n",
            "Inference\n",
            "in\n",
            "Discrete\n",
            "Graphical\n",
            "Models\n",
            "Your\n",
            "Classifier\n",
            "can\n",
            "Secretly\n",
            "Suffice\n",
            "Multi-Source\n",
            "Domain\n",
            "Adaptation\n",
            "Labelling\n",
            "unlabelled\n",
            "videos\n",
            "from\n",
            "scratch\n",
            "with\n",
            "multi-modal\n",
            "self-supervision\n",
            "A\n",
            "Non-Asymptotic\n",
            "Analysis\n",
            "for\n",
            "Stein\n",
            "Variational\n",
            "Gradient\n",
            "Descent\n",
            "Robust\n",
            "Meta-learning\n",
            "for\n",
            "Mixed\n",
            "Linear\n",
            "Regression\n",
            "with\n",
            "Small\n",
            "Batches\n",
            "Bayesian\n",
            "Deep\n",
            "Learning\n",
            "and\n",
            "a\n",
            "Probabilistic\n",
            "Perspective\n",
            "of\n",
            "Generalization\n",
            "Unsupervised\n",
            "Learning\n",
            "of\n",
            "Object\n",
            "Landmarks\n",
            "via\n",
            "Self-Training\n",
            "Correspondence\n",
            "Randomized\n",
            "tests\n",
            "for\n",
            "high-dimensional\n",
            "regression\n",
            ":\n",
            "A\n",
            "more\n",
            "efficient\n",
            "and\n",
            "powerful\n",
            "solution\n",
            "Learning\n",
            "Representations\n",
            "from\n",
            "Audio-Visual\n",
            "Spatial\n",
            "Alignment\n",
            "Generative\n",
            "View\n",
            "Synthesis\n",
            ":\n",
            "From\n",
            "Single-view\n",
            "Semantics\n",
            "to\n",
            "Novel-view\n",
            "Images\n",
            "Towards\n",
            "More\n",
            "Practical\n",
            "Adversarial\n",
            "Attacks\n",
            "on\n",
            "Graph\n",
            "Neural\n",
            "Networks\n",
            "Multi-Task\n",
            "Reinforcement\n",
            "Learning\n",
            "with\n",
            "Soft\n",
            "Modularization\n",
            "Causal\n",
            "Shapley\n",
            "Values\n",
            ":\n",
            "Exploiting\n",
            "Causal\n",
            "Knowledge\n",
            "to\n",
            "Explain\n",
            "Individual\n",
            "Predictions\n",
            "of\n",
            "Complex\n",
            "Models\n",
            "On\n",
            "the\n",
            "training\n",
            "dynamics\n",
            "of\n",
            "deep\n",
            "networks\n",
            "with\n",
            "$\n",
            "L_2\n",
            "$\n",
            "regularization\n",
            "Improved\n",
            "Algorithms\n",
            "for\n",
            "Convex-Concave\n",
            "Minimax\n",
            "Optimization\n",
            "Deep\n",
            "Variational\n",
            "Instance\n",
            "Segmentation\n",
            "Learning\n",
            "Implicit\n",
            "Functions\n",
            "for\n",
            "Topology-Varying\n",
            "Dense\n",
            "3D\n",
            "Shape\n",
            "Correspondence\n",
            "Deep\n",
            "Multimodal\n",
            "Fusion\n",
            "by\n",
            "Channel\n",
            "Exchanging\n",
            "Hierarchically\n",
            "Organized\n",
            "Latent\n",
            "Modules\n",
            "for\n",
            "Exploratory\n",
            "Search\n",
            "in\n",
            "Morphogenetic\n",
            "Systems\n",
            "AI\n",
            "Feynman\n",
            "2.0\n",
            ":\n",
            "Pareto-optimal\n",
            "symbolic\n",
            "regression\n",
            "exploiting\n",
            "graph\n",
            "modularity\n",
            "Delay\n",
            "and\n",
            "Cooperation\n",
            "in\n",
            "Nonstochastic\n",
            "Linear\n",
            "Bandits\n",
            "Probabilistic\n",
            "Orientation\n",
            "Estimation\n",
            "with\n",
            "Matrix\n",
            "Fisher\n",
            "Distributions\n",
            "Minimax\n",
            "Dynamics\n",
            "of\n",
            "Optimally\n",
            "Balanced\n",
            "Spiking\n",
            "Networks\n",
            "of\n",
            "Excitatory\n",
            "and\n",
            "Inhibitory\n",
            "Neurons\n",
            "Telescoping\n",
            "Density-Ratio\n",
            "Estimation\n",
            "Towards\n",
            "Deeper\n",
            "Graph\n",
            "Neural\n",
            "Networks\n",
            "with\n",
            "Differentiable\n",
            "Group\n",
            "Normalization\n",
            "Stochastic\n",
            "Optimization\n",
            "for\n",
            "Performative\n",
            "Prediction\n",
            "Learning\n",
            "Differentiable\n",
            "Programs\n",
            "with\n",
            "Admissible\n",
            "Neural\n",
            "Heuristics\n",
            "Improved\n",
            "guarantees\n",
            "and\n",
            "a\n",
            "multiple-descent\n",
            "curve\n",
            "for\n",
            "Column\n",
            "Subset\n",
            "Selection\n",
            "and\n",
            "the\n",
            "Nystrom\n",
            "method\n",
            "Domain\n",
            "Adaptation\n",
            "as\n",
            "a\n",
            "Problem\n",
            "of\n",
            "Inference\n",
            "on\n",
            "Graphical\n",
            "Models\n",
            "Network\n",
            "size\n",
            "and\n",
            "size\n",
            "of\n",
            "the\n",
            "weights\n",
            "in\n",
            "memorization\n",
            "with\n",
            "two-layers\n",
            "neural\n",
            "networks\n",
            "Certifying\n",
            "Strategyproof\n",
            "Auction\n",
            "Networks\n",
            "Continual\n",
            "Learning\n",
            "of\n",
            "Control\n",
            "Primitives\n",
            ":\n",
            "Skill\n",
            "Discovery\n",
            "via\n",
            "Reset-Games\n",
            "HOI\n",
            "Analysis\n",
            ":\n",
            "Integrating\n",
            "and\n",
            "Decomposing\n",
            "Human-Object\n",
            "Interaction\n",
            "Strongly\n",
            "local\n",
            "p-norm-cut\n",
            "algorithms\n",
            "for\n",
            "semi-supervised\n",
            "learning\n",
            "and\n",
            "local\n",
            "graph\n",
            "clustering\n",
            "Deep\n",
            "Direct\n",
            "Likelihood\n",
            "Knockoffs\n",
            "Meta-Neighborhoods\n",
            "Neural\n",
            "Dynamic\n",
            "Policies\n",
            "for\n",
            "End-to-End\n",
            "Sensorimotor\n",
            "Learning\n",
            "A\n",
            "new\n",
            "inference\n",
            "approach\n",
            "for\n",
            "training\n",
            "shallow\n",
            "and\n",
            "deep\n",
            "generalized\n",
            "linear\n",
            "models\n",
            "of\n",
            "noisy\n",
            "interacting\n",
            "neurons\n",
            "Decision-Making\n",
            "with\n",
            "Auto-Encoding\n",
            "Variational\n",
            "Bayes\n",
            "Attribution\n",
            "Preservation\n",
            "in\n",
            "Network\n",
            "Compression\n",
            "for\n",
            "Reliable\n",
            "Network\n",
            "Interpretation\n",
            "Feature\n",
            "Importance\n",
            "Ranking\n",
            "for\n",
            "Deep\n",
            "Learning\n",
            "Causal\n",
            "Estimation\n",
            "with\n",
            "Functional\n",
            "Confounders\n",
            "Model\n",
            "Inversion\n",
            "Networks\n",
            "for\n",
            "Model-Based\n",
            "Optimization\n",
            "Hausdorff\n",
            "Dimension\n",
            ",\n",
            "Heavy\n",
            "Tails\n",
            ",\n",
            "and\n",
            "Generalization\n",
            "in\n",
            "Neural\n",
            "Networks\n",
            "Exact\n",
            "expressions\n",
            "for\n",
            "double\n",
            "descent\n",
            "and\n",
            "implicit\n",
            "regularization\n",
            "via\n",
            "surrogate\n",
            "random\n",
            "design\n",
            "Certifying\n",
            "Confidence\n",
            "via\n",
            "Randomized\n",
            "Smoothing\n",
            "Learning\n",
            "Physical\n",
            "Constraints\n",
            "with\n",
            "Neural\n",
            "Projections\n",
            "Robust\n",
            "Optimization\n",
            "for\n",
            "Fairness\n",
            "with\n",
            "Noisy\n",
            "Protected\n",
            "Groups\n",
            "Noise-Contrastive\n",
            "Estimation\n",
            "for\n",
            "Multivariate\n",
            "Point\n",
            "Processes\n",
            "A\n",
            "Game-Theoretic\n",
            "Analysis\n",
            "of\n",
            "the\n",
            "Empirical\n",
            "Revenue\n",
            "Maximization\n",
            "Algorithm\n",
            "with\n",
            "Endogenous\n",
            "Sampling\n",
            "Neural\n",
            "Path\n",
            "Features\n",
            "and\n",
            "Neural\n",
            "Path\n",
            "Kernel\n",
            ":\n",
            "Understanding\n",
            "the\n",
            "role\n",
            "of\n",
            "gates\n",
            "in\n",
            "deep\n",
            "learning\n",
            "Multiscale\n",
            "Deep\n",
            "Equilibrium\n",
            "Models\n",
            "Sparse\n",
            "Graphical\n",
            "Memory\n",
            "for\n",
            "Robust\n",
            "Planning\n",
            "Second\n",
            "Order\n",
            "PAC-Bayesian\n",
            "Bounds\n",
            "for\n",
            "the\n",
            "Weighted\n",
            "Majority\n",
            "Vote\n",
            "Dirichlet\n",
            "Graph\n",
            "Variational\n",
            "Autoencoder\n",
            "Modeling\n",
            "Task\n",
            "Effects\n",
            "on\n",
            "Meaning\n",
            "Representation\n",
            "in\n",
            "the\n",
            "Brain\n",
            "via\n",
            "Zero-Shot\n",
            "MEG\n",
            "Prediction\n",
            "Counterfactual\n",
            "Vision-and-Language\n",
            "Navigation\n",
            ":\n",
            "Unravelling\n",
            "the\n",
            "Unseen\n",
            "Robust\n",
            "Quantization\n",
            ":\n",
            "One\n",
            "Model\n",
            "to\n",
            "Rule\n",
            "Them\n",
            "All\n",
            "Enabling\n",
            "certification\n",
            "of\n",
            "verification-agnostic\n",
            "networks\n",
            "via\n",
            "memory-efficient\n",
            "semidefinite\n",
            "programming\n",
            "Federated\n",
            "Accelerated\n",
            "Stochastic\n",
            "Gradient\n",
            "Descent\n",
            "Robust\n",
            "Density\n",
            "Estimation\n",
            "under\n",
            "Besov\n",
            "IPM\n",
            "Losses\n",
            "An\n",
            "analytic\n",
            "theory\n",
            "of\n",
            "shallow\n",
            "networks\n",
            "dynamics\n",
            "for\n",
            "hinge\n",
            "loss\n",
            "classification\n",
            "Fixed-Support\n",
            "Wasserstein\n",
            "Barycenters\n",
            ":\n",
            "Computational\n",
            "Hardness\n",
            "and\n",
            "Fast\n",
            "Algorithm\n",
            "Learning\n",
            "to\n",
            "Orient\n",
            "Surfaces\n",
            "by\n",
            "Self-supervised\n",
            "Spherical\n",
            "CNNs\n",
            "Adam\n",
            "with\n",
            "Bandit\n",
            "Sampling\n",
            "for\n",
            "Deep\n",
            "Learning\n",
            "Parabolic\n",
            "Approximation\n",
            "Line\n",
            "Search\n",
            "for\n",
            "DNNs\n",
            "Agnostic\n",
            "Learning\n",
            "of\n",
            "a\n",
            "Single\n",
            "Neuron\n",
            "with\n",
            "Gradient\n",
            "Descent\n",
            "Statistical\n",
            "Efficiency\n",
            "of\n",
            "Thompson\n",
            "Sampling\n",
            "for\n",
            "Combinatorial\n",
            "Semi-Bandits\n",
            "Analytic\n",
            "Characterization\n",
            "of\n",
            "the\n",
            "Hessian\n",
            "in\n",
            "Shallow\n",
            "ReLU\n",
            "Models\n",
            ":\n",
            "A\n",
            "Tale\n",
            "of\n",
            "Symmetry\n",
            "Generative\n",
            "causal\n",
            "explanations\n",
            "of\n",
            "black-box\n",
            "classifiers\n",
            "Sub-sampling\n",
            "for\n",
            "Efficient\n",
            "Non-Parametric\n",
            "Bandit\n",
            "Exploration\n",
            "Learning\n",
            "under\n",
            "Model\n",
            "Misspecification\n",
            ":\n",
            "Applications\n",
            "to\n",
            "Variational\n",
            "and\n",
            "Ensemble\n",
            "methods\n",
            "Language\n",
            "Through\n",
            "a\n",
            "Prism\n",
            ":\n",
            "A\n",
            "Spectral\n",
            "Approach\n",
            "for\n",
            "Multiscale\n",
            "Language\n",
            "Representations\n",
            "DVERGE\n",
            ":\n",
            "Diversifying\n",
            "Vulnerabilities\n",
            "for\n",
            "Enhanced\n",
            "Robust\n",
            "Generation\n",
            "of\n",
            "Ensembles\n",
            "Towards\n",
            "practical\n",
            "differentially\n",
            "private\n",
            "causal\n",
            "graph\n",
            "discovery\n",
            "Independent\n",
            "Policy\n",
            "Gradient\n",
            "Methods\n",
            "for\n",
            "Competitive\n",
            "Reinforcement\n",
            "Learning\n",
            "The\n",
            "Value\n",
            "Equivalence\n",
            "Principle\n",
            "for\n",
            "Model-Based\n",
            "Reinforcement\n",
            "Learning\n",
            "Structured\n",
            "Convolutions\n",
            "for\n",
            "Efficient\n",
            "Neural\n",
            "Network\n",
            "Design\n",
            "Latent\n",
            "World\n",
            "Models\n",
            "For\n",
            "Intrinsically\n",
            "Motivated\n",
            "Exploration\n",
            "Estimating\n",
            "Rank-One\n",
            "Spikes\n",
            "from\n",
            "Heavy-Tailed\n",
            "Noise\n",
            "via\n",
            "Self-Avoiding\n",
            "Walks\n",
            "Policy\n",
            "Improvement\n",
            "via\n",
            "Imitation\n",
            "of\n",
            "Multiple\n",
            "Oracles\n",
            "Training\n",
            "Generative\n",
            "Adversarial\n",
            "Networks\n",
            "by\n",
            "Solving\n",
            "Ordinary\n",
            "Differential\n",
            "Equations\n",
            "Learning\n",
            "of\n",
            "Discrete\n",
            "Graphical\n",
            "Models\n",
            "with\n",
            "Neural\n",
            "Networks\n",
            "RepPoints\n",
            "v2\n",
            ":\n",
            "Verification\n",
            "Meets\n",
            "Regression\n",
            "for\n",
            "Object\n",
            "Detection\n",
            "Unfolding\n",
            "the\n",
            "Alternating\n",
            "Optimization\n",
            "for\n",
            "Blind\n",
            "Super\n",
            "Resolution\n",
            "Entrywise\n",
            "convergence\n",
            "of\n",
            "iterative\n",
            "methods\n",
            "for\n",
            "eigenproblems\n",
            "Learning\n",
            "Object-Centric\n",
            "Representations\n",
            "of\n",
            "Multi-Object\n",
            "Scenes\n",
            "from\n",
            "Multiple\n",
            "Views\n",
            "A\n",
            "Catalyst\n",
            "Framework\n",
            "for\n",
            "Minimax\n",
            "Optimization\n",
            "Self-supervised\n",
            "Co-Training\n",
            "for\n",
            "Video\n",
            "Representation\n",
            "Learning\n",
            "Gradient\n",
            "Estimation\n",
            "with\n",
            "Stochastic\n",
            "Softmax\n",
            "Tricks\n",
            "Meta-Learning\n",
            "Requires\n",
            "Meta-Augmentation\n",
            "SLIP\n",
            ":\n",
            "Learning\n",
            "to\n",
            "predict\n",
            "in\n",
            "unknown\n",
            "dynamical\n",
            "systems\n",
            "with\n",
            "long-term\n",
            "memory\n",
            "Improving\n",
            "GAN\n",
            "Training\n",
            "with\n",
            "Probability\n",
            "Ratio\n",
            "Clipping\n",
            "and\n",
            "Sample\n",
            "Reweighting\n",
            "Bayesian\n",
            "Bits\n",
            ":\n",
            "Unifying\n",
            "Quantization\n",
            "and\n",
            "Pruning\n",
            "On\n",
            "Testing\n",
            "of\n",
            "Samplers\n",
            "Gaussian\n",
            "Process\n",
            "Bandit\n",
            "Optimization\n",
            "of\n",
            "the\n",
            "Thermodynamic\n",
            "Variational\n",
            "Objective\n",
            "MiniLM\n",
            ":\n",
            "Deep\n",
            "Self-Attention\n",
            "Distillation\n",
            "for\n",
            "Task-Agnostic\n",
            "Compression\n",
            "of\n",
            "Pre-Trained\n",
            "Transformers\n",
            "Optimal\n",
            "Epoch\n",
            "Stochastic\n",
            "Gradient\n",
            "Descent\n",
            "Ascent\n",
            "Methods\n",
            "for\n",
            "Min-Max\n",
            "Optimization\n",
            "Woodbury\n",
            "Transformations\n",
            "for\n",
            "Deep\n",
            "Generative\n",
            "Flows\n",
            "Graph\n",
            "Contrastive\n",
            "Learning\n",
            "with\n",
            "Augmentations\n",
            "Gradient\n",
            "Surgery\n",
            "for\n",
            "Multi-Task\n",
            "Learning\n",
            "Bayesian\n",
            "Probabilistic\n",
            "Numerical\n",
            "Integration\n",
            "with\n",
            "Tree-Based\n",
            "Models\n",
            "Deep\n",
            "learning\n",
            "versus\n",
            "kernel\n",
            "learning\n",
            ":\n",
            "an\n",
            "empirical\n",
            "study\n",
            "of\n",
            "loss\n",
            "landscape\n",
            "geometry\n",
            "and\n",
            "the\n",
            "time\n",
            "evolution\n",
            "of\n",
            "the\n",
            "Neural\n",
            "Tangent\n",
            "Kernel\n",
            "Graph\n",
            "Meta\n",
            "Learning\n",
            "via\n",
            "Local\n",
            "Subgraphs\n",
            "Stochastic\n",
            "Deep\n",
            "Gaussian\n",
            "Processes\n",
            "over\n",
            "Graphs\n",
            "Bayesian\n",
            "Causal\n",
            "Structural\n",
            "Learning\n",
            "with\n",
            "Zero-Inflated\n",
            "Poisson\n",
            "Bayesian\n",
            "Networks\n",
            "Evaluating\n",
            "Attribution\n",
            "for\n",
            "Graph\n",
            "Neural\n",
            "Networks\n",
            "On\n",
            "Second\n",
            "Order\n",
            "Behaviour\n",
            "in\n",
            "Augmented\n",
            "Neural\n",
            "ODEs\n",
            "Neuron\n",
            "Shapley\n",
            ":\n",
            "Discovering\n",
            "the\n",
            "Responsible\n",
            "Neurons\n",
            "Stochastic\n",
            "Normalizing\n",
            "Flows\n",
            "GPU-Accelerated\n",
            "Primal\n",
            "Learning\n",
            "for\n",
            "Extremely\n",
            "Fast\n",
            "Large-Scale\n",
            "Classification\n",
            "Random\n",
            "Reshuffling\n",
            "is\n",
            "Not\n",
            "Always\n",
            "Better\n",
            "Model\n",
            "Agnostic\n",
            "Multilevel\n",
            "Explanations\n",
            "NeuMiss\n",
            "networks\n",
            ":\n",
            "differentiable\n",
            "programming\n",
            "for\n",
            "supervised\n",
            "learning\n",
            "with\n",
            "missing\n",
            "values\n",
            ".\n",
            "Revisiting\n",
            "Parameter\n",
            "Sharing\n",
            "for\n",
            "Automatic\n",
            "Neural\n",
            "Channel\n",
            "Number\n",
            "Search\n",
            "Differentially-Private\n",
            "Federated\n",
            "Linear\n",
            "Bandits\n",
            "Is\n",
            "Plug-in\n",
            "Solver\n",
            "Sample-Efficient\n",
            "for\n",
            "Feature-based\n",
            "Reinforcement\n",
            "Learning\n",
            "?\n",
            "Learning\n",
            "Physical\n",
            "Graph\n",
            "Representations\n",
            "from\n",
            "Visual\n",
            "Scenes\n",
            "Deep\n",
            "Graph\n",
            "Pose\n",
            ":\n",
            "a\n",
            "semi-supervised\n",
            "deep\n",
            "graphical\n",
            "model\n",
            "for\n",
            "improved\n",
            "animal\n",
            "pose\n",
            "tracking\n",
            "Meta-learning\n",
            "from\n",
            "Tasks\n",
            "with\n",
            "Heterogeneous\n",
            "Attribute\n",
            "Spaces\n",
            "Estimating\n",
            "decision\n",
            "tree\n",
            "learnability\n",
            "with\n",
            "polylogarithmic\n",
            "sample\n",
            "complexity\n",
            "Sparse\n",
            "Symplectically\n",
            "Integrated\n",
            "Neural\n",
            "Networks\n",
            "Continuous\n",
            "Object\n",
            "Representation\n",
            "Networks\n",
            ":\n",
            "Novel\n",
            "View\n",
            "Synthesis\n",
            "without\n",
            "Target\n",
            "View\n",
            "Supervision\n",
            "Multimodal\n",
            "Generative\n",
            "Learning\n",
            "Utilizing\n",
            "Jensen-Shannon-Divergence\n",
            "Solver-in-the-Loop\n",
            ":\n",
            "Learning\n",
            "from\n",
            "Differentiable\n",
            "Physics\n",
            "to\n",
            "Interact\n",
            "with\n",
            "Iterative\n",
            "PDE-Solvers\n",
            "Reinforcement\n",
            "Learning\n",
            "with\n",
            "General\n",
            "Value\n",
            "Function\n",
            "Approximation\n",
            ":\n",
            "Provably\n",
            "Efficient\n",
            "Approach\n",
            "via\n",
            "Bounded\n",
            "Eluder\n",
            "Dimension\n",
            "Predicting\n",
            "Training\n",
            "Time\n",
            "Without\n",
            "Training\n",
            "How\n",
            "does\n",
            "This\n",
            "Interaction\n",
            "Affect\n",
            "Me\n",
            "?\n",
            "Interpretable\n",
            "Attribution\n",
            "for\n",
            "Feature\n",
            "Interactions\n",
            "Optimal\n",
            "Adaptive\n",
            "Electrode\n",
            "Selection\n",
            "to\n",
            "Maximize\n",
            "Simultaneously\n",
            "Recorded\n",
            "Neuron\n",
            "Yield\n",
            "Neurosymbolic\n",
            "Reinforcement\n",
            "Learning\n",
            "with\n",
            "Formally\n",
            "Verified\n",
            "Exploration\n",
            "Wavelet\n",
            "Flow\n",
            ":\n",
            "Fast\n",
            "Training\n",
            "of\n",
            "High\n",
            "Resolution\n",
            "Normalizing\n",
            "Flows\n",
            "Multi-task\n",
            "Batch\n",
            "Reinforcement\n",
            "Learning\n",
            "with\n",
            "Metric\n",
            "Learning\n",
            "On\n",
            "1/n\n",
            "neural\n",
            "representation\n",
            "and\n",
            "robustness\n",
            "Boundary\n",
            "thickness\n",
            "and\n",
            "robustness\n",
            "in\n",
            "learning\n",
            "models\n",
            "Demixed\n",
            "shared\n",
            "component\n",
            "analysis\n",
            "of\n",
            "neural\n",
            "population\n",
            "data\n",
            "from\n",
            "multiple\n",
            "brain\n",
            "areas\n",
            "Learning\n",
            "Kernel\n",
            "Tests\n",
            "Without\n",
            "Data\n",
            "Splitting\n",
            "Unsupervised\n",
            "Data\n",
            "Augmentation\n",
            "for\n",
            "Consistency\n",
            "Training\n",
            "Subgroup-based\n",
            "Rank-1\n",
            "Lattice\n",
            "Quasi-Monte\n",
            "Carlo\n",
            "Minibatch\n",
            "vs\n",
            "Local\n",
            "SGD\n",
            "for\n",
            "Heterogeneous\n",
            "Distributed\n",
            "Learning\n",
            "Multi-task\n",
            "Causal\n",
            "Learning\n",
            "with\n",
            "Gaussian\n",
            "Processes\n",
            "Proximity\n",
            "Operator\n",
            "of\n",
            "the\n",
            "Matrix\n",
            "Perspective\n",
            "Function\n",
            "and\n",
            "its\n",
            "Applications\n",
            "Generative\n",
            "3D\n",
            "Part\n",
            "Assembly\n",
            "via\n",
            "Dynamic\n",
            "Graph\n",
            "Learning\n",
            "Improving\n",
            "Natural\n",
            "Language\n",
            "Processing\n",
            "Tasks\n",
            "with\n",
            "Human\n",
            "Gaze-Guided\n",
            "Neural\n",
            "Attention\n",
            "The\n",
            "Power\n",
            "of\n",
            "Comparisons\n",
            "for\n",
            "Actively\n",
            "Learning\n",
            "Linear\n",
            "Classifiers\n",
            "From\n",
            "Boltzmann\n",
            "Machines\n",
            "to\n",
            "Neural\n",
            "Networks\n",
            "and\n",
            "Back\n",
            "Again\n",
            "Crush\n",
            "Optimism\n",
            "with\n",
            "Pessimism\n",
            ":\n",
            "Structured\n",
            "Bandits\n",
            "Beyond\n",
            "Asymptotic\n",
            "Optimality\n",
            "Pruning\n",
            "neural\n",
            "networks\n",
            "without\n",
            "any\n",
            "data\n",
            "by\n",
            "iteratively\n",
            "conserving\n",
            "synaptic\n",
            "flow\n",
            "Detecting\n",
            "Interactions\n",
            "from\n",
            "Neural\n",
            "Networks\n",
            "via\n",
            "Topological\n",
            "Analysis\n",
            "Neural\n",
            "Bridge\n",
            "Sampling\n",
            "for\n",
            "Evaluating\n",
            "Safety-Critical\n",
            "Autonomous\n",
            "Systems\n",
            "Interpretable\n",
            "and\n",
            "Personalized\n",
            "Apprenticeship\n",
            "Scheduling\n",
            ":\n",
            "Learning\n",
            "Interpretable\n",
            "Scheduling\n",
            "Policies\n",
            "from\n",
            "Heterogeneous\n",
            "User\n",
            "Demonstrations\n",
            "Task-Agnostic\n",
            "Online\n",
            "Reinforcement\n",
            "Learning\n",
            "with\n",
            "an\n",
            "Infinite\n",
            "Mixture\n",
            "of\n",
            "Gaussian\n",
            "Processes\n",
            "Benchmarking\n",
            "Deep\n",
            "Learning\n",
            "Interpretability\n",
            "in\n",
            "Time\n",
            "Series\n",
            "Predictions\n",
            "Federated\n",
            "Principal\n",
            "Component\n",
            "Analysis\n",
            "(\n",
            "De\n",
            ")\n",
            "Randomized\n",
            "Smoothing\n",
            "for\n",
            "Certifiable\n",
            "Defense\n",
            "against\n",
            "Patch\n",
            "Attacks\n",
            "SMYRF\n",
            "-\n",
            "Efficient\n",
            "Attention\n",
            "using\n",
            "Asymmetric\n",
            "Clustering\n",
            "Introducing\n",
            "Routing\n",
            "Uncertainty\n",
            "in\n",
            "Capsule\n",
            "Networks\n",
            "A\n",
            "Simple\n",
            "and\n",
            "Efficient\n",
            "Smoothing\n",
            "Method\n",
            "for\n",
            "Faster\n",
            "Optimization\n",
            "and\n",
            "Local\n",
            "Exploration\n",
            "Hyperparameter\n",
            "Ensembles\n",
            "for\n",
            "Robustness\n",
            "and\n",
            "Uncertainty\n",
            "Quantification\n",
            "Neutralizing\n",
            "Self-Selection\n",
            "Bias\n",
            "in\n",
            "Sampling\n",
            "for\n",
            "Sortition\n",
            "On\n",
            "the\n",
            "Convergence\n",
            "of\n",
            "Smooth\n",
            "Regularized\n",
            "Approximate\n",
            "Value\n",
            "Iteration\n",
            "Schemes\n",
            "Off-Policy\n",
            "Evaluation\n",
            "via\n",
            "the\n",
            "Regularized\n",
            "Lagrangian\n",
            "The\n",
            "LoCA\n",
            "Regret\n",
            ":\n",
            "A\n",
            "Consistent\n",
            "Metric\n",
            "to\n",
            "Evaluate\n",
            "Model-Based\n",
            "Behavior\n",
            "in\n",
            "Reinforcement\n",
            "Learning\n",
            "Neural\n",
            "Power\n",
            "Units\n",
            "Towards\n",
            "Scalable\n",
            "Bayesian\n",
            "Learning\n",
            "of\n",
            "Causal\n",
            "DAGs\n",
            "A\n",
            "Dictionary\n",
            "Approach\n",
            "to\n",
            "Domain-Invariant\n",
            "Learning\n",
            "in\n",
            "Deep\n",
            "Networks\n",
            "Bootstrapping\n",
            "neural\n",
            "processes\n",
            "Large-Scale\n",
            "Adversarial\n",
            "Training\n",
            "for\n",
            "Vision-and-Language\n",
            "Representation\n",
            "Learning\n",
            "Most\n",
            "ReLU\n",
            "Networks\n",
            "Suffer\n",
            "from\n",
            "$\n",
            "\\ell^2\n",
            "$\n",
            "Adversarial\n",
            "Perturbations\n",
            "Compositional\n",
            "Visual\n",
            "Generation\n",
            "with\n",
            "Energy\n",
            "Based\n",
            "Models\n",
            "Factor\n",
            "Graph\n",
            "Grammars\n",
            "Erdos\n",
            "Goes\n",
            "Neural\n",
            ":\n",
            "an\n",
            "Unsupervised\n",
            "Learning\n",
            "Framework\n",
            "for\n",
            "Combinatorial\n",
            "Optimization\n",
            "on\n",
            "Graphs\n",
            "Autoregressive\n",
            "Score\n",
            "Matching\n",
            "Debiasing\n",
            "Distributed\n",
            "Second\n",
            "Order\n",
            "Optimization\n",
            "with\n",
            "Surrogate\n",
            "Sketching\n",
            "and\n",
            "Scaled\n",
            "Regularization\n",
            "Neural\n",
            "Controlled\n",
            "Differential\n",
            "Equations\n",
            "for\n",
            "Irregular\n",
            "Time\n",
            "Series\n",
            "On\n",
            "Efficiency\n",
            "in\n",
            "Hierarchical\n",
            "Reinforcement\n",
            "Learning\n",
            "On\n",
            "Correctness\n",
            "of\n",
            "Automatic\n",
            "Differentiation\n",
            "for\n",
            "Non-Differentiable\n",
            "Functions\n",
            "Probabilistic\n",
            "Linear\n",
            "Solvers\n",
            "for\n",
            "Machine\n",
            "Learning\n",
            "Dynamic\n",
            "Regret\n",
            "of\n",
            "Policy\n",
            "Optimization\n",
            "in\n",
            "Non-Stationary\n",
            "Environments\n",
            "Multipole\n",
            "Graph\n",
            "Neural\n",
            "Operator\n",
            "for\n",
            "Parametric\n",
            "Partial\n",
            "Differential\n",
            "Equations\n",
            "BlockGAN\n",
            ":\n",
            "Learning\n",
            "3D\n",
            "Object-aware\n",
            "Scene\n",
            "Representations\n",
            "from\n",
            "Unlabelled\n",
            "Images\n",
            "Online\n",
            "Structured\n",
            "Meta-learning\n",
            "Learning\n",
            "Strategic\n",
            "Network\n",
            "Emergence\n",
            "Games\n",
            "Towards\n",
            "Interpretable\n",
            "Natural\n",
            "Language\n",
            "Understanding\n",
            "with\n",
            "Explanations\n",
            "as\n",
            "Latent\n",
            "Variables\n",
            "The\n",
            "Mean-Squared\n",
            "Error\n",
            "of\n",
            "Double\n",
            "Q-Learning\n",
            "What\n",
            "Makes\n",
            "for\n",
            "Good\n",
            "Views\n",
            "for\n",
            "Contrastive\n",
            "Learning\n",
            "?\n",
            "Denoising\n",
            "Diffusion\n",
            "Probabilistic\n",
            "Models\n",
            "Barking\n",
            "up\n",
            "the\n",
            "right\n",
            "tree\n",
            ":\n",
            "an\n",
            "approach\n",
            "to\n",
            "search\n",
            "over\n",
            "molecule\n",
            "synthesis\n",
            "DAGs\n",
            "On\n",
            "Uniform\n",
            "Convergence\n",
            "and\n",
            "Low-Norm\n",
            "Interpolation\n",
            "Learning\n",
            "Bandit\n",
            "Samplers\n",
            "for\n",
            "Training\n",
            "Graph\n",
            "Neural\n",
            "Networks\n",
            "Sampling\n",
            "from\n",
            "a\n",
            "k-DPP\n",
            "without\n",
            "looking\n",
            "at\n",
            "all\n",
            "items\n",
            "Uncovering\n",
            "the\n",
            "Topology\n",
            "of\n",
            "Time-Varying\n",
            "fMRI\n",
            "Data\n",
            "using\n",
            "Cubical\n",
            "Persistence\n",
            "Hierarchical\n",
            "Poset\n",
            "Decoding\n",
            "for\n",
            "Compositional\n",
            "Generalization\n",
            "in\n",
            "Language\n",
            "Evaluating\n",
            "and\n",
            "Rewarding\n",
            "Teamwork\n",
            "Using\n",
            "Cooperative\n",
            "Game\n",
            "Abstractions\n",
            "Exchangeable\n",
            "Neural\n",
            "ODE\n",
            "for\n",
            "Set\n",
            "Modeling\n",
            "Profile\n",
            "Entropy\n",
            ":\n",
            "A\n",
            "Fundamental\n",
            "Measure\n",
            "for\n",
            "the\n",
            "Learnability\n",
            "and\n",
            "Compressibility\n",
            "of\n",
            "Distributions\n",
            "CoADNet\n",
            ":\n",
            "Collaborative\n",
            "Aggregation-and-Distribution\n",
            "Networks\n",
            "for\n",
            "Co-Salient\n",
            "Object\n",
            "Detection\n",
            "Regularized\n",
            "linear\n",
            "autoencoders\n",
            "recover\n",
            "the\n",
            "principal\n",
            "components\n",
            ",\n",
            "eventually\n",
            "Semi-Supervised\n",
            "Partial\n",
            "Label\n",
            "Learning\n",
            "via\n",
            "Confidence-Rated\n",
            "Margin\n",
            "Maximization\n",
            "GramGAN\n",
            ":\n",
            "Deep\n",
            "3D\n",
            "Texture\n",
            "Synthesis\n",
            "From\n",
            "2D\n",
            "Exemplars\n",
            "UWSOD\n",
            ":\n",
            "Toward\n",
            "Fully-Supervised-Level\n",
            "Capacity\n",
            "Weakly\n",
            "Supervised\n",
            "Object\n",
            "Detection\n",
            "Learning\n",
            "Restricted\n",
            "Boltzmann\n",
            "Machines\n",
            "with\n",
            "Sparse\n",
            "Latent\n",
            "Variables\n",
            "Sample\n",
            "Complexity\n",
            "of\n",
            "Asynchronous\n",
            "Q-Learning\n",
            ":\n",
            "Sharper\n",
            "Analysis\n",
            "and\n",
            "Variance\n",
            "Reduction\n",
            "Curriculum\n",
            "learning\n",
            "for\n",
            "multilevel\n",
            "budgeted\n",
            "combinatorial\n",
            "problems\n",
            "FedSplit\n",
            ":\n",
            "an\n",
            "algorithmic\n",
            "framework\n",
            "for\n",
            "fast\n",
            "federated\n",
            "optimization\n",
            "Estimation\n",
            "and\n",
            "Imputation\n",
            "in\n",
            "Probabilistic\n",
            "Principal\n",
            "Component\n",
            "Analysis\n",
            "with\n",
            "Missing\n",
            "Not\n",
            "At\n",
            "Random\n",
            "Data\n",
            "Correlation\n",
            "Robust\n",
            "Influence\n",
            "Maximization\n",
            "Neuronal\n",
            "Gaussian\n",
            "Process\n",
            "Regression\n",
            "Nonconvex\n",
            "Sparse\n",
            "Graph\n",
            "Learning\n",
            "under\n",
            "Laplacian\n",
            "Constrained\n",
            "Graphical\n",
            "Model\n",
            "Synthetic\n",
            "Data\n",
            "Generators\n",
            "--\n",
            "Sequential\n",
            "and\n",
            "Private\n",
            "Uncertainty\n",
            "Quantification\n",
            "for\n",
            "Inferring\n",
            "Hawkes\n",
            "Networks\n",
            "Implicit\n",
            "Distributional\n",
            "Reinforcement\n",
            "Learning\n",
            "Auxiliary\n",
            "Task\n",
            "Reweighting\n",
            "for\n",
            "Minimum-data\n",
            "Learning\n",
            "Small\n",
            "Nash\n",
            "Equilibrium\n",
            "Certificates\n",
            "in\n",
            "Very\n",
            "Large\n",
            "Games\n",
            "Training\n",
            "Linear\n",
            "Finite-State\n",
            "Machines\n",
            "Efficient\n",
            "active\n",
            "learning\n",
            "of\n",
            "sparse\n",
            "halfspaces\n",
            "with\n",
            "arbitrary\n",
            "bounded\n",
            "noise\n",
            "Swapping\n",
            "Autoencoder\n",
            "for\n",
            "Deep\n",
            "Image\n",
            "Manipulation\n",
            "Self-Supervised\n",
            "Few-Shot\n",
            "Learning\n",
            "on\n",
            "Point\n",
            "Clouds\n",
            "Faster\n",
            "Differentially\n",
            "Private\n",
            "Samplers\n",
            "via\n",
            "Rényi\n",
            "Divergence\n",
            "Analysis\n",
            "of\n",
            "Discretized\n",
            "Langevin\n",
            "MCMC\n",
            "Learning\n",
            "identifiable\n",
            "and\n",
            "interpretable\n",
            "latent\n",
            "models\n",
            "of\n",
            "high-dimensional\n",
            "neural\n",
            "activity\n",
            "using\n",
            "pi-VAE\n",
            "RL\n",
            "Unplugged\n",
            ":\n",
            "A\n",
            "Suite\n",
            "of\n",
            "Benchmarks\n",
            "for\n",
            "Offline\n",
            "Reinforcement\n",
            "Learning\n",
            "Dual\n",
            "T\n",
            ":\n",
            "Reducing\n",
            "Estimation\n",
            "Error\n",
            "for\n",
            "Transition\n",
            "Matrix\n",
            "in\n",
            "Label-noise\n",
            "Learning\n",
            "Interior\n",
            "Point\n",
            "Solving\n",
            "for\n",
            "LP-based\n",
            "prediction+optimisation\n",
            "A\n",
            "simple\n",
            "normative\n",
            "network\n",
            "approximates\n",
            "local\n",
            "non-Hebbian\n",
            "learning\n",
            "in\n",
            "the\n",
            "cortex\n",
            "Kernelized\n",
            "information\n",
            "bottleneck\n",
            "leads\n",
            "to\n",
            "biologically\n",
            "plausible\n",
            "3-factor\n",
            "Hebbian\n",
            "learning\n",
            "in\n",
            "deep\n",
            "networks\n",
            "Understanding\n",
            "the\n",
            "Role\n",
            "of\n",
            "Training\n",
            "Regimes\n",
            "in\n",
            "Continual\n",
            "Learning\n",
            "Fair\n",
            "regression\n",
            "with\n",
            "Wasserstein\n",
            "barycenters\n",
            "Training\n",
            "Stronger\n",
            "Baselines\n",
            "for\n",
            "Learning\n",
            "to\n",
            "Optimize\n",
            "Exactly\n",
            "Computing\n",
            "the\n",
            "Local\n",
            "Lipschitz\n",
            "Constant\n",
            "of\n",
            "ReLU\n",
            "Networks\n",
            "Strictly\n",
            "Batch\n",
            "Imitation\n",
            "Learning\n",
            "by\n",
            "Energy-based\n",
            "Distribution\n",
            "Matching\n",
            "On\n",
            "the\n",
            "Ergodicity\n",
            ",\n",
            "Bias\n",
            "and\n",
            "Asymptotic\n",
            "Normality\n",
            "of\n",
            "Randomized\n",
            "Midpoint\n",
            "Sampling\n",
            "Method\n",
            "A\n",
            "Single-Loop\n",
            "Smoothed\n",
            "Gradient\n",
            "Descent-Ascent\n",
            "Algorithm\n",
            "for\n",
            "Nonconvex-Concave\n",
            "Min-Max\n",
            "Problems\n",
            "Generating\n",
            "Correct\n",
            "Answers\n",
            "for\n",
            "Progressive\n",
            "Matrices\n",
            "Intelligence\n",
            "Tests\n",
            "HyNet\n",
            ":\n",
            "Learning\n",
            "Local\n",
            "Descriptor\n",
            "with\n",
            "Hybrid\n",
            "Similarity\n",
            "Measure\n",
            "and\n",
            "Triplet\n",
            "Loss\n",
            "Preference\n",
            "learning\n",
            "along\n",
            "multiple\n",
            "criteria\n",
            ":\n",
            "A\n",
            "game-theoretic\n",
            "perspective\n",
            "Multi-Plane\n",
            "Program\n",
            "Induction\n",
            "with\n",
            "3D\n",
            "Box\n",
            "Priors\n",
            "Online\n",
            "Neural\n",
            "Connectivity\n",
            "Estimation\n",
            "with\n",
            "Noisy\n",
            "Group\n",
            "Testing\n",
            "Once-for-All\n",
            "Adversarial\n",
            "Training\n",
            ":\n",
            "In-Situ\n",
            "Tradeoff\n",
            "between\n",
            "Robustness\n",
            "and\n",
            "Accuracy\n",
            "for\n",
            "Free\n",
            "Implicit\n",
            "Neural\n",
            "Representations\n",
            "with\n",
            "Periodic\n",
            "Activation\n",
            "Functions\n",
            "Rotated\n",
            "Binary\n",
            "Neural\n",
            "Network\n",
            "Community\n",
            "detection\n",
            "in\n",
            "sparse\n",
            "time-evolving\n",
            "graphs\n",
            "with\n",
            "a\n",
            "dynamical\n",
            "Bethe-Hessian\n",
            "Simple\n",
            "and\n",
            "Principled\n",
            "Uncertainty\n",
            "Estimation\n",
            "with\n",
            "Deterministic\n",
            "Deep\n",
            "Learning\n",
            "via\n",
            "Distance\n",
            "Awareness\n",
            "Adaptive\n",
            "Learning\n",
            "of\n",
            "Rank-One\n",
            "Models\n",
            "for\n",
            "Efficient\n",
            "Pairwise\n",
            "Sequence\n",
            "Alignment\n",
            "Hierarchical\n",
            "nucleation\n",
            "in\n",
            "deep\n",
            "neural\n",
            "networks\n",
            "Fourier\n",
            "Features\n",
            "Let\n",
            "Networks\n",
            "Learn\n",
            "High\n",
            "Frequency\n",
            "Functions\n",
            "in\n",
            "Low\n",
            "Dimensional\n",
            "Domains\n",
            "Graph\n",
            "Geometry\n",
            "Interaction\n",
            "Learning\n",
            "Differentiable\n",
            "Augmentation\n",
            "for\n",
            "Data-Efficient\n",
            "GAN\n",
            "Training\n",
            "Heuristic\n",
            "Domain\n",
            "Adaptation\n",
            "Learning\n",
            "Certified\n",
            "Individually\n",
            "Fair\n",
            "Representations\n",
            "Part-dependent\n",
            "Label\n",
            "Noise\n",
            ":\n",
            "Towards\n",
            "Instance-dependent\n",
            "Label\n",
            "Noise\n",
            "Tackling\n",
            "the\n",
            "Objective\n",
            "Inconsistency\n",
            "Problem\n",
            "in\n",
            "Heterogeneous\n",
            "Federated\n",
            "Optimization\n",
            "An\n",
            "Improved\n",
            "Analysis\n",
            "of\n",
            "(\n",
            "Variance-Reduced\n",
            ")\n",
            "Policy\n",
            "Gradient\n",
            "and\n",
            "Natural\n",
            "Policy\n",
            "Gradient\n",
            "Methods\n",
            "Geometric\n",
            "Exploration\n",
            "for\n",
            "Online\n",
            "Control\n",
            "Automatic\n",
            "Curriculum\n",
            "Learning\n",
            "through\n",
            "Value\n",
            "Disagreement\n",
            "MRI\n",
            "Banding\n",
            "Removal\n",
            "via\n",
            "Adversarial\n",
            "Training\n",
            "The\n",
            "NetHack\n",
            "Learning\n",
            "Environment\n",
            "Language\n",
            "and\n",
            "Visual\n",
            "Entity\n",
            "Relationship\n",
            "Graph\n",
            "for\n",
            "Agent\n",
            "Navigation\n",
            "ICAM\n",
            ":\n",
            "Interpretable\n",
            "Classification\n",
            "via\n",
            "Disentangled\n",
            "Representations\n",
            "and\n",
            "Feature\n",
            "Attribution\n",
            "Mapping\n",
            "Spectra\n",
            "of\n",
            "the\n",
            "Conjugate\n",
            "Kernel\n",
            "and\n",
            "Neural\n",
            "Tangent\n",
            "Kernel\n",
            "for\n",
            "linear-width\n",
            "neural\n",
            "networks\n",
            "No-Regret\n",
            "Learning\n",
            "Dynamics\n",
            "for\n",
            "Extensive-Form\n",
            "Correlated\n",
            "Equilibrium\n",
            "Estimating\n",
            "weighted\n",
            "areas\n",
            "under\n",
            "the\n",
            "ROC\n",
            "curve\n",
            "Can\n",
            "Implicit\n",
            "Bias\n",
            "Explain\n",
            "Generalization\n",
            "?\n",
            "Stochastic\n",
            "Convex\n",
            "Optimization\n",
            "as\n",
            "a\n",
            "Case\n",
            "Study\n",
            "Generalized\n",
            "Hindsight\n",
            "for\n",
            "Reinforcement\n",
            "Learning\n",
            "Critic\n",
            "Regularized\n",
            "Regression\n",
            "Boosting\n",
            "Adversarial\n",
            "Training\n",
            "with\n",
            "Hypersphere\n",
            "Embedding\n",
            "Beyond\n",
            "Homophily\n",
            "in\n",
            "Graph\n",
            "Neural\n",
            "Networks\n",
            ":\n",
            "Current\n",
            "Limitations\n",
            "and\n",
            "Effective\n",
            "Designs\n",
            "Modeling\n",
            "Continuous\n",
            "Stochastic\n",
            "Processes\n",
            "with\n",
            "Dynamic\n",
            "Normalizing\n",
            "Flows\n",
            "Efficient\n",
            "Online\n",
            "Learning\n",
            "of\n",
            "Optimal\n",
            "Rankings\n",
            ":\n",
            "Dimensionality\n",
            "Reduction\n",
            "via\n",
            "Gradient\n",
            "Descent\n",
            "Training\n",
            "Normalizing\n",
            "Flows\n",
            "with\n",
            "the\n",
            "Information\n",
            "Bottleneck\n",
            "for\n",
            "Competitive\n",
            "Generative\n",
            "Classification\n",
            "Detecting\n",
            "Hands\n",
            "and\n",
            "Recognizing\n",
            "Physical\n",
            "Contact\n",
            "in\n",
            "the\n",
            "Wild\n",
            "On\n",
            "the\n",
            "Theory\n",
            "of\n",
            "Transfer\n",
            "Learning\n",
            ":\n",
            "The\n",
            "Importance\n",
            "of\n",
            "Task\n",
            "Diversity\n",
            "Finite-Time\n",
            "Analysis\n",
            "of\n",
            "Round-Robin\n",
            "Kullback-Leibler\n",
            "Upper\n",
            "Confidence\n",
            "Bounds\n",
            "for\n",
            "Optimal\n",
            "Adaptive\n",
            "Allocation\n",
            "with\n",
            "Multiple\n",
            "Plays\n",
            "and\n",
            "Markovian\n",
            "Rewards\n",
            "Neural\n",
            "Star\n",
            "Domain\n",
            "as\n",
            "Primitive\n",
            "Representation\n",
            "Off-Policy\n",
            "Interval\n",
            "Estimation\n",
            "with\n",
            "Lipschitz\n",
            "Value\n",
            "Iteration\n",
            "Inverse\n",
            "Rational\n",
            "Control\n",
            "with\n",
            "Partially\n",
            "Observable\n",
            "Continuous\n",
            "Nonlinear\n",
            "Dynamics\n",
            "Deep\n",
            "Statistical\n",
            "Solvers\n",
            "Distributionally\n",
            "Robust\n",
            "Parametric\n",
            "Maximum\n",
            "Likelihood\n",
            "Estimation\n",
            "Secretary\n",
            "and\n",
            "Online\n",
            "Matching\n",
            "Problems\n",
            "with\n",
            "Machine\n",
            "Learned\n",
            "Advice\n",
            "Deep\n",
            "Transformation-Invariant\n",
            "Clustering\n",
            "Overfitting\n",
            "Can\n",
            "Be\n",
            "Harmless\n",
            "for\n",
            "Basis\n",
            "Pursuit\n",
            ",\n",
            "But\n",
            "Only\n",
            "to\n",
            "a\n",
            "Degree\n",
            "Improving\n",
            "Generalization\n",
            "in\n",
            "Reinforcement\n",
            "Learning\n",
            "with\n",
            "Mixture\n",
            "Regularization\n",
            "Pontryagin\n",
            "Differentiable\n",
            "Programming\n",
            ":\n",
            "An\n",
            "End-to-End\n",
            "Learning\n",
            "and\n",
            "Control\n",
            "Framework\n",
            "Learning\n",
            "from\n",
            "Aggregate\n",
            "Observations\n",
            "The\n",
            "Devil\n",
            "is\n",
            "in\n",
            "the\n",
            "Detail\n",
            ":\n",
            "A\n",
            "Framework\n",
            "for\n",
            "Macroscopic\n",
            "Prediction\n",
            "via\n",
            "Microscopic\n",
            "Models\n",
            "Subgraph\n",
            "Neural\n",
            "Networks\n",
            "Demystifying\n",
            "Orthogonal\n",
            "Monte\n",
            "Carlo\n",
            "and\n",
            "Beyond\n",
            "Optimal\n",
            "Robustness-Consistency\n",
            "Trade-offs\n",
            "for\n",
            "Learning-Augmented\n",
            "Online\n",
            "Algorithms\n",
            "A\n",
            "Scalable\n",
            "Approach\n",
            "for\n",
            "Privacy-Preserving\n",
            "Collaborative\n",
            "Machine\n",
            "Learning\n",
            "Glow-TTS\n",
            ":\n",
            "A\n",
            "Generative\n",
            "Flow\n",
            "for\n",
            "Text-to-Speech\n",
            "via\n",
            "Monotonic\n",
            "Alignment\n",
            "Search\n",
            "Towards\n",
            "Learning\n",
            "Convolutions\n",
            "from\n",
            "Scratch\n",
            "Cycle-Contrast\n",
            "for\n",
            "Self-Supervised\n",
            "Video\n",
            "Representation\n",
            "Learning\n",
            "Posterior\n",
            "Re-calibration\n",
            "for\n",
            "Imbalanced\n",
            "Datasets\n",
            "Novelty\n",
            "Search\n",
            "in\n",
            "Representational\n",
            "Space\n",
            "for\n",
            "Sample\n",
            "Efficient\n",
            "Exploration\n",
            "Robust\n",
            "Reinforcement\n",
            "Learning\n",
            "via\n",
            "Adversarial\n",
            "training\n",
            "with\n",
            "Langevin\n",
            "Dynamics\n",
            "Adversarial\n",
            "Blocking\n",
            "Bandits\n",
            "Online\n",
            "Algorithms\n",
            "for\n",
            "Multi-shop\n",
            "Ski\n",
            "Rental\n",
            "with\n",
            "Machine\n",
            "Learned\n",
            "Advice\n",
            "Multi-label\n",
            "Contrastive\n",
            "Predictive\n",
            "Coding\n",
            "Rotation-Invariant\n",
            "Local-to-Global\n",
            "Representation\n",
            "Learning\n",
            "for\n",
            "3D\n",
            "Point\n",
            "Cloud\n",
            "Learning\n",
            "Invariants\n",
            "through\n",
            "Soft\n",
            "Unification\n",
            "One\n",
            "Solution\n",
            "is\n",
            "Not\n",
            "All\n",
            "You\n",
            "Need\n",
            ":\n",
            "Few-Shot\n",
            "Extrapolation\n",
            "via\n",
            "Structured\n",
            "MaxEnt\n",
            "RL\n",
            "Variational\n",
            "Bayesian\n",
            "Monte\n",
            "Carlo\n",
            "with\n",
            "Noisy\n",
            "Likelihoods\n",
            "Finite-Sample\n",
            "Analysis\n",
            "of\n",
            "Contractive\n",
            "Stochastic\n",
            "Approximation\n",
            "Using\n",
            "Smooth\n",
            "Convex\n",
            "Envelopes\n",
            "Self-Supervised\n",
            "Generative\n",
            "Adversarial\n",
            "Compression\n",
            "An\n",
            "efficient\n",
            "nonconvex\n",
            "reformulation\n",
            "of\n",
            "stagewise\n",
            "convex\n",
            "optimization\n",
            "problems\n",
            "From\n",
            "Finite\n",
            "to\n",
            "Countable-Armed\n",
            "Bandits\n",
            "Adversarial\n",
            "Distributional\n",
            "Training\n",
            "for\n",
            "Robust\n",
            "Deep\n",
            "Learning\n",
            "Meta-Learning\n",
            "Stationary\n",
            "Stochastic\n",
            "Process\n",
            "Prediction\n",
            "with\n",
            "Convolutional\n",
            "Neural\n",
            "Processes\n",
            "Theory-Inspired\n",
            "Path-Regularized\n",
            "Differential\n",
            "Network\n",
            "Architecture\n",
            "Search\n",
            "Conic\n",
            "Descent\n",
            "and\n",
            "its\n",
            "Application\n",
            "to\n",
            "Memory-efficient\n",
            "Optimization\n",
            "over\n",
            "Positive\n",
            "Semidefinite\n",
            "Matrices\n",
            "Learning\n",
            "the\n",
            "Geometry\n",
            "of\n",
            "Wave-Based\n",
            "Imaging\n",
            "Greedy\n",
            "inference\n",
            "with\n",
            "structure-exploiting\n",
            "lazy\n",
            "maps\n",
            "Nimble\n",
            ":\n",
            "Lightweight\n",
            "and\n",
            "Parallel\n",
            "GPU\n",
            "Task\n",
            "Scheduling\n",
            "for\n",
            "Deep\n",
            "Learning\n",
            "Finding\n",
            "the\n",
            "Homology\n",
            "of\n",
            "Decision\n",
            "Boundaries\n",
            "with\n",
            "Active\n",
            "Learning\n",
            "Reinforced\n",
            "Molecular\n",
            "Optimization\n",
            "with\n",
            "Neighborhood-Controlled\n",
            "Grammars\n",
            "Natural\n",
            "Policy\n",
            "Gradient\n",
            "Primal-Dual\n",
            "Method\n",
            "for\n",
            "Constrained\n",
            "Markov\n",
            "Decision\n",
            "Processes\n",
            "Classification\n",
            "Under\n",
            "Misspecification\n",
            ":\n",
            "Halfspaces\n",
            ",\n",
            "Generalized\n",
            "Linear\n",
            "Models\n",
            ",\n",
            "and\n",
            "Evolvability\n",
            "Certified\n",
            "Defense\n",
            "to\n",
            "Image\n",
            "Transformations\n",
            "via\n",
            "Randomized\n",
            "Smoothing\n",
            "Estimation\n",
            "of\n",
            "Skill\n",
            "Distribution\n",
            "from\n",
            "a\n",
            "Tournament\n",
            "Reparameterizing\n",
            "Mirror\n",
            "Descent\n",
            "as\n",
            "Gradient\n",
            "Descent\n",
            "General\n",
            "Control\n",
            "Functions\n",
            "for\n",
            "Causal\n",
            "Effect\n",
            "Estimation\n",
            "from\n",
            "IVs\n",
            "Optimal\n",
            "Algorithms\n",
            "for\n",
            "Stochastic\n",
            "Multi-Armed\n",
            "Bandits\n",
            "with\n",
            "Heavy\n",
            "Tailed\n",
            "Rewards\n",
            "Certified\n",
            "Robustness\n",
            "of\n",
            "Graph\n",
            "Convolution\n",
            "Networks\n",
            "for\n",
            "Graph\n",
            "Classification\n",
            "under\n",
            "Topological\n",
            "Attacks\n",
            "Zero-Resource\n",
            "Knowledge-Grounded\n",
            "Dialogue\n",
            "Generation\n",
            "Targeted\n",
            "Adversarial\n",
            "Perturbations\n",
            "for\n",
            "Monocular\n",
            "Depth\n",
            "Prediction\n",
            "Beyond\n",
            "the\n",
            "Mean-Field\n",
            ":\n",
            "Structured\n",
            "Deep\n",
            "Gaussian\n",
            "Processes\n",
            "Improve\n",
            "the\n",
            "Predictive\n",
            "Uncertainties\n",
            "Offline\n",
            "Imitation\n",
            "Learning\n",
            "with\n",
            "a\n",
            "Misspecified\n",
            "Simulator\n",
            "Multi-Fidelity\n",
            "Bayesian\n",
            "Optimization\n",
            "via\n",
            "Deep\n",
            "Neural\n",
            "Networks\n",
            "PlanGAN\n",
            ":\n",
            "Model-based\n",
            "Planning\n",
            "With\n",
            "Sparse\n",
            "Rewards\n",
            "and\n",
            "Multiple\n",
            "Goals\n",
            "Bad\n",
            "Global\n",
            "Minima\n",
            "Exist\n",
            "and\n",
            "SGD\n",
            "Can\n",
            "Reach\n",
            "Them\n",
            "Optimal\n",
            "Prediction\n",
            "of\n",
            "the\n",
            "Number\n",
            "of\n",
            "Unseen\n",
            "Species\n",
            "with\n",
            "Multiplicity\n",
            "Characterizing\n",
            "Optimal\n",
            "Mixed\n",
            "Policies\n",
            ":\n",
            "Where\n",
            "to\n",
            "Intervene\n",
            "and\n",
            "What\n",
            "to\n",
            "Observe\n",
            "Factor\n",
            "Graph\n",
            "Neural\n",
            "Networks\n",
            "A\n",
            "Closer\n",
            "Look\n",
            "at\n",
            "Accuracy\n",
            "vs.\n",
            "Robustness\n",
            "Curriculum\n",
            "Learning\n",
            "by\n",
            "Dynamic\n",
            "Instance\n",
            "Hardness\n",
            "Spin-Weighted\n",
            "Spherical\n",
            "CNNs\n",
            "Learning\n",
            "to\n",
            "Execute\n",
            "Programs\n",
            "with\n",
            "Instruction\n",
            "Pointer\n",
            "Attention\n",
            "Graph\n",
            "Neural\n",
            "Networks\n",
            "AutoPrivacy\n",
            ":\n",
            "Automated\n",
            "Layer-wise\n",
            "Parameter\n",
            "Selection\n",
            "for\n",
            "Secure\n",
            "Neural\n",
            "Network\n",
            "Inference\n",
            "Baxter\n",
            "Permutation\n",
            "Process\n",
            "Characterizing\n",
            "emergent\n",
            "representations\n",
            "in\n",
            "a\n",
            "space\n",
            "of\n",
            "candidate\n",
            "learning\n",
            "rules\n",
            "for\n",
            "deep\n",
            "networks\n",
            "Fast\n",
            ",\n",
            "Accurate\n",
            ",\n",
            "and\n",
            "Simple\n",
            "Models\n",
            "for\n",
            "Tabular\n",
            "Data\n",
            "via\n",
            "Augmented\n",
            "Distillation\n",
            "Adaptive\n",
            "Probing\n",
            "Policies\n",
            "for\n",
            "Shortest\n",
            "Path\n",
            "Routing\n",
            "Approximate\n",
            "Heavily-Constrained\n",
            "Learning\n",
            "with\n",
            "Lagrange\n",
            "Multiplier\n",
            "Models\n",
            "Faster\n",
            "Randomized\n",
            "Infeasible\n",
            "Interior\n",
            "Point\n",
            "Methods\n",
            "for\n",
            "Tall/Wide\n",
            "Linear\n",
            "Programs\n",
            "Sliding\n",
            "Window\n",
            "Algorithms\n",
            "for\n",
            "k-Clustering\n",
            "Problems\n",
            "AdaShare\n",
            ":\n",
            "Learning\n",
            "What\n",
            "To\n",
            "Share\n",
            "For\n",
            "Efficient\n",
            "Deep\n",
            "Multi-Task\n",
            "Learning\n",
            "Approximate\n",
            "Cross-Validation\n",
            "for\n",
            "Structured\n",
            "Models\n",
            "Exemplar\n",
            "VAE\n",
            ":\n",
            "Linking\n",
            "Generative\n",
            "Models\n",
            ",\n",
            "Nearest\n",
            "Neighbor\n",
            "Retrieval\n",
            ",\n",
            "and\n",
            "Data\n",
            "Augmentation\n",
            "Debiased\n",
            "Contrastive\n",
            "Learning\n",
            "UCSG-NET-\n",
            "Unsupervised\n",
            "Discovering\n",
            "of\n",
            "Constructive\n",
            "Solid\n",
            "Geometry\n",
            "Tree\n",
            "Generalized\n",
            "Boosting\n",
            "COT-GAN\n",
            ":\n",
            "Generating\n",
            "Sequential\n",
            "Data\n",
            "via\n",
            "Causal\n",
            "Optimal\n",
            "Transport\n",
            "Impossibility\n",
            "Results\n",
            "for\n",
            "Grammar-Compressed\n",
            "Linear\n",
            "Algebra\n",
            "Understanding\n",
            "spiking\n",
            "networks\n",
            "through\n",
            "convex\n",
            "optimization\n",
            "Better\n",
            "Full-Matrix\n",
            "Regret\n",
            "via\n",
            "Parameter-Free\n",
            "Online\n",
            "Learning\n",
            "Large-Scale\n",
            "Methods\n",
            "for\n",
            "Distributionally\n",
            "Robust\n",
            "Optimization\n",
            "Analysis\n",
            "and\n",
            "Design\n",
            "of\n",
            "Thompson\n",
            "Sampling\n",
            "for\n",
            "Stochastic\n",
            "Partial\n",
            "Monitoring\n",
            "Bandit\n",
            "Linear\n",
            "Control\n",
            "Refactoring\n",
            "Policy\n",
            "for\n",
            "Compositional\n",
            "Generalizability\n",
            "using\n",
            "Self-Supervised\n",
            "Object\n",
            "Proposals\n",
            "PEP\n",
            ":\n",
            "Parameter\n",
            "Ensembling\n",
            "by\n",
            "Perturbation\n",
            "Theoretical\n",
            "Insights\n",
            "Into\n",
            "Multiclass\n",
            "Classification\n",
            ":\n",
            "A\n",
            "High-dimensional\n",
            "Asymptotic\n",
            "View\n",
            "Adversarial\n",
            "Example\n",
            "Games\n",
            "Residual\n",
            "Distillation\n",
            ":\n",
            "Towards\n",
            "Portable\n",
            "Deep\n",
            "Neural\n",
            "Networks\n",
            "without\n",
            "Shortcuts\n",
            "Provably\n",
            "Efficient\n",
            "Neural\n",
            "Estimation\n",
            "of\n",
            "Structural\n",
            "Equation\n",
            "Models\n",
            ":\n",
            "An\n",
            "Adversarial\n",
            "Approach\n",
            "Security\n",
            "Analysis\n",
            "of\n",
            "Safe\n",
            "and\n",
            "Seldonian\n",
            "Reinforcement\n",
            "Learning\n",
            "Algorithms\n",
            "Learning\n",
            "to\n",
            "Play\n",
            "Sequential\n",
            "Games\n",
            "versus\n",
            "Unknown\n",
            "Opponents\n",
            "Further\n",
            "Analysis\n",
            "of\n",
            "Outlier\n",
            "Detection\n",
            "with\n",
            "Deep\n",
            "Generative\n",
            "Models\n",
            "Bridging\n",
            "Imagination\n",
            "and\n",
            "Reality\n",
            "for\n",
            "Model-Based\n",
            "Deep\n",
            "Reinforcement\n",
            "Learning\n",
            "Neural\n",
            "Networks\n",
            "Learning\n",
            "and\n",
            "Memorization\n",
            "with\n",
            "(\n",
            "almost\n",
            ")\n",
            "no\n",
            "Over-Parameterization\n",
            "Exploiting\n",
            "Higher\n",
            "Order\n",
            "Smoothness\n",
            "in\n",
            "Derivative-free\n",
            "Optimization\n",
            "and\n",
            "Continuous\n",
            "Bandits\n",
            "Towards\n",
            "a\n",
            "Combinatorial\n",
            "Characterization\n",
            "of\n",
            "Bounded-Memory\n",
            "Learning\n",
            "Chaos\n",
            ",\n",
            "Extremism\n",
            "and\n",
            "Optimism\n",
            ":\n",
            "Volume\n",
            "Analysis\n",
            "of\n",
            "Learning\n",
            "in\n",
            "Games\n",
            "On\n",
            "Regret\n",
            "with\n",
            "Multiple\n",
            "Best\n",
            "Arms\n",
            "Matrix\n",
            "Completion\n",
            "with\n",
            "Hierarchical\n",
            "Graph\n",
            "Side\n",
            "Information\n",
            "Is\n",
            "Long\n",
            "Horizon\n",
            "RL\n",
            "More\n",
            "Difficult\n",
            "Than\n",
            "Short\n",
            "Horizon\n",
            "RL\n",
            "?\n",
            "Hamiltonian\n",
            "Monte\n",
            "Carlo\n",
            "using\n",
            "an\n",
            "adjoint-differentiated\n",
            "Laplace\n",
            "approximation\n",
            ":\n",
            "Bayesian\n",
            "inference\n",
            "for\n",
            "latent\n",
            "Gaussian\n",
            "models\n",
            "and\n",
            "beyond\n",
            "Adversarial\n",
            "Learning\n",
            "for\n",
            "Robust\n",
            "Deep\n",
            "Clustering\n",
            "Learning\n",
            "Mutational\n",
            "Semantics\n",
            "Learning\n",
            "to\n",
            "Learn\n",
            "Variational\n",
            "Semantic\n",
            "Memory\n",
            "Myersonian\n",
            "Regression\n",
            "Learnability\n",
            "with\n",
            "Indirect\n",
            "Supervision\n",
            "Signals\n",
            "Towards\n",
            "Safe\n",
            "Policy\n",
            "Improvement\n",
            "for\n",
            "Non-Stationary\n",
            "MDPs\n",
            "Finer\n",
            "Metagenomic\n",
            "Reconstruction\n",
            "via\n",
            "Biodiversity\n",
            "Optimization\n",
            "Causal\n",
            "Discovery\n",
            "in\n",
            "Physical\n",
            "Systems\n",
            "from\n",
            "Videos\n",
            "Glyph\n",
            ":\n",
            "Fast\n",
            "and\n",
            "Accurately\n",
            "Training\n",
            "Deep\n",
            "Neural\n",
            "Networks\n",
            "on\n",
            "Encrypted\n",
            "Data\n",
            "Smoothed\n",
            "Analysis\n",
            "of\n",
            "Online\n",
            "and\n",
            "Differentially\n",
            "Private\n",
            "Learning\n",
            "Self-Paced\n",
            "Deep\n",
            "Reinforcement\n",
            "Learning\n",
            "Kalman\n",
            "Filtering\n",
            "Attention\n",
            "for\n",
            "User\n",
            "Behavior\n",
            "Modeling\n",
            "in\n",
            "CTR\n",
            "Prediction\n",
            "Towards\n",
            "Maximizing\n",
            "the\n",
            "Representation\n",
            "Gap\n",
            "between\n",
            "In-Domain\n",
            "&\n",
            "Out-of-Distribution\n",
            "Examples\n",
            "Fully\n",
            "Convolutional\n",
            "Mesh\n",
            "Autoencoder\n",
            "using\n",
            "Efficient\n",
            "Spatially\n",
            "Varying\n",
            "Kernels\n",
            "GNNGuard\n",
            ":\n",
            "Defending\n",
            "Graph\n",
            "Neural\n",
            "Networks\n",
            "against\n",
            "Adversarial\n",
            "Attacks\n",
            "Geo-PIFu\n",
            ":\n",
            "Geometry\n",
            "and\n",
            "Pixel\n",
            "Aligned\n",
            "Implicit\n",
            "Functions\n",
            "for\n",
            "Single-view\n",
            "Human\n",
            "Reconstruction\n",
            "Optimal\n",
            "visual\n",
            "search\n",
            "based\n",
            "on\n",
            "a\n",
            "model\n",
            "of\n",
            "target\n",
            "detectability\n",
            "in\n",
            "natural\n",
            "images\n",
            "Towards\n",
            "Convergence\n",
            "Rate\n",
            "Analysis\n",
            "of\n",
            "Random\n",
            "Forests\n",
            "for\n",
            "Classification\n",
            "List-Decodable\n",
            "Mean\n",
            "Estimation\n",
            "via\n",
            "Iterative\n",
            "Multi-Filtering\n",
            "Exact\n",
            "Recovery\n",
            "of\n",
            "Mangled\n",
            "Clusters\n",
            "with\n",
            "Same-Cluster\n",
            "Queries\n",
            "Steady\n",
            "State\n",
            "Analysis\n",
            "of\n",
            "Episodic\n",
            "Reinforcement\n",
            "Learning\n",
            "Direct\n",
            "Feedback\n",
            "Alignment\n",
            "Scales\n",
            "to\n",
            "Modern\n",
            "Deep\n",
            "Learning\n",
            "Tasks\n",
            "and\n",
            "Architectures\n",
            "Bayesian\n",
            "Optimization\n",
            "for\n",
            "Iterative\n",
            "Learning\n",
            "Minimax\n",
            "Bounds\n",
            "for\n",
            "Generalized\n",
            "Linear\n",
            "Models\n",
            "Projection\n",
            "Robust\n",
            "Wasserstein\n",
            "Distance\n",
            "and\n",
            "Riemannian\n",
            "Optimization\n",
            "CoinDICE\n",
            ":\n",
            "Off-Policy\n",
            "Confidence\n",
            "Interval\n",
            "Estimation\n",
            "Simple\n",
            "and\n",
            "Fast\n",
            "Algorithm\n",
            "for\n",
            "Binary\n",
            "Integer\n",
            "and\n",
            "Online\n",
            "Linear\n",
            "Programming\n",
            "Learning\n",
            "Diverse\n",
            "and\n",
            "Discriminative\n",
            "Representations\n",
            "via\n",
            "the\n",
            "Principle\n",
            "of\n",
            "Maximal\n",
            "Coding\n",
            "Rate\n",
            "Reduction\n",
            "Learning\n",
            "Rich\n",
            "Rankings\n",
            "Color\n",
            "Visual\n",
            "Illusions\n",
            ":\n",
            "A\n",
            "Statistics-based\n",
            "Computational\n",
            "Model\n",
            "Retrieval-Augmented\n",
            "Generation\n",
            "for\n",
            "Knowledge-Intensive\n",
            "NLP\n",
            "Tasks\n",
            "Universal\n",
            "guarantees\n",
            "for\n",
            "decision\n",
            "tree\n",
            "induction\n",
            "via\n",
            "a\n",
            "higher-order\n",
            "splitting\n",
            "criterion\n",
            "Trade-offs\n",
            "and\n",
            "Guarantees\n",
            "of\n",
            "Adversarial\n",
            "Representation\n",
            "Learning\n",
            "for\n",
            "Information\n",
            "Obfuscation\n",
            "A\n",
            "Boolean\n",
            "Task\n",
            "Algebra\n",
            "for\n",
            "Reinforcement\n",
            "Learning\n",
            "Learning\n",
            "with\n",
            "Differentiable\n",
            "Pertubed\n",
            "Optimizers\n",
            "Optimal\n",
            "Learning\n",
            "from\n",
            "Verified\n",
            "Training\n",
            "Data\n",
            "Online\n",
            "Linear\n",
            "Optimization\n",
            "with\n",
            "Many\n",
            "Hints\n",
            "Dynamical\n",
            "mean-field\n",
            "theory\n",
            "for\n",
            "stochastic\n",
            "gradient\n",
            "descent\n",
            "in\n",
            "Gaussian\n",
            "mixture\n",
            "classification\n",
            "Causal\n",
            "Discovery\n",
            "from\n",
            "Soft\n",
            "Interventions\n",
            "with\n",
            "Unknown\n",
            "Targets\n",
            ":\n",
            "Characterization\n",
            "and\n",
            "Learning\n",
            "Exploiting\n",
            "the\n",
            "Surrogate\n",
            "Gap\n",
            "in\n",
            "Online\n",
            "Multiclass\n",
            "Classification\n",
            "The\n",
            "Pitfalls\n",
            "of\n",
            "Simplicity\n",
            "Bias\n",
            "in\n",
            "Neural\n",
            "Networks\n",
            "Automatically\n",
            "Learning\n",
            "Compact\n",
            "Quality-aware\n",
            "Surrogates\n",
            "for\n",
            "Optimization\n",
            "Problems\n",
            "Empirical\n",
            "Likelihood\n",
            "for\n",
            "Contextual\n",
            "Bandits\n",
            "Can\n",
            "Q-Learning\n",
            "with\n",
            "Graph\n",
            "Networks\n",
            "Learn\n",
            "a\n",
            "Generalizable\n",
            "Branching\n",
            "Heuristic\n",
            "for\n",
            "a\n",
            "SAT\n",
            "Solver\n",
            "?\n",
            "Non-reversible\n",
            "Gaussian\n",
            "processes\n",
            "for\n",
            "identifying\n",
            "latent\n",
            "dynamical\n",
            "structure\n",
            "in\n",
            "neural\n",
            "data\n",
            "Listening\n",
            "to\n",
            "Sounds\n",
            "of\n",
            "Silence\n",
            "for\n",
            "Speech\n",
            "Denoising\n",
            "BoxE\n",
            ":\n",
            "A\n",
            "Box\n",
            "Embedding\n",
            "Model\n",
            "for\n",
            "Knowledge\n",
            "Base\n",
            "Completion\n",
            "Coherent\n",
            "Hierarchical\n",
            "Multi-Label\n",
            "Classification\n",
            "Networks\n",
            "Walsh-Hadamard\n",
            "Variational\n",
            "Inference\n",
            "for\n",
            "Bayesian\n",
            "Deep\n",
            "Learning\n",
            "Federated\n",
            "Bayesian\n",
            "Optimization\n",
            "via\n",
            "Thompson\n",
            "Sampling\n",
            "MultiON\n",
            ":\n",
            "Benchmarking\n",
            "Semantic\n",
            "Map\n",
            "Memory\n",
            "using\n",
            "Multi-Object\n",
            "Navigation\n",
            "Neural\n",
            "Complexity\n",
            "Measures\n",
            "Optimal\n",
            "Iterative\n",
            "Sketching\n",
            "Methods\n",
            "with\n",
            "the\n",
            "Subsampled\n",
            "Randomized\n",
            "Hadamard\n",
            "Transform\n",
            "Provably\n",
            "adaptive\n",
            "reinforcement\n",
            "learning\n",
            "in\n",
            "metric\n",
            "spaces\n",
            "ShapeFlow\n",
            ":\n",
            "Learnable\n",
            "Deformation\n",
            "Flows\n",
            "Among\n",
            "3D\n",
            "Shapes\n",
            "Self-Supervised\n",
            "Learning\n",
            "by\n",
            "Cross-Modal\n",
            "Audio-Video\n",
            "Clustering\n",
            "Optimal\n",
            "Query\n",
            "Complexity\n",
            "of\n",
            "Secure\n",
            "Stochastic\n",
            "Convex\n",
            "Optimization\n",
            "DynaBERT\n",
            ":\n",
            "Dynamic\n",
            "BERT\n",
            "with\n",
            "Adaptive\n",
            "Width\n",
            "and\n",
            "Depth\n",
            "Generalization\n",
            "Bound\n",
            "of\n",
            "Gradient\n",
            "Descent\n",
            "for\n",
            "Non-Convex\n",
            "Metric\n",
            "Learning\n",
            "Dynamic\n",
            "Submodular\n",
            "Maximization\n",
            "Inference\n",
            "for\n",
            "Batched\n",
            "Bandits\n",
            "Approximate\n",
            "Cross-Validation\n",
            "with\n",
            "Low-Rank\n",
            "Data\n",
            "in\n",
            "High\n",
            "Dimensions\n",
            "GANSpace\n",
            ":\n",
            "Discovering\n",
            "Interpretable\n",
            "GAN\n",
            "Controls\n",
            "Differentiable\n",
            "Expected\n",
            "Hypervolume\n",
            "Improvement\n",
            "for\n",
            "Parallel\n",
            "Multi-Objective\n",
            "Bayesian\n",
            "Optimization\n",
            "Neuron-level\n",
            "Structured\n",
            "Pruning\n",
            "using\n",
            "Polarization\n",
            "Regularizer\n",
            "Limits\n",
            "on\n",
            "Testing\n",
            "Structural\n",
            "Changes\n",
            "in\n",
            "Ising\n",
            "Models\n",
            "Field-wise\n",
            "Learning\n",
            "for\n",
            "Multi-field\n",
            "Categorical\n",
            "Data\n",
            "Continual\n",
            "Learning\n",
            "in\n",
            "Low-rank\n",
            "Orthogonal\n",
            "Subspaces\n",
            "Unsupervised\n",
            "Learning\n",
            "of\n",
            "Visual\n",
            "Features\n",
            "by\n",
            "Contrasting\n",
            "Cluster\n",
            "Assignments\n",
            "Sharpened\n",
            "Generalization\n",
            "Bounds\n",
            "based\n",
            "on\n",
            "Conditional\n",
            "Mutual\n",
            "Information\n",
            "and\n",
            "an\n",
            "Application\n",
            "to\n",
            "Noisy\n",
            ",\n",
            "Iterative\n",
            "Algorithms\n",
            "Learning\n",
            "Deformable\n",
            "Tetrahedral\n",
            "Meshes\n",
            "for\n",
            "3D\n",
            "Reconstruction\n",
            "Information\n",
            "theoretic\n",
            "limits\n",
            "of\n",
            "learning\n",
            "a\n",
            "sparse\n",
            "rule\n",
            "Self-supervised\n",
            "learning\n",
            "through\n",
            "the\n",
            "eyes\n",
            "of\n",
            "a\n",
            "child\n",
            "Unsupervised\n",
            "Semantic\n",
            "Aggregation\n",
            "and\n",
            "Deformable\n",
            "Template\n",
            "Matching\n",
            "for\n",
            "Semi-Supervised\n",
            "Learning\n",
            "A\n",
            "game-theoretic\n",
            "analysis\n",
            "of\n",
            "networked\n",
            "system\n",
            "control\n",
            "for\n",
            "common-pool\n",
            "resource\n",
            "management\n",
            "using\n",
            "multi-agent\n",
            "reinforcement\n",
            "learning\n",
            "What\n",
            "shapes\n",
            "feature\n",
            "representations\n",
            "?\n",
            "Exploring\n",
            "datasets\n",
            ",\n",
            "architectures\n",
            ",\n",
            "and\n",
            "training\n",
            "Optimal\n",
            "Best-arm\n",
            "Identification\n",
            "in\n",
            "Linear\n",
            "Bandits\n",
            "Data\n",
            "Diversification\n",
            ":\n",
            "A\n",
            "Simple\n",
            "Strategy\n",
            "For\n",
            "Neural\n",
            "Machine\n",
            "Translation\n",
            "Interstellar\n",
            ":\n",
            "Searching\n",
            "Recurrent\n",
            "Architecture\n",
            "for\n",
            "Knowledge\n",
            "Graph\n",
            "Embedding\n",
            "CoSE\n",
            ":\n",
            "Compositional\n",
            "Stroke\n",
            "Embeddings\n",
            "Learning\n",
            "Multi-Agent\n",
            "Coordination\n",
            "for\n",
            "Enhancing\n",
            "Target\n",
            "Coverage\n",
            "in\n",
            "Directional\n",
            "Sensor\n",
            "Networks\n",
            "Biological\n",
            "credit\n",
            "assignment\n",
            "through\n",
            "dynamic\n",
            "inversion\n",
            "of\n",
            "feedforward\n",
            "networks\n",
            "Discriminative\n",
            "Sounding\n",
            "Objects\n",
            "Localization\n",
            "via\n",
            "Self-supervised\n",
            "Audiovisual\n",
            "Matching\n",
            "Learning\n",
            "Multi-Agent\n",
            "Communication\n",
            "through\n",
            "Structured\n",
            "Attentive\n",
            "Reasoning\n",
            "Private\n",
            "Identity\n",
            "Testing\n",
            "for\n",
            "High-Dimensional\n",
            "Distributions\n",
            "On\n",
            "the\n",
            "Optimal\n",
            "Weighted\n",
            "$\n",
            "\\ell_2\n",
            "$\n",
            "Regularization\n",
            "in\n",
            "Overparameterized\n",
            "Linear\n",
            "Regression\n",
            "An\n",
            "Efficient\n",
            "Asynchronous\n",
            "Method\n",
            "for\n",
            "Integrating\n",
            "Evolutionary\n",
            "and\n",
            "Gradient-based\n",
            "Policy\n",
            "Search\n",
            "MetaSDF\n",
            ":\n",
            "Meta-Learning\n",
            "Signed\n",
            "Distance\n",
            "Functions\n",
            "Simple\n",
            "and\n",
            "Scalable\n",
            "Sparse\n",
            "k-means\n",
            "Clustering\n",
            "via\n",
            "Feature\n",
            "Ranking\n",
            "Model-based\n",
            "Adversarial\n",
            "Meta-Reinforcement\n",
            "Learning\n",
            "Graph\n",
            "Policy\n",
            "Network\n",
            "for\n",
            "Transferable\n",
            "Active\n",
            "Learning\n",
            "on\n",
            "Graphs\n",
            "Towards\n",
            "a\n",
            "Better\n",
            "Global\n",
            "Loss\n",
            "Landscape\n",
            "of\n",
            "GANs\n",
            "Weighted\n",
            "QMIX\n",
            ":\n",
            "Expanding\n",
            "Monotonic\n",
            "Value\n",
            "Function\n",
            "Factorisation\n",
            "for\n",
            "Deep\n",
            "Multi-Agent\n",
            "Reinforcement\n",
            "Learning\n",
            "BanditPAM\n",
            ":\n",
            "Almost\n",
            "Linear\n",
            "Time\n",
            "k-Medoids\n",
            "Clustering\n",
            "via\n",
            "Multi-Armed\n",
            "Bandits\n",
            "UDH\n",
            ":\n",
            "Universal\n",
            "Deep\n",
            "Hiding\n",
            "for\n",
            "Steganography\n",
            ",\n",
            "Watermarking\n",
            ",\n",
            "and\n",
            "Light\n",
            "Field\n",
            "Messaging\n",
            "Evidential\n",
            "Sparsification\n",
            "of\n",
            "Multimodal\n",
            "Latent\n",
            "Spaces\n",
            "in\n",
            "Conditional\n",
            "Variational\n",
            "Autoencoders\n",
            "An\n",
            "Unbiased\n",
            "Risk\n",
            "Estimator\n",
            "for\n",
            "Learning\n",
            "with\n",
            "Augmented\n",
            "Classes\n",
            "AutoBSS\n",
            ":\n",
            "An\n",
            "Efficient\n",
            "Algorithm\n",
            "for\n",
            "Block\n",
            "Stacking\n",
            "Style\n",
            "Search\n",
            "Pushing\n",
            "the\n",
            "Limits\n",
            "of\n",
            "Narrow\n",
            "Precision\n",
            "Inferencing\n",
            "at\n",
            "Cloud\n",
            "Scale\n",
            "with\n",
            "Microsoft\n",
            "Floating\n",
            "Point\n",
            "Stochastic\n",
            "Optimization\n",
            "with\n",
            "Laggard\n",
            "Data\n",
            "Pipelines\n",
            "Self-supervised\n",
            "Auxiliary\n",
            "Learning\n",
            "with\n",
            "Meta-paths\n",
            "for\n",
            "Heterogeneous\n",
            "Graphs\n",
            "GPS-Net\n",
            ":\n",
            "Graph-based\n",
            "Photometric\n",
            "Stereo\n",
            "Network\n",
            "Consistent\n",
            "Structural\n",
            "Relation\n",
            "Learning\n",
            "for\n",
            "Zero-Shot\n",
            "Segmentation\n",
            "Model\n",
            "Selection\n",
            "in\n",
            "Contextual\n",
            "Stochastic\n",
            "Bandit\n",
            "Problems\n",
            "Truncated\n",
            "Linear\n",
            "Regression\n",
            "in\n",
            "High\n",
            "Dimensions\n",
            "Incorporating\n",
            "Pragmatic\n",
            "Reasoning\n",
            "Communication\n",
            "into\n",
            "Emergent\n",
            "Language\n",
            "Deep\n",
            "Subspace\n",
            "Clustering\n",
            "with\n",
            "Data\n",
            "Augmentation\n",
            "An\n",
            "Empirical\n",
            "Process\n",
            "Approach\n",
            "to\n",
            "the\n",
            "Union\n",
            "Bound\n",
            ":\n",
            "Practical\n",
            "Algorithms\n",
            "for\n",
            "Combinatorial\n",
            "and\n",
            "Linear\n",
            "Bandits\n",
            "Can\n",
            "Graph\n",
            "Neural\n",
            "Networks\n",
            "Count\n",
            "Substructures\n",
            "?\n",
            "A\n",
            "Bayesian\n",
            "Perspective\n",
            "on\n",
            "Training\n",
            "Speed\n",
            "and\n",
            "Model\n",
            "Selection\n",
            "On\n",
            "the\n",
            "Modularity\n",
            "of\n",
            "Hypernetworks\n",
            "Doubly\n",
            "Robust\n",
            "Off-Policy\n",
            "Value\n",
            "and\n",
            "Gradient\n",
            "Estimation\n",
            "for\n",
            "Deterministic\n",
            "Policies\n",
            "Provably\n",
            "Efficient\n",
            "Neural\n",
            "GTD\n",
            "for\n",
            "Off-Policy\n",
            "Learning\n",
            "Learning\n",
            "Discrete\n",
            "Energy-based\n",
            "Models\n",
            "via\n",
            "Auxiliary-variable\n",
            "Local\n",
            "Exploration\n",
            "Stable\n",
            "and\n",
            "expressive\n",
            "recurrent\n",
            "vision\n",
            "models\n",
            "Entropic\n",
            "Optimal\n",
            "Transport\n",
            "between\n",
            "Unbalanced\n",
            "Gaussian\n",
            "Measures\n",
            "has\n",
            "a\n",
            "Closed\n",
            "Form\n",
            "BRP-NAS\n",
            ":\n",
            "Prediction-based\n",
            "NAS\n",
            "using\n",
            "GCNs\n",
            "Deep\n",
            "Shells\n",
            ":\n",
            "Unsupervised\n",
            "Shape\n",
            "Correspondence\n",
            "with\n",
            "Optimal\n",
            "Transport\n",
            "ISTA-NAS\n",
            ":\n",
            "Efficient\n",
            "and\n",
            "Consistent\n",
            "Neural\n",
            "Architecture\n",
            "Search\n",
            "by\n",
            "Sparse\n",
            "Coding\n",
            "Rel3D\n",
            ":\n",
            "A\n",
            "Minimally\n",
            "Contrastive\n",
            "Benchmark\n",
            "for\n",
            "Grounding\n",
            "Spatial\n",
            "Relations\n",
            "in\n",
            "3D\n",
            "Regularizing\n",
            "Black-box\n",
            "Models\n",
            "for\n",
            "Improved\n",
            "Interpretability\n",
            "Trust\n",
            "the\n",
            "Model\n",
            "When\n",
            "It\n",
            "Is\n",
            "Confident\n",
            ":\n",
            "Masked\n",
            "Model-based\n",
            "Actor-Critic\n",
            "Semi-Supervised\n",
            "Neural\n",
            "Architecture\n",
            "Search\n",
            "Consistency\n",
            "Regularization\n",
            "for\n",
            "Certified\n",
            "Robustness\n",
            "of\n",
            "Smoothed\n",
            "Classifiers\n",
            "Robust\n",
            "Multi-Agent\n",
            "Reinforcement\n",
            "Learning\n",
            "with\n",
            "Model\n",
            "Uncertainty\n",
            "SIRI\n",
            ":\n",
            "Spatial\n",
            "Relation\n",
            "Induced\n",
            "Network\n",
            "For\n",
            "Spatial\n",
            "Description\n",
            "Resolution\n",
            "Adaptive\n",
            "Shrinkage\n",
            "Estimation\n",
            "for\n",
            "Streaming\n",
            "Graphs\n",
            "Make\n",
            "One-Shot\n",
            "Video\n",
            "Object\n",
            "Segmentation\n",
            "Efficient\n",
            "Again\n",
            "Depth\n",
            "Uncertainty\n",
            "in\n",
            "Neural\n",
            "Networks\n",
            "Non-Euclidean\n",
            "Universal\n",
            "Approximation\n",
            "Constraining\n",
            "Variational\n",
            "Inference\n",
            "with\n",
            "Geometric\n",
            "Jensen-Shannon\n",
            "Divergence\n",
            "Gibbs\n",
            "Sampling\n",
            "with\n",
            "People\n",
            "HM-ANN\n",
            ":\n",
            "Efficient\n",
            "Billion-Point\n",
            "Nearest\n",
            "Neighbor\n",
            "Search\n",
            "on\n",
            "Heterogeneous\n",
            "Memory\n",
            "FrugalML\n",
            ":\n",
            "How\n",
            "to\n",
            "use\n",
            "ML\n",
            "Prediction\n",
            "APIs\n",
            "more\n",
            "accurately\n",
            "and\n",
            "cheaply\n",
            "Sharp\n",
            "Representation\n",
            "Theorems\n",
            "for\n",
            "ReLU\n",
            "Networks\n",
            "with\n",
            "Precise\n",
            "Dependence\n",
            "on\n",
            "Depth\n",
            "Shared\n",
            "Experience\n",
            "Actor-Critic\n",
            "for\n",
            "Multi-Agent\n",
            "Reinforcement\n",
            "Learning\n",
            "Monotone\n",
            "operator\n",
            "equilibrium\n",
            "networks\n",
            "When\n",
            "and\n",
            "How\n",
            "to\n",
            "Lift\n",
            "the\n",
            "Lockdown\n",
            "?\n",
            "Global\n",
            "COVID-19\n",
            "Scenario\n",
            "Analysis\n",
            "and\n",
            "Policy\n",
            "Assessment\n",
            "using\n",
            "Compartmental\n",
            "Gaussian\n",
            "Processes\n",
            "Unsupervised\n",
            "Learning\n",
            "of\n",
            "Lagrangian\n",
            "Dynamics\n",
            "from\n",
            "Images\n",
            "for\n",
            "Prediction\n",
            "and\n",
            "Control\n",
            "High-Dimensional\n",
            "Sparse\n",
            "Linear\n",
            "Bandits\n",
            "Non-Stochastic\n",
            "Control\n",
            "with\n",
            "Bandit\n",
            "Feedback\n",
            "Generalized\n",
            "Leverage\n",
            "Score\n",
            "Sampling\n",
            "for\n",
            "Neural\n",
            "Networks\n",
            "An\n",
            "Optimal\n",
            "Elimination\n",
            "Algorithm\n",
            "for\n",
            "Learning\n",
            "a\n",
            "Best\n",
            "Arm\n",
            "Efficient\n",
            "Projection-free\n",
            "Algorithms\n",
            "for\n",
            "Saddle\n",
            "Point\n",
            "Problems\n",
            "A\n",
            "mathematical\n",
            "model\n",
            "for\n",
            "automatic\n",
            "differentiation\n",
            "in\n",
            "machine\n",
            "learning\n",
            "Unsupervised\n",
            "Text\n",
            "Generation\n",
            "by\n",
            "Learning\n",
            "from\n",
            "Search\n",
            "Learning\n",
            "Compositional\n",
            "Rules\n",
            "via\n",
            "Neural\n",
            "Program\n",
            "Synthesis\n",
            "Incorporating\n",
            "BERT\n",
            "into\n",
            "Parallel\n",
            "Sequence\n",
            "Decoding\n",
            "with\n",
            "Adapters\n",
            "Estimating\n",
            "Fluctuations\n",
            "in\n",
            "Neural\n",
            "Representations\n",
            "of\n",
            "Uncertain\n",
            "Environments\n",
            "Discover\n",
            ",\n",
            "Hallucinate\n",
            ",\n",
            "and\n",
            "Adapt\n",
            ":\n",
            "Open\n",
            "Compound\n",
            "Domain\n",
            "Adaptation\n",
            "for\n",
            "Semantic\n",
            "Segmentation\n",
            "SURF\n",
            ":\n",
            "A\n",
            "Simple\n",
            ",\n",
            "Universal\n",
            ",\n",
            "Robust\n",
            ",\n",
            "Fast\n",
            "Distribution\n",
            "Learning\n",
            "Algorithm\n",
            "Understanding\n",
            "Approximate\n",
            "Fisher\n",
            "Information\n",
            "for\n",
            "Fast\n",
            "Convergence\n",
            "of\n",
            "Natural\n",
            "Gradient\n",
            "Descent\n",
            "in\n",
            "Wide\n",
            "Neural\n",
            "Networks\n",
            "General\n",
            "Transportability\n",
            "of\n",
            "Soft\n",
            "Interventions\n",
            ":\n",
            "Completeness\n",
            "Results\n",
            "GAIT-prop\n",
            ":\n",
            "A\n",
            "biologically\n",
            "plausible\n",
            "learning\n",
            "rule\n",
            "derived\n",
            "from\n",
            "backpropagation\n",
            "of\n",
            "error\n",
            "Lipschitz\n",
            "Bounds\n",
            "and\n",
            "Provably\n",
            "Robust\n",
            "Training\n",
            "by\n",
            "Laplacian\n",
            "Smoothing\n",
            "SCOP\n",
            ":\n",
            "Scientific\n",
            "Control\n",
            "for\n",
            "Reliable\n",
            "Neural\n",
            "Network\n",
            "Pruning\n",
            "Provably\n",
            "Consistent\n",
            "Partial-Label\n",
            "Learning\n",
            "Robust\n",
            ",\n",
            "Accurate\n",
            "Stochastic\n",
            "Optimization\n",
            "for\n",
            "Variational\n",
            "Inference\n",
            "Discovering\n",
            "conflicting\n",
            "groups\n",
            "in\n",
            "signed\n",
            "networks\n",
            "Learning\n",
            "Some\n",
            "Popular\n",
            "Gaussian\n",
            "Graphical\n",
            "Models\n",
            "without\n",
            "Condition\n",
            "Number\n",
            "Bounds\n",
            "Sense\n",
            "and\n",
            "Sensitivity\n",
            "Analysis\n",
            ":\n",
            "Simple\n",
            "Post-Hoc\n",
            "Analysis\n",
            "of\n",
            "Bias\n",
            "Due\n",
            "to\n",
            "Unobserved\n",
            "Confounding\n",
            "Mix\n",
            "and\n",
            "Match\n",
            ":\n",
            "An\n",
            "Optimistic\n",
            "Tree-Search\n",
            "Approach\n",
            "for\n",
            "Learning\n",
            "Models\n",
            "from\n",
            "Mixture\n",
            "Distributions\n",
            "Understanding\n",
            "Double\n",
            "Descent\n",
            "Requires\n",
            "A\n",
            "Fine-Grained\n",
            "Bias-Variance\n",
            "Decomposition\n",
            "VIME\n",
            ":\n",
            "Extending\n",
            "the\n",
            "Success\n",
            "of\n",
            "Self-\n",
            "and\n",
            "Semi-supervised\n",
            "Learning\n",
            "to\n",
            "Tabular\n",
            "Domain\n",
            "The\n",
            "Smoothed\n",
            "Possibility\n",
            "of\n",
            "Social\n",
            "Choice\n",
            "A\n",
            "Decentralized\n",
            "Parallel\n",
            "Algorithm\n",
            "for\n",
            "Training\n",
            "Generative\n",
            "Adversarial\n",
            "Nets\n",
            "Phase\n",
            "retrieval\n",
            "in\n",
            "high\n",
            "dimensions\n",
            ":\n",
            "Statistical\n",
            "and\n",
            "computational\n",
            "phase\n",
            "transitions\n",
            "Fair\n",
            "Performance\n",
            "Metric\n",
            "Elicitation\n",
            "Hybrid\n",
            "Variance-Reduced\n",
            "SGD\n",
            "Algorithms\n",
            "For\n",
            "Minimax\n",
            "Problems\n",
            "with\n",
            "Nonconvex-Linear\n",
            "Function\n",
            "Belief-Dependent\n",
            "Macro-Action\n",
            "Discovery\n",
            "in\n",
            "POMDPs\n",
            "using\n",
            "the\n",
            "Value\n",
            "of\n",
            "Information\n",
            "Soft\n",
            "Contrastive\n",
            "Learning\n",
            "for\n",
            "Visual\n",
            "Localization\n",
            "Fine-Grained\n",
            "Dynamic\n",
            "Head\n",
            "for\n",
            "Object\n",
            "Detection\n",
            "LoCo\n",
            ":\n",
            "Local\n",
            "Contrastive\n",
            "Representation\n",
            "Learning\n",
            "Modeling\n",
            "and\n",
            "Optimization\n",
            "Trade-off\n",
            "in\n",
            "Meta-learning\n",
            "SnapBoost\n",
            ":\n",
            "A\n",
            "Heterogeneous\n",
            "Boosting\n",
            "Machine\n",
            "On\n",
            "Adaptive\n",
            "Distance\n",
            "Estimation\n",
            "Stage-wise\n",
            "Conservative\n",
            "Linear\n",
            "Bandits\n",
            "RELATE\n",
            ":\n",
            "Physically\n",
            "Plausible\n",
            "Multi-Object\n",
            "Scene\n",
            "Synthesis\n",
            "Using\n",
            "Structured\n",
            "Latent\n",
            "Spaces\n",
            "Metric-Free\n",
            "Individual\n",
            "Fairness\n",
            "in\n",
            "Online\n",
            "Learning\n",
            "GreedyFool\n",
            ":\n",
            "Distortion-Aware\n",
            "Sparse\n",
            "Adversarial\n",
            "Attack\n",
            "VAEM\n",
            ":\n",
            "a\n",
            "Deep\n",
            "Generative\n",
            "Model\n",
            "for\n",
            "Heterogeneous\n",
            "Mixed\n",
            "Type\n",
            "Data\n",
            "RetroXpert\n",
            ":\n",
            "Decompose\n",
            "Retrosynthesis\n",
            "Prediction\n",
            "Like\n",
            "A\n",
            "Chemist\n",
            "Sample-Efficient\n",
            "Optimization\n",
            "in\n",
            "the\n",
            "Latent\n",
            "Space\n",
            "of\n",
            "Deep\n",
            "Generative\n",
            "Models\n",
            "via\n",
            "Weighted\n",
            "Retraining\n",
            "Improved\n",
            "Sample\n",
            "Complexity\n",
            "for\n",
            "Incremental\n",
            "Autonomous\n",
            "Exploration\n",
            "in\n",
            "MDPs\n",
            "TinyTL\n",
            ":\n",
            "Reduce\n",
            "Memory\n",
            ",\n",
            "Not\n",
            "Parameters\n",
            "for\n",
            "Efficient\n",
            "On-Device\n",
            "Learning\n",
            "RD\n",
            "$\n",
            "^2\n",
            "$\n",
            ":\n",
            "Reward\n",
            "Decomposition\n",
            "with\n",
            "Representation\n",
            "Decomposition\n",
            "Self-paced\n",
            "Contrastive\n",
            "Learning\n",
            "with\n",
            "Hybrid\n",
            "Memory\n",
            "for\n",
            "Domain\n",
            "Adaptive\n",
            "Object\n",
            "Re-ID\n",
            "Fairness\n",
            "constraints\n",
            "can\n",
            "help\n",
            "exact\n",
            "inference\n",
            "in\n",
            "structured\n",
            "prediction\n",
            "Instance-based\n",
            "Generalization\n",
            "in\n",
            "Reinforcement\n",
            "Learning\n",
            "Smooth\n",
            "And\n",
            "Consistent\n",
            "Probabilistic\n",
            "Regression\n",
            "Trees\n",
            "Computing\n",
            "Valid\n",
            "p-value\n",
            "for\n",
            "Optimal\n",
            "Changepoint\n",
            "by\n",
            "Selective\n",
            "Inference\n",
            "using\n",
            "Dynamic\n",
            "Programming\n",
            "Factorized\n",
            "Neural\n",
            "Processes\n",
            "for\n",
            "Neural\n",
            "Processes\n",
            ":\n",
            "K-Shot\n",
            "Prediction\n",
            "of\n",
            "Neural\n",
            "Responses\n",
            "Winning\n",
            "the\n",
            "Lottery\n",
            "with\n",
            "Continuous\n",
            "Sparsification\n",
            "Adversarial\n",
            "robustness\n",
            "via\n",
            "robust\n",
            "low\n",
            "rank\n",
            "representations\n",
            "Joints\n",
            "in\n",
            "Random\n",
            "Forests\n",
            "Compositional\n",
            "Generalization\n",
            "by\n",
            "Learning\n",
            "Analytical\n",
            "Expressions\n",
            "JAX\n",
            "MD\n",
            ":\n",
            "A\n",
            "Framework\n",
            "for\n",
            "Differentiable\n",
            "Physics\n",
            "An\n",
            "implicit\n",
            "function\n",
            "learning\n",
            "approach\n",
            "for\n",
            "parametric\n",
            "modal\n",
            "regression\n",
            "SDF-SRN\n",
            ":\n",
            "Learning\n",
            "Signed\n",
            "Distance\n",
            "3D\n",
            "Object\n",
            "Reconstruction\n",
            "from\n",
            "Static\n",
            "Images\n",
            "Coresets\n",
            "for\n",
            "Robust\n",
            "Training\n",
            "of\n",
            "Deep\n",
            "Neural\n",
            "Networks\n",
            "against\n",
            "Noisy\n",
            "Labels\n",
            "Adapting\n",
            "to\n",
            "Misspecification\n",
            "in\n",
            "Contextual\n",
            "Bandits\n",
            "Convergence\n",
            "of\n",
            "Meta-Learning\n",
            "with\n",
            "Task-Specific\n",
            "Adaptation\n",
            "over\n",
            "Partial\n",
            "Parameters\n",
            "MetaPerturb\n",
            ":\n",
            "Transferable\n",
            "Regularizer\n",
            "for\n",
            "Heterogeneous\n",
            "Tasks\n",
            "and\n",
            "Architectures\n",
            "Learning\n",
            "to\n",
            "solve\n",
            "TV\n",
            "regularised\n",
            "problems\n",
            "with\n",
            "unrolled\n",
            "algorithms\n",
            "Object-Centric\n",
            "Learning\n",
            "with\n",
            "Slot\n",
            "Attention\n",
            "Improving\n",
            "robustness\n",
            "against\n",
            "common\n",
            "corruptions\n",
            "by\n",
            "covariate\n",
            "shift\n",
            "adaptation\n",
            "Deep\n",
            "Smoothing\n",
            "of\n",
            "the\n",
            "Implied\n",
            "Volatility\n",
            "Surface\n",
            "Probabilistic\n",
            "Inference\n",
            "with\n",
            "Algebraic\n",
            "Constraints\n",
            ":\n",
            "Theoretical\n",
            "Limits\n",
            "and\n",
            "Practical\n",
            "Approximations\n",
            "Provable\n",
            "Online\n",
            "CP/PARAFAC\n",
            "Decomposition\n",
            "of\n",
            "a\n",
            "Structured\n",
            "Tensor\n",
            "via\n",
            "Dictionary\n",
            "Learning\n",
            "Look-ahead\n",
            "Meta\n",
            "Learning\n",
            "for\n",
            "Continual\n",
            "Learning\n",
            "A\n",
            "polynomial-time\n",
            "algorithm\n",
            "for\n",
            "learning\n",
            "nonparametric\n",
            "causal\n",
            "graphs\n",
            "Sparse\n",
            "Learning\n",
            "with\n",
            "CART\n",
            "Proximal\n",
            "Mapping\n",
            "for\n",
            "Deep\n",
            "Regularization\n",
            "Identifying\n",
            "Causal-Effect\n",
            "Inference\n",
            "Failure\n",
            "with\n",
            "Uncertainty-Aware\n",
            "Models\n",
            "Hierarchical\n",
            "Granularity\n",
            "Transfer\n",
            "Learning\n",
            "Deep\n",
            "active\n",
            "inference\n",
            "agents\n",
            "using\n",
            "Monte-Carlo\n",
            "methods\n",
            "Consistent\n",
            "Estimation\n",
            "of\n",
            "Identifiable\n",
            "Nonparametric\n",
            "Mixture\n",
            "Models\n",
            "from\n",
            "Grouped\n",
            "Observations\n",
            "Manifold\n",
            "structure\n",
            "in\n",
            "graph\n",
            "embeddings\n",
            "Adaptive\n",
            "Learned\n",
            "Bloom\n",
            "Filter\n",
            "(\n",
            "Ada-BF\n",
            ")\n",
            ":\n",
            "Efficient\n",
            "Utilization\n",
            "of\n",
            "the\n",
            "Classifier\n",
            "with\n",
            "Application\n",
            "to\n",
            "Real-Time\n",
            "Information\n",
            "Filtering\n",
            "on\n",
            "the\n",
            "Web\n",
            "MCUNet\n",
            ":\n",
            "Tiny\n",
            "Deep\n",
            "Learning\n",
            "on\n",
            "IoT\n",
            "Devices\n",
            "In\n",
            "search\n",
            "of\n",
            "robust\n",
            "measures\n",
            "of\n",
            "generalization\n",
            "Task-agnostic\n",
            "Exploration\n",
            "in\n",
            "Reinforcement\n",
            "Learning\n",
            "Multi-task\n",
            "Additive\n",
            "Models\n",
            "for\n",
            "Robust\n",
            "Estimation\n",
            "and\n",
            "Automatic\n",
            "Structure\n",
            "Discovery\n",
            "Provably\n",
            "Efficient\n",
            "Reward-Agnostic\n",
            "Navigation\n",
            "with\n",
            "Linear\n",
            "Value\n",
            "Iteration\n",
            "Softmax\n",
            "Deep\n",
            "Double\n",
            "Deterministic\n",
            "Policy\n",
            "Gradients\n",
            "Online\n",
            "Decision\n",
            "Based\n",
            "Visual\n",
            "Tracking\n",
            "via\n",
            "Reinforcement\n",
            "Learning\n",
            "Efficient\n",
            "Marginalization\n",
            "of\n",
            "Discrete\n",
            "and\n",
            "Structured\n",
            "Latent\n",
            "Variables\n",
            "via\n",
            "Sparsity\n",
            "DeepI2I\n",
            ":\n",
            "Enabling\n",
            "Deep\n",
            "Hierarchical\n",
            "Image-to-Image\n",
            "Translation\n",
            "by\n",
            "Transferring\n",
            "from\n",
            "GANs\n",
            "Distributional\n",
            "Robustness\n",
            "with\n",
            "IPMs\n",
            "and\n",
            "links\n",
            "to\n",
            "Regularization\n",
            "and\n",
            "GANs\n",
            "A\n",
            "shooting\n",
            "formulation\n",
            "of\n",
            "deep\n",
            "learning\n",
            "CSI\n",
            ":\n",
            "Novelty\n",
            "Detection\n",
            "via\n",
            "Contrastive\n",
            "Learning\n",
            "on\n",
            "Distributionally\n",
            "Shifted\n",
            "Instances\n",
            "Learning\n",
            "Implicit\n",
            "Credit\n",
            "Assignment\n",
            "for\n",
            "Cooperative\n",
            "Multi-Agent\n",
            "Reinforcement\n",
            "Learning\n",
            "MATE\n",
            ":\n",
            "Plugging\n",
            "in\n",
            "Model\n",
            "Awareness\n",
            "to\n",
            "Task\n",
            "Embedding\n",
            "for\n",
            "Meta\n",
            "Learning\n",
            "Restless-UCB\n",
            ",\n",
            "an\n",
            "Efficient\n",
            "and\n",
            "Low-complexity\n",
            "Algorithm\n",
            "for\n",
            "Online\n",
            "Restless\n",
            "Bandits\n",
            "Predictive\n",
            "Information\n",
            "Accelerates\n",
            "Learning\n",
            "in\n",
            "RL\n",
            "Robust\n",
            "and\n",
            "Heavy-Tailed\n",
            "Mean\n",
            "Estimation\n",
            "Made\n",
            "Simple\n",
            ",\n",
            "via\n",
            "Regret\n",
            "Minimization\n",
            "High-Fidelity\n",
            "Generative\n",
            "Image\n",
            "Compression\n",
            "A\n",
            "Statistical\n",
            "Mechanics\n",
            "Framework\n",
            "for\n",
            "Task-Agnostic\n",
            "Sample\n",
            "Design\n",
            "in\n",
            "Machine\n",
            "Learning\n",
            "Counterexample-Guided\n",
            "Learning\n",
            "of\n",
            "Monotonic\n",
            "Neural\n",
            "Networks\n",
            "A\n",
            "Novel\n",
            "Approach\n",
            "for\n",
            "Constrained\n",
            "Optimization\n",
            "in\n",
            "Graphical\n",
            "Models\n",
            "Global\n",
            "Convergence\n",
            "of\n",
            "Deep\n",
            "Networks\n",
            "with\n",
            "One\n",
            "Wide\n",
            "Layer\n",
            "Followed\n",
            "by\n",
            "Pyramidal\n",
            "Topology\n",
            "On\n",
            "the\n",
            "Trade-off\n",
            "between\n",
            "Adversarial\n",
            "and\n",
            "Backdoor\n",
            "Robustness\n",
            "Implicit\n",
            "Graph\n",
            "Neural\n",
            "Networks\n",
            "Rethinking\n",
            "Importance\n",
            "Weighting\n",
            "for\n",
            "Deep\n",
            "Learning\n",
            "under\n",
            "Distribution\n",
            "Shift\n",
            "Guiding\n",
            "Deep\n",
            "Molecular\n",
            "Optimization\n",
            "with\n",
            "Genetic\n",
            "Exploration\n",
            "Temporal\n",
            "Spike\n",
            "Sequence\n",
            "Learning\n",
            "via\n",
            "Backpropagation\n",
            "for\n",
            "Deep\n",
            "Spiking\n",
            "Neural\n",
            "Networks\n",
            "TSPNet\n",
            ":\n",
            "Hierarchical\n",
            "Feature\n",
            "Learning\n",
            "via\n",
            "Temporal\n",
            "Semantic\n",
            "Pyramid\n",
            "for\n",
            "Sign\n",
            "Language\n",
            "Translation\n",
            "Neural\n",
            "Topographic\n",
            "Factor\n",
            "Analysis\n",
            "for\n",
            "fMRI\n",
            "Data\n",
            "Neural\n",
            "Architecture\n",
            "Generator\n",
            "Optimization\n",
            "A\n",
            "Bandit\n",
            "Learning\n",
            "Algorithm\n",
            "and\n",
            "Applications\n",
            "to\n",
            "Auction\n",
            "Design\n",
            "MetaPoison\n",
            ":\n",
            "Practical\n",
            "General-purpose\n",
            "Clean-label\n",
            "Data\n",
            "Poisoning\n",
            "Sample\n",
            "Efficient\n",
            "Reinforcement\n",
            "Learning\n",
            "via\n",
            "Low-Rank\n",
            "Matrix\n",
            "Estimation\n",
            "Training\n",
            "Generative\n",
            "Adversarial\n",
            "Networks\n",
            "with\n",
            "Limited\n",
            "Data\n",
            "Deeply\n",
            "Learned\n",
            "Spectral\n",
            "Total\n",
            "Variation\n",
            "Decomposition\n",
            "FracTrain\n",
            ":\n",
            "Fractionally\n",
            "Squeezing\n",
            "Bit\n",
            "Savings\n",
            "Both\n",
            "Temporally\n",
            "and\n",
            "Spatially\n",
            "for\n",
            "Efficient\n",
            "DNN\n",
            "Training\n",
            "Improving\n",
            "Neural\n",
            "Network\n",
            "Training\n",
            "in\n",
            "Low\n",
            "Dimensional\n",
            "Random\n",
            "Bases\n",
            "Safe\n",
            "Reinforcement\n",
            "Learning\n",
            "via\n",
            "Curriculum\n",
            "Induction\n",
            "Leverage\n",
            "the\n",
            "Average\n",
            ":\n",
            "an\n",
            "Analysis\n",
            "of\n",
            "KL\n",
            "Regularization\n",
            "in\n",
            "Reinforcement\n",
            "Learning\n",
            "How\n",
            "Robust\n",
            "are\n",
            "the\n",
            "Estimated\n",
            "Effects\n",
            "of\n",
            "Nonpharmaceutical\n",
            "Interventions\n",
            "against\n",
            "COVID-19\n",
            "?\n",
            "Beyond\n",
            "Individualized\n",
            "Recourse\n",
            ":\n",
            "Interpretable\n",
            "and\n",
            "Interactive\n",
            "Summaries\n",
            "of\n",
            "Actionable\n",
            "Recourses\n",
            "Generalization\n",
            "error\n",
            "in\n",
            "high-dimensional\n",
            "perceptrons\n",
            ":\n",
            "Approaching\n",
            "Bayes\n",
            "error\n",
            "with\n",
            "convex\n",
            "optimization\n",
            "Projection\n",
            "Efficient\n",
            "Subgradient\n",
            "Method\n",
            "and\n",
            "Optimal\n",
            "Nonsmooth\n",
            "Frank-Wolfe\n",
            "Method\n",
            "PGM-Explainer\n",
            ":\n",
            "Probabilistic\n",
            "Graphical\n",
            "Model\n",
            "Explanations\n",
            "for\n",
            "Graph\n",
            "Neural\n",
            "Networks\n",
            "Few-Cost\n",
            "Salient\n",
            "Object\n",
            "Detection\n",
            "with\n",
            "Adversarial-Paced\n",
            "Learning\n",
            "Minimax\n",
            "Estimation\n",
            "of\n",
            "Conditional\n",
            "Moment\n",
            "Models\n",
            "Causal\n",
            "Imitation\n",
            "Learning\n",
            "With\n",
            "Unobserved\n",
            "Confounders\n",
            "Your\n",
            "GAN\n",
            "is\n",
            "Secretly\n",
            "an\n",
            "Energy-based\n",
            "Model\n",
            "and\n",
            "You\n",
            "Should\n",
            "Use\n",
            "Discriminator\n",
            "Driven\n",
            "Latent\n",
            "Sampling\n",
            "Learning\n",
            "Black-Box\n",
            "Attackers\n",
            "with\n",
            "Transferable\n",
            "Priors\n",
            "and\n",
            "Query\n",
            "Feedback\n",
            "Locally\n",
            "Differentially\n",
            "Private\n",
            "(\n",
            "Contextual\n",
            ")\n",
            "Bandits\n",
            "Learning\n",
            "Invertible\n",
            "Gaussian\n",
            "Reparameterization\n",
            ":\n",
            "Revisiting\n",
            "the\n",
            "Gumbel-Softmax\n",
            "Kernel\n",
            "Based\n",
            "Progressive\n",
            "Distillation\n",
            "for\n",
            "Adder\n",
            "Neural\n",
            "Networks\n",
            "Adversarial\n",
            "Soft\n",
            "Advantage\n",
            "Fitting\n",
            ":\n",
            "Imitation\n",
            "Learning\n",
            "without\n",
            "Policy\n",
            "Optimization\n",
            "Agree\n",
            "to\n",
            "Disagree\n",
            ":\n",
            "Adaptive\n",
            "Ensemble\n",
            "Knowledge\n",
            "Distillation\n",
            "in\n",
            "Gradient\n",
            "Space\n",
            "The\n",
            "Wasserstein\n",
            "Proximal\n",
            "Gradient\n",
            "Algorithm\n",
            "Universally\n",
            "Quantized\n",
            "Neural\n",
            "Compression\n",
            "Temporal\n",
            "Variability\n",
            "in\n",
            "Implicit\n",
            "Online\n",
            "Learning\n",
            "Investigating\n",
            "Gender\n",
            "Bias\n",
            "in\n",
            "Language\n",
            "Models\n",
            "Using\n",
            "Causal\n",
            "Mediation\n",
            "Analysis\n",
            "Off-Policy\n",
            "Imitation\n",
            "Learning\n",
            "from\n",
            "Observations\n",
            "Escaping\n",
            "Saddle-Point\n",
            "Faster\n",
            "under\n",
            "Interpolation-like\n",
            "Conditions\n",
            "Matérn\n",
            "Gaussian\n",
            "Processes\n",
            "on\n",
            "Riemannian\n",
            "Manifolds\n",
            "Improved\n",
            "Techniques\n",
            "for\n",
            "Training\n",
            "Score-Based\n",
            "Generative\n",
            "Models\n",
            "wav2vec\n",
            "2.0\n",
            ":\n",
            "A\n",
            "Framework\n",
            "for\n",
            "Self-Supervised\n",
            "Learning\n",
            "of\n",
            "Speech\n",
            "Representations\n",
            "A\n",
            "Maximum-Entropy\n",
            "Approach\n",
            "to\n",
            "Off-Policy\n",
            "Evaluation\n",
            "in\n",
            "Average-Reward\n",
            "MDPs\n",
            "Instead\n",
            "of\n",
            "Rewriting\n",
            "Foreign\n",
            "Code\n",
            "for\n",
            "Machine\n",
            "Learning\n",
            ",\n",
            "Automatically\n",
            "Synthesize\n",
            "Fast\n",
            "Gradients\n",
            "Does\n",
            "Unsupervised\n",
            "Architecture\n",
            "Representation\n",
            "Learning\n",
            "Help\n",
            "Neural\n",
            "Architecture\n",
            "Search\n",
            "?\n",
            "Value-driven\n",
            "Hindsight\n",
            "Modelling\n",
            "Dynamic\n",
            "Regret\n",
            "of\n",
            "Convex\n",
            "and\n",
            "Smooth\n",
            "Functions\n",
            "On\n",
            "Convergence\n",
            "of\n",
            "Nearest\n",
            "Neighbor\n",
            "Classifiers\n",
            "over\n",
            "Feature\n",
            "Transformations\n",
            "Mitigating\n",
            "Manipulation\n",
            "in\n",
            "Peer\n",
            "Review\n",
            "via\n",
            "Randomized\n",
            "Reviewer\n",
            "Assignments\n",
            "Contrastive\n",
            "learning\n",
            "of\n",
            "global\n",
            "and\n",
            "local\n",
            "features\n",
            "for\n",
            "medical\n",
            "image\n",
            "segmentation\n",
            "with\n",
            "limited\n",
            "annotations\n",
            "Self-Supervised\n",
            "Graph\n",
            "Transformer\n",
            "on\n",
            "Large-Scale\n",
            "Molecular\n",
            "Data\n",
            "Generative\n",
            "Neurosymbolic\n",
            "Machines\n",
            "How\n",
            "many\n",
            "samples\n",
            "is\n",
            "a\n",
            "good\n",
            "initial\n",
            "point\n",
            "worth\n",
            "in\n",
            "Low-rank\n",
            "Matrix\n",
            "Recovery\n",
            "?\n",
            "CSER\n",
            ":\n",
            "Communication-efficient\n",
            "SGD\n",
            "with\n",
            "Error\n",
            "Reset\n",
            "Efficient\n",
            "estimation\n",
            "of\n",
            "neural\n",
            "tuning\n",
            "during\n",
            "naturalistic\n",
            "behavior\n",
            "High-recall\n",
            "causal\n",
            "discovery\n",
            "for\n",
            "autocorrelated\n",
            "time\n",
            "series\n",
            "with\n",
            "latent\n",
            "confounders\n",
            "Forget\n",
            "About\n",
            "the\n",
            "LiDAR\n",
            ":\n",
            "Self-Supervised\n",
            "Depth\n",
            "Estimators\n",
            "with\n",
            "MED\n",
            "Probability\n",
            "Volumes\n",
            "Joint\n",
            "Contrastive\n",
            "Learning\n",
            "with\n",
            "Infinite\n",
            "Possibilities\n",
            "Robust\n",
            "Gaussian\n",
            "Covariance\n",
            "Estimation\n",
            "in\n",
            "Nearly-Matrix\n",
            "Multiplication\n",
            "Time\n",
            "Adversarially-learned\n",
            "Inference\n",
            "via\n",
            "an\n",
            "Ensemble\n",
            "of\n",
            "Discrete\n",
            "Undirected\n",
            "Graphical\n",
            "Models\n",
            "GS-WGAN\n",
            ":\n",
            "A\n",
            "Gradient-Sanitized\n",
            "Approach\n",
            "for\n",
            "Learning\n",
            "Differentially\n",
            "Private\n",
            "Generators\n",
            "SurVAE\n",
            "Flows\n",
            ":\n",
            "Surjections\n",
            "to\n",
            "Bridge\n",
            "the\n",
            "Gap\n",
            "between\n",
            "VAEs\n",
            "and\n",
            "Flows\n",
            "Learning\n",
            "Causal\n",
            "Effects\n",
            "via\n",
            "Weighted\n",
            "Empirical\n",
            "Risk\n",
            "Minimization\n",
            "Revisiting\n",
            "the\n",
            "Sample\n",
            "Complexity\n",
            "of\n",
            "Sparse\n",
            "Spectrum\n",
            "Approximation\n",
            "of\n",
            "Gaussian\n",
            "Processes\n",
            "Incorporating\n",
            "Interpretable\n",
            "Output\n",
            "Constraints\n",
            "in\n",
            "Bayesian\n",
            "Neural\n",
            "Networks\n",
            "Multi-Stage\n",
            "Influence\n",
            "Function\n",
            "Probabilistic\n",
            "Fair\n",
            "Clustering\n",
            "Stochastic\n",
            "Segmentation\n",
            "Networks\n",
            ":\n",
            "Modelling\n",
            "Spatially\n",
            "Correlated\n",
            "Aleatoric\n",
            "Uncertainty\n",
            "ICE-BeeM\n",
            ":\n",
            "Identifiable\n",
            "Conditional\n",
            "Energy-Based\n",
            "Deep\n",
            "Models\n",
            "Based\n",
            "on\n",
            "Nonlinear\n",
            "ICA\n",
            "Testing\n",
            "Determinantal\n",
            "Point\n",
            "Processes\n",
            "CogLTX\n",
            ":\n",
            "Applying\n",
            "BERT\n",
            "to\n",
            "Long\n",
            "Texts\n",
            "f-GAIL\n",
            ":\n",
            "Learning\n",
            "f-Divergence\n",
            "for\n",
            "Generative\n",
            "Adversarial\n",
            "Imitation\n",
            "Learning\n",
            "Non-parametric\n",
            "Models\n",
            "for\n",
            "Non-negative\n",
            "Functions\n",
            "Uncertainty\n",
            "Aware\n",
            "Semi-Supervised\n",
            "Learning\n",
            "on\n",
            "Graph\n",
            "Data\n",
            "ConvBERT\n",
            ":\n",
            "Improving\n",
            "BERT\n",
            "with\n",
            "Span-based\n",
            "Dynamic\n",
            "Convolution\n",
            "Practical\n",
            "No-box\n",
            "Adversarial\n",
            "Attacks\n",
            "against\n",
            "DNNs\n",
            "Breaking\n",
            "the\n",
            "Sample\n",
            "Size\n",
            "Barrier\n",
            "in\n",
            "Model-Based\n",
            "Reinforcement\n",
            "Learning\n",
            "with\n",
            "a\n",
            "Generative\n",
            "Model\n",
            "Walking\n",
            "in\n",
            "the\n",
            "Shadow\n",
            ":\n",
            "A\n",
            "New\n",
            "Perspective\n",
            "on\n",
            "Descent\n",
            "Directions\n",
            "for\n",
            "Constrained\n",
            "Minimization\n",
            "Path\n",
            "Sample-Analytic\n",
            "Gradient\n",
            "Estimators\n",
            "for\n",
            "Stochastic\n",
            "Binary\n",
            "Networks\n",
            "Reward\n",
            "Propagation\n",
            "Using\n",
            "Graph\n",
            "Convolutional\n",
            "Networks\n",
            "LoopReg\n",
            ":\n",
            "Self-supervised\n",
            "Learning\n",
            "of\n",
            "Implicit\n",
            "Surface\n",
            "Correspondences\n",
            ",\n",
            "Pose\n",
            "and\n",
            "Shape\n",
            "for\n",
            "3D\n",
            "Human\n",
            "Mesh\n",
            "Registration\n",
            "Fully\n",
            "Dynamic\n",
            "Algorithm\n",
            "for\n",
            "Constrained\n",
            "Submodular\n",
            "Optimization\n",
            "Robust\n",
            "Optimal\n",
            "Transport\n",
            "with\n",
            "Applications\n",
            "in\n",
            "Generative\n",
            "Modeling\n",
            "and\n",
            "Domain\n",
            "Adaptation\n",
            "Autofocused\n",
            "oracles\n",
            "for\n",
            "model-based\n",
            "design\n",
            "Debiasing\n",
            "Averaged\n",
            "Stochastic\n",
            "Gradient\n",
            "Descent\n",
            "to\n",
            "handle\n",
            "missing\n",
            "values\n",
            "Trajectory-wise\n",
            "Multiple\n",
            "Choice\n",
            "Learning\n",
            "for\n",
            "Dynamics\n",
            "Generalization\n",
            "in\n",
            "Reinforcement\n",
            "Learning\n",
            "CompRess\n",
            ":\n",
            "Self-Supervised\n",
            "Learning\n",
            "by\n",
            "Compressing\n",
            "Representations\n",
            "Sample\n",
            "complexity\n",
            "and\n",
            "effective\n",
            "dimension\n",
            "for\n",
            "regression\n",
            "on\n",
            "manifolds\n",
            "The\n",
            "phase\n",
            "diagram\n",
            "of\n",
            "approximation\n",
            "rates\n",
            "for\n",
            "deep\n",
            "neural\n",
            "networks\n",
            "Timeseries\n",
            "Anomaly\n",
            "Detection\n",
            "using\n",
            "Temporal\n",
            "Hierarchical\n",
            "One-Class\n",
            "Network\n",
            "EcoLight\n",
            ":\n",
            "Intersection\n",
            "Control\n",
            "in\n",
            "Developing\n",
            "Regions\n",
            "Under\n",
            "Extreme\n",
            "Budget\n",
            "and\n",
            "Network\n",
            "Constraints\n",
            "Reconstructing\n",
            "Perceptive\n",
            "Images\n",
            "from\n",
            "Brain\n",
            "Activity\n",
            "by\n",
            "Shape-Semantic\n",
            "GAN\n",
            "Emergent\n",
            "Complexity\n",
            "and\n",
            "Zero-shot\n",
            "Transfer\n",
            "via\n",
            "Unsupervised\n",
            "Environment\n",
            "Design\n",
            "A\n",
            "Spectral\n",
            "Energy\n",
            "Distance\n",
            "for\n",
            "Parallel\n",
            "Speech\n",
            "Synthesis\n",
            "Simulating\n",
            "a\n",
            "Primary\n",
            "Visual\n",
            "Cortex\n",
            "at\n",
            "the\n",
            "Front\n",
            "of\n",
            "CNNs\n",
            "Improves\n",
            "Robustness\n",
            "to\n",
            "Image\n",
            "Perturbations\n",
            "Learning\n",
            "from\n",
            "Positive\n",
            "and\n",
            "Unlabeled\n",
            "Data\n",
            "with\n",
            "Arbitrary\n",
            "Positive\n",
            "Shift\n",
            "Deep\n",
            "Energy-based\n",
            "Modeling\n",
            "of\n",
            "Discrete-Time\n",
            "Physics\n",
            "Quantifying\n",
            "Learnability\n",
            "and\n",
            "Describability\n",
            "of\n",
            "Visual\n",
            "Concepts\n",
            "Emerging\n",
            "in\n",
            "Representation\n",
            "Learning\n",
            "Self-Learning\n",
            "Transformations\n",
            "for\n",
            "Improving\n",
            "Gaze\n",
            "and\n",
            "Head\n",
            "Redirection\n",
            "Language-Conditioned\n",
            "Imitation\n",
            "Learning\n",
            "for\n",
            "Robot\n",
            "Manipulation\n",
            "Tasks\n",
            "POMDPs\n",
            "in\n",
            "Continuous\n",
            "Time\n",
            "and\n",
            "Discrete\n",
            "Spaces\n",
            "Exemplar\n",
            "Guided\n",
            "Active\n",
            "Learning\n",
            "Grasp\n",
            "Proposal\n",
            "Networks\n",
            ":\n",
            "An\n",
            "End-to-End\n",
            "Solution\n",
            "for\n",
            "Visual\n",
            "Learning\n",
            "of\n",
            "Robotic\n",
            "Grasps\n",
            "Node\n",
            "Embeddings\n",
            "and\n",
            "Exact\n",
            "Low-Rank\n",
            "Representations\n",
            "of\n",
            "Complex\n",
            "Networks\n",
            "Fictitious\n",
            "Play\n",
            "for\n",
            "Mean\n",
            "Field\n",
            "Games\n",
            ":\n",
            "Continuous\n",
            "Time\n",
            "Analysis\n",
            "and\n",
            "Applications\n",
            "Steering\n",
            "Distortions\n",
            "to\n",
            "Preserve\n",
            "Classes\n",
            "and\n",
            "Neighbors\n",
            "in\n",
            "Supervised\n",
            "Dimensionality\n",
            "Reduction\n",
            "On\n",
            "Infinite-Width\n",
            "Hypernetworks\n",
            "Interferobot\n",
            ":\n",
            "aligning\n",
            "an\n",
            "optical\n",
            "interferometer\n",
            "by\n",
            "a\n",
            "reinforcement\n",
            "learning\n",
            "agent\n",
            "Program\n",
            "Synthesis\n",
            "with\n",
            "Pragmatic\n",
            "Communication\n",
            "Principal\n",
            "Neighbourhood\n",
            "Aggregation\n",
            "for\n",
            "Graph\n",
            "Nets\n",
            "Reliable\n",
            "Graph\n",
            "Neural\n",
            "Networks\n",
            "via\n",
            "Robust\n",
            "Aggregation\n",
            "Instance\n",
            "Selection\n",
            "for\n",
            "GANs\n",
            "Linear\n",
            "Disentangled\n",
            "Representations\n",
            "and\n",
            "Unsupervised\n",
            "Action\n",
            "Estimation\n",
            "Video\n",
            "Frame\n",
            "Interpolation\n",
            "without\n",
            "Temporal\n",
            "Priors\n",
            "Learning\n",
            "compositional\n",
            "functions\n",
            "via\n",
            "multiplicative\n",
            "weight\n",
            "updates\n",
            "Sample\n",
            "Complexity\n",
            "of\n",
            "Uniform\n",
            "Convergence\n",
            "for\n",
            "Multicalibration\n",
            "Differentiable\n",
            "Neural\n",
            "Architecture\n",
            "Search\n",
            "in\n",
            "Equivalent\n",
            "Space\n",
            "with\n",
            "Exploration\n",
            "Enhancement\n",
            "The\n",
            "interplay\n",
            "between\n",
            "randomness\n",
            "and\n",
            "structure\n",
            "during\n",
            "learning\n",
            "in\n",
            "RNNs\n",
            "A\n",
            "Generalized\n",
            "Neural\n",
            "Tangent\n",
            "Kernel\n",
            "Analysis\n",
            "for\n",
            "Two-layer\n",
            "Neural\n",
            "Networks\n",
            "Instance-wise\n",
            "Feature\n",
            "Grouping\n",
            "Robust\n",
            "Disentanglement\n",
            "of\n",
            "a\n",
            "Few\n",
            "Factors\n",
            "at\n",
            "a\n",
            "Time\n",
            "using\n",
            "rPU-VAE\n",
            "PC-PG\n",
            ":\n",
            "Policy\n",
            "Cover\n",
            "Directed\n",
            "Exploration\n",
            "for\n",
            "Provable\n",
            "Policy\n",
            "Gradient\n",
            "Learning\n",
            "Group\n",
            "Contextual\n",
            "Encoding\n",
            "for\n",
            "3D\n",
            "Point\n",
            "Clouds\n",
            "Latent\n",
            "Bandits\n",
            "Revisited\n",
            "Is\n",
            "normalization\n",
            "indispensable\n",
            "for\n",
            "training\n",
            "deep\n",
            "neural\n",
            "network\n",
            "?\n",
            "Optimization\n",
            "and\n",
            "Generalization\n",
            "of\n",
            "Shallow\n",
            "Neural\n",
            "Networks\n",
            "with\n",
            "Quadratic\n",
            "Activation\n",
            "Functions\n",
            "Intra\n",
            "Order-preserving\n",
            "Functions\n",
            "for\n",
            "Calibration\n",
            "of\n",
            "Multi-Class\n",
            "Neural\n",
            "Networks\n",
            "Linear\n",
            "Time\n",
            "Sinkhorn\n",
            "Divergences\n",
            "using\n",
            "Positive\n",
            "Features\n",
            "VarGrad\n",
            ":\n",
            "A\n",
            "Low-Variance\n",
            "Gradient\n",
            "Estimator\n",
            "for\n",
            "Variational\n",
            "Inference\n",
            "A\n",
            "Convolutional\n",
            "Auto-Encoder\n",
            "for\n",
            "Haplotype\n",
            "Assembly\n",
            "and\n",
            "Viral\n",
            "Quasispecies\n",
            "Reconstruction\n",
            "Promoting\n",
            "Stochasticity\n",
            "for\n",
            "Expressive\n",
            "Policies\n",
            "via\n",
            "a\n",
            "Simple\n",
            "and\n",
            "Efficient\n",
            "Regularization\n",
            "Method\n",
            "Adversarial\n",
            "Counterfactual\n",
            "Learning\n",
            "and\n",
            "Evaluation\n",
            "for\n",
            "Recommender\n",
            "System\n",
            "Memory-Efficient\n",
            "Learning\n",
            "of\n",
            "Stable\n",
            "Linear\n",
            "Dynamical\n",
            "Systems\n",
            "for\n",
            "Prediction\n",
            "and\n",
            "Control\n",
            "Evolving\n",
            "Normalization-Activation\n",
            "Layers\n",
            "ScaleCom\n",
            ":\n",
            "Scalable\n",
            "Sparsified\n",
            "Gradient\n",
            "Compression\n",
            "for\n",
            "Communication-Efficient\n",
            "Distributed\n",
            "Training\n",
            "RelationNet++\n",
            ":\n",
            "Bridging\n",
            "Visual\n",
            "Representations\n",
            "for\n",
            "Object\n",
            "Detection\n",
            "via\n",
            "Transformer\n",
            "Decoder\n",
            "Efficient\n",
            "Learning\n",
            "of\n",
            "Discrete\n",
            "Graphical\n",
            "Models\n",
            "Near-Optimal\n",
            "SQ\n",
            "Lower\n",
            "Bounds\n",
            "for\n",
            "Agnostically\n",
            "Learning\n",
            "Halfspaces\n",
            "and\n",
            "ReLUs\n",
            "under\n",
            "Gaussian\n",
            "Marginals\n",
            "Neurosymbolic\n",
            "Transformers\n",
            "for\n",
            "Multi-Agent\n",
            "Communication\n",
            "Fairness\n",
            "in\n",
            "Streaming\n",
            "Submodular\n",
            "Maximization\n",
            ":\n",
            "Algorithms\n",
            "and\n",
            "Hardness\n",
            "Smoothed\n",
            "Geometry\n",
            "for\n",
            "Robust\n",
            "Attribution\n",
            "Fast\n",
            "Adversarial\n",
            "Robustness\n",
            "Certification\n",
            "of\n",
            "Nearest\n",
            "Prototype\n",
            "Classifiers\n",
            "for\n",
            "Arbitrary\n",
            "Seminorms\n",
            "Multi-agent\n",
            "active\n",
            "perception\n",
            "with\n",
            "prediction\n",
            "rewards\n",
            "A\n",
            "Local\n",
            "Temporal\n",
            "Difference\n",
            "Code\n",
            "for\n",
            "Distributional\n",
            "Reinforcement\n",
            "Learning\n",
            "Learning\n",
            "with\n",
            "Optimized\n",
            "Random\n",
            "Features\n",
            ":\n",
            "Exponential\n",
            "Speedup\n",
            "by\n",
            "Quantum\n",
            "Machine\n",
            "Learning\n",
            "without\n",
            "Sparsity\n",
            "and\n",
            "Low-Rank\n",
            "Assumptions\n",
            "CaSPR\n",
            ":\n",
            "Learning\n",
            "Canonical\n",
            "Spatiotemporal\n",
            "Point\n",
            "Cloud\n",
            "Representations\n",
            "Deep\n",
            "Automodulators\n",
            "Convolutional\n",
            "Tensor-Train\n",
            "LSTM\n",
            "for\n",
            "Spatio-Temporal\n",
            "Learning\n",
            "The\n",
            "Potts-Ising\n",
            "model\n",
            "for\n",
            "discrete\n",
            "multivariate\n",
            "data\n",
            "Interpretable\n",
            "multi-timescale\n",
            "models\n",
            "for\n",
            "predicting\n",
            "fMRI\n",
            "responses\n",
            "to\n",
            "continuous\n",
            "natural\n",
            "speech\n",
            "Group-Fair\n",
            "Online\n",
            "Allocation\n",
            "in\n",
            "Continuous\n",
            "Time\n",
            "Decentralized\n",
            "TD\n",
            "Tracking\n",
            "with\n",
            "Linear\n",
            "Function\n",
            "Approximation\n",
            "and\n",
            "its\n",
            "Finite-Time\n",
            "Analysis\n",
            "Understanding\n",
            "Gradient\n",
            "Clipping\n",
            "in\n",
            "Private\n",
            "SGD\n",
            ":\n",
            "A\n",
            "Geometric\n",
            "Perspective\n",
            "O\n",
            "(\n",
            "n\n",
            ")\n",
            "Connections\n",
            "are\n",
            "Expressive\n",
            "Enough\n",
            ":\n",
            "Universal\n",
            "Approximability\n",
            "of\n",
            "Sparse\n",
            "Transformers\n",
            "Identifying\n",
            "signal\n",
            "and\n",
            "noise\n",
            "structure\n",
            "in\n",
            "neural\n",
            "population\n",
            "activity\n",
            "with\n",
            "Gaussian\n",
            "process\n",
            "factor\n",
            "models\n",
            "Equivariant\n",
            "Networks\n",
            "for\n",
            "Hierarchical\n",
            "Structures\n",
            "MinMax\n",
            "Methods\n",
            "for\n",
            "Optimal\n",
            "Transport\n",
            "and\n",
            "Beyond\n",
            ":\n",
            "Regularization\n",
            ",\n",
            "Approximation\n",
            "and\n",
            "Numerics\n",
            "A\n",
            "Discrete\n",
            "Variational\n",
            "Recurrent\n",
            "Topic\n",
            "Model\n",
            "without\n",
            "the\n",
            "Reparametrization\n",
            "Trick\n",
            "Transferable\n",
            "Graph\n",
            "Optimizers\n",
            "for\n",
            "ML\n",
            "Compilers\n",
            "Learning\n",
            "with\n",
            "Operator-valued\n",
            "Kernels\n",
            "in\n",
            "Reproducing\n",
            "Kernel\n",
            "Krein\n",
            "Spaces\n",
            "Learning\n",
            "Bounds\n",
            "for\n",
            "Risk-sensitive\n",
            "Learning\n",
            "Simplifying\n",
            "Hamiltonian\n",
            "and\n",
            "Lagrangian\n",
            "Neural\n",
            "Networks\n",
            "via\n",
            "Explicit\n",
            "Constraints\n",
            "Beyond\n",
            "accuracy\n",
            ":\n",
            "quantifying\n",
            "trial-by-trial\n",
            "behaviour\n",
            "of\n",
            "CNNs\n",
            "and\n",
            "humans\n",
            "by\n",
            "measuring\n",
            "error\n",
            "consistency\n",
            "Provably\n",
            "Efficient\n",
            "Reinforcement\n",
            "Learning\n",
            "with\n",
            "Kernel\n",
            "and\n",
            "Neural\n",
            "Function\n",
            "Approximations\n",
            "Constant-Expansion\n",
            "Suffices\n",
            "for\n",
            "Compressed\n",
            "Sensing\n",
            "with\n",
            "Generative\n",
            "Priors\n",
            "RANet\n",
            ":\n",
            "Region\n",
            "Attention\n",
            "Network\n",
            "for\n",
            "Semantic\n",
            "Segmentation\n",
            "A\n",
            "random\n",
            "matrix\n",
            "analysis\n",
            "of\n",
            "random\n",
            "Fourier\n",
            "features\n",
            ":\n",
            "beyond\n",
            "the\n",
            "Gaussian\n",
            "kernel\n",
            ",\n",
            "a\n",
            "precise\n",
            "phase\n",
            "transition\n",
            ",\n",
            "and\n",
            "the\n",
            "corresponding\n",
            "double\n",
            "descent\n",
            "Learning\n",
            "sparse\n",
            "codes\n",
            "from\n",
            "compressed\n",
            "representations\n",
            "with\n",
            "biologically\n",
            "plausible\n",
            "local\n",
            "wiring\n",
            "constraints\n",
            "Self-Imitation\n",
            "Learning\n",
            "via\n",
            "Generalized\n",
            "Lower\n",
            "Bound\n",
            "Q-learning\n",
            "Private\n",
            "Learning\n",
            "of\n",
            "Halfspaces\n",
            ":\n",
            "Simplifying\n",
            "the\n",
            "Construction\n",
            "and\n",
            "Reducing\n",
            "the\n",
            "Sample\n",
            "Complexity\n",
            "Directional\n",
            "Pruning\n",
            "of\n",
            "Deep\n",
            "Neural\n",
            "Networks\n",
            "Smoothly\n",
            "Bounding\n",
            "User\n",
            "Contributions\n",
            "in\n",
            "Differential\n",
            "Privacy\n",
            "Accelerating\n",
            "Training\n",
            "of\n",
            "Transformer-Based\n",
            "Language\n",
            "Models\n",
            "with\n",
            "Progressive\n",
            "Layer\n",
            "Dropping\n",
            "Online\n",
            "Planning\n",
            "with\n",
            "Lookahead\n",
            "Policies\n",
            "Learning\n",
            "Deep\n",
            "Attribution\n",
            "Priors\n",
            "Based\n",
            "On\n",
            "Prior\n",
            "Knowledge\n",
            "Using\n",
            "noise\n",
            "to\n",
            "probe\n",
            "recurrent\n",
            "neural\n",
            "network\n",
            "structure\n",
            "and\n",
            "prune\n",
            "synapses\n",
            "NanoFlow\n",
            ":\n",
            "Scalable\n",
            "Normalizing\n",
            "Flows\n",
            "with\n",
            "Sublinear\n",
            "Parameter\n",
            "Complexity\n",
            "Group\n",
            "Knowledge\n",
            "Transfer\n",
            ":\n",
            "Federated\n",
            "Learning\n",
            "of\n",
            "Large\n",
            "CNNs\n",
            "at\n",
            "the\n",
            "Edge\n",
            "Neural\n",
            "FFTs\n",
            "for\n",
            "Universal\n",
            "Texture\n",
            "Image\n",
            "Synthesis\n",
            "Graph\n",
            "Cross\n",
            "Networks\n",
            "with\n",
            "Vertex\n",
            "Infomax\n",
            "Pooling\n",
            "Instance-optimality\n",
            "in\n",
            "differential\n",
            "privacy\n",
            "via\n",
            "approximate\n",
            "inverse\n",
            "sensitivity\n",
            "mechanisms\n",
            "Calibration\n",
            "of\n",
            "Shared\n",
            "Equilibria\n",
            "in\n",
            "General\n",
            "Sum\n",
            "Partially\n",
            "Observable\n",
            "Markov\n",
            "Games\n",
            "MOPO\n",
            ":\n",
            "Model-based\n",
            "Offline\n",
            "Policy\n",
            "Optimization\n",
            "Building\n",
            "powerful\n",
            "and\n",
            "equivariant\n",
            "graph\n",
            "neural\n",
            "networks\n",
            "with\n",
            "structural\n",
            "message-passing\n",
            "Efficient\n",
            "Model-Based\n",
            "Reinforcement\n",
            "Learning\n",
            "through\n",
            "Optimistic\n",
            "Policy\n",
            "Search\n",
            "and\n",
            "Planning\n",
            "Practical\n",
            "Low-Rank\n",
            "Communication\n",
            "Compression\n",
            "in\n",
            "Decentralized\n",
            "Deep\n",
            "Learning\n",
            "Mutual\n",
            "exclusivity\n",
            "as\n",
            "a\n",
            "challenge\n",
            "for\n",
            "deep\n",
            "neural\n",
            "networks\n",
            "3D\n",
            "Shape\n",
            "Reconstruction\n",
            "from\n",
            "Vision\n",
            "and\n",
            "Touch\n",
            "GradAug\n",
            ":\n",
            "A\n",
            "New\n",
            "Regularization\n",
            "Method\n",
            "for\n",
            "Deep\n",
            "Neural\n",
            "Networks\n",
            "An\n",
            "Equivalence\n",
            "between\n",
            "Loss\n",
            "Functions\n",
            "and\n",
            "Non-Uniform\n",
            "Sampling\n",
            "in\n",
            "Experience\n",
            "Replay\n",
            "Learning\n",
            "Utilities\n",
            "and\n",
            "Equilibria\n",
            "in\n",
            "Non-Truthful\n",
            "Auctions\n",
            "Rational\n",
            "neural\n",
            "networks\n",
            "DISK\n",
            ":\n",
            "Learning\n",
            "local\n",
            "features\n",
            "with\n",
            "policy\n",
            "gradient\n",
            "Transfer\n",
            "Learning\n",
            "via\n",
            "$\n",
            "\\ell_1\n",
            "$\n",
            "Regularization\n",
            "GOCor\n",
            ":\n",
            "Bringing\n",
            "Globally\n",
            "Optimized\n",
            "Correspondence\n",
            "Volumes\n",
            "into\n",
            "Your\n",
            "Neural\n",
            "Network\n",
            "Deep\n",
            "Inverse\n",
            "Q-learning\n",
            "with\n",
            "Constraints\n",
            "Optimistic\n",
            "Dual\n",
            "Extrapolation\n",
            "for\n",
            "Coherent\n",
            "Non-monotone\n",
            "Variational\n",
            "Inequalities\n",
            "Prediction\n",
            "with\n",
            "Corrupted\n",
            "Expert\n",
            "Advice\n",
            "Human\n",
            "Parsing\n",
            "Based\n",
            "Texture\n",
            "Transfer\n",
            "from\n",
            "Single\n",
            "Image\n",
            "to\n",
            "3D\n",
            "Human\n",
            "via\n",
            "Cross-View\n",
            "Consistency\n",
            "Knowledge\n",
            "Augmented\n",
            "Deep\n",
            "Neural\n",
            "Networks\n",
            "for\n",
            "Joint\n",
            "Facial\n",
            "Expression\n",
            "and\n",
            "Action\n",
            "Unit\n",
            "Recognition\n",
            "Point\n",
            "process\n",
            "models\n",
            "for\n",
            "sequence\n",
            "detection\n",
            "in\n",
            "high-dimensional\n",
            "neural\n",
            "spike\n",
            "trains\n",
            "Adversarial\n",
            "Attacks\n",
            "on\n",
            "Linear\n",
            "Contextual\n",
            "Bandits\n",
            "Meta-Consolidation\n",
            "for\n",
            "Continual\n",
            "Learning\n",
            "Organizing\n",
            "recurrent\n",
            "network\n",
            "dynamics\n",
            "by\n",
            "task-computation\n",
            "to\n",
            "enable\n",
            "continual\n",
            "learning\n",
            "Lifelong\n",
            "Policy\n",
            "Gradient\n",
            "Learning\n",
            "of\n",
            "Factored\n",
            "Policies\n",
            "for\n",
            "Faster\n",
            "Training\n",
            "Without\n",
            "Forgetting\n",
            "Kernel\n",
            "Methods\n",
            "Through\n",
            "the\n",
            "Roof\n",
            ":\n",
            "Handling\n",
            "Billions\n",
            "of\n",
            "Points\n",
            "Efficiently\n",
            "Spike\n",
            "and\n",
            "slab\n",
            "variational\n",
            "Bayes\n",
            "for\n",
            "high\n",
            "dimensional\n",
            "logistic\n",
            "regression\n",
            "Maximum-Entropy\n",
            "Adversarial\n",
            "Data\n",
            "Augmentation\n",
            "for\n",
            "Improved\n",
            "Generalization\n",
            "and\n",
            "Robustness\n",
            "Fast\n",
            "geometric\n",
            "learning\n",
            "with\n",
            "symbolic\n",
            "matrices\n",
            "MESA\n",
            ":\n",
            "Boost\n",
            "Ensemble\n",
            "Imbalanced\n",
            "Learning\n",
            "with\n",
            "MEta-SAmpler\n",
            "CoinPress\n",
            ":\n",
            "Practical\n",
            "Private\n",
            "Mean\n",
            "and\n",
            "Covariance\n",
            "Estimation\n",
            "Planning\n",
            "with\n",
            "General\n",
            "Objective\n",
            "Functions\n",
            ":\n",
            "Going\n",
            "Beyond\n",
            "Total\n",
            "Rewards\n",
            "Scattering\n",
            "GCN\n",
            ":\n",
            "Overcoming\n",
            "Oversmoothness\n",
            "in\n",
            "Graph\n",
            "Convolutional\n",
            "Networks\n",
            "KFC\n",
            ":\n",
            "A\n",
            "Scalable\n",
            "Approximation\n",
            "Algorithm\n",
            "for\n",
            "$\n",
            "k\n",
            "$\n",
            "−center\n",
            "Fair\n",
            "Clustering\n",
            "Leveraging\n",
            "Predictions\n",
            "in\n",
            "Smoothed\n",
            "Online\n",
            "Convex\n",
            "Optimization\n",
            "via\n",
            "Gradient-based\n",
            "Algorithms\n",
            "Learning\n",
            "the\n",
            "Linear\n",
            "Quadratic\n",
            "Regulator\n",
            "from\n",
            "Nonlinear\n",
            "Observations\n",
            "Reconciling\n",
            "Modern\n",
            "Deep\n",
            "Learning\n",
            "with\n",
            "Traditional\n",
            "Optimization\n",
            "Analyses\n",
            ":\n",
            "The\n",
            "Intrinsic\n",
            "Learning\n",
            "Rate\n",
            "Scalable\n",
            "Graph\n",
            "Neural\n",
            "Networks\n",
            "via\n",
            "Bidirectional\n",
            "Propagation\n",
            "Distribution\n",
            "Aligning\n",
            "Refinery\n",
            "of\n",
            "Pseudo-label\n",
            "for\n",
            "Imbalanced\n",
            "Semi-supervised\n",
            "Learning\n",
            "Assisted\n",
            "Learning\n",
            ":\n",
            "A\n",
            "Framework\n",
            "for\n",
            "Multi-Organization\n",
            "Learning\n",
            "The\n",
            "Strong\n",
            "Screening\n",
            "Rule\n",
            "for\n",
            "SLOPE\n",
            "STLnet\n",
            ":\n",
            "Signal\n",
            "Temporal\n",
            "Logic\n",
            "Enforced\n",
            "Multivariate\n",
            "Recurrent\n",
            "Neural\n",
            "Networks\n",
            "Election\n",
            "Coding\n",
            "for\n",
            "Distributed\n",
            "Learning\n",
            ":\n",
            "Protecting\n",
            "SignSGD\n",
            "against\n",
            "Byzantine\n",
            "Attacks\n",
            "Reducing\n",
            "Adversarially\n",
            "Robust\n",
            "Learning\n",
            "to\n",
            "Non-Robust\n",
            "PAC\n",
            "Learning\n",
            "Top-k\n",
            "Training\n",
            "of\n",
            "GANs\n",
            ":\n",
            "Improving\n",
            "GAN\n",
            "Performance\n",
            "by\n",
            "Throwing\n",
            "Away\n",
            "Bad\n",
            "Samples\n",
            "Black-Box\n",
            "Optimization\n",
            "with\n",
            "Local\n",
            "Generative\n",
            "Surrogates\n",
            "Efficient\n",
            "Generation\n",
            "of\n",
            "Structured\n",
            "Objects\n",
            "with\n",
            "Constrained\n",
            "Adversarial\n",
            "Networks\n",
            "Hard\n",
            "Example\n",
            "Generation\n",
            "by\n",
            "Texture\n",
            "Synthesis\n",
            "for\n",
            "Cross-domain\n",
            "Shape\n",
            "Similarity\n",
            "Learning\n",
            "Recovery\n",
            "of\n",
            "sparse\n",
            "linear\n",
            "classifiers\n",
            "from\n",
            "mixture\n",
            "of\n",
            "responses\n",
            "Efficient\n",
            "Distance\n",
            "Approximation\n",
            "for\n",
            "Structured\n",
            "High-Dimensional\n",
            "Distributions\n",
            "via\n",
            "Learning\n",
            "A\n",
            "Single\n",
            "Recipe\n",
            "for\n",
            "Online\n",
            "Submodular\n",
            "Maximization\n",
            "with\n",
            "Adversarial\n",
            "or\n",
            "Stochastic\n",
            "Constraints\n",
            "Learning\n",
            "Sparse\n",
            "Prototypes\n",
            "for\n",
            "Text\n",
            "Generation\n",
            "Implicit\n",
            "Rank-Minimizing\n",
            "Autoencoder\n",
            "Storage\n",
            "Efficient\n",
            "and\n",
            "Dynamic\n",
            "Flexible\n",
            "Runtime\n",
            "Channel\n",
            "Pruning\n",
            "via\n",
            "Deep\n",
            "Reinforcement\n",
            "Learning\n",
            "Task-Oriented\n",
            "Feature\n",
            "Distillation\n",
            "Entropic\n",
            "Causal\n",
            "Inference\n",
            ":\n",
            "Identifiability\n",
            "and\n",
            "Finite\n",
            "Sample\n",
            "Results\n",
            "Rewriting\n",
            "History\n",
            "with\n",
            "Inverse\n",
            "RL\n",
            ":\n",
            "Hindsight\n",
            "Inference\n",
            "for\n",
            "Policy\n",
            "Improvement\n",
            "Variance-Reduced\n",
            "Off-Policy\n",
            "TDC\n",
            "Learning\n",
            ":\n",
            "Non-Asymptotic\n",
            "Convergence\n",
            "Analysis\n",
            "AdaTune\n",
            ":\n",
            "Adaptive\n",
            "Tensor\n",
            "Program\n",
            "Compilation\n",
            "Made\n",
            "Efficient\n",
            "When\n",
            "Do\n",
            "Neural\n",
            "Networks\n",
            "Outperform\n",
            "Kernel\n",
            "Methods\n",
            "?\n",
            "STEER\n",
            ":\n",
            "Simple\n",
            "Temporal\n",
            "Regularization\n",
            "For\n",
            "Neural\n",
            "ODE\n",
            "A\n",
            "Variational\n",
            "Approach\n",
            "for\n",
            "Learning\n",
            "from\n",
            "Positive\n",
            "and\n",
            "Unlabeled\n",
            "Data\n",
            "Efficient\n",
            "Clustering\n",
            "Based\n",
            "On\n",
            "A\n",
            "Unified\n",
            "View\n",
            "Of\n",
            "$\n",
            "K\n",
            "$\n",
            "-means\n",
            "And\n",
            "Ratio-cut\n",
            "Recurrent\n",
            "Switching\n",
            "Dynamical\n",
            "Systems\n",
            "Models\n",
            "for\n",
            "Multiple\n",
            "Interacting\n",
            "Neural\n",
            "Populations\n",
            "Coresets\n",
            "via\n",
            "Bilevel\n",
            "Optimization\n",
            "for\n",
            "Continual\n",
            "Learning\n",
            "and\n",
            "Streaming\n",
            "Generalized\n",
            "Independent\n",
            "Noise\n",
            "Condition\n",
            "for\n",
            "Estimating\n",
            "Latent\n",
            "Variable\n",
            "Causal\n",
            "Graphs\n",
            "Understanding\n",
            "and\n",
            "Exploring\n",
            "the\n",
            "Network\n",
            "with\n",
            "Stochastic\n",
            "Architectures\n",
            "All-or-nothing\n",
            "statistical\n",
            "and\n",
            "computational\n",
            "phase\n",
            "transitions\n",
            "in\n",
            "sparse\n",
            "spiked\n",
            "matrix\n",
            "estimation\n",
            "Deep\n",
            "Evidential\n",
            "Regression\n",
            "Analytical\n",
            "Probability\n",
            "Distributions\n",
            "and\n",
            "Exact\n",
            "Expectation-Maximization\n",
            "for\n",
            "Deep\n",
            "Generative\n",
            "Networks\n",
            "Bayesian\n",
            "Pseudocoresets\n",
            "See\n",
            ",\n",
            "Hear\n",
            ",\n",
            "Explore\n",
            ":\n",
            "Curiosity\n",
            "via\n",
            "Audio-Visual\n",
            "Association\n",
            "Adversarial\n",
            "Training\n",
            "is\n",
            "a\n",
            "Form\n",
            "of\n",
            "Data-dependent\n",
            "Operator\n",
            "Norm\n",
            "Regularization\n",
            "A\n",
            "Biologically\n",
            "Plausible\n",
            "Neural\n",
            "Network\n",
            "for\n",
            "Slow\n",
            "Feature\n",
            "Analysis\n",
            "Learning\n",
            "Feature\n",
            "Sparse\n",
            "Principal\n",
            "Subspace\n",
            "Online\n",
            "Adaptation\n",
            "for\n",
            "Consistent\n",
            "Mesh\n",
            "Reconstruction\n",
            "in\n",
            "the\n",
            "Wild\n",
            "Online\n",
            "learning\n",
            "with\n",
            "dynamics\n",
            ":\n",
            "A\n",
            "minimax\n",
            "perspective\n",
            "Learning\n",
            "to\n",
            "Select\n",
            "Best\n",
            "Forecast\n",
            "Tasks\n",
            "for\n",
            "Clinical\n",
            "Outcome\n",
            "Prediction\n",
            "Stochastic\n",
            "Optimization\n",
            "with\n",
            "Heavy-Tailed\n",
            "Noise\n",
            "via\n",
            "Accelerated\n",
            "Gradient\n",
            "Clipping\n",
            "Adaptive\n",
            "Experimental\n",
            "Design\n",
            "with\n",
            "Temporal\n",
            "Interference\n",
            ":\n",
            "A\n",
            "Maximum\n",
            "Likelihood\n",
            "Approach\n",
            "From\n",
            "Trees\n",
            "to\n",
            "Continuous\n",
            "Embeddings\n",
            "and\n",
            "Back\n",
            ":\n",
            "Hyperbolic\n",
            "Hierarchical\n",
            "Clustering\n",
            "The\n",
            "Autoencoding\n",
            "Variational\n",
            "Autoencoder\n",
            "A\n",
            "Fair\n",
            "Classifier\n",
            "Using\n",
            "Kernel\n",
            "Density\n",
            "Estimation\n",
            "A\n",
            "Randomized\n",
            "Algorithm\n",
            "to\n",
            "Reduce\n",
            "the\n",
            "Support\n",
            "of\n",
            "Discrete\n",
            "Measures\n",
            "Distributionally\n",
            "Robust\n",
            "Federated\n",
            "Averaging\n",
            "Sharp\n",
            "uniform\n",
            "convergence\n",
            "bounds\n",
            "through\n",
            "empirical\n",
            "centralization\n",
            "COBE\n",
            ":\n",
            "Contextualized\n",
            "Object\n",
            "Embeddings\n",
            "from\n",
            "Narrated\n",
            "Instructional\n",
            "Video\n",
            "Knowledge\n",
            "Transfer\n",
            "in\n",
            "Multi-Task\n",
            "Deep\n",
            "Reinforcement\n",
            "Learning\n",
            "for\n",
            "Continuous\n",
            "Control\n",
            "Finite\n",
            "Versus\n",
            "Infinite\n",
            "Neural\n",
            "Networks\n",
            ":\n",
            "an\n",
            "Empirical\n",
            "Study\n",
            "Supermasks\n",
            "in\n",
            "Superposition\n",
            "Nonasymptotic\n",
            "Guarantees\n",
            "for\n",
            "Spiked\n",
            "Matrix\n",
            "Recovery\n",
            "with\n",
            "Generative\n",
            "Priors\n",
            "Almost\n",
            "Optimal\n",
            "Model-Free\n",
            "Reinforcement\n",
            "Learningvia\n",
            "Reference-Advantage\n",
            "Decomposition\n",
            "Learning\n",
            "to\n",
            "Incentivize\n",
            "Other\n",
            "Learning\n",
            "Agents\n",
            "Displacement-Invariant\n",
            "Matching\n",
            "Cost\n",
            "Learning\n",
            "for\n",
            "Accurate\n",
            "Optical\n",
            "Flow\n",
            "Estimation\n",
            "Distributionally\n",
            "Robust\n",
            "Local\n",
            "Non-parametric\n",
            "Conditional\n",
            "Estimation\n",
            "Robust\n",
            "Multi-Object\n",
            "Matching\n",
            "via\n",
            "Iterative\n",
            "Reweighting\n",
            "of\n",
            "the\n",
            "Graph\n",
            "Connection\n",
            "Laplacian\n",
            "Meta-Gradient\n",
            "Reinforcement\n",
            "Learning\n",
            "with\n",
            "an\n",
            "Objective\n",
            "Discovered\n",
            "Online\n",
            "Learning\n",
            "Strategy-Aware\n",
            "Linear\n",
            "Classifiers\n",
            "Upper\n",
            "Confidence\n",
            "Primal-Dual\n",
            "Reinforcement\n",
            "Learning\n",
            "for\n",
            "CMDP\n",
            "with\n",
            "Adversarial\n",
            "Loss\n",
            "Calibrating\n",
            "Deep\n",
            "Neural\n",
            "Networks\n",
            "using\n",
            "Focal\n",
            "Loss\n",
            "Optimizing\n",
            "Mode\n",
            "Connectivity\n",
            "via\n",
            "Neuron\n",
            "Alignment\n",
            "Information\n",
            "Theoretic\n",
            "Regret\n",
            "Bounds\n",
            "for\n",
            "Online\n",
            "Nonlinear\n",
            "Control\n",
            "A\n",
            "kernel\n",
            "test\n",
            "for\n",
            "quasi-independence\n",
            "First\n",
            "Order\n",
            "Constrained\n",
            "Optimization\n",
            "in\n",
            "Policy\n",
            "Space\n",
            "Learning\n",
            "Augmented\n",
            "Energy\n",
            "Minimization\n",
            "via\n",
            "Speed\n",
            "Scaling\n",
            "Exploiting\n",
            "MMD\n",
            "and\n",
            "Sinkhorn\n",
            "Divergences\n",
            "for\n",
            "Fair\n",
            "and\n",
            "Transferable\n",
            "Representation\n",
            "Learning\n",
            "Deep\n",
            "Rao-Blackwellised\n",
            "Particle\n",
            "Filters\n",
            "for\n",
            "Time\n",
            "Series\n",
            "Forecasting\n",
            "Why\n",
            "are\n",
            "Adaptive\n",
            "Methods\n",
            "Good\n",
            "for\n",
            "Attention\n",
            "Models\n",
            "?\n",
            "Neural\n",
            "Sparse\n",
            "Representation\n",
            "for\n",
            "Image\n",
            "Restoration\n",
            "Boosting\n",
            "First-Order\n",
            "Methods\n",
            "by\n",
            "Shifting\n",
            "Objective\n",
            ":\n",
            "New\n",
            "Schemes\n",
            "with\n",
            "Faster\n",
            "Worst-Case\n",
            "Rates\n",
            "Robust\n",
            "Sequence\n",
            "Submodular\n",
            "Maximization\n",
            "Certified\n",
            "Monotonic\n",
            "Neural\n",
            "Networks\n",
            "System\n",
            "Identification\n",
            "with\n",
            "Biophysical\n",
            "Constraints\n",
            ":\n",
            "A\n",
            "Circuit\n",
            "Model\n",
            "of\n",
            "the\n",
            "Inner\n",
            "Retina\n",
            "Efficient\n",
            "Algorithms\n",
            "for\n",
            "Device\n",
            "Placement\n",
            "of\n",
            "DNN\n",
            "Graph\n",
            "Operators\n",
            "Active\n",
            "Invariant\n",
            "Causal\n",
            "Prediction\n",
            ":\n",
            "Experiment\n",
            "Selection\n",
            "through\n",
            "Stability\n",
            "BOSS\n",
            ":\n",
            "Bayesian\n",
            "Optimization\n",
            "over\n",
            "String\n",
            "Spaces\n",
            "Model\n",
            "Interpretability\n",
            "through\n",
            "the\n",
            "lens\n",
            "of\n",
            "Computational\n",
            "Complexity\n",
            "Markovian\n",
            "Score\n",
            "Climbing\n",
            ":\n",
            "Variational\n",
            "Inference\n",
            "with\n",
            "KL\n",
            "(\n",
            "p||q\n",
            ")\n",
            "Improved\n",
            "Analysis\n",
            "of\n",
            "Clipping\n",
            "Algorithms\n",
            "for\n",
            "Non-convex\n",
            "Optimization\n",
            "Bias\n",
            "no\n",
            "more\n",
            ":\n",
            "high-probability\n",
            "data-dependent\n",
            "regret\n",
            "bounds\n",
            "for\n",
            "adversarial\n",
            "bandits\n",
            "and\n",
            "MDPs\n",
            "A\n",
            "Ranking-based\n",
            ",\n",
            "Balanced\n",
            "Loss\n",
            "Function\n",
            "Unifying\n",
            "Classification\n",
            "and\n",
            "Localisation\n",
            "in\n",
            "Object\n",
            "Detection\n",
            "StratLearner\n",
            ":\n",
            "Learning\n",
            "a\n",
            "Strategy\n",
            "for\n",
            "Misinformation\n",
            "Prevention\n",
            "in\n",
            "Social\n",
            "Networks\n",
            "A\n",
            "Unified\n",
            "Switching\n",
            "System\n",
            "Perspective\n",
            "and\n",
            "Convergence\n",
            "Analysis\n",
            "of\n",
            "Q-Learning\n",
            "Algorithms\n",
            "Kernel\n",
            "Alignment\n",
            "Risk\n",
            "Estimator\n",
            ":\n",
            "Risk\n",
            "Prediction\n",
            "from\n",
            "Training\n",
            "Data\n",
            "Calibrating\n",
            "CNNs\n",
            "for\n",
            "Lifelong\n",
            "Learning\n",
            "Online\n",
            "Convex\n",
            "Optimization\n",
            "Over\n",
            "Erdos-Renyi\n",
            "Random\n",
            "Networks\n",
            "Robustness\n",
            "of\n",
            "Bayesian\n",
            "Neural\n",
            "Networks\n",
            "to\n",
            "Gradient-Based\n",
            "Attacks\n",
            "Parametric\n",
            "Instance\n",
            "Classification\n",
            "for\n",
            "Unsupervised\n",
            "Visual\n",
            "Feature\n",
            "learning\n",
            "Sparse\n",
            "Weight\n",
            "Activation\n",
            "Training\n",
            "Collapsing\n",
            "Bandits\n",
            "and\n",
            "Their\n",
            "Application\n",
            "to\n",
            "Public\n",
            "Health\n",
            "Intervention\n",
            "Neural\n",
            "Sparse\n",
            "Voxel\n",
            "Fields\n",
            "A\n",
            "Flexible\n",
            "Framework\n",
            "for\n",
            "Designing\n",
            "Trainable\n",
            "Priors\n",
            "with\n",
            "Adaptive\n",
            "Smoothing\n",
            "and\n",
            "Game\n",
            "Encoding\n",
            "The\n",
            "Discrete\n",
            "Gaussian\n",
            "for\n",
            "Differential\n",
            "Privacy\n",
            "Robust\n",
            "Sub-Gaussian\n",
            "Principal\n",
            "Component\n",
            "Analysis\n",
            "and\n",
            "Width-Independent\n",
            "Schatten\n",
            "Packing\n",
            "Adaptive\n",
            "Importance\n",
            "Sampling\n",
            "for\n",
            "Finite-Sum\n",
            "Optimization\n",
            "and\n",
            "Sampling\n",
            "with\n",
            "Decreasing\n",
            "Step-Sizes\n",
            "Learning\n",
            "efficient\n",
            "task-dependent\n",
            "representations\n",
            "with\n",
            "synaptic\n",
            "plasticity\n",
            "A\n",
            "Contour\n",
            "Stochastic\n",
            "Gradient\n",
            "Langevin\n",
            "Dynamics\n",
            "Algorithm\n",
            "for\n",
            "Simulations\n",
            "of\n",
            "Multi-modal\n",
            "Distributions\n",
            "Error\n",
            "Bounds\n",
            "of\n",
            "Imitating\n",
            "Policies\n",
            "and\n",
            "Environments\n",
            "Disentangling\n",
            "Human\n",
            "Error\n",
            "from\n",
            "Ground\n",
            "Truth\n",
            "in\n",
            "Segmentation\n",
            "of\n",
            "Medical\n",
            "Images\n",
            "Consequences\n",
            "of\n",
            "Misaligned\n",
            "AI\n",
            "Promoting\n",
            "Coordination\n",
            "through\n",
            "Policy\n",
            "Regularization\n",
            "in\n",
            "Multi-Agent\n",
            "Deep\n",
            "Reinforcement\n",
            "Learning\n",
            "Emergent\n",
            "Reciprocity\n",
            "and\n",
            "Team\n",
            "Formation\n",
            "from\n",
            "Randomized\n",
            "Uncertain\n",
            "Social\n",
            "Preferences\n",
            "Hitting\n",
            "the\n",
            "High\n",
            "Notes\n",
            ":\n",
            "Subset\n",
            "Selection\n",
            "for\n",
            "Maximizing\n",
            "Expected\n",
            "Order\n",
            "Statistics\n",
            "Towards\n",
            "Scale-Invariant\n",
            "Graph-related\n",
            "Problem\n",
            "Solving\n",
            "by\n",
            "Iterative\n",
            "Homogeneous\n",
            "GNNs\n",
            "Regret\n",
            "Bounds\n",
            "without\n",
            "Lipschitz\n",
            "Continuity\n",
            ":\n",
            "Online\n",
            "Learning\n",
            "with\n",
            "Relative-Lipschitz\n",
            "Losses\n",
            "The\n",
            "Lottery\n",
            "Ticket\n",
            "Hypothesis\n",
            "for\n",
            "Pre-trained\n",
            "BERT\n",
            "Networks\n",
            "Label-Aware\n",
            "Neural\n",
            "Tangent\n",
            "Kernel\n",
            ":\n",
            "Toward\n",
            "Better\n",
            "Generalization\n",
            "and\n",
            "Local\n",
            "Elasticity\n",
            "Beyond\n",
            "Perturbations\n",
            ":\n",
            "Learning\n",
            "Guarantees\n",
            "with\n",
            "Arbitrary\n",
            "Adversarial\n",
            "Test\n",
            "Examples\n",
            "AdvFlow\n",
            ":\n",
            "Inconspicuous\n",
            "Black-box\n",
            "Adversarial\n",
            "Attacks\n",
            "using\n",
            "Normalizing\n",
            "Flows\n",
            "Few-shot\n",
            "Image\n",
            "Generation\n",
            "with\n",
            "Elastic\n",
            "Weight\n",
            "Consolidation\n",
            "On\n",
            "the\n",
            "Expressiveness\n",
            "of\n",
            "Approximate\n",
            "Inference\n",
            "in\n",
            "Bayesian\n",
            "Neural\n",
            "Networks\n",
            "Non-Crossing\n",
            "Quantile\n",
            "Regression\n",
            "for\n",
            "Distributional\n",
            "Reinforcement\n",
            "Learning\n",
            "Dark\n",
            "Experience\n",
            "for\n",
            "General\n",
            "Continual\n",
            "Learning\n",
            ":\n",
            "a\n",
            "Strong\n",
            ",\n",
            "Simple\n",
            "Baseline\n",
            "Learning\n",
            "to\n",
            "Utilize\n",
            "Shaping\n",
            "Rewards\n",
            ":\n",
            "A\n",
            "New\n",
            "Approach\n",
            "of\n",
            "Reward\n",
            "Shaping\n",
            "Neural\n",
            "encoding\n",
            "with\n",
            "visual\n",
            "attention\n",
            "On\n",
            "the\n",
            "linearity\n",
            "of\n",
            "large\n",
            "non-linear\n",
            "models\n",
            ":\n",
            "when\n",
            "and\n",
            "why\n",
            "the\n",
            "tangent\n",
            "kernel\n",
            "is\n",
            "constant\n",
            "PLLay\n",
            ":\n",
            "Efficient\n",
            "Topological\n",
            "Layer\n",
            "based\n",
            "on\n",
            "Persistent\n",
            "Landscapes\n",
            "Decentralized\n",
            "Langevin\n",
            "Dynamics\n",
            "for\n",
            "Bayesian\n",
            "Learning\n",
            "Shared\n",
            "Space\n",
            "Transfer\n",
            "Learning\n",
            "for\n",
            "analyzing\n",
            "multi-site\n",
            "fMRI\n",
            "data\n",
            "The\n",
            "Diversified\n",
            "Ensemble\n",
            "Neural\n",
            "Network\n",
            "Inductive\n",
            "Quantum\n",
            "Embedding\n",
            "Variational\n",
            "Bayesian\n",
            "Unlearning\n",
            "Batched\n",
            "Coarse\n",
            "Ranking\n",
            "in\n",
            "Multi-Armed\n",
            "Bandits\n",
            "Understanding\n",
            "and\n",
            "Improving\n",
            "Fast\n",
            "Adversarial\n",
            "Training\n",
            "Coded\n",
            "Sequential\n",
            "Matrix\n",
            "Multiplication\n",
            "For\n",
            "Straggler\n",
            "Mitigation\n",
            "Attack\n",
            "of\n",
            "the\n",
            "Tails\n",
            ":\n",
            "Yes\n",
            ",\n",
            "You\n",
            "Really\n",
            "Can\n",
            "Backdoor\n",
            "Federated\n",
            "Learning\n",
            "Certifiably\n",
            "Adversarially\n",
            "Robust\n",
            "Detection\n",
            "of\n",
            "Out-of-Distribution\n",
            "Data\n",
            "Domain\n",
            "Generalization\n",
            "via\n",
            "Entropy\n",
            "Regularization\n",
            "Bayesian\n",
            "Meta-Learning\n",
            "for\n",
            "the\n",
            "Few-Shot\n",
            "Setting\n",
            "via\n",
            "Deep\n",
            "Kernels\n",
            "Skeleton-bridged\n",
            "Point\n",
            "Completion\n",
            ":\n",
            "From\n",
            "Global\n",
            "Inference\n",
            "to\n",
            "Local\n",
            "Adjustment\n",
            "Compressing\n",
            "Images\n",
            "by\n",
            "Encoding\n",
            "Their\n",
            "Latent\n",
            "Representations\n",
            "with\n",
            "Relative\n",
            "Entropy\n",
            "Coding\n",
            "Improved\n",
            "Guarantees\n",
            "for\n",
            "k-means++\n",
            "and\n",
            "k-means++\n",
            "Parallel\n",
            "Sparse\n",
            "Spectrum\n",
            "Warped\n",
            "Input\n",
            "Measures\n",
            "for\n",
            "Nonstationary\n",
            "Kernel\n",
            "Learning\n",
            "An\n",
            "Efficient\n",
            "Adversarial\n",
            "Attack\n",
            "for\n",
            "Tree\n",
            "Ensembles\n",
            "Learning\n",
            "Continuous\n",
            "System\n",
            "Dynamics\n",
            "from\n",
            "Irregularly-Sampled\n",
            "Partial\n",
            "Observations\n",
            "Online\n",
            "Bayesian\n",
            "Persuasion\n",
            "Robust\n",
            "Pre-Training\n",
            "by\n",
            "Adversarial\n",
            "Contrastive\n",
            "Learning\n",
            "Random\n",
            "Walk\n",
            "Graph\n",
            "Neural\n",
            "Networks\n",
            "Explore\n",
            "Aggressively\n",
            ",\n",
            "Update\n",
            "Conservatively\n",
            ":\n",
            "Stochastic\n",
            "Extragradient\n",
            "Methods\n",
            "with\n",
            "Variable\n",
            "Stepsize\n",
            "Scaling\n",
            "Fast\n",
            "and\n",
            "Accurate\n",
            "$\n",
            "k\n",
            "$\n",
            "-means++\n",
            "via\n",
            "Rejection\n",
            "Sampling\n",
            "Variational\n",
            "Amodal\n",
            "Object\n",
            "Completion\n",
            "When\n",
            "Counterpoint\n",
            "Meets\n",
            "Chinese\n",
            "Folk\n",
            "Melodies\n",
            "Sub-linear\n",
            "Regret\n",
            "Bounds\n",
            "for\n",
            "Bayesian\n",
            "Optimisation\n",
            "in\n",
            "Unknown\n",
            "Search\n",
            "Spaces\n",
            "Universal\n",
            "Domain\n",
            "Adaptation\n",
            "through\n",
            "Self\n",
            "Supervision\n",
            "Patch2Self\n",
            ":\n",
            "Denoising\n",
            "Diffusion\n",
            "MRI\n",
            "with\n",
            "Self-Supervised\n",
            "Learning​\n",
            "Stochastic\n",
            "Normalization\n",
            "Constrained\n",
            "episodic\n",
            "reinforcement\n",
            "learning\n",
            "in\n",
            "concave-convex\n",
            "and\n",
            "knapsack\n",
            "settings\n",
            "On\n",
            "Learning\n",
            "Ising\n",
            "Models\n",
            "under\n",
            "Huber\n",
            "'s\n",
            "Contamination\n",
            "Model\n",
            "Cross-validation\n",
            "Confidence\n",
            "Intervals\n",
            "for\n",
            "Test\n",
            "Error\n",
            "DeepSVG\n",
            ":\n",
            "A\n",
            "Hierarchical\n",
            "Generative\n",
            "Network\n",
            "for\n",
            "Vector\n",
            "Graphics\n",
            "Animation\n",
            "Bayesian\n",
            "Attention\n",
            "Modules\n",
            "Robustness\n",
            "Analysis\n",
            "of\n",
            "Non-Convex\n",
            "Stochastic\n",
            "Gradient\n",
            "Descent\n",
            "using\n",
            "Biased\n",
            "Expectations\n",
            "SoftFlow\n",
            ":\n",
            "Probabilistic\n",
            "Framework\n",
            "for\n",
            "Normalizing\n",
            "Flow\n",
            "on\n",
            "Manifolds\n",
            "A\n",
            "meta-learning\n",
            "approach\n",
            "to\n",
            "(\n",
            "re\n",
            ")\n",
            "discover\n",
            "plasticity\n",
            "rules\n",
            "that\n",
            "carve\n",
            "a\n",
            "desired\n",
            "function\n",
            "into\n",
            "a\n",
            "neural\n",
            "network\n",
            "Greedy\n",
            "Optimization\n",
            "Provably\n",
            "Wins\n",
            "the\n",
            "Lottery\n",
            ":\n",
            "Logarithmic\n",
            "Number\n",
            "of\n",
            "Winning\n",
            "Tickets\n",
            "is\n",
            "Enough\n",
            "Path\n",
            "Integral\n",
            "Based\n",
            "Convolution\n",
            "and\n",
            "Pooling\n",
            "for\n",
            "Graph\n",
            "Neural\n",
            "Networks\n",
            "Estimating\n",
            "the\n",
            "Effects\n",
            "of\n",
            "Continuous-valued\n",
            "Interventions\n",
            "using\n",
            "Generative\n",
            "Adversarial\n",
            "Networks\n",
            "Latent\n",
            "Dynamic\n",
            "Factor\n",
            "Analysis\n",
            "of\n",
            "High-Dimensional\n",
            "Neural\n",
            "Recordings\n",
            "Conditioning\n",
            "and\n",
            "Processing\n",
            ":\n",
            "Techniques\n",
            "to\n",
            "Improve\n",
            "Information-Theoretic\n",
            "Generalization\n",
            "Bounds\n",
            "Bongard-LOGO\n",
            ":\n",
            "A\n",
            "New\n",
            "Benchmark\n",
            "for\n",
            "Human-Level\n",
            "Concept\n",
            "Learning\n",
            "and\n",
            "Reasoning\n",
            "GAN\n",
            "Memory\n",
            "with\n",
            "No\n",
            "Forgetting\n",
            "Deep\n",
            "Reinforcement\n",
            "Learning\n",
            "with\n",
            "Stacked\n",
            "Hierarchical\n",
            "Attention\n",
            "for\n",
            "Text-based\n",
            "Games\n",
            "Gaussian\n",
            "Gated\n",
            "Linear\n",
            "Networks\n",
            "Node\n",
            "Classification\n",
            "on\n",
            "Graphs\n",
            "with\n",
            "Few-Shot\n",
            "Novel\n",
            "Labels\n",
            "via\n",
            "Meta\n",
            "Transformed\n",
            "Network\n",
            "Embedding\n",
            "Online\n",
            "Fast\n",
            "Adaptation\n",
            "and\n",
            "Knowledge\n",
            "Accumulation\n",
            "(\n",
            "OSAKA\n",
            ")\n",
            ":\n",
            "a\n",
            "New\n",
            "Approach\n",
            "to\n",
            "Continual\n",
            "Learning\n",
            "Convex\n",
            "optimization\n",
            "based\n",
            "on\n",
            "global\n",
            "lower\n",
            "second-order\n",
            "models\n",
            "Simultaneously\n",
            "Learning\n",
            "Stochastic\n",
            "and\n",
            "Adversarial\n",
            "Episodic\n",
            "MDPs\n",
            "with\n",
            "Known\n",
            "Transition\n",
            "Relative\n",
            "gradient\n",
            "optimization\n",
            "of\n",
            "the\n",
            "Jacobian\n",
            "term\n",
            "in\n",
            "unsupervised\n",
            "deep\n",
            "learning\n",
            "Self-Supervised\n",
            "Visual\n",
            "Representation\n",
            "Learning\n",
            "from\n",
            "Hierarchical\n",
            "Grouping\n",
            "Optimal\n",
            "Variance\n",
            "Control\n",
            "of\n",
            "the\n",
            "Score-Function\n",
            "Gradient\n",
            "Estimator\n",
            "for\n",
            "Importance-Weighted\n",
            "Bounds\n",
            "Explicit\n",
            "Regularisation\n",
            "in\n",
            "Gaussian\n",
            "Noise\n",
            "Injections\n",
            "Numerically\n",
            "Solving\n",
            "Parametric\n",
            "Families\n",
            "of\n",
            "High-Dimensional\n",
            "Kolmogorov\n",
            "Partial\n",
            "Differential\n",
            "Equations\n",
            "via\n",
            "Deep\n",
            "Learning\n",
            "Finite-Time\n",
            "Analysis\n",
            "for\n",
            "Double\n",
            "Q-learning\n",
            "Learning\n",
            "to\n",
            "Detect\n",
            "Objects\n",
            "with\n",
            "a\n",
            "1\n",
            "Megapixel\n",
            "Event\n",
            "Camera\n",
            "End-to-End\n",
            "Learning\n",
            "and\n",
            "Intervention\n",
            "in\n",
            "Games\n",
            "Least\n",
            "Squares\n",
            "Regression\n",
            "with\n",
            "Markovian\n",
            "Data\n",
            ":\n",
            "Fundamental\n",
            "Limits\n",
            "and\n",
            "Algorithms\n",
            "Predictive\n",
            "coding\n",
            "in\n",
            "balanced\n",
            "neural\n",
            "networks\n",
            "with\n",
            "noise\n",
            ",\n",
            "chaos\n",
            "and\n",
            "delays\n",
            "Interpolation\n",
            "Technique\n",
            "to\n",
            "Speed\n",
            "Up\n",
            "Gradients\n",
            "Propagation\n",
            "in\n",
            "Neural\n",
            "ODEs\n",
            "On\n",
            "the\n",
            "Equivalence\n",
            "between\n",
            "Online\n",
            "and\n",
            "Private\n",
            "Learnability\n",
            "beyond\n",
            "Binary\n",
            "Classification\n",
            "AViD\n",
            "Dataset\n",
            ":\n",
            "Anonymized\n",
            "Videos\n",
            "from\n",
            "Diverse\n",
            "Countries\n",
            "Probably\n",
            "Approximately\n",
            "Correct\n",
            "Constrained\n",
            "Learning\n",
            "RATT\n",
            ":\n",
            "Recurrent\n",
            "Attention\n",
            "to\n",
            "Transient\n",
            "Tasks\n",
            "for\n",
            "Continual\n",
            "Image\n",
            "Captioning\n",
            "Decisions\n",
            ",\n",
            "Counterfactual\n",
            "Explanations\n",
            "and\n",
            "Strategic\n",
            "Behavior\n",
            "Hierarchical\n",
            "Patch\n",
            "VAE-GAN\n",
            ":\n",
            "Generating\n",
            "Diverse\n",
            "Videos\n",
            "from\n",
            "a\n",
            "Single\n",
            "Sample\n",
            "A\n",
            "Feasible\n",
            "Level\n",
            "Proximal\n",
            "Point\n",
            "Method\n",
            "for\n",
            "Nonconvex\n",
            "Sparse\n",
            "Constrained\n",
            "Optimization\n",
            "Reservoir\n",
            "Computing\n",
            "meets\n",
            "Recurrent\n",
            "Kernels\n",
            "and\n",
            "Structured\n",
            "Transforms\n",
            "Comprehensive\n",
            "Attention\n",
            "Self-Distillation\n",
            "for\n",
            "Weakly-Supervised\n",
            "Object\n",
            "Detection\n",
            "Linear\n",
            "Dynamical\n",
            "Systems\n",
            "as\n",
            "a\n",
            "Core\n",
            "Computational\n",
            "Primitive\n",
            "Ratio\n",
            "Trace\n",
            "Formulation\n",
            "of\n",
            "Wasserstein\n",
            "Discriminant\n",
            "Analysis\n",
            "PAC-Bayes\n",
            "Analysis\n",
            "Beyond\n",
            "the\n",
            "Usual\n",
            "Bounds\n",
            "Few-shot\n",
            "Visual\n",
            "Reasoning\n",
            "with\n",
            "Meta-Analogical\n",
            "Contrastive\n",
            "Learning\n",
            "MPNet\n",
            ":\n",
            "Masked\n",
            "and\n",
            "Permuted\n",
            "Pre-training\n",
            "for\n",
            "Language\n",
            "Understanding\n",
            "Reinforcement\n",
            "Learning\n",
            "with\n",
            "Feedback\n",
            "Graphs\n",
            "Zap\n",
            "Q-Learning\n",
            "With\n",
            "Nonlinear\n",
            "Function\n",
            "Approximation\n",
            "Lipschitz-Certifiable\n",
            "Training\n",
            "with\n",
            "a\n",
            "Tight\n",
            "Outer\n",
            "Bound\n",
            "Fast\n",
            "Adaptive\n",
            "Non-Monotone\n",
            "Submodular\n",
            "Maximization\n",
            "Subject\n",
            "to\n",
            "a\n",
            "Knapsack\n",
            "Constraint\n",
            "Conformal\n",
            "Symplectic\n",
            "and\n",
            "Relativistic\n",
            "Optimization\n",
            "Bayes\n",
            "Consistency\n",
            "vs.\n",
            "H-Consistency\n",
            ":\n",
            "The\n",
            "Interplay\n",
            "between\n",
            "Surrogate\n",
            "Loss\n",
            "Functions\n",
            "and\n",
            "the\n",
            "Scoring\n",
            "Function\n",
            "Class\n",
            "Inverting\n",
            "Gradients\n",
            "-\n",
            "How\n",
            "easy\n",
            "is\n",
            "it\n",
            "to\n",
            "break\n",
            "privacy\n",
            "in\n",
            "federated\n",
            "learning\n",
            "?\n",
            "Dynamic\n",
            "allocation\n",
            "of\n",
            "limited\n",
            "memory\n",
            "resources\n",
            "in\n",
            "reinforcement\n",
            "learning\n",
            "CryptoNAS\n",
            ":\n",
            "Private\n",
            "Inference\n",
            "on\n",
            "a\n",
            "ReLU\n",
            "Budget\n",
            "A\n",
            "Stochastic\n",
            "Path\n",
            "Integral\n",
            "Differential\n",
            "EstimatoR\n",
            "Expectation\n",
            "Maximization\n",
            "Algorithm\n",
            "CHIP\n",
            ":\n",
            "A\n",
            "Hawkes\n",
            "Process\n",
            "Model\n",
            "for\n",
            "Continuous-time\n",
            "Networks\n",
            "with\n",
            "Scalable\n",
            "and\n",
            "Consistent\n",
            "Estimation\n",
            "SAC\n",
            ":\n",
            "Accelerating\n",
            "and\n",
            "Structuring\n",
            "Self-Attention\n",
            "via\n",
            "Sparse\n",
            "Adaptive\n",
            "Connection\n",
            "Design\n",
            "Space\n",
            "for\n",
            "Graph\n",
            "Neural\n",
            "Networks\n",
            "HiFi-GAN\n",
            ":\n",
            "Generative\n",
            "Adversarial\n",
            "Networks\n",
            "for\n",
            "Efficient\n",
            "and\n",
            "High\n",
            "Fidelity\n",
            "Speech\n",
            "Synthesis\n",
            "Unbalanced\n",
            "Sobolev\n",
            "Descent\n",
            "Identifying\n",
            "Mislabeled\n",
            "Data\n",
            "using\n",
            "the\n",
            "Area\n",
            "Under\n",
            "the\n",
            "Margin\n",
            "Ranking\n",
            "Combining\n",
            "Deep\n",
            "Reinforcement\n",
            "Learning\n",
            "and\n",
            "Search\n",
            "for\n",
            "Imperfect-Information\n",
            "Games\n",
            "High-Throughput\n",
            "Synchronous\n",
            "Deep\n",
            "RL\n",
            "Contrastive\n",
            "Learning\n",
            "with\n",
            "Adversarial\n",
            "Examples\n",
            "Mixed\n",
            "Hamiltonian\n",
            "Monte\n",
            "Carlo\n",
            "for\n",
            "Mixed\n",
            "Discrete\n",
            "and\n",
            "Continuous\n",
            "Variables\n",
            "Adversarial\n",
            "Sparse\n",
            "Transformer\n",
            "for\n",
            "Time\n",
            "Series\n",
            "Forecasting\n",
            "The\n",
            "Surprising\n",
            "Simplicity\n",
            "of\n",
            "the\n",
            "Early-Time\n",
            "Learning\n",
            "Dynamics\n",
            "of\n",
            "Neural\n",
            "Networks\n",
            "CLEARER\n",
            ":\n",
            "Multi-Scale\n",
            "Neural\n",
            "Architecture\n",
            "Search\n",
            "for\n",
            "Image\n",
            "Restoration\n",
            "Hierarchical\n",
            "Gaussian\n",
            "Process\n",
            "Priors\n",
            "for\n",
            "Bayesian\n",
            "Neural\n",
            "Network\n",
            "Weights\n",
            "Compositional\n",
            "Explanations\n",
            "of\n",
            "Neurons\n",
            "Calibrated\n",
            "Reliable\n",
            "Regression\n",
            "using\n",
            "Maximum\n",
            "Mean\n",
            "Discrepancy\n",
            "Directional\n",
            "convergence\n",
            "and\n",
            "alignment\n",
            "in\n",
            "deep\n",
            "learning\n",
            "Functional\n",
            "Regularization\n",
            "for\n",
            "Representation\n",
            "Learning\n",
            ":\n",
            "A\n",
            "Unified\n",
            "Theoretical\n",
            "Perspective\n",
            "Provably\n",
            "Efficient\n",
            "Online\n",
            "Hyperparameter\n",
            "Optimization\n",
            "with\n",
            "Population-Based\n",
            "Bandits\n",
            "Understanding\n",
            "Global\n",
            "Feature\n",
            "Contributions\n",
            "With\n",
            "Additive\n",
            "Importance\n",
            "Measures\n",
            "Online\n",
            "Non-Convex\n",
            "Optimization\n",
            "with\n",
            "Imperfect\n",
            "Feedback\n",
            "Co-Tuning\n",
            "for\n",
            "Transfer\n",
            "Learning\n",
            "Multifaceted\n",
            "Uncertainty\n",
            "Estimation\n",
            "for\n",
            "Label-Efficient\n",
            "Deep\n",
            "Learning\n",
            "Continuous\n",
            "Surface\n",
            "Embeddings\n",
            "Succinct\n",
            "and\n",
            "Robust\n",
            "Multi-Agent\n",
            "Communication\n",
            "With\n",
            "Temporal\n",
            "Message\n",
            "Control\n",
            "Big\n",
            "Bird\n",
            ":\n",
            "Transformers\n",
            "for\n",
            "Longer\n",
            "Sequences\n",
            "Neural\n",
            "Execution\n",
            "Engines\n",
            ":\n",
            "Learning\n",
            "to\n",
            "Execute\n",
            "Subroutines\n",
            "Random\n",
            "Reshuffling\n",
            ":\n",
            "Simple\n",
            "Analysis\n",
            "with\n",
            "Vast\n",
            "Improvements\n",
            "Long-Horizon\n",
            "Visual\n",
            "Planning\n",
            "with\n",
            "Goal-Conditioned\n",
            "Hierarchical\n",
            "Predictors\n",
            "Statistical\n",
            "Optimal\n",
            "Transport\n",
            "posed\n",
            "as\n",
            "Learning\n",
            "Kernel\n",
            "Embedding\n",
            "Dual-Resolution\n",
            "Correspondence\n",
            "Networks\n",
            "Advances\n",
            "in\n",
            "Black-Box\n",
            "VI\n",
            ":\n",
            "Normalizing\n",
            "Flows\n",
            ",\n",
            "Importance\n",
            "Weighting\n",
            ",\n",
            "and\n",
            "Optimization\n",
            "f-Divergence\n",
            "Variational\n",
            "Inference\n",
            "Unfolding\n",
            "recurrence\n",
            "by\n",
            "Green\n",
            "’\n",
            "s\n",
            "functions\n",
            "for\n",
            "optimized\n",
            "reservoir\n",
            "computing\n",
            "The\n",
            "Dilemma\n",
            "of\n",
            "TriHard\n",
            "Loss\n",
            "and\n",
            "an\n",
            "Element-Weighted\n",
            "TriHard\n",
            "Loss\n",
            "for\n",
            "Person\n",
            "Re-Identification\n",
            "Disentangling\n",
            "by\n",
            "Subspace\n",
            "Diffusion\n",
            "Towards\n",
            "Neural\n",
            "Programming\n",
            "Interfaces\n",
            "Discovering\n",
            "Symbolic\n",
            "Models\n",
            "from\n",
            "Deep\n",
            "Learning\n",
            "with\n",
            "Inductive\n",
            "Biases\n",
            "Real\n",
            "World\n",
            "Games\n",
            "Look\n",
            "Like\n",
            "Spinning\n",
            "Tops\n",
            "Cooperative\n",
            "Heterogeneous\n",
            "Deep\n",
            "Reinforcement\n",
            "Learning\n",
            "Mitigating\n",
            "Forgetting\n",
            "in\n",
            "Online\n",
            "Continual\n",
            "Learning\n",
            "via\n",
            "Instance-Aware\n",
            "Parameterization\n",
            "ImpatientCapsAndRuns\n",
            ":\n",
            "Approximately\n",
            "Optimal\n",
            "Algorithm\n",
            "Configuration\n",
            "from\n",
            "an\n",
            "Infinite\n",
            "Pool\n",
            "Dense\n",
            "Correspondences\n",
            "between\n",
            "Human\n",
            "Bodies\n",
            "via\n",
            "Learning\n",
            "Transformation\n",
            "Synchronization\n",
            "on\n",
            "Graphs\n",
            "Reasoning\n",
            "about\n",
            "Uncertainties\n",
            "in\n",
            "Discrete-Time\n",
            "Dynamical\n",
            "Systems\n",
            "using\n",
            "Polynomial\n",
            "Forms\n",
            ".\n",
            "Applications\n",
            "of\n",
            "Common\n",
            "Entropy\n",
            "for\n",
            "Causal\n",
            "Inference\n",
            "SGD\n",
            "with\n",
            "shuffling\n",
            ":\n",
            "optimal\n",
            "rates\n",
            "without\n",
            "component\n",
            "convexity\n",
            "and\n",
            "large\n",
            "epoch\n",
            "requirements\n",
            "Unsupervised\n",
            "Joint\n",
            "k-node\n",
            "Graph\n",
            "Representations\n",
            "with\n",
            "Compositional\n",
            "Energy-Based\n",
            "Models\n",
            "Neural\n",
            "Manifold\n",
            "Ordinary\n",
            "Differential\n",
            "Equations\n",
            "CO-Optimal\n",
            "Transport\n",
            "Continuous\n",
            "Meta-Learning\n",
            "without\n",
            "Tasks\n",
            "A\n",
            "mathematical\n",
            "theory\n",
            "of\n",
            "cooperative\n",
            "communication\n",
            "Penalized\n",
            "Langevin\n",
            "dynamics\n",
            "with\n",
            "vanishing\n",
            "penalty\n",
            "for\n",
            "smooth\n",
            "and\n",
            "log-concave\n",
            "targets\n",
            "Learning\n",
            "Invariances\n",
            "in\n",
            "Neural\n",
            "Networks\n",
            "from\n",
            "Training\n",
            "Data\n",
            "A\n",
            "Finite-Time\n",
            "Analysis\n",
            "of\n",
            "Two\n",
            "Time-Scale\n",
            "Actor-Critic\n",
            "Methods\n",
            "Pruning\n",
            "Filter\n",
            "in\n",
            "Filter\n",
            "Learning\n",
            "to\n",
            "Mutate\n",
            "with\n",
            "Hypergradient\n",
            "Guided\n",
            "Population\n",
            "A\n",
            "convex\n",
            "optimization\n",
            "formulation\n",
            "for\n",
            "multivariate\n",
            "regression\n",
            "Online\n",
            "Meta-Critic\n",
            "Learning\n",
            "for\n",
            "Off-Policy\n",
            "Actor-Critic\n",
            "Methods\n",
            "The\n",
            "All-or-Nothing\n",
            "Phenomenon\n",
            "in\n",
            "Sparse\n",
            "Tensor\n",
            "PCA\n",
            "Synthesize\n",
            ",\n",
            "Execute\n",
            "and\n",
            "Debug\n",
            ":\n",
            "Learning\n",
            "to\n",
            "Repair\n",
            "for\n",
            "Neural\n",
            "Program\n",
            "Synthesis\n",
            "ARMA\n",
            "Nets\n",
            ":\n",
            "Expanding\n",
            "Receptive\n",
            "Field\n",
            "for\n",
            "Dense\n",
            "Prediction\n",
            "Diversity-Guided\n",
            "Multi-Objective\n",
            "Bayesian\n",
            "Optimization\n",
            "With\n",
            "Batch\n",
            "Evaluations\n",
            "SOLOv2\n",
            ":\n",
            "Dynamic\n",
            "and\n",
            "Fast\n",
            "Instance\n",
            "Segmentation\n",
            "Robust\n",
            "Recovery\n",
            "via\n",
            "Implicit\n",
            "Bias\n",
            "of\n",
            "Discrepant\n",
            "Learning\n",
            "Rates\n",
            "for\n",
            "Double\n",
            "Over-parameterization\n",
            "Axioms\n",
            "for\n",
            "Learning\n",
            "from\n",
            "Pairwise\n",
            "Comparisons\n",
            "Continuous\n",
            "Regularized\n",
            "Wasserstein\n",
            "Barycenters\n",
            "Spectral\n",
            "Temporal\n",
            "Graph\n",
            "Neural\n",
            "Network\n",
            "for\n",
            "Multivariate\n",
            "Time-series\n",
            "Forecasting\n",
            "Online\n",
            "Multitask\n",
            "Learning\n",
            "with\n",
            "Long-Term\n",
            "Memory\n",
            "Fewer\n",
            "is\n",
            "More\n",
            ":\n",
            "A\n",
            "Deep\n",
            "Graph\n",
            "Metric\n",
            "Learning\n",
            "Perspective\n",
            "Using\n",
            "Fewer\n",
            "Proxies\n",
            "Adaptive\n",
            "Graph\n",
            "Convolutional\n",
            "Recurrent\n",
            "Network\n",
            "for\n",
            "Traffic\n",
            "Forecasting\n",
            "On\n",
            "Reward-Free\n",
            "Reinforcement\n",
            "Learning\n",
            "with\n",
            "Linear\n",
            "Function\n",
            "Approximation\n",
            "Robustness\n",
            "of\n",
            "Community\n",
            "Detection\n",
            "to\n",
            "Random\n",
            "Geometric\n",
            "Perturbations\n",
            "Learning\n",
            "outside\n",
            "the\n",
            "Black-Box\n",
            ":\n",
            "The\n",
            "pursuit\n",
            "of\n",
            "interpretable\n",
            "models\n",
            "Breaking\n",
            "Reversibility\n",
            "Accelerates\n",
            "Langevin\n",
            "Dynamics\n",
            "for\n",
            "Non-Convex\n",
            "Optimization\n",
            "Robust\n",
            "large-margin\n",
            "learning\n",
            "in\n",
            "hyperbolic\n",
            "space\n",
            "Replica-Exchange\n",
            "Nos\\\n",
            "'\n",
            "e-Hoover\n",
            "Dynamics\n",
            "for\n",
            "Bayesian\n",
            "Learning\n",
            "on\n",
            "Large\n",
            "Datasets\n",
            "Adversarially\n",
            "Robust\n",
            "Few-Shot\n",
            "Learning\n",
            ":\n",
            "A\n",
            "Meta-Learning\n",
            "Approach\n",
            "Neural\n",
            "Anisotropy\n",
            "Directions\n",
            "Digraph\n",
            "Inception\n",
            "Convolutional\n",
            "Networks\n",
            "PAC-Bayesian\n",
            "Bound\n",
            "for\n",
            "the\n",
            "Conditional\n",
            "Value\n",
            "at\n",
            "Risk\n",
            "Stochastic\n",
            "Stein\n",
            "Discrepancies\n",
            "On\n",
            "the\n",
            "Role\n",
            "of\n",
            "Sparsity\n",
            "and\n",
            "DAG\n",
            "Constraints\n",
            "for\n",
            "Learning\n",
            "Linear\n",
            "DAGs\n",
            "Cream\n",
            "of\n",
            "the\n",
            "Crop\n",
            ":\n",
            "Distilling\n",
            "Prioritized\n",
            "Paths\n",
            "For\n",
            "One-Shot\n",
            "Neural\n",
            "Architecture\n",
            "Search\n",
            "Fair\n",
            "Multiple\n",
            "Decision\n",
            "Making\n",
            "Through\n",
            "Soft\n",
            "Interventions\n",
            "Representation\n",
            "Learning\n",
            "for\n",
            "Integrating\n",
            "Multi-domain\n",
            "Outcomes\n",
            "to\n",
            "Optimize\n",
            "Individualized\n",
            "Treatment\n",
            "Learning\n",
            "to\n",
            "Play\n",
            "No-Press\n",
            "Diplomacy\n",
            "with\n",
            "Best\n",
            "Response\n",
            "Policy\n",
            "Iteration\n",
            "Inverse\n",
            "Learning\n",
            "of\n",
            "Symmetries\n",
            "DiffGCN\n",
            ":\n",
            "Graph\n",
            "Convolutional\n",
            "Networks\n",
            "via\n",
            "Differential\n",
            "Operators\n",
            "and\n",
            "Algebraic\n",
            "Multigrid\n",
            "Pooling\n",
            "Distributed\n",
            "Newton\n",
            "Can\n",
            "Communicate\n",
            "Less\n",
            "and\n",
            "Resist\n",
            "Byzantine\n",
            "Workers\n",
            "Efficient\n",
            "Nonmyopic\n",
            "Bayesian\n",
            "Optimization\n",
            "via\n",
            "One-Shot\n",
            "Multi-Step\n",
            "Trees\n",
            "Effective\n",
            "Diversity\n",
            "in\n",
            "Population\n",
            "Based\n",
            "Reinforcement\n",
            "Learning\n",
            "Elastic-InfoGAN\n",
            ":\n",
            "Unsupervised\n",
            "Disentangled\n",
            "Representation\n",
            "Learning\n",
            "in\n",
            "Class-Imbalanced\n",
            "Data\n",
            "Direct\n",
            "Policy\n",
            "Gradients\n",
            ":\n",
            "Direct\n",
            "Optimization\n",
            "of\n",
            "Policies\n",
            "in\n",
            "Discrete\n",
            "Action\n",
            "Spaces\n",
            "Hybrid\n",
            "Models\n",
            "for\n",
            "Learning\n",
            "to\n",
            "Branch\n",
            "WoodFisher\n",
            ":\n",
            "Efficient\n",
            "Second-Order\n",
            "Approximation\n",
            "for\n",
            "Neural\n",
            "Network\n",
            "Compression\n",
            "Bi-level\n",
            "Score\n",
            "Matching\n",
            "for\n",
            "Learning\n",
            "Energy-based\n",
            "Latent\n",
            "Variable\n",
            "Models\n",
            "Counterfactual\n",
            "Contrastive\n",
            "Learning\n",
            "for\n",
            "Weakly-Supervised\n",
            "Vision-Language\n",
            "Grounding\n",
            "Decision\n",
            "trees\n",
            "as\n",
            "partitioning\n",
            "machines\n",
            "to\n",
            "characterize\n",
            "their\n",
            "generalization\n",
            "properties\n",
            "Learning\n",
            "to\n",
            "Prove\n",
            "Theorems\n",
            "by\n",
            "Learning\n",
            "to\n",
            "Generate\n",
            "Theorems\n",
            "3D\n",
            "Self-Supervised\n",
            "Methods\n",
            "for\n",
            "Medical\n",
            "Imaging\n",
            "Bayesian\n",
            "filtering\n",
            "unifies\n",
            "adaptive\n",
            "and\n",
            "non-adaptive\n",
            "neural\n",
            "network\n",
            "optimization\n",
            "methods\n",
            "Worst-Case\n",
            "Analysis\n",
            "for\n",
            "Randomly\n",
            "Collected\n",
            "Data\n",
            "Truthful\n",
            "Data\n",
            "Acquisition\n",
            "via\n",
            "Peer\n",
            "Prediction\n",
            "Learning\n",
            "Robust\n",
            "Decision\n",
            "Policies\n",
            "from\n",
            "Observational\n",
            "Data\n",
            "Byzantine\n",
            "Resilient\n",
            "Distributed\n",
            "Multi-Task\n",
            "Learning\n",
            "Reinforcement\n",
            "Learning\n",
            "in\n",
            "Factored\n",
            "MDPs\n",
            ":\n",
            "Oracle-Efficient\n",
            "Algorithms\n",
            "and\n",
            "Tighter\n",
            "Regret\n",
            "Bounds\n",
            "for\n",
            "the\n",
            "Non-Episodic\n",
            "Setting\n",
            "Improving\n",
            "model\n",
            "calibration\n",
            "with\n",
            "accuracy\n",
            "versus\n",
            "uncertainty\n",
            "optimization\n",
            "The\n",
            "Convolution\n",
            "Exponential\n",
            "and\n",
            "Generalized\n",
            "Sylvester\n",
            "Flows\n",
            "An\n",
            "Improved\n",
            "Analysis\n",
            "of\n",
            "Stochastic\n",
            "Gradient\n",
            "Descent\n",
            "with\n",
            "Momentum\n",
            "Precise\n",
            "expressions\n",
            "for\n",
            "random\n",
            "projections\n",
            ":\n",
            "Low-rank\n",
            "approximation\n",
            "and\n",
            "randomized\n",
            "Newton\n",
            "The\n",
            "MAGICAL\n",
            "Benchmark\n",
            "for\n",
            "Robust\n",
            "Imitation\n",
            "X-CAL\n",
            ":\n",
            "Explicit\n",
            "Calibration\n",
            "for\n",
            "Survival\n",
            "Analysis\n",
            "Decentralized\n",
            "Accelerated\n",
            "Proximal\n",
            "Gradient\n",
            "Descent\n",
            "Making\n",
            "Non-Stochastic\n",
            "Control\n",
            "(\n",
            "Almost\n",
            ")\n",
            "as\n",
            "Easy\n",
            "as\n",
            "Stochastic\n",
            "BERT\n",
            "Loses\n",
            "Patience\n",
            ":\n",
            "Fast\n",
            "and\n",
            "Robust\n",
            "Inference\n",
            "with\n",
            "Early\n",
            "Exit\n",
            "Optimal\n",
            "and\n",
            "Practical\n",
            "Algorithms\n",
            "for\n",
            "Smooth\n",
            "and\n",
            "Strongly\n",
            "Convex\n",
            "Decentralized\n",
            "Optimization\n",
            "BAIL\n",
            ":\n",
            "Best-Action\n",
            "Imitation\n",
            "Learning\n",
            "for\n",
            "Batch\n",
            "Deep\n",
            "Reinforcement\n",
            "Learning\n",
            "Regularizing\n",
            "Towards\n",
            "Permutation\n",
            "Invariance\n",
            "In\n",
            "Recurrent\n",
            "Models\n",
            "What\n",
            "Did\n",
            "You\n",
            "Think\n",
            "Would\n",
            "Happen\n",
            "?\n",
            "Explaining\n",
            "Agent\n",
            "Behaviour\n",
            "through\n",
            "Intended\n",
            "Outcomes\n",
            "Batch\n",
            "normalization\n",
            "provably\n",
            "avoids\n",
            "ranks\n",
            "collapse\n",
            "for\n",
            "randomly\n",
            "initialised\n",
            "deep\n",
            "networks\n",
            "Choice\n",
            "Bandits\n",
            "What\n",
            "if\n",
            "Neural\n",
            "Networks\n",
            "had\n",
            "SVDs\n",
            "?\n",
            "A\n",
            "Matrix\n",
            "Chernoff\n",
            "Bound\n",
            "for\n",
            "Markov\n",
            "Chains\n",
            "and\n",
            "Its\n",
            "Application\n",
            "to\n",
            "Co-occurrence\n",
            "Matrices\n",
            "CoMIR\n",
            ":\n",
            "Contrastive\n",
            "Multimodal\n",
            "Image\n",
            "Representation\n",
            "for\n",
            "Registration\n",
            "Ensuring\n",
            "Fairness\n",
            "Beyond\n",
            "the\n",
            "Training\n",
            "Data\n",
            "How\n",
            "do\n",
            "fair\n",
            "decisions\n",
            "fare\n",
            "in\n",
            "long-term\n",
            "qualification\n",
            "?\n",
            "Pre-training\n",
            "via\n",
            "Paraphrasing\n",
            "GCN\n",
            "meets\n",
            "GPU\n",
            ":\n",
            "Decoupling\n",
            "“\n",
            "When\n",
            "to\n",
            "Sample\n",
            "”\n",
            "from\n",
            "“\n",
            "How\n",
            "to\n",
            "Sample\n",
            "”\n",
            "Continual\n",
            "Learning\n",
            "of\n",
            "a\n",
            "Mixed\n",
            "Sequence\n",
            "of\n",
            "Similar\n",
            "and\n",
            "Dissimilar\n",
            "Tasks\n",
            "All\n",
            "your\n",
            "loss\n",
            "are\n",
            "belong\n",
            "to\n",
            "Bayes\n",
            "HAWQ-V2\n",
            ":\n",
            "Hessian\n",
            "Aware\n",
            "trace-Weighted\n",
            "Quantization\n",
            "of\n",
            "Neural\n",
            "Networks\n",
            "Sample-Efficient\n",
            "Reinforcement\n",
            "Learning\n",
            "of\n",
            "Undercomplete\n",
            "POMDPs\n",
            "Non-Convex\n",
            "SGD\n",
            "Learns\n",
            "Halfspaces\n",
            "with\n",
            "Adversarial\n",
            "Label\n",
            "Noise\n",
            "A\n",
            "Tight\n",
            "Lower\n",
            "Bound\n",
            "and\n",
            "Efficient\n",
            "Reduction\n",
            "for\n",
            "Swap\n",
            "Regret\n",
            "DisCor\n",
            ":\n",
            "Corrective\n",
            "Feedback\n",
            "in\n",
            "Reinforcement\n",
            "Learning\n",
            "via\n",
            "Distribution\n",
            "Correction\n",
            "OTLDA\n",
            ":\n",
            "A\n",
            "Geometry-aware\n",
            "Optimal\n",
            "Transport\n",
            "Approach\n",
            "for\n",
            "Topic\n",
            "Modeling\n",
            "Measuring\n",
            "Robustness\n",
            "to\n",
            "Natural\n",
            "Distribution\n",
            "Shifts\n",
            "in\n",
            "Image\n",
            "Classification\n",
            "Can\n",
            "I\n",
            "Trust\n",
            "My\n",
            "Fairness\n",
            "Metric\n",
            "?\n",
            "Assessing\n",
            "Fairness\n",
            "with\n",
            "Unlabeled\n",
            "Data\n",
            "and\n",
            "Bayesian\n",
            "Inference\n",
            "RandAugment\n",
            ":\n",
            "Practical\n",
            "Automated\n",
            "Data\n",
            "Augmentation\n",
            "with\n",
            "a\n",
            "Reduced\n",
            "Search\n",
            "Space\n",
            "Asymptotic\n",
            "normality\n",
            "and\n",
            "confidence\n",
            "intervals\n",
            "for\n",
            "derivatives\n",
            "of\n",
            "2-layers\n",
            "neural\n",
            "network\n",
            "in\n",
            "the\n",
            "random\n",
            "features\n",
            "model\n",
            "DisARM\n",
            ":\n",
            "An\n",
            "Antithetic\n",
            "Gradient\n",
            "Estimator\n",
            "for\n",
            "Binary\n",
            "Latent\n",
            "Variables\n",
            "Variational\n",
            "Inference\n",
            "for\n",
            "Graph\n",
            "Convolutional\n",
            "Networks\n",
            "in\n",
            "the\n",
            "Absence\n",
            "of\n",
            "Graph\n",
            "Data\n",
            "and\n",
            "Adversarial\n",
            "Settings\n",
            "Supervised\n",
            "Contrastive\n",
            "Learning\n",
            "Learning\n",
            "Optimal\n",
            "Representations\n",
            "with\n",
            "the\n",
            "Decodable\n",
            "Information\n",
            "Bottleneck\n",
            "Meta-trained\n",
            "agents\n",
            "implement\n",
            "Bayes-optimal\n",
            "agents\n",
            "Learning\n",
            "Agent\n",
            "Representations\n",
            "for\n",
            "Ice\n",
            "Hockey\n",
            "Weak\n",
            "Form\n",
            "Generalized\n",
            "Hamiltonian\n",
            "Learning\n",
            "Neural\n",
            "Non-Rigid\n",
            "Tracking\n",
            "Collegial\n",
            "Ensembles\n",
            "ICNet\n",
            ":\n",
            "Intra-saliency\n",
            "Correlation\n",
            "Network\n",
            "for\n",
            "Co-Saliency\n",
            "Detection\n",
            "Improved\n",
            "Variational\n",
            "Bayesian\n",
            "Phylogenetic\n",
            "Inference\n",
            "with\n",
            "Normalizing\n",
            "Flows\n",
            "Deep\n",
            "Metric\n",
            "Learning\n",
            "with\n",
            "Spherical\n",
            "Embedding\n",
            "Preference-based\n",
            "Reinforcement\n",
            "Learning\n",
            "with\n",
            "Finite-Time\n",
            "Guarantees\n",
            "AdaBelief\n",
            "Optimizer\n",
            ":\n",
            "Adapting\n",
            "Stepsizes\n",
            "by\n",
            "the\n",
            "Belief\n",
            "in\n",
            "Observed\n",
            "Gradients\n",
            "Interpretable\n",
            "Sequence\n",
            "Learning\n",
            "for\n",
            "Covid-19\n",
            "Forecasting\n",
            "Off-policy\n",
            "Policy\n",
            "Evaluation\n",
            "For\n",
            "Sequential\n",
            "Decisions\n",
            "Under\n",
            "Unobserved\n",
            "Confounding\n",
            "Modern\n",
            "Hopfield\n",
            "Networks\n",
            "and\n",
            "Attention\n",
            "for\n",
            "Immune\n",
            "Repertoire\n",
            "Classification\n",
            "One\n",
            "Ring\n",
            "to\n",
            "Rule\n",
            "Them\n",
            "All\n",
            ":\n",
            "Certifiably\n",
            "Robust\n",
            "Geometric\n",
            "Perception\n",
            "with\n",
            "Outliers\n",
            "Task-Robust\n",
            "Model-Agnostic\n",
            "Meta-Learning\n",
            "R-learning\n",
            "in\n",
            "actor-critic\n",
            "model\n",
            "offers\n",
            "a\n",
            "biologically\n",
            "relevant\n",
            "mechanism\n",
            "for\n",
            "sequential\n",
            "decision-making\n",
            "Revisiting\n",
            "Frank-Wolfe\n",
            "for\n",
            "Polytopes\n",
            ":\n",
            "Strict\n",
            "Complementarity\n",
            "and\n",
            "Sparsity\n",
            "Fast\n",
            "Convergence\n",
            "of\n",
            "Langevin\n",
            "Dynamics\n",
            "on\n",
            "Manifold\n",
            ":\n",
            "Geodesics\n",
            "meet\n",
            "Log-Sobolev\n",
            "Tensor\n",
            "Completion\n",
            "Made\n",
            "Practical\n",
            "Optimization\n",
            "and\n",
            "Generalization\n",
            "Analysis\n",
            "of\n",
            "Transduction\n",
            "through\n",
            "Gradient\n",
            "Boosting\n",
            "and\n",
            "Application\n",
            "to\n",
            "Multi-scale\n",
            "Graph\n",
            "Neural\n",
            "Networks\n",
            "Content\n",
            "Provider\n",
            "Dynamics\n",
            "and\n",
            "Coordination\n",
            "in\n",
            "Recommendation\n",
            "Ecosystems\n",
            "Almost\n",
            "Surely\n",
            "Stable\n",
            "Deep\n",
            "Dynamics\n",
            "Experimental\n",
            "design\n",
            "for\n",
            "MRI\n",
            "by\n",
            "greedy\n",
            "policy\n",
            "search\n",
            "Expert-Supervised\n",
            "Reinforcement\n",
            "Learning\n",
            "for\n",
            "Offline\n",
            "Policy\n",
            "Learning\n",
            "and\n",
            "Evaluation\n",
            "ColdGANs\n",
            ":\n",
            "Taming\n",
            "Language\n",
            "GANs\n",
            "with\n",
            "Cautious\n",
            "Sampling\n",
            "Strategies\n",
            "Hedging\n",
            "in\n",
            "games\n",
            ":\n",
            "Faster\n",
            "convergence\n",
            "of\n",
            "external\n",
            "and\n",
            "swap\n",
            "regrets\n",
            "The\n",
            "Origins\n",
            "and\n",
            "Prevalence\n",
            "of\n",
            "Texture\n",
            "Bias\n",
            "in\n",
            "Convolutional\n",
            "Neural\n",
            "Networks\n",
            "Time-Reversal\n",
            "Symmetric\n",
            "ODE\n",
            "Network\n",
            "Provable\n",
            "Overlapping\n",
            "Community\n",
            "Detection\n",
            "in\n",
            "Weighted\n",
            "Graphs\n",
            "Fast\n",
            "Unbalanced\n",
            "Optimal\n",
            "Transport\n",
            "on\n",
            "a\n",
            "Tree\n",
            "Acceleration\n",
            "with\n",
            "a\n",
            "Ball\n",
            "Optimization\n",
            "Oracle\n",
            "Avoiding\n",
            "Side\n",
            "Effects\n",
            "By\n",
            "Considering\n",
            "Future\n",
            "Tasks\n",
            "Handling\n",
            "Missing\n",
            "Data\n",
            "with\n",
            "Graph\n",
            "Representation\n",
            "Learning\n",
            "Improving\n",
            "Auto-Augment\n",
            "via\n",
            "Augmentation-Wise\n",
            "Weight\n",
            "Sharing\n",
            "MMA\n",
            "Regularization\n",
            ":\n",
            "Decorrelating\n",
            "Weights\n",
            "of\n",
            "Neural\n",
            "Networks\n",
            "by\n",
            "Maximizing\n",
            "the\n",
            "Minimal\n",
            "Angles\n",
            "HRN\n",
            ":\n",
            "A\n",
            "Holistic\n",
            "Approach\n",
            "to\n",
            "One\n",
            "Class\n",
            "Learning\n",
            "The\n",
            "Generalized\n",
            "Lasso\n",
            "with\n",
            "Nonlinear\n",
            "Observations\n",
            "and\n",
            "Generative\n",
            "Priors\n",
            "Fair\n",
            "regression\n",
            "via\n",
            "plug-in\n",
            "estimator\n",
            "and\n",
            "recalibration\n",
            "with\n",
            "statistical\n",
            "guarantees\n",
            "Modeling\n",
            "Shared\n",
            "responses\n",
            "in\n",
            "Neuroimaging\n",
            "Studies\n",
            "through\n",
            "MultiView\n",
            "ICA\n",
            "Efficient\n",
            "Planning\n",
            "in\n",
            "Large\n",
            "MDPs\n",
            "with\n",
            "Weak\n",
            "Linear\n",
            "Function\n",
            "Approximation\n",
            "Efficient\n",
            "Learning\n",
            "of\n",
            "Generative\n",
            "Models\n",
            "via\n",
            "Finite-Difference\n",
            "Score\n",
            "Matching\n",
            "Semialgebraic\n",
            "Optimization\n",
            "for\n",
            "Lipschitz\n",
            "Constants\n",
            "of\n",
            "ReLU\n",
            "Networks\n",
            "Linear-Sample\n",
            "Learning\n",
            "of\n",
            "Low-Rank\n",
            "Distributions\n",
            "Transferable\n",
            "Calibration\n",
            "with\n",
            "Lower\n",
            "Bias\n",
            "and\n",
            "Variance\n",
            "in\n",
            "Domain\n",
            "Adaptation\n",
            "Generalization\n",
            "bound\n",
            "of\n",
            "globally\n",
            "optimal\n",
            "non-convex\n",
            "neural\n",
            "network\n",
            "training\n",
            ":\n",
            "Transportation\n",
            "map\n",
            "estimation\n",
            "by\n",
            "infinite\n",
            "dimensional\n",
            "Langevin\n",
            "dynamics\n",
            "Online\n",
            "Bayesian\n",
            "Goal\n",
            "Inference\n",
            "for\n",
            "Boundedly\n",
            "Rational\n",
            "Planning\n",
            "Agents\n",
            "BayReL\n",
            ":\n",
            "Bayesian\n",
            "Relational\n",
            "Learning\n",
            "for\n",
            "Multi-omics\n",
            "Data\n",
            "Integration\n",
            "Weakly\n",
            "Supervised\n",
            "Deep\n",
            "Functional\n",
            "Maps\n",
            "for\n",
            "Shape\n",
            "Matching\n",
            "Domain\n",
            "Adaptation\n",
            "with\n",
            "Conditional\n",
            "Distribution\n",
            "Matching\n",
            "and\n",
            "Generalized\n",
            "Label\n",
            "Shift\n",
            "Rethinking\n",
            "the\n",
            "Value\n",
            "of\n",
            "Labels\n",
            "for\n",
            "Improving\n",
            "Class-Imbalanced\n",
            "Learning\n",
            "Provably\n",
            "Robust\n",
            "Metric\n",
            "Learning\n",
            "Iterative\n",
            "Deep\n",
            "Graph\n",
            "Learning\n",
            "for\n",
            "Graph\n",
            "Neural\n",
            "Networks\n",
            ":\n",
            "Better\n",
            "and\n",
            "Robust\n",
            "Node\n",
            "Embeddings\n",
            "COPT\n",
            ":\n",
            "Coordinated\n",
            "Optimal\n",
            "Transport\n",
            "on\n",
            "Graphs\n",
            "No\n",
            "Subclass\n",
            "Left\n",
            "Behind\n",
            ":\n",
            "Fine-Grained\n",
            "Robustness\n",
            "in\n",
            "Coarse-Grained\n",
            "Classification\n",
            "Problems\n",
            "Model\n",
            "Rubik\n",
            "’\n",
            "s\n",
            "Cube\n",
            ":\n",
            "Twisting\n",
            "Resolution\n",
            ",\n",
            "Depth\n",
            "and\n",
            "Width\n",
            "for\n",
            "TinyNets\n",
            "Self-Adaptive\n",
            "Training\n",
            ":\n",
            "beyond\n",
            "Empirical\n",
            "Risk\n",
            "Minimization\n",
            "Effective\n",
            "Dimension\n",
            "Adaptive\n",
            "Sketching\n",
            "Methods\n",
            "for\n",
            "Faster\n",
            "Regularized\n",
            "Least-Squares\n",
            "Optimization\n",
            "Near-Optimal\n",
            "Comparison\n",
            "Based\n",
            "Clustering\n",
            "Multi-Task\n",
            "Temporal\n",
            "Shift\n",
            "Attention\n",
            "Networks\n",
            "for\n",
            "On-Device\n",
            "Contactless\n",
            "Vitals\n",
            "Measurement\n",
            "A\n",
            "new\n",
            "convergent\n",
            "variant\n",
            "of\n",
            "Q-learning\n",
            "with\n",
            "linear\n",
            "function\n",
            "approximation\n",
            "TaylorGAN\n",
            ":\n",
            "Neighbor-Augmented\n",
            "Policy\n",
            "Update\n",
            "Towards\n",
            "Sample-Efficient\n",
            "Natural\n",
            "Language\n",
            "Generation\n",
            "Neural\n",
            "Networks\n",
            "with\n",
            "Small\n",
            "Weights\n",
            "and\n",
            "Depth-Separation\n",
            "Barriers\n",
            "Untangling\n",
            "tradeoffs\n",
            "between\n",
            "recurrence\n",
            "and\n",
            "self-attention\n",
            "in\n",
            "artificial\n",
            "neural\n",
            "networks\n",
            "Dual-Free\n",
            "Stochastic\n",
            "Decentralized\n",
            "Optimization\n",
            "with\n",
            "Variance\n",
            "Reduction\n",
            "Online\n",
            "Learning\n",
            "in\n",
            "Contextual\n",
            "Bandits\n",
            "using\n",
            "Gated\n",
            "Linear\n",
            "Networks\n",
            "Throughput-Optimal\n",
            "Topology\n",
            "Design\n",
            "for\n",
            "Cross-Silo\n",
            "Federated\n",
            "Learning\n",
            "Quantized\n",
            "Variational\n",
            "Inference\n",
            "Asymptotically\n",
            "Optimal\n",
            "Exact\n",
            "Minibatch\n",
            "Metropolis-Hastings\n",
            "Learning\n",
            "Search\n",
            "Space\n",
            "Partition\n",
            "for\n",
            "Black-box\n",
            "Optimization\n",
            "using\n",
            "Monte\n",
            "Carlo\n",
            "Tree\n",
            "Search\n",
            "Feature\n",
            "Shift\n",
            "Detection\n",
            ":\n",
            "Localizing\n",
            "Which\n",
            "Features\n",
            "Have\n",
            "Shifted\n",
            "via\n",
            "Conditional\n",
            "Distribution\n",
            "Tests\n",
            "Unifying\n",
            "Activation-\n",
            "and\n",
            "Timing-based\n",
            "Learning\n",
            "Rules\n",
            "for\n",
            "Spiking\n",
            "Neural\n",
            "Networks\n",
            "Space-Time\n",
            "Correspondence\n",
            "as\n",
            "a\n",
            "Contrastive\n",
            "Random\n",
            "Walk\n",
            "The\n",
            "Flajolet-Martin\n",
            "Sketch\n",
            "Itself\n",
            "Preserves\n",
            "Differential\n",
            "Privacy\n",
            ":\n",
            "Private\n",
            "Counting\n",
            "with\n",
            "Minimal\n",
            "Space\n",
            "Exponential\n",
            "ergodicity\n",
            "of\n",
            "mirror-Langevin\n",
            "diffusions\n",
            "An\n",
            "Efficient\n",
            "Framework\n",
            "for\n",
            "Clustered\n",
            "Federated\n",
            "Learning\n",
            "Autoencoders\n",
            "that\n",
            "do\n",
            "n't\n",
            "overfit\n",
            "towards\n",
            "the\n",
            "Identity\n",
            "Polynomial-Time\n",
            "Computation\n",
            "of\n",
            "Optimal\n",
            "Correlated\n",
            "Equilibria\n",
            "in\n",
            "Two-Player\n",
            "Extensive-Form\n",
            "Games\n",
            "with\n",
            "Public\n",
            "Chance\n",
            "Moves\n",
            "and\n",
            "Beyond\n",
            "Parameterized\n",
            "Explainer\n",
            "for\n",
            "Graph\n",
            "Neural\n",
            "Network\n",
            "Recursive\n",
            "Inference\n",
            "for\n",
            "Variational\n",
            "Autoencoders\n",
            "Flexible\n",
            "mean\n",
            "field\n",
            "variational\n",
            "inference\n",
            "using\n",
            "mixtures\n",
            "of\n",
            "non-overlapping\n",
            "exponential\n",
            "families\n",
            "HYDRA\n",
            ":\n",
            "Pruning\n",
            "Adversarially\n",
            "Robust\n",
            "Neural\n",
            "Networks\n",
            "NVAE\n",
            ":\n",
            "A\n",
            "Deep\n",
            "Hierarchical\n",
            "Variational\n",
            "Autoencoder\n",
            "Can\n",
            "Temporal-Diﬀerence\n",
            "and\n",
            "Q-Learning\n",
            "Learn\n",
            "Representation\n",
            "?\n",
            "A\n",
            "Mean-Field\n",
            "Theory\n",
            "What\n",
            "Do\n",
            "Neural\n",
            "Networks\n",
            "Learn\n",
            "When\n",
            "Trained\n",
            "With\n",
            "Random\n",
            "Labels\n",
            "?\n",
            "Counterfactual\n",
            "Prediction\n",
            "for\n",
            "Bundle\n",
            "Treatment\n",
            "Beta\n",
            "Embeddings\n",
            "for\n",
            "Multi-Hop\n",
            "Logical\n",
            "Reasoning\n",
            "in\n",
            "Knowledge\n",
            "Graphs\n",
            "Learning\n",
            "Disentangled\n",
            "Representations\n",
            "and\n",
            "Group\n",
            "Structure\n",
            "of\n",
            "Dynamical\n",
            "Environments\n",
            "Learning\n",
            "Linear\n",
            "Programs\n",
            "from\n",
            "Optimal\n",
            "Decisions\n",
            "Wisdom\n",
            "of\n",
            "the\n",
            "Ensemble\n",
            ":\n",
            "Improving\n",
            "Consistency\n",
            "of\n",
            "Deep\n",
            "Learning\n",
            "Models\n",
            "Universal\n",
            "Function\n",
            "Approximation\n",
            "on\n",
            "Graphs\n",
            "Accelerating\n",
            "Reinforcement\n",
            "Learning\n",
            "through\n",
            "GPU\n",
            "Atari\n",
            "Emulation\n",
            "EvolveGraph\n",
            ":\n",
            "Multi-Agent\n",
            "Trajectory\n",
            "Prediction\n",
            "with\n",
            "Dynamic\n",
            "Relational\n",
            "Reasoning\n",
            "Comparator-Adaptive\n",
            "Convex\n",
            "Bandits\n",
            "Model-based\n",
            "Reinforcement\n",
            "Learning\n",
            "for\n",
            "Semi-Markov\n",
            "Decision\n",
            "Processes\n",
            "with\n",
            "Neural\n",
            "ODEs\n",
            "The\n",
            "Adaptive\n",
            "Complexity\n",
            "of\n",
            "Maximizing\n",
            "a\n",
            "Gross\n",
            "Substitutes\n",
            "Valuation\n",
            "A\n",
            "Robust\n",
            "Functional\n",
            "EM\n",
            "Algorithm\n",
            "for\n",
            "Incomplete\n",
            "Panel\n",
            "Count\n",
            "Data\n",
            "Graph\n",
            "Stochastic\n",
            "Neural\n",
            "Networks\n",
            "for\n",
            "Semi-supervised\n",
            "Learning\n",
            "Compositional\n",
            "Zero-Shot\n",
            "Learning\n",
            "via\n",
            "Fine-Grained\n",
            "Dense\n",
            "Feature\n",
            "Composition\n",
            "A\n",
            "Benchmark\n",
            "for\n",
            "Systematic\n",
            "Generalization\n",
            "in\n",
            "Grounded\n",
            "Language\n",
            "Understanding\n",
            "Weston-Watkins\n",
            "Hinge\n",
            "Loss\n",
            "and\n",
            "Ordered\n",
            "Partitions\n",
            "Reinforcement\n",
            "Learning\n",
            "with\n",
            "Augmented\n",
            "Data\n",
            "Towards\n",
            "Minimax\n",
            "Optimal\n",
            "Reinforcement\n",
            "Learning\n",
            "in\n",
            "Factored\n",
            "Markov\n",
            "Decision\n",
            "Processes\n",
            "Graduated\n",
            "Assignment\n",
            "for\n",
            "Joint\n",
            "Multi-Graph\n",
            "Matching\n",
            "and\n",
            "Clustering\n",
            "with\n",
            "Application\n",
            "to\n",
            "Unsupervised\n",
            "Graph\n",
            "Matching\n",
            "Network\n",
            "Learning\n",
            "Estimating\n",
            "Training\n",
            "Data\n",
            "Influence\n",
            "by\n",
            "Tracing\n",
            "Gradient\n",
            "Descent\n",
            "Joint\n",
            "Policy\n",
            "Search\n",
            "for\n",
            "Multi-agent\n",
            "Collaboration\n",
            "with\n",
            "Imperfect\n",
            "Information\n",
            "Adversarial\n",
            "Bandits\n",
            "with\n",
            "Corruptions\n",
            ":\n",
            "Regret\n",
            "Lower\n",
            "Bound\n",
            "and\n",
            "No-regret\n",
            "Algorithm\n",
            "Beta\n",
            "R-CNN\n",
            ":\n",
            "Looking\n",
            "into\n",
            "Pedestrian\n",
            "Detection\n",
            "from\n",
            "Another\n",
            "Perspective\n",
            "Batch\n",
            "Normalization\n",
            "Biases\n",
            "Residual\n",
            "Blocks\n",
            "Towards\n",
            "the\n",
            "Identity\n",
            "Function\n",
            "in\n",
            "Deep\n",
            "Networks\n",
            "Learning\n",
            "Retrospective\n",
            "Knowledge\n",
            "with\n",
            "Reverse\n",
            "Reinforcement\n",
            "Learning\n",
            "Dialog\n",
            "without\n",
            "Dialog\n",
            "Data\n",
            ":\n",
            "Learning\n",
            "Visual\n",
            "Dialog\n",
            "Agents\n",
            "from\n",
            "VQA\n",
            "Data\n",
            "GCOMB\n",
            ":\n",
            "Learning\n",
            "Budget-constrained\n",
            "Combinatorial\n",
            "Algorithms\n",
            "over\n",
            "Billion-sized\n",
            "Graphs\n",
            "A\n",
            "General\n",
            "Large\n",
            "Neighborhood\n",
            "Search\n",
            "Framework\n",
            "for\n",
            "Solving\n",
            "Integer\n",
            "Linear\n",
            "Programs\n",
            "A\n",
            "Theoretical\n",
            "Framework\n",
            "for\n",
            "Target\n",
            "Propagation\n",
            "OrganITE\n",
            ":\n",
            "Optimal\n",
            "transplant\n",
            "donor\n",
            "organ\n",
            "offering\n",
            "using\n",
            "an\n",
            "individual\n",
            "treatment\n",
            "effect\n",
            "The\n",
            "Complete\n",
            "Lasso\n",
            "Tradeoff\n",
            "Diagram\n",
            "On\n",
            "the\n",
            "universality\n",
            "of\n",
            "deep\n",
            "learning\n",
            "Regression\n",
            "with\n",
            "reject\n",
            "option\n",
            "and\n",
            "application\n",
            "to\n",
            "kNN\n",
            "The\n",
            "Primal-Dual\n",
            "method\n",
            "for\n",
            "Learning\n",
            "Augmented\n",
            "Algorithms\n",
            "FLAMBE\n",
            ":\n",
            "Structural\n",
            "Complexity\n",
            "and\n",
            "Representation\n",
            "Learning\n",
            "of\n",
            "Low\n",
            "Rank\n",
            "MDPs\n",
            "A\n",
            "Class\n",
            "of\n",
            "Algorithms\n",
            "for\n",
            "General\n",
            "Instrumental\n",
            "Variable\n",
            "Models\n",
            "Black-Box\n",
            "Ripper\n",
            ":\n",
            "Copying\n",
            "black-box\n",
            "models\n",
            "using\n",
            "generative\n",
            "evolutionary\n",
            "algorithms\n",
            "Bayesian\n",
            "Optimization\n",
            "of\n",
            "Risk\n",
            "Measures\n",
            "TorsionNet\n",
            ":\n",
            "A\n",
            "Reinforcement\n",
            "Learning\n",
            "Approach\n",
            "to\n",
            "Sequential\n",
            "Conformer\n",
            "Search\n",
            "GRAF\n",
            ":\n",
            "Generative\n",
            "Radiance\n",
            "Fields\n",
            "for\n",
            "3D-Aware\n",
            "Image\n",
            "Synthesis\n",
            "PIE-NET\n",
            ":\n",
            "Parametric\n",
            "Inference\n",
            "of\n",
            "Point\n",
            "Cloud\n",
            "Edges\n",
            "A\n",
            "Simple\n",
            "Language\n",
            "Model\n",
            "for\n",
            "Task-Oriented\n",
            "Dialogue\n",
            "A\n",
            "Continuous-Time\n",
            "Mirror\n",
            "Descent\n",
            "Approach\n",
            "to\n",
            "Sparse\n",
            "Phase\n",
            "Retrieval\n",
            "Confidence\n",
            "sequences\n",
            "for\n",
            "sampling\n",
            "without\n",
            "replacement\n",
            "A\n",
            "mean-field\n",
            "analysis\n",
            "of\n",
            "two-player\n",
            "zero-sum\n",
            "games\n",
            "Leap-Of-Thought\n",
            ":\n",
            "Teaching\n",
            "Pre-Trained\n",
            "Models\n",
            "to\n",
            "Systematically\n",
            "Reason\n",
            "Over\n",
            "Implicit\n",
            "Knowledge\n",
            "Pipeline\n",
            "PSRO\n",
            ":\n",
            "A\n",
            "Scalable\n",
            "Approach\n",
            "for\n",
            "Finding\n",
            "Approximate\n",
            "Nash\n",
            "Equilibria\n",
            "in\n",
            "Large\n",
            "Games\n",
            "Improving\n",
            "Sparse\n",
            "Vector\n",
            "Technique\n",
            "with\n",
            "Renyi\n",
            "Differential\n",
            "Privacy\n",
            "Latent\n",
            "Template\n",
            "Induction\n",
            "with\n",
            "Gumbel-CRFs\n",
            "Instance\n",
            "Based\n",
            "Approximations\n",
            "to\n",
            "Profile\n",
            "Maximum\n",
            "Likelihood\n",
            "Factorizable\n",
            "Graph\n",
            "Convolutional\n",
            "Networks\n",
            "Guided\n",
            "Adversarial\n",
            "Attack\n",
            "for\n",
            "Evaluating\n",
            "and\n",
            "Enhancing\n",
            "Adversarial\n",
            "Defenses\n",
            "A\n",
            "Study\n",
            "on\n",
            "Encodings\n",
            "for\n",
            "Neural\n",
            "Architecture\n",
            "Search\n",
            "Noise2Same\n",
            ":\n",
            "Optimizing\n",
            "A\n",
            "Self-Supervised\n",
            "Bound\n",
            "for\n",
            "Image\n",
            "Denoising\n",
            "Early-Learning\n",
            "Regularization\n",
            "Prevents\n",
            "Memorization\n",
            "of\n",
            "Noisy\n",
            "Labels\n",
            "LAPAR\n",
            ":\n",
            "Linearly-Assembled\n",
            "Pixel-Adaptive\n",
            "Regression\n",
            "Network\n",
            "for\n",
            "Single\n",
            "Image\n",
            "Super-resolution\n",
            "and\n",
            "Beyond\n",
            "Learning\n",
            "Parities\n",
            "with\n",
            "Neural\n",
            "Networks\n",
            "Consistent\n",
            "Plug-in\n",
            "Classifiers\n",
            "for\n",
            "Complex\n",
            "Objectives\n",
            "and\n",
            "Constraints\n",
            "Movement\n",
            "Pruning\n",
            ":\n",
            "Adaptive\n",
            "Sparsity\n",
            "by\n",
            "Fine-Tuning\n",
            "Sanity-Checking\n",
            "Pruning\n",
            "Methods\n",
            ":\n",
            "Random\n",
            "Tickets\n",
            "can\n",
            "Win\n",
            "the\n",
            "Jackpot\n",
            "Online\n",
            "Matrix\n",
            "Completion\n",
            "with\n",
            "Side\n",
            "Information\n",
            "Position-based\n",
            "Scaled\n",
            "Gradient\n",
            "for\n",
            "Model\n",
            "Quantization\n",
            "and\n",
            "Pruning\n",
            "Online\n",
            "Learning\n",
            "with\n",
            "Primary\n",
            "and\n",
            "Secondary\n",
            "Losses\n",
            "Graph\n",
            "Information\n",
            "Bottleneck\n",
            "The\n",
            "Complexity\n",
            "of\n",
            "Adversarially\n",
            "Robust\n",
            "Proper\n",
            "Learning\n",
            "of\n",
            "Halfspaces\n",
            "with\n",
            "Agnostic\n",
            "Noise\n",
            "Adaptive\n",
            "Online\n",
            "Estimation\n",
            "of\n",
            "Piecewise\n",
            "Polynomial\n",
            "Trends\n",
            "RNNPool\n",
            ":\n",
            "Efficient\n",
            "Non-linear\n",
            "Pooling\n",
            "for\n",
            "RAM\n",
            "Constrained\n",
            "Inference\n",
            "Agnostic\n",
            "Learning\n",
            "with\n",
            "Multiple\n",
            "Objectives\n",
            "3D\n",
            "Multi-bodies\n",
            ":\n",
            "Fitting\n",
            "Sets\n",
            "of\n",
            "Plausible\n",
            "3D\n",
            "Human\n",
            "Models\n",
            "to\n",
            "Ambiguous\n",
            "Image\n",
            "Data\n",
            "Auto-Panoptic\n",
            ":\n",
            "Cooperative\n",
            "Multi-Component\n",
            "Architecture\n",
            "Search\n",
            "for\n",
            "Panoptic\n",
            "Segmentation\n",
            "Differentiable\n",
            "Top-k\n",
            "with\n",
            "Optimal\n",
            "Transport\n",
            "Information-theoretic\n",
            "Task\n",
            "Selection\n",
            "for\n",
            "Meta-Reinforcement\n",
            "Learning\n",
            "A\n",
            "Limitation\n",
            "of\n",
            "the\n",
            "PAC-Bayes\n",
            "Framework\n",
            "On\n",
            "Completeness-aware\n",
            "Concept-Based\n",
            "Explanations\n",
            "in\n",
            "Deep\n",
            "Neural\n",
            "Networks\n",
            "Stochastic\n",
            "Recursive\n",
            "Gradient\n",
            "Descent\n",
            "Ascent\n",
            "for\n",
            "Stochastic\n",
            "Nonconvex-Strongly-Concave\n",
            "Minimax\n",
            "Problems\n",
            "Why\n",
            "Normalizing\n",
            "Flows\n",
            "Fail\n",
            "to\n",
            "Detect\n",
            "Out-of-Distribution\n",
            "Data\n",
            "Explaining\n",
            "Naive\n",
            "Bayes\n",
            "and\n",
            "Other\n",
            "Linear\n",
            "Classifiers\n",
            "with\n",
            "Polynomial\n",
            "Time\n",
            "and\n",
            "Delay\n",
            "Unsupervised\n",
            "Translation\n",
            "of\n",
            "Programming\n",
            "Languages\n",
            "Adversarial\n",
            "Style\n",
            "Mining\n",
            "for\n",
            "One-Shot\n",
            "Unsupervised\n",
            "Domain\n",
            "Adaptation\n",
            "Optimally\n",
            "Deceiving\n",
            "a\n",
            "Learning\n",
            "Leader\n",
            "in\n",
            "Stackelberg\n",
            "Games\n",
            "Online\n",
            "Optimization\n",
            "with\n",
            "Memory\n",
            "and\n",
            "Competitive\n",
            "Control\n",
            "IDEAL\n",
            ":\n",
            "Inexact\n",
            "DEcentralized\n",
            "Accelerated\n",
            "Augmented\n",
            "Lagrangian\n",
            "Method\n",
            "Evolving\n",
            "Graphical\n",
            "Planner\n",
            ":\n",
            "Contextual\n",
            "Global\n",
            "Planning\n",
            "for\n",
            "Vision-and-Language\n",
            "Navigation\n",
            "Learning\n",
            "from\n",
            "Failure\n",
            ":\n",
            "De-biasing\n",
            "Classifier\n",
            "from\n",
            "Biased\n",
            "Classifier\n",
            "Likelihood\n",
            "Regret\n",
            ":\n",
            "An\n",
            "Out-of-Distribution\n",
            "Detection\n",
            "Score\n",
            "For\n",
            "Variational\n",
            "Auto-encoder\n",
            "Deep\n",
            "Diffusion-Invariant\n",
            "Wasserstein\n",
            "Distributional\n",
            "Classification\n",
            "Finding\n",
            "All\n",
            "$\n",
            "\\epsilon\n",
            "$\n",
            "-Good\n",
            "Arms\n",
            "in\n",
            "Stochastic\n",
            "Bandits\n",
            "Meta-Learning\n",
            "through\n",
            "Hebbian\n",
            "Plasticity\n",
            "in\n",
            "Random\n",
            "Networks\n",
            "A\n",
            "Computational\n",
            "Separation\n",
            "between\n",
            "Private\n",
            "Learning\n",
            "and\n",
            "Online\n",
            "Learning\n",
            "Top-KAST\n",
            ":\n",
            "Top-K\n",
            "Always\n",
            "Sparse\n",
            "Training\n",
            "Meta-Learning\n",
            "with\n",
            "Adaptive\n",
            "Hyperparameters\n",
            "Tight\n",
            "last-iterate\n",
            "convergence\n",
            "rates\n",
            "for\n",
            "no-regret\n",
            "learning\n",
            "in\n",
            "multi-player\n",
            "games\n",
            "Curvature\n",
            "Regularization\n",
            "to\n",
            "Prevent\n",
            "Distortion\n",
            "in\n",
            "Graph\n",
            "Embedding\n",
            "Perturbing\n",
            "Across\n",
            "the\n",
            "Feature\n",
            "Hierarchy\n",
            "to\n",
            "Improve\n",
            "Standard\n",
            "and\n",
            "Strict\n",
            "Blackbox\n",
            "Attack\n",
            "Transferability\n",
            "Statistical\n",
            "and\n",
            "Topological\n",
            "Properties\n",
            "of\n",
            "Sliced\n",
            "Probability\n",
            "Divergences\n",
            "Probabilistic\n",
            "Active\n",
            "Meta-Learning\n",
            "Knowledge\n",
            "Distillation\n",
            "in\n",
            "Wide\n",
            "Neural\n",
            "Networks\n",
            ":\n",
            "Risk\n",
            "Bound\n",
            ",\n",
            "Data\n",
            "Efficiency\n",
            "and\n",
            "Imperfect\n",
            "Teacher\n",
            "Adversarial\n",
            "Attacks\n",
            "on\n",
            "Deep\n",
            "Graph\n",
            "Matching\n",
            "The\n",
            "Generalization-Stability\n",
            "Tradeoff\n",
            "In\n",
            "Neural\n",
            "Network\n",
            "Pruning\n",
            "Gradient-EM\n",
            "Bayesian\n",
            "Meta-Learning\n",
            "Logarithmic\n",
            "Regret\n",
            "Bound\n",
            "in\n",
            "Partially\n",
            "Observable\n",
            "Linear\n",
            "Dynamical\n",
            "Systems\n",
            "Linearly\n",
            "Converging\n",
            "Error\n",
            "Compensated\n",
            "SGD\n",
            "Canonical\n",
            "3D\n",
            "Deformer\n",
            "Maps\n",
            ":\n",
            "Unifying\n",
            "parametric\n",
            "and\n",
            "non-parametric\n",
            "methods\n",
            "for\n",
            "dense\n",
            "weakly-supervised\n",
            "category\n",
            "reconstruction\n",
            "A\n",
            "Self-Tuning\n",
            "Actor-Critic\n",
            "Algorithm\n",
            "The\n",
            "Cone\n",
            "of\n",
            "Silence\n",
            ":\n",
            "Speech\n",
            "Separation\n",
            "by\n",
            "Localization\n",
            "High-Dimensional\n",
            "Bayesian\n",
            "Optimization\n",
            "via\n",
            "Nested\n",
            "Riemannian\n",
            "Manifolds\n",
            "Train-by-Reconnect\n",
            ":\n",
            "Decoupling\n",
            "Locations\n",
            "of\n",
            "Weights\n",
            "from\n",
            "Their\n",
            "Values\n",
            "Learning\n",
            "discrete\n",
            "distributions\n",
            ":\n",
            "user\n",
            "vs\n",
            "item-level\n",
            "privacy\n",
            "Matrix\n",
            "Completion\n",
            "with\n",
            "Quantified\n",
            "Uncertainty\n",
            "through\n",
            "Low\n",
            "Rank\n",
            "Gaussian\n",
            "Copula\n",
            "Sparse\n",
            "and\n",
            "Continuous\n",
            "Attention\n",
            "Mechanisms\n",
            "Generalized\n",
            "Focal\n",
            "Loss\n",
            ":\n",
            "Learning\n",
            "Qualified\n",
            "and\n",
            "Distributed\n",
            "Bounding\n",
            "Boxes\n",
            "for\n",
            "Dense\n",
            "Object\n",
            "Detection\n",
            "Learning\n",
            "by\n",
            "Minimizing\n",
            "the\n",
            "Sum\n",
            "of\n",
            "Ranked\n",
            "Range\n",
            "Robust\n",
            "Deep\n",
            "Reinforcement\n",
            "Learning\n",
            "against\n",
            "Adversarial\n",
            "Perturbations\n",
            "on\n",
            "State\n",
            "Observations\n",
            "Understanding\n",
            "Anomaly\n",
            "Detection\n",
            "with\n",
            "Deep\n",
            "Invertible\n",
            "Networks\n",
            "through\n",
            "Hierarchies\n",
            "of\n",
            "Distributions\n",
            "and\n",
            "Features\n",
            "Fair\n",
            "Hierarchical\n",
            "Clustering\n",
            "Self-training\n",
            "Avoids\n",
            "Using\n",
            "Spurious\n",
            "Features\n",
            "Under\n",
            "Domain\n",
            "Shift\n",
            "Improving\n",
            "Online\n",
            "Rent-or-Buy\n",
            "Algorithms\n",
            "with\n",
            "Sequential\n",
            "Decision\n",
            "Making\n",
            "and\n",
            "ML\n",
            "Predictions\n",
            "CircleGAN\n",
            ":\n",
            "Generative\n",
            "Adversarial\n",
            "Learning\n",
            "across\n",
            "Spherical\n",
            "Circles\n",
            "WOR\n",
            "and\n",
            "$\n",
            "p\n",
            "$\n",
            "'s\n",
            ":\n",
            "Sketches\n",
            "for\n",
            "$\n",
            "\\ell_p\n",
            "$\n",
            "-Sampling\n",
            "Without\n",
            "Replacement\n",
            "Hypersolvers\n",
            ":\n",
            "Toward\n",
            "Fast\n",
            "Continuous-Depth\n",
            "Models\n",
            "Log-Likelihood\n",
            "Ratio\n",
            "Minimizing\n",
            "Flows\n",
            ":\n",
            "Towards\n",
            "Robust\n",
            "and\n",
            "Quantifiable\n",
            "Neural\n",
            "Distribution\n",
            "Alignment\n",
            "Escaping\n",
            "the\n",
            "Gravitational\n",
            "Pull\n",
            "of\n",
            "Softmax\n",
            "Regret\n",
            "in\n",
            "Online\n",
            "Recommendation\n",
            "Systems\n",
            "On\n",
            "Convergence\n",
            "and\n",
            "Generalization\n",
            "of\n",
            "Dropout\n",
            "Training\n",
            "Second\n",
            "Order\n",
            "Optimality\n",
            "in\n",
            "Decentralized\n",
            "Non-Convex\n",
            "Optimization\n",
            "via\n",
            "Perturbed\n",
            "Gradient\n",
            "Tracking\n",
            "Implicit\n",
            "Regularization\n",
            "in\n",
            "Deep\n",
            "Learning\n",
            "May\n",
            "Not\n",
            "Be\n",
            "Explainable\n",
            "by\n",
            "Norms\n",
            "POMO\n",
            ":\n",
            "Policy\n",
            "Optimization\n",
            "with\n",
            "Multiple\n",
            "Optima\n",
            "for\n",
            "Reinforcement\n",
            "Learning\n",
            "Uncertainty-aware\n",
            "Self-training\n",
            "for\n",
            "Few-shot\n",
            "Text\n",
            "Classification\n",
            "Learning\n",
            "to\n",
            "Learn\n",
            "with\n",
            "Feedback\n",
            "and\n",
            "Local\n",
            "Plasticity\n",
            "Every\n",
            "View\n",
            "Counts\n",
            ":\n",
            "Cross-View\n",
            "Consistency\n",
            "in\n",
            "3D\n",
            "Object\n",
            "Detection\n",
            "with\n",
            "Hybrid-Cylindrical-Spherical\n",
            "Voxelization\n",
            "Sharper\n",
            "Generalization\n",
            "Bounds\n",
            "for\n",
            "Pairwise\n",
            "Learning\n",
            "A\n",
            "Measure-Theoretic\n",
            "Approach\n",
            "to\n",
            "Kernel\n",
            "Conditional\n",
            "Mean\n",
            "Embeddings\n",
            "Quantifying\n",
            "the\n",
            "Empirical\n",
            "Wasserstein\n",
            "Distance\n",
            "to\n",
            "a\n",
            "Set\n",
            "of\n",
            "Measures\n",
            ":\n",
            "Beating\n",
            "the\n",
            "Curse\n",
            "of\n",
            "Dimensionality\n",
            "Bootstrap\n",
            "Your\n",
            "Own\n",
            "Latent\n",
            "-\n",
            "A\n",
            "New\n",
            "Approach\n",
            "to\n",
            "Self-Supervised\n",
            "Learning\n",
            "Towards\n",
            "Theoretically\n",
            "Understanding\n",
            "Why\n",
            "Sgd\n",
            "Generalizes\n",
            "Better\n",
            "Than\n",
            "Adam\n",
            "in\n",
            "Deep\n",
            "Learning\n",
            "RSKDD-Net\n",
            ":\n",
            "Random\n",
            "Sample-based\n",
            "Keypoint\n",
            "Detector\n",
            "and\n",
            "Descriptor\n",
            "Efficient\n",
            "Clustering\n",
            "for\n",
            "Stretched\n",
            "Mixtures\n",
            ":\n",
            "Landscape\n",
            "and\n",
            "Optimality\n",
            "A\n",
            "Group-Theoretic\n",
            "Framework\n",
            "for\n",
            "Data\n",
            "Augmentation\n",
            "The\n",
            "Statistical\n",
            "Cost\n",
            "of\n",
            "Robust\n",
            "Kernel\n",
            "Hyperparameter\n",
            "Turning\n",
            "How\n",
            "does\n",
            "Weight\n",
            "Correlation\n",
            "Affect\n",
            "Generalisation\n",
            "Ability\n",
            "of\n",
            "Deep\n",
            "Neural\n",
            "Networks\n",
            "?\n",
            "ContraGAN\n",
            ":\n",
            "Contrastive\n",
            "Learning\n",
            "for\n",
            "Conditional\n",
            "Image\n",
            "Generation\n",
            "On\n",
            "the\n",
            "distance\n",
            "between\n",
            "two\n",
            "neural\n",
            "networks\n",
            "and\n",
            "the\n",
            "stability\n",
            "of\n",
            "learning\n",
            "A\n",
            "Topological\n",
            "Filter\n",
            "for\n",
            "Learning\n",
            "with\n",
            "Label\n",
            "Noise\n",
            "Personalized\n",
            "Federated\n",
            "Learning\n",
            "with\n",
            "Moreau\n",
            "Envelopes\n",
            "Avoiding\n",
            "Side\n",
            "Effects\n",
            "in\n",
            "Complex\n",
            "Environments\n",
            "No-regret\n",
            "Learning\n",
            "in\n",
            "Price\n",
            "Competitions\n",
            "under\n",
            "Consumer\n",
            "Reference\n",
            "Effects\n",
            "Geometric\n",
            "Dataset\n",
            "Distances\n",
            "via\n",
            "Optimal\n",
            "Transport\n",
            "Task-Agnostic\n",
            "Amortized\n",
            "Inference\n",
            "of\n",
            "Gaussian\n",
            "Process\n",
            "Hyperparameters\n",
            "A\n",
            "novel\n",
            "variational\n",
            "form\n",
            "of\n",
            "the\n",
            "Schatten-\n",
            "$\n",
            "p\n",
            "$\n",
            "quasi-norm\n",
            "Energy-based\n",
            "Out-of-distribution\n",
            "Detection\n",
            "On\n",
            "the\n",
            "Loss\n",
            "Landscape\n",
            "of\n",
            "Adversarial\n",
            "Training\n",
            ":\n",
            "Identifying\n",
            "Challenges\n",
            "and\n",
            "How\n",
            "to\n",
            "Overcome\n",
            "Them\n",
            "User-Dependent\n",
            "Neural\n",
            "Sequence\n",
            "Models\n",
            "for\n",
            "Continuous-Time\n",
            "Event\n",
            "Data\n",
            "Active\n",
            "Structure\n",
            "Learning\n",
            "of\n",
            "Causal\n",
            "DAGs\n",
            "via\n",
            "Directed\n",
            "Clique\n",
            "Trees\n",
            "Convergence\n",
            "and\n",
            "Stability\n",
            "of\n",
            "Graph\n",
            "Convolutional\n",
            "Networks\n",
            "on\n",
            "Large\n",
            "Random\n",
            "Graphs\n",
            "BoTorch\n",
            ":\n",
            "A\n",
            "Framework\n",
            "for\n",
            "Efficient\n",
            "Monte-Carlo\n",
            "Bayesian\n",
            "Optimization\n",
            "Reconsidering\n",
            "Generative\n",
            "Objectives\n",
            "For\n",
            "Counterfactual\n",
            "Reasoning\n",
            "Robust\n",
            "Federated\n",
            "Learning\n",
            ":\n",
            "The\n",
            "Case\n",
            "of\n",
            "Affine\n",
            "Distribution\n",
            "Shifts\n",
            "Quantile\n",
            "Propagation\n",
            "for\n",
            "Wasserstein-Approximate\n",
            "Gaussian\n",
            "Processes\n",
            "Generating\n",
            "Adjacency-Constrained\n",
            "Subgoals\n",
            "in\n",
            "Hierarchical\n",
            "Reinforcement\n",
            "Learning\n",
            "High-contrast\n",
            "“\n",
            "gaudy\n",
            "”\n",
            "images\n",
            "improve\n",
            "the\n",
            "training\n",
            "of\n",
            "deep\n",
            "neural\n",
            "network\n",
            "models\n",
            "of\n",
            "visual\n",
            "cortex\n",
            "Duality-Induced\n",
            "Regularizer\n",
            "for\n",
            "Tensor\n",
            "Factorization\n",
            "Based\n",
            "Knowledge\n",
            "Graph\n",
            "Completion\n",
            "Distributed\n",
            "Training\n",
            "with\n",
            "Heterogeneous\n",
            "Data\n",
            ":\n",
            "Bridging\n",
            "Median-\n",
            "and\n",
            "Mean-Based\n",
            "Algorithms\n",
            "H-Mem\n",
            ":\n",
            "Harnessing\n",
            "synaptic\n",
            "plasticity\n",
            "with\n",
            "Hebbian\n",
            "Memory\n",
            "Networks\n",
            "Neural\n",
            "Unsigned\n",
            "Distance\n",
            "Fields\n",
            "for\n",
            "Implicit\n",
            "Function\n",
            "Learning\n",
            "Curriculum\n",
            "By\n",
            "Smoothing\n",
            "Fast\n",
            "Transformers\n",
            "with\n",
            "Clustered\n",
            "Attention\n",
            "The\n",
            "Convex\n",
            "Relaxation\n",
            "Barrier\n",
            ",\n",
            "Revisited\n",
            ":\n",
            "Tightened\n",
            "Single-Neuron\n",
            "Relaxations\n",
            "for\n",
            "Neural\n",
            "Network\n",
            "Verification\n",
            "Strongly\n",
            "Incremental\n",
            "Constituency\n",
            "Parsing\n",
            "with\n",
            "Graph\n",
            "Neural\n",
            "Networks\n",
            "AOT\n",
            ":\n",
            "Appearance\n",
            "Optimal\n",
            "Transport\n",
            "Based\n",
            "Identity\n",
            "Swapping\n",
            "for\n",
            "Forgery\n",
            "Detection\n",
            "Uncertainty-Aware\n",
            "Learning\n",
            "for\n",
            "Zero-Shot\n",
            "Semantic\n",
            "Segmentation\n",
            "Delta-STN\n",
            ":\n",
            "Efficient\n",
            "Bilevel\n",
            "Optimization\n",
            "for\n",
            "Neural\n",
            "Networks\n",
            "using\n",
            "Structured\n",
            "Response\n",
            "Jacobians\n",
            "First-Order\n",
            "Methods\n",
            "for\n",
            "Large-Scale\n",
            "Market\n",
            "Equilibrium\n",
            "Computation\n",
            "Minimax\n",
            "Optimal\n",
            "Nonparametric\n",
            "Estimation\n",
            "of\n",
            "Heterogeneous\n",
            "Treatment\n",
            "Effects\n",
            "Residual\n",
            "Force\n",
            "Control\n",
            "for\n",
            "Agile\n",
            "Human\n",
            "Behavior\n",
            "Imitation\n",
            "and\n",
            "Extended\n",
            "Motion\n",
            "Synthesis\n",
            "A\n",
            "General\n",
            "Method\n",
            "for\n",
            "Robust\n",
            "Learning\n",
            "from\n",
            "Batches\n",
            "Not\n",
            "All\n",
            "Unlabeled\n",
            "Data\n",
            "are\n",
            "Equal\n",
            ":\n",
            "Learning\n",
            "to\n",
            "Weight\n",
            "Data\n",
            "in\n",
            "Semi-supervised\n",
            "Learning\n",
            "Hard\n",
            "Negative\n",
            "Mixing\n",
            "for\n",
            "Contrastive\n",
            "Learning\n",
            "MOReL\n",
            ":\n",
            "Model-Based\n",
            "Offline\n",
            "Reinforcement\n",
            "Learning\n",
            "Weisfeiler\n",
            "and\n",
            "Leman\n",
            "go\n",
            "sparse\n",
            ":\n",
            "Towards\n",
            "scalable\n",
            "higher-order\n",
            "graph\n",
            "embeddings\n",
            "Adversarial\n",
            "Crowdsourcing\n",
            "Through\n",
            "Robust\n",
            "Rank-One\n",
            "Matrix\n",
            "Completion\n",
            "Learning\n",
            "Semantic-aware\n",
            "Normalization\n",
            "for\n",
            "Generative\n",
            "Adversarial\n",
            "Networks\n",
            "Differentiable\n",
            "Causal\n",
            "Discovery\n",
            "from\n",
            "Interventional\n",
            "Data\n",
            "One-sample\n",
            "Guided\n",
            "Object\n",
            "Representation\n",
            "Disassembling\n",
            "Extrapolation\n",
            "Towards\n",
            "Imaginary\n",
            "0-Nearest\n",
            "Neighbour\n",
            "and\n",
            "Its\n",
            "Improved\n",
            "Convergence\n",
            "Rate\n",
            "Robust\n",
            "Persistence\n",
            "Diagrams\n",
            "using\n",
            "Reproducing\n",
            "Kernels\n",
            "Contextual\n",
            "Games\n",
            ":\n",
            "Multi-Agent\n",
            "Learning\n",
            "with\n",
            "Side\n",
            "Information\n",
            "Goal-directed\n",
            "Generation\n",
            "of\n",
            "Discrete\n",
            "Structures\n",
            "with\n",
            "Conditional\n",
            "Generative\n",
            "Models\n",
            "Beyond\n",
            "Lazy\n",
            "Training\n",
            "for\n",
            "Over-parameterized\n",
            "Tensor\n",
            "Decomposition\n",
            "Denoised\n",
            "Smoothing\n",
            ":\n",
            "A\n",
            "Provable\n",
            "Defense\n",
            "for\n",
            "Pretrained\n",
            "Classifiers\n",
            "Minibatch\n",
            "Stochastic\n",
            "Approximate\n",
            "Proximal\n",
            "Point\n",
            "Methods\n",
            "Attribute\n",
            "Prototype\n",
            "Network\n",
            "for\n",
            "Zero-Shot\n",
            "Learning\n",
            "CrossTransformers\n",
            ":\n",
            "spatially-aware\n",
            "few-shot\n",
            "transfer\n",
            "Learning\n",
            "Latent\n",
            "Space\n",
            "Energy-Based\n",
            "Prior\n",
            "Model\n",
            "SEVIR\n",
            ":\n",
            "A\n",
            "Storm\n",
            "Event\n",
            "Imagery\n",
            "Dataset\n",
            "for\n",
            "Deep\n",
            "Learning\n",
            "Applications\n",
            "in\n",
            "Radar\n",
            "and\n",
            "Satellite\n",
            "Meteorology\n",
            "Lightweight\n",
            "Generative\n",
            "Adversarial\n",
            "Networks\n",
            "for\n",
            "Text-Guided\n",
            "Image\n",
            "Manipulation\n",
            "High-Dimensional\n",
            "Contextual\n",
            "Policy\n",
            "Search\n",
            "with\n",
            "Unknown\n",
            "Context\n",
            "Rewards\n",
            "using\n",
            "Bayesian\n",
            "Optimization\n",
            "Model\n",
            "Fusion\n",
            "via\n",
            "Optimal\n",
            "Transport\n",
            "On\n",
            "the\n",
            "Stability\n",
            "and\n",
            "Convergence\n",
            "of\n",
            "Robust\n",
            "Adversarial\n",
            "Reinforcement\n",
            "Learning\n",
            ":\n",
            "A\n",
            "Case\n",
            "Study\n",
            "on\n",
            "Linear\n",
            "Quadratic\n",
            "Systems\n",
            "Learning\n",
            "Individually\n",
            "Inferred\n",
            "Communication\n",
            "for\n",
            "Multi-Agent\n",
            "Cooperation\n",
            "Set2Graph\n",
            ":\n",
            "Learning\n",
            "Graphs\n",
            "From\n",
            "Sets\n",
            "Graph\n",
            "Random\n",
            "Neural\n",
            "Networks\n",
            "for\n",
            "Semi-Supervised\n",
            "Learning\n",
            "on\n",
            "Graphs\n",
            "Gradient\n",
            "Boosted\n",
            "Normalizing\n",
            "Flows\n",
            "Open\n",
            "Graph\n",
            "Benchmark\n",
            ":\n",
            "Datasets\n",
            "for\n",
            "Machine\n",
            "Learning\n",
            "on\n",
            "Graphs\n",
            "Towards\n",
            "Understanding\n",
            "Hierarchical\n",
            "Learning\n",
            ":\n",
            "Benefits\n",
            "of\n",
            "Neural\n",
            "Representations\n",
            "Texture\n",
            "Interpolation\n",
            "for\n",
            "Probing\n",
            "Visual\n",
            "Perception\n",
            "Hierarchical\n",
            "Neural\n",
            "Architecture\n",
            "Search\n",
            "for\n",
            "Deep\n",
            "Stereo\n",
            "Matching\n",
            "MuSCLE\n",
            ":\n",
            "Multi\n",
            "Sweep\n",
            "Compression\n",
            "of\n",
            "LiDAR\n",
            "using\n",
            "Deep\n",
            "Entropy\n",
            "Models\n",
            "Implicit\n",
            "Bias\n",
            "in\n",
            "Deep\n",
            "Linear\n",
            "Classification\n",
            ":\n",
            "Initialization\n",
            "Scale\n",
            "vs\n",
            "Training\n",
            "Accuracy\n",
            "Focus\n",
            "of\n",
            "Attention\n",
            "Improves\n",
            "Information\n",
            "Transfer\n",
            "in\n",
            "Visual\n",
            "Features\n",
            "Auditing\n",
            "Differentially\n",
            "Private\n",
            "Machine\n",
            "Learning\n",
            ":\n",
            "How\n",
            "Private\n",
            "is\n",
            "Private\n",
            "SGD\n",
            "?\n",
            "A\n",
            "Dynamical\n",
            "Central\n",
            "Limit\n",
            "Theorem\n",
            "for\n",
            "Shallow\n",
            "Neural\n",
            "Networks\n",
            "Measuring\n",
            "Systematic\n",
            "Generalization\n",
            "in\n",
            "Neural\n",
            "Proof\n",
            "Generation\n",
            "with\n",
            "Transformers\n",
            "Big\n",
            "Self-Supervised\n",
            "Models\n",
            "are\n",
            "Strong\n",
            "Semi-Supervised\n",
            "Learners\n",
            "Learning\n",
            "from\n",
            "Label\n",
            "Proportions\n",
            ":\n",
            "A\n",
            "Mutual\n",
            "Contamination\n",
            "Framework\n",
            "Fast\n",
            "Matrix\n",
            "Square\n",
            "Roots\n",
            "with\n",
            "Applications\n",
            "to\n",
            "Gaussian\n",
            "Processes\n",
            "and\n",
            "Bayesian\n",
            "Optimization\n",
            "Self-Adaptively\n",
            "Learning\n",
            "to\n",
            "Demoiré\n",
            "from\n",
            "Focused\n",
            "and\n",
            "Defocused\n",
            "Image\n",
            "Pairs\n",
            "Confounding-Robust\n",
            "Policy\n",
            "Evaluation\n",
            "in\n",
            "Infinite-Horizon\n",
            "Reinforcement\n",
            "Learning\n",
            "Model\n",
            "Class\n",
            "Reliance\n",
            "for\n",
            "Random\n",
            "Forests\n",
            "Follow\n",
            "the\n",
            "Perturbed\n",
            "Leader\n",
            ":\n",
            "Optimism\n",
            "and\n",
            "Fast\n",
            "Parallel\n",
            "Algorithms\n",
            "for\n",
            "Smooth\n",
            "Minimax\n",
            "Games\n",
            "Agnostic\n",
            "$\n",
            "Q\n",
            "$\n",
            "-learning\n",
            "with\n",
            "Function\n",
            "Approximation\n",
            "in\n",
            "Deterministic\n",
            "Systems\n",
            ":\n",
            "Near-Optimal\n",
            "Bounds\n",
            "on\n",
            "Approximation\n",
            "Error\n",
            "and\n",
            "Sample\n",
            "Complexity\n",
            "Learning\n",
            "to\n",
            "Adapt\n",
            "to\n",
            "Evolving\n",
            "Domains\n",
            "Synthesizing\n",
            "Tasks\n",
            "for\n",
            "Block-based\n",
            "Programming\n",
            "Scalable\n",
            "Belief\n",
            "Propagation\n",
            "via\n",
            "Relaxed\n",
            "Scheduling\n",
            "Firefly\n",
            "Neural\n",
            "Architecture\n",
            "Descent\n",
            ":\n",
            "a\n",
            "General\n",
            "Approach\n",
            "for\n",
            "Growing\n",
            "Neural\n",
            "Networks\n",
            "Risk-Sensitive\n",
            "Reinforcement\n",
            "Learning\n",
            ":\n",
            "Near-Optimal\n",
            "Risk-Sample\n",
            "Tradeoff\n",
            "in\n",
            "Regret\n",
            "Learning\n",
            "to\n",
            "Decode\n",
            ":\n",
            "Reinforcement\n",
            "Learning\n",
            "for\n",
            "Decoding\n",
            "of\n",
            "Sparse\n",
            "Graph-Based\n",
            "Channel\n",
            "Codes\n",
            "Faster\n",
            "DBSCAN\n",
            "via\n",
            "subsampled\n",
            "similarity\n",
            "queries\n",
            "De-Anonymizing\n",
            "Text\n",
            "by\n",
            "Fingerprinting\n",
            "Language\n",
            "Generation\n",
            "Multiparameter\n",
            "Persistence\n",
            "Image\n",
            "for\n",
            "Topological\n",
            "Machine\n",
            "Learning\n",
            "PLANS\n",
            ":\n",
            "Neuro-Symbolic\n",
            "Program\n",
            "Learning\n",
            "from\n",
            "Videos\n",
            "Matrix\n",
            "Inference\n",
            "and\n",
            "Estimation\n",
            "in\n",
            "Multi-Layer\n",
            "Models\n",
            "MeshSDF\n",
            ":\n",
            "Differentiable\n",
            "Iso-Surface\n",
            "Extraction\n",
            "Variational\n",
            "Interaction\n",
            "Information\n",
            "Maximization\n",
            "for\n",
            "Cross-domain\n",
            "Disentanglement\n",
            "Provably\n",
            "Efficient\n",
            "Exploration\n",
            "for\n",
            "Reinforcement\n",
            "Learning\n",
            "Using\n",
            "Unsupervised\n",
            "Learning\n",
            "Faithful\n",
            "Embeddings\n",
            "for\n",
            "Knowledge\n",
            "Base\n",
            "Queries\n",
            "Wasserstein\n",
            "Distances\n",
            "for\n",
            "Stereo\n",
            "Disparity\n",
            "Estimation\n",
            "Multi-agent\n",
            "Trajectory\n",
            "Prediction\n",
            "with\n",
            "Fuzzy\n",
            "Query\n",
            "Attention\n",
            "Multilabel\n",
            "Classification\n",
            "by\n",
            "Hierarchical\n",
            "Partitioning\n",
            "and\n",
            "Data-dependent\n",
            "Grouping\n",
            "An\n",
            "Analysis\n",
            "of\n",
            "SVD\n",
            "for\n",
            "Deep\n",
            "Rotation\n",
            "Estimation\n",
            "Can\n",
            "the\n",
            "Brain\n",
            "Do\n",
            "Backpropagation\n",
            "?\n",
            "--\n",
            "-\n",
            "Exact\n",
            "Implementation\n",
            "of\n",
            "Backpropagation\n",
            "in\n",
            "Predictive\n",
            "Coding\n",
            "Networks\n",
            "Manifold\n",
            "GPLVMs\n",
            "for\n",
            "discovering\n",
            "non-Euclidean\n",
            "latent\n",
            "structure\n",
            "in\n",
            "neural\n",
            "data\n",
            "Distributed\n",
            "Distillation\n",
            "for\n",
            "On-Device\n",
            "Learning\n",
            "COOT\n",
            ":\n",
            "Cooperative\n",
            "Hierarchical\n",
            "Transformer\n",
            "for\n",
            "Video-Text\n",
            "Representation\n",
            "Learning\n",
            "Passport-aware\n",
            "Normalization\n",
            "for\n",
            "Deep\n",
            "Model\n",
            "Protection\n",
            "Sampling-Decomposable\n",
            "Generative\n",
            "Adversarial\n",
            "Recommender\n",
            "Limits\n",
            "to\n",
            "Depth\n",
            "Efficiencies\n",
            "of\n",
            "Self-Attention\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kgekq-SPhtrr",
        "outputId": "0fee075d-c556-412b-dc74-8e0b785720a3"
      },
      "source": [
        "corpusNGrams[0]\n",
        "print(len(corpusNGrams))\n",
        "print(len(filteredTexts))\n",
        "print(len(lstNGrams))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13253\n",
            "1898\n",
            "1898\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hus7LvysN50t",
        "outputId": "708a7cb4-ec9f-48d4-919d-2d0c61716b74"
      },
      "source": [
        "lstNGrams[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rrjSrZYjeY4",
        "outputId": "636bf740-2ac8-45cb-c934-fdea776d4bfb"
      },
      "source": [
        "len(lstNGrams)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1898"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsPJC5iVcKuT"
      },
      "source": [
        "### Transitive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gB1kJLdigSq3",
        "outputId": "00c8f986-aa6e-4629-e743-a4a131932496"
      },
      "source": [
        "!pip install sentence-transformers\n",
        "!pip install LexRank\n",
        "!pip install xgboost\n",
        "!pip install gensim\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentence-transformers in /opt/conda/lib/python3.7/site-packages (2.0.0)\n",
            "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (4.61.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.9.0)\n",
            "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.0.12)\n",
            "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.7.0)\n",
            "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.10.0)\n",
            "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.1.96)\n",
            "Requirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (3.6.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (4.9.1)\n",
            "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.23.2)\n",
            "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.6.0->sentence-transformers) (3.10.0.0)\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.0.13)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2019.8.19)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.10.3)\n",
            "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.0)\n",
            "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.10.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (5.4.1)\n",
            "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.25.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from nltk->sentence-transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk->sentence-transformers) (8.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.26.6)\n",
            "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->sentence-transformers) (8.3.1)\n",
            "Requirement already satisfied: LexRank in /opt/conda/lib/python3.7/site-packages (0.1.0)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from LexRank) (0.17.3)\n",
            "Requirement already satisfied: path.py>=10.5 in /opt/conda/lib/python3.7/site-packages (from LexRank) (12.5.0)\n",
            "Requirement already satisfied: regex>=2017.11.9 in /opt/conda/lib/python3.7/site-packages (from LexRank) (2019.8.19)\n",
            "Requirement already satisfied: urlextract>=0.7 in /opt/conda/lib/python3.7/site-packages (from LexRank) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from LexRank) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /opt/conda/lib/python3.7/site-packages (from LexRank) (1.7.0)\n",
            "Requirement already satisfied: path in /opt/conda/lib/python3.7/site-packages (from path.py>=10.5->LexRank) (16.2.0)\n",
            "Requirement already satisfied: appdirs in /opt/conda/lib/python3.7/site-packages (from urlextract>=0.7->LexRank) (1.4.4)\n",
            "Requirement already satisfied: uritools in /opt/conda/lib/python3.7/site-packages (from urlextract>=0.7->LexRank) (3.0.2)\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from urlextract>=0.7->LexRank) (3.0.12)\n",
            "Requirement already satisfied: idna in /opt/conda/lib/python3.7/site-packages (from urlextract>=0.7->LexRank) (2.10)\n",
            "Requirement already satisfied: xgboost in /opt/conda/lib/python3.7/site-packages (1.4.2)\n",
            "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.19.5)\n",
            "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.7.0)\n",
            "Requirement already satisfied: gensim in /opt/conda/lib/python3.7/site-packages (4.0.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /opt/conda/lib/python3.7/site-packages (from gensim) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.7/site-packages (from gensim) (1.7.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from gensim) (5.1.0)\n",
            "Collecting en_core_web_sm==2.3.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 7.1 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: spacy<2.4.0,>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from en_core_web_sm==2.3.1) (2.3.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.5)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.7.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.25.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n",
            "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (49.6.0.post20210108)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.19.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.61.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.5)\n",
            "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /opt/conda/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.10.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.26.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2021.5.30)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dL--dEGZgFCd",
        "outputId": "eb369fde-2a75-408e-fe02-933eed311a26"
      },
      "source": [
        "\n",
        "from lexrank import STOPWORDS, LexRank\n",
        "from path import Path\n",
        "import json\n",
        "import os\n",
        "# For caculating approximate time to process notebook (IGNORE)\n",
        "import datetime\n",
        "datetime.datetime.now()\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import operator\n",
        "import pickle as pkl \n",
        "import matplotlib.pyplot as plt\n",
        "import nltk as nl\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "import statistics\n",
        "import random\n",
        "import warnings\n",
        "from string import punctuation\n",
        "from matplotlib import pyplot\n",
        "from pandas import Series, datetime\n",
        "from pandas.plotting import scatter_matrix, autocorrelation_plot\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV, TimeSeriesSplit\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, mean_squared_error\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from spacy import displacy \n",
        "import nltk\n",
        "import re\n",
        "import io\n",
        "import requests\n",
        "import time\n",
        "import gensim\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "import nltk.sentiment\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import numpy as np\n",
        "import spacy\n",
        "from spacy.lang.en import English\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('brown')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:22: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
            "/opt/conda/lib/python3.7/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
            "  warnings.warn(msg)\n",
            "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/jupyter/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /home/jupyter/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /home/jupyter/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     /home/jupyter/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package brown to /home/jupyter/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wq2BSMpgMN2Z",
        "outputId": "2a7f197e-93ae-43d5-f6ae-75ecc9219c32"
      },
      "source": [
        "len(lstNGrams)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1898"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wd31aFH5fx1R",
        "outputId": "8037f76b-e205-462c-bec7-846b82378c13"
      },
      "source": [
        "lstNGrams[5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['neural-methods-point-wise-dependency',\n",
              " 'methods-point-wise-dependency-estimation']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1PeR8LaDNW5q",
        "outputId": "1be0f694-36ef-4c64-a21d-c53f142e2e40"
      },
      "source": [
        "str_ =lstNGrams[5][0].replace('-', ' ')\n",
        "str_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'neural methods point wise dependency'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M43GuW21OibK"
      },
      "source": [
        "#### Making Topic from N-grams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKiVy0M2Nszx"
      },
      "source": [
        "topic_list = []\n",
        "\n",
        "for i in range(len(lstNGrams)):\n",
        "  temp_str = ''\n",
        "  j_len = len(lstNGrams[i])\n",
        "  for j in range(j_len):\n",
        "    temp_str = temp_str +' ' +lstNGrams[i][j].replace('-', ' ')\n",
        "  #print(temp_str)\n",
        "  topic_list.append(temp_str.strip())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82_vrYsFR5LF",
        "outputId": "4f145beb-f55b-499d-8098-f34bcbb0dd66"
      },
      "source": [
        "topic_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " 'unsupervised information theoretic perceptual quality information theoretic perceptual quality metric',\n",
              " 'self supervised multimodal versatile networks',\n",
              " 'benchmarking deep inverse models time deep inverse models time neural inverse models time neural adjoint models time neural adjoint method',\n",
              " 'off policy evaluation learning external policy evaluation learning external validity evaluation learning external validity covariate learning external validity covariate shift',\n",
              " 'neural methods point wise dependency methods point wise dependency estimation',\n",
              " 'fast flexible temporal point processes flexible temporal point processes triangular temporal point processes triangular maps',\n",
              " 'backpropagating linearly improves transferability adversarial linearly improves transferability adversarial examples',\n",
              " 'pyglove symbolic programming automated machine symbolic programming automated machine learning',\n",
              " 'fourier sparse leverage scores approximate sparse leverage scores approximate kernel leverage scores approximate kernel learning',\n",
              " 'improved algorithms online submodular maximization algorithms online submodular maximization via online submodular maximization via first submodular maximization via first order maximization via first order regret via first order regret bounds',\n",
              " 'synbols probing learning algorithms synthetic probing learning algorithms synthetic datasets',\n",
              " 'adversarially robust streaming algorithms via robust streaming algorithms via differential streaming algorithms via differential privacy',\n",
              " 'trading personalization accuracy data debugging personalization accuracy data debugging collaborative accuracy data debugging collaborative filtering',\n",
              " 'cascaded text generation markov transformers',\n",
              " 'improving local identifiability probabilistic box local identifiability probabilistic box embeddings',\n",
              " 'permute and flip new mechanism and flip new mechanism differentially flip new mechanism differentially private new mechanism differentially private selection',\n",
              " 'deep reconstruction strange attractors time reconstruction strange attractors time series',\n",
              " 'reciprocal adversarial learning via characteristic adversarial learning via characteristic functions',\n",
              " 'statistical guarantees distributed nearest neighbor guarantees distributed nearest neighbor classification',\n",
              " 'stein self repulsive dynamics benefits self repulsive dynamics benefits past repulsive dynamics benefits past samples',\n",
              " 'statistical complexity early stopped mirror complexity early stopped mirror descent',\n",
              " 'algorithmic recourse imperfect causal knowledge recourse imperfect causal knowledge probabilistic imperfect causal knowledge probabilistic approach',\n",
              " 'quantitative propagation chaos sgd wide propagation chaos sgd wide neural chaos sgd wide neural networks',\n",
              " 'causal view robustness neural networks',\n",
              " 'minimax classification 0 1 loss classification 0 1 loss performance 0 1 loss performance guarantees',\n",
              " 'learn useful critic model based useful critic model based action critic model based action gradient model based action gradient estimator based action gradient estimator policy action gradient estimator policy optimization',\n",
              " '',\n",
              " 'learning composable energy surrogates pde composable energy surrogates pde order energy surrogates pde order reduction',\n",
              " 'efficient contextual bandits continuous actions',\n",
              " 'achieving equalized odds resampling sensitive equalized odds resampling sensitive attributes',\n",
              " 'multi robot collision avoidance uncertainty robot collision avoidance uncertainty probabilistic collision avoidance uncertainty probabilistic safety avoidance uncertainty probabilistic safety barrier uncertainty probabilistic safety barrier certificates',\n",
              " 'hard shape constrained kernel machines',\n",
              " 'closer look training strategy modern look training strategy modern meta training strategy modern meta learning',\n",
              " 'value out of distribution testing out of distribution testing example of distribution testing example goodhart distribution testing example goodhart s testing example goodhart s law',\n",
              " 'generalised bayesian filtering via sequential bayesian filtering via sequential monte filtering via sequential monte carlo',\n",
              " 'deterministic approximation submodular maximization matroid approximation submodular maximization matroid nearly submodular maximization matroid nearly linear maximization matroid nearly linear time',\n",
              " 'flows simultaneous manifold learning density simultaneous manifold learning density estimation',\n",
              " 'simultaneous preference metric learning paired preference metric learning paired comparisons',\n",
              " 'efficient variational inference sparse deep variational inference sparse deep learning inference sparse deep learning theoretical sparse deep learning theoretical guarantee',\n",
              " 'learning manifold implicitly via explicit manifold implicitly via explicit heat implicitly via explicit heat kernel via explicit heat kernel learning',\n",
              " 'deep relational topic modeling via relational topic modeling via graph topic modeling via graph poisson modeling via graph poisson gamma via graph poisson gamma belief graph poisson gamma belief network',\n",
              " 'one bit supervision image classification',\n",
              " '',\n",
              " '',\n",
              " 'neural networks recurrent generative feedback',\n",
              " 'learning extrapolate knowledge transductive few extrapolate knowledge transductive few shot knowledge transductive few shot out transductive few shot out of few shot out of graph shot out of graph link out of graph link prediction',\n",
              " 'exploiting weakly supervised visual patterns weakly supervised visual patterns learn supervised visual patterns learn partial visual patterns learn partial annotations',\n",
              " 'improving inference neural image compression',\n",
              " 'neuron merging compensating pruned neurons',\n",
              " 'fixmatch simplifying semi supervised learning simplifying semi supervised learning consistency semi supervised learning consistency confidence',\n",
              " 'reinforcement learning combinatorial actions application learning combinatorial actions application vehicle combinatorial actions application vehicle routing',\n",
              " 'towards playing full moba games playing full moba games deep full moba games deep reinforcement moba games deep reinforcement learning',\n",
              " 'rankmax adaptive projection alternative softmax adaptive projection alternative softmax function',\n",
              " 'online agnostic boosting via regret agnostic boosting via regret minimization',\n",
              " 'causal intervention weakly supervised semantic intervention weakly supervised semantic segmentation',\n",
              " '',\n",
              " 'over parameterized adversarial training analysis parameterized adversarial training analysis overcoming adversarial training analysis overcoming curse training analysis overcoming curse dimensionality',\n",
              " 'post training iterative hierarchical data training iterative hierarchical data augmentation iterative hierarchical data augmentation deep hierarchical data augmentation deep networks',\n",
              " '',\n",
              " 'robust compressed sensing using generative compressed sensing using generative models',\n",
              " 'fairness without demographics adversarially reweighted without demographics adversarially reweighted learning',\n",
              " 'stochastic latent actor critic deep latent actor critic deep reinforcement actor critic deep reinforcement learning critic deep reinforcement learning latent deep reinforcement learning latent variable reinforcement learning latent variable model',\n",
              " 'ridge rider finding diverse solutions rider finding diverse solutions following finding diverse solutions following eigenvectors diverse solutions following eigenvectors hessian',\n",
              " 'route chaos routing games price chaos routing games price anarchy routing games price anarchy optimistic',\n",
              " 'online algorithm unsupervised sequential selection algorithm unsupervised sequential selection contextual unsupervised sequential selection contextual information',\n",
              " '',\n",
              " 'went wrong instance wise feature wrong instance wise feature importance instance wise feature importance time wise feature importance time series feature importance time series black importance time series black box time series black box models',\n",
              " 'towards better generalization adaptive gradient better generalization adaptive gradient methods',\n",
              " 'learning guidance rewards trajectory space guidance rewards trajectory space smoothing',\n",
              " 'variance reduction via accelerated dual reduction via accelerated dual averaging via accelerated dual averaging finite accelerated dual averaging finite sum dual averaging finite sum optimization',\n",
              " 'tree tree low dimensional hyperbolic tree low dimensional hyperbolic embedding',\n",
              " 'deep structural causal models tractable structural causal models tractable counterfactual causal models tractable counterfactual inference',\n",
              " 'convolutional generation textured 3d meshes',\n",
              " 'statistical framework low bitwidth training framework low bitwidth training deep low bitwidth training deep neural bitwidth training deep neural networks',\n",
              " 'better set representations relational reasoning',\n",
              " 'autosync learning synchronize data parallel learning synchronize data parallel distributed synchronize data parallel distributed deep data parallel distributed deep learning',\n",
              " '',\n",
              " 'hardness learning neural networks natural learning neural networks natural weights',\n",
              " 'higher order spectral clustering directed order spectral clustering directed graphs',\n",
              " 'primal dual mesh convolutional neural dual mesh convolutional neural networks',\n",
              " 'advantage conditional meta learning biased conditional meta learning biased regularization meta learning biased regularization fine learning biased regularization fine tuning',\n",
              " 'watch motion blurring vision deep motion blurring vision deep neural blurring vision deep neural networks',\n",
              " 'sinkhorn barycenter via functional gradient barycenter via functional gradient descent',\n",
              " '',\n",
              " 'bayesian deep ensembles via neural deep ensembles via neural tangent ensembles via neural tangent kernel',\n",
              " 'improved schemes episodic memory based schemes episodic memory based lifelong episodic memory based lifelong learning',\n",
              " 'adaptive sampling stochastic risk averse sampling stochastic risk averse learning',\n",
              " 'deep wiener deconvolution wiener meets wiener deconvolution wiener meets deep deconvolution wiener meets deep learning wiener meets deep learning image meets deep learning image deblurring',\n",
              " '',\n",
              " 'taming discrete integration via boon discrete integration via boon dimensionality',\n",
              " 'blind video temporal consistency via video temporal consistency via deep temporal consistency via deep video consistency via deep video prior',\n",
              " 'simplify robustify negative sampling implicit robustify negative sampling implicit collaborative negative sampling implicit collaborative filtering',\n",
              " 'model selection production system via selection production system via automated production system via automated online system via automated online experiments',\n",
              " 'almost sure convergence stochastic gradient sure convergence stochastic gradient descent convergence stochastic gradient descent non stochastic gradient descent non convex gradient descent non convex problems',\n",
              " 'automatic perturbation analysis scalable certified perturbation analysis scalable certified robustness analysis scalable certified robustness beyond',\n",
              " 'adaptation properties allow identification optimized properties allow identification optimized neural allow identification optimized neural codes',\n",
              " 'global convergence variance reduction class convergence variance reduction class nonconvex variance reduction class nonconvex nonconcave reduction class nonconvex nonconcave minimax class nonconvex nonconcave minimax problems',\n",
              " 'model based multi agent rl based multi agent rl zero multi agent rl zero sum agent rl zero sum markov rl zero sum markov games zero sum markov games near sum markov games near optimal markov games near optimal sample games near optimal sample complexity',\n",
              " 'conservative q learning offline reinforcement q learning offline reinforcement learning',\n",
              " 'online influence maximization linear threshold influence maximization linear threshold model',\n",
              " 'ensembling geophysical models bayesian neural geophysical models bayesian neural networks',\n",
              " 'delving cyclic mechanism semi supervised cyclic mechanism semi supervised video mechanism semi supervised video object semi supervised video object segmentation',\n",
              " 'asymmetric shapley values incorporating causal shapley values incorporating causal knowledge values incorporating causal knowledge model incorporating causal knowledge model agnostic causal knowledge model agnostic explainability',\n",
              " 'understanding deep architecture reasoning layer',\n",
              " 'planning markov decision processes gap markov decision processes gap dependent decision processes gap dependent sample processes gap dependent sample complexity',\n",
              " 'provably good batch off policy good batch off policy reinforcement batch off policy reinforcement learning off policy reinforcement learning without policy reinforcement learning without great reinforcement learning without great exploration',\n",
              " 'detection regression certified object detection regression certified object detection median certified object detection median smoothing',\n",
              " 'contextual reserve price optimization auctions reserve price optimization auctions via price optimization auctions via mixed optimization auctions via mixed integer auctions via mixed integer programming',\n",
              " 'expandnets linear over parameterization train linear over parameterization train compact over parameterization train compact convolutional parameterization train compact convolutional networks',\n",
              " '',\n",
              " 'implications local correlation learning deep local correlation learning deep functions',\n",
              " 'learning search efficiently causally near search efficiently causally near optimal efficiently causally near optimal treatments',\n",
              " 'game theoretic analysis additive adversarial theoretic analysis additive adversarial attacks analysis additive adversarial attacks defenses',\n",
              " 'posterior network uncertainty estimation without network uncertainty estimation without ood uncertainty estimation without ood samples estimation without ood samples via without ood samples via density ood samples via density based samples via density based pseudo via density based pseudo counts',\n",
              " '',\n",
              " 'no regret learning mixed nash regret learning mixed nash equilibria learning mixed nash equilibria mix',\n",
              " 'unifying view optimism episodic reinforcement view optimism episodic reinforcement learning',\n",
              " 'continuous submodular maximization beyond dr submodular maximization beyond dr submodularity',\n",
              " 'asymptotically optimal primal dual incremental optimal primal dual incremental algorithm primal dual incremental algorithm contextual dual incremental algorithm contextual linear incremental algorithm contextual linear bandits',\n",
              " 'assessing satnet s ability solve satnet s ability solve symbol s ability solve symbol grounding ability solve symbol grounding problem',\n",
              " 'bayesian nonparametrics view deep representations',\n",
              " 'similarity laplace neural tangent kernels',\n",
              " 'causal view compositional zero shot view compositional zero shot recognition',\n",
              " 'hippo recurrent memory optimal polynomial recurrent memory optimal polynomial projections',\n",
              " '',\n",
              " 'castle regularization via auxiliary causal regularization via auxiliary causal graph via auxiliary causal graph discovery',\n",
              " 'long tailed classification keeping good tailed classification keeping good removing classification keeping good removing bad keeping good removing bad momentum good removing bad momentum causal removing bad momentum causal effect',\n",
              " '',\n",
              " '',\n",
              " 're examining linear embeddings high examining linear embeddings high dimensional linear embeddings high dimensional bayesian embeddings high dimensional bayesian optimization',\n",
              " 'unmodnet learning unwrap modulo image learning unwrap modulo image high unwrap modulo image high dynamic modulo image high dynamic range image high dynamic range imaging',\n",
              " 'thunder fast coordinate selection solver fast coordinate selection solver sparse coordinate selection solver sparse learning',\n",
              " 'neural networks fail learn periodic networks fail learn periodic functions fail learn periodic functions fix',\n",
              " '',\n",
              " 'correspondence learning via linearly invariant learning via linearly invariant embedding',\n",
              " 'learning dispatch job shop scheduling dispatch job shop scheduling via job shop scheduling via deep shop scheduling via deep reinforcement scheduling via deep reinforcement learning',\n",
              " 'adaptive attacks adversarial example defenses',\n",
              " 'sinkhorn natural gradient generative models',\n",
              " 'online sinkhorn optimal transport distances sinkhorn optimal transport distances sample optimal transport distances sample streams',\n",
              " '',\n",
              " 'locally adaptive nonparametric online learning',\n",
              " 'compositional generalization via neural symbolic generalization via neural symbolic stack via neural symbolic stack machines',\n",
              " 'graphon neural networks transferability graph neural networks transferability graph neural networks transferability graph neural networks',\n",
              " 'unreasonable effectiveness greedy algorithms multi effectiveness greedy algorithms multi armed greedy algorithms multi armed bandit algorithms multi armed bandit many multi armed bandit many arms',\n",
              " 'gamma models generative temporal difference models generative temporal difference learning generative temporal difference learning infinite temporal difference learning infinite horizon difference learning infinite horizon prediction',\n",
              " '',\n",
              " 'neural mesh flow 3d manifold mesh flow 3d manifold mesh flow 3d manifold mesh generation 3d manifold mesh generation via manifold mesh generation via diffeomorphic mesh generation via diffeomorphic flows',\n",
              " 'statistical control spatio temporal meg control spatio temporal meg eeg spatio temporal meg eeg source temporal meg eeg source imaging meg eeg source imaging desparsified eeg source imaging desparsified mutli source imaging desparsified mutli task imaging desparsified mutli task lasso',\n",
              " 'scalable mip based method learning mip based method learning optimal based method learning optimal multivariate method learning optimal multivariate decision learning optimal multivariate decision trees',\n",
              " 'efficient exact verification binarized neural exact verification binarized neural networks',\n",
              " 'ultra low precision 4 bit low precision 4 bit training precision 4 bit training deep 4 bit training deep neural bit training deep neural networks',\n",
              " 'bridging gap sample based one gap sample based one shot sample based one shot neural based one shot neural architecture one shot neural architecture search shot neural architecture search bonas',\n",
              " '',\n",
              " 'outlier robust mean estimation subgaussian robust mean estimation subgaussian rates mean estimation subgaussian rates via estimation subgaussian rates via stability',\n",
              " '',\n",
              " 'information theoretic counterfactual learning missing theoretic counterfactual learning missing not counterfactual learning missing not at learning missing not at random missing not at random feedback',\n",
              " 'prophet attention predicting attention future attention predicting attention future attention',\n",
              " 'language models few shot learners',\n",
              " 'margins insufficient explaining gradient boosting',\n",
              " 'fourier transform based attribution priors transform based attribution priors improve based attribution priors improve interpretability attribution priors improve interpretability stability priors improve interpretability stability deep improve interpretability stability deep learning interpretability stability deep learning models stability deep learning models genomics',\n",
              " 'momentumrnn integrating momentum recurrent neural integrating momentum recurrent neural networks',\n",
              " 'marginal utility planning continuous large utility planning continuous large discrete planning continuous large discrete action continuous large discrete action spaces',\n",
              " 'projected stein variational gradient descent',\n",
              " 'minimax lower bounds transfer learning lower bounds transfer learning linear bounds transfer learning linear one transfer learning linear one hidden learning linear one hidden layer linear one hidden layer neural one hidden layer neural networks',\n",
              " 'se 3 transformers 3d roto 3 transformers 3d roto translation transformers 3d roto translation equivariant 3d roto translation equivariant attention roto translation equivariant attention networks',\n",
              " 'equivalence molecular graph convolution molecular molecular graph convolution molecular wave graph convolution molecular wave function convolution molecular wave function poor molecular wave function poor basis wave function poor basis set',\n",
              " '',\n",
              " 'learning affordance landscapes interaction exploration affordance landscapes interaction exploration 3d landscapes interaction exploration 3d environments',\n",
              " 'cooperative multi player bandit optimization',\n",
              " 'tight first second order regret first second order regret bounds second order regret bounds adversarial order regret bounds adversarial linear regret bounds adversarial linear bandits',\n",
              " 'pick sign optimizing deep multitask sign optimizing deep multitask models optimizing deep multitask models gradient deep multitask models gradient sign multitask models gradient sign dropout',\n",
              " 'loss function generative neural networks function generative neural networks based generative neural networks based watson neural networks based watson perceptual networks based watson perceptual model',\n",
              " 'dynamic fusion eye movement data fusion eye movement data verbal eye movement data verbal narrations movement data verbal narrations knowledge data verbal narrations knowledge rich verbal narrations knowledge rich domains',\n",
              " 'scalable multi agent reinforcement learning multi agent reinforcement learning networked agent reinforcement learning networked systems reinforcement learning networked systems average learning networked systems average reward',\n",
              " 'optimizing neural networks via koopman neural networks via koopman operator networks via koopman operator theory',\n",
              " 'svgd kernelized wasserstein gradient flow kernelized wasserstein gradient flow chi wasserstein gradient flow chi squared gradient flow chi squared divergence',\n",
              " 'adversarial robustness supervised sparse coding',\n",
              " 'differentiable meta learning bandit policies',\n",
              " 'biologically inspired mechanisms adversarial robustness',\n",
              " 'statistical query lower bounds via query lower bounds via functional lower bounds via functional gradients',\n",
              " 'near optimal reinforcement learning self optimal reinforcement learning self play',\n",
              " 'network diffusions via neural mean diffusions via neural mean field via neural mean field dynamics',\n",
              " 'self distillation instance specific label distillation instance specific label smoothing',\n",
              " 'towards problem dependent optimal learning problem dependent optimal learning rates',\n",
              " 'cross lingual retrieval iterative self lingual retrieval iterative self supervised retrieval iterative self supervised training',\n",
              " 'rethinking pooling graph neural networks',\n",
              " '',\n",
              " 'gradient regularized v learning dynamic regularized v learning dynamic treatment v learning dynamic treatment regimes',\n",
              " 'faster wasserstein distance estimation sinkhorn wasserstein distance estimation sinkhorn divergence',\n",
              " '',\n",
              " 'robust recursive partitioning heterogeneous treatment recursive partitioning heterogeneous treatment effects partitioning heterogeneous treatment effects uncertainty heterogeneous treatment effects uncertainty quantification',\n",
              " 'rescuing neural spike train models neural spike train models bad spike train models bad mle',\n",
              " 'lower bounds optimal algorithms personalized bounds optimal algorithms personalized federated optimal algorithms personalized federated learning',\n",
              " 'black box certification randomized smoothing box certification randomized smoothing functional certification randomized smoothing functional optimization randomized smoothing functional optimization based smoothing functional optimization based framework',\n",
              " 'deep imitation learning bimanual robotic imitation learning bimanual robotic manipulation',\n",
              " 'stationary activations uncertainty calibration deep activations uncertainty calibration deep learning',\n",
              " 'ensemble distillation robust model fusion distillation robust model fusion federated robust model fusion federated learning',\n",
              " 'falcon fast spectral inference encrypted fast spectral inference encrypted data',\n",
              " '',\n",
              " 'practical quasi newton methods training quasi newton methods training deep newton methods training deep neural methods training deep neural networks',\n",
              " 'approximation based variance reduction reparameterization based variance reduction reparameterization gradients',\n",
              " 'inference stage optimization cross scenario stage optimization cross scenario 3d optimization cross scenario 3d human cross scenario 3d human pose scenario 3d human pose estimation',\n",
              " 'consistent feature selection analytic deep feature selection analytic deep neural selection analytic deep neural networks',\n",
              " 'glance focus dynamic approach reducing focus dynamic approach reducing spatial dynamic approach reducing spatial redundancy approach reducing spatial redundancy image reducing spatial redundancy image classification',\n",
              " 'information maximization few shot learning',\n",
              " 'inverse reinforcement learning gradient based reinforcement learning gradient based learner',\n",
              " 'bayesian multi type mean field multi type mean field multi type mean field multi agent mean field multi agent imitation field multi agent imitation learning',\n",
              " 'bayesian robust optimization imitation learning',\n",
              " 'multiview neural surface reconstruction disentangling neural surface reconstruction disentangling geometry surface reconstruction disentangling geometry appearance',\n",
              " '',\n",
              " 'attention gated brain propagation brain gated brain propagation brain implement brain propagation brain implement reward propagation brain implement reward based brain implement reward based error implement reward based error backpropagation',\n",
              " 'asymptotic guarantees generative modeling based guarantees generative modeling based smooth generative modeling based smooth wasserstein modeling based smooth wasserstein distance',\n",
              " 'online robust regression via sgd robust regression via sgd l1 regression via sgd l1 loss',\n",
              " 'prank motion prediction based ranking',\n",
              " 'fighting copycat agents behavioral cloning copycat agents behavioral cloning observation agents behavioral cloning observation histories',\n",
              " 'tight nonparametric convergence rates stochastic nonparametric convergence rates stochastic gradient convergence rates stochastic gradient descent rates stochastic gradient descent noiseless stochastic gradient descent noiseless linear gradient descent noiseless linear model',\n",
              " 'structured prediction conditional meta learning',\n",
              " 'optimal lottery tickets via subset lottery tickets via subset sum tickets via subset sum logarithmic via subset sum logarithmic over subset sum logarithmic over parameterization sum logarithmic over parameterization sufficient',\n",
              " 'hateful memes challenge detecting hate memes challenge detecting hate speech challenge detecting hate speech multimodal detecting hate speech multimodal memes',\n",
              " 'stochasticity deterministic gradient descent large deterministic gradient descent large learning gradient descent large learning rate descent large learning rate multiscale large learning rate multiscale objective learning rate multiscale objective function',\n",
              " 'identifying learning rules neural network learning rules neural network observables',\n",
              " 'optimal approximation smoothness tradeoffs soft approximation smoothness tradeoffs soft max smoothness tradeoffs soft max functions',\n",
              " 'weakly supervised reinforcement learning controllable supervised reinforcement learning controllable behavior',\n",
              " 'improving policy constrained kidney exchange policy constrained kidney exchange via constrained kidney exchange via pre kidney exchange via pre screening',\n",
              " 'learning abstract structure drawing efficient abstract structure drawing efficient motor structure drawing efficient motor program drawing efficient motor program induction',\n",
              " 'deep residual networks generalize better residual networks generalize better deep networks generalize better deep feedforward generalize better deep feedforward networks better deep feedforward networks neural deep feedforward networks neural tangent feedforward networks neural tangent kernel networks neural tangent kernel perspective',\n",
              " '',\n",
              " 'stochastic gradient descent correlated settings gradient descent correlated settings study descent correlated settings study gaussian correlated settings study gaussian processes',\n",
              " '',\n",
              " 'minimax value interval off policy value interval off policy evaluation interval off policy evaluation policy off policy evaluation policy optimization',\n",
              " 'biased stochastic first order methods stochastic first order methods conditional first order methods conditional stochastic order methods conditional stochastic optimization methods conditional stochastic optimization applications conditional stochastic optimization applications meta stochastic optimization applications meta learning',\n",
              " 'shiftaddnet hardware inspired deep network',\n",
              " 'network to network translation conditional to network translation conditional invertible network translation conditional invertible neural translation conditional invertible neural networks',\n",
              " 'intra processing methods debiasing neural processing methods debiasing neural networks',\n",
              " 'finding second order stationary points second order stationary points efficiently order stationary points efficiently smooth stationary points efficiently smooth nonconvex points efficiently smooth nonconvex linearly efficiently smooth nonconvex linearly constrained smooth nonconvex linearly constrained optimization nonconvex linearly constrained optimization problems',\n",
              " 'model based policy optimization unsupervised based policy optimization unsupervised model policy optimization unsupervised model adaptation',\n",
              " 'implicit regularization convergence weight normalization',\n",
              " 'geometric all way boolean tensor all way boolean tensor decomposition',\n",
              " '',\n",
              " 'a b testing dense large b testing dense large scale testing dense large scale networks dense large scale networks design large scale networks design inference',\n",
              " 'neural networks memorize discovering long networks memorize discovering long tail memorize discovering long tail via discovering long tail via influence long tail via influence estimation',\n",
              " '',\n",
              " 'partial optimal tranport applications positive optimal tranport applications positive unlabeled tranport applications positive unlabeled learning',\n",
              " 'toward fundamental limits imitation learning',\n",
              " '',\n",
              " 'hold tight influence discriminative features tight influence discriminative features deep influence discriminative features deep network discriminative features deep network boundaries',\n",
              " 'learning mixtures private public populations',\n",
              " 'adversarial weight perturbation helps robust weight perturbation helps robust generalization',\n",
              " 'stateful posted pricing vanishing regret posted pricing vanishing regret via pricing vanishing regret via dynamic vanishing regret via dynamic deterministic regret via dynamic deterministic markov via dynamic deterministic markov decision dynamic deterministic markov decision processes',\n",
              " 'adversarial self supervised contrastive learning',\n",
              " 'normalizing kalman filters multivariate time kalman filters multivariate time series filters multivariate time series analysis',\n",
              " '',\n",
              " 'fourier spectrum discrepancies deep network spectrum discrepancies deep network generated discrepancies deep network generated images',\n",
              " 'lamina specific neuronal properties promote specific neuronal properties promote robust neuronal properties promote robust stable properties promote robust stable signal promote robust stable signal propagation robust stable signal propagation feedforward stable signal propagation feedforward networks',\n",
              " 'learning dynamic belief graphs generalize dynamic belief graphs generalize text belief graphs generalize text based graphs generalize text based games',\n",
              " 'triple descent two kinds overfitting descent two kinds overfitting appear',\n",
              " 'multimodal graph networks compositional generalization graph networks compositional generalization visual networks compositional generalization visual question compositional generalization visual question answering',\n",
              " 'learning graph structure finite state graph structure finite state automaton structure finite state automaton layer',\n",
              " 'universal approximation theorem deep neural approximation theorem deep neural networks theorem deep neural networks expressing deep neural networks expressing probability neural networks expressing probability distributions',\n",
              " 'unsupervised object centric video generation object centric video generation decomposition centric video generation decomposition 3d',\n",
              " 'domain generalization medical imaging classification generalization medical imaging classification linear medical imaging classification linear dependency imaging classification linear dependency regularization',\n",
              " 'multi label classification hamming loss label classification hamming loss subset classification hamming loss subset accuracy hamming loss subset accuracy really loss subset accuracy really conflict',\n",
              " 'novel automated curriculum strategy solve automated curriculum strategy solve hard curriculum strategy solve hard sokoban strategy solve hard sokoban planning solve hard sokoban planning instances',\n",
              " 'causal analysis covid 19 spread analysis covid 19 spread germany',\n",
              " 'locally private non asymptotic testing private non asymptotic testing discrete non asymptotic testing discrete distributions asymptotic testing discrete distributions faster testing discrete distributions faster using discrete distributions faster using interactive distributions faster using interactive mechanisms',\n",
              " 'adaptive gradient quantization data parallel gradient quantization data parallel sgd',\n",
              " '',\n",
              " 'removing bias multi modal classifiers bias multi modal classifiers regularization multi modal classifiers regularization maximizing modal classifiers regularization maximizing functional classifiers regularization maximizing functional entropies',\n",
              " 'compact task representations normative model task representations normative model higher representations normative model higher order normative model higher order brain model higher order brain activity',\n",
              " 'robust adaptive control linear systems adaptive control linear systems beyond control linear systems beyond quadratic linear systems beyond quadratic costs',\n",
              " 'co exposure maximization online social exposure maximization online social networks',\n",
              " 'uclid net single view reconstruction net single view reconstruction object single view reconstruction object space',\n",
              " 'reinforcement learning control multiple frequencies',\n",
              " 'complex dynamics simple neural networks dynamics simple neural networks understanding simple neural networks understanding gradient neural networks understanding gradient flow networks understanding gradient flow phase understanding gradient flow phase retrieval',\n",
              " 'neural message passing multi relational message passing multi relational ordered passing multi relational ordered recursive multi relational ordered recursive hypergraphs',\n",
              " 'unified view label shift estimation',\n",
              " 'optimal private median estimation minimal private median estimation minimal distributional median estimation minimal distributional assumptions',\n",
              " 'breaking communication privacy accuracy trilemma',\n",
              " 'audeo audio generation silent performance audio generation silent performance video',\n",
              " '',\n",
              " 'self distillation amplifies regularization hilbert distillation amplifies regularization hilbert space',\n",
              " 'coupling based invertible neural networks based invertible neural networks universal invertible neural networks universal diffeomorphism neural networks universal diffeomorphism approximators',\n",
              " 'community detection using fast low detection using fast low cardinality using fast low cardinality semidefinite fast low cardinality semidefinite programming',\n",
              " 'modeling noisy annotations crowd counting',\n",
              " 'operator view policy gradient methods',\n",
              " 'demystifying contrastive self supervised learning contrastive self supervised learning invariances self supervised learning invariances augmentations supervised learning invariances augmentations dataset learning invariances augmentations dataset biases',\n",
              " 'online map inference determinantal point map inference determinantal point processes',\n",
              " 'video object segmentation adaptive feature object segmentation adaptive feature bank segmentation adaptive feature bank uncertain adaptive feature bank uncertain region feature bank uncertain region refinement',\n",
              " 'inferring learning rules animal decision learning rules animal decision making',\n",
              " 'input aware dynamic backdoor attack',\n",
              " 'hard distinguish graphs graph neural distinguish graphs graph neural networks',\n",
              " 'minimax regret switching constrained online regret switching constrained online convex switching constrained online convex optimization constrained online convex optimization phase online convex optimization phase transition',\n",
              " 'dual manifold adversarial robustness defense manifold adversarial robustness defense lp adversarial robustness defense lp non robustness defense lp non lp defense lp non lp adversarial lp non lp adversarial attacks',\n",
              " 'cross scale internal graph neural scale internal graph neural network internal graph neural network image graph neural network image super neural network image super resolution',\n",
              " 'unsupervised representation learning invariance propagation',\n",
              " 'restoring negative information few shot negative information few shot object information few shot object detection',\n",
              " 'adversarially robust imagenet models transfer robust imagenet models transfer better',\n",
              " 'robust correction sampling bias using correction sampling bias using cumulative sampling bias using cumulative distribution bias using cumulative distribution functions',\n",
              " 'personalized federated learning theoretical guarantees federated learning theoretical guarantees model learning theoretical guarantees model agnostic theoretical guarantees model agnostic meta guarantees model agnostic meta learning model agnostic meta learning approach',\n",
              " 'pixel level cycle association new level cycle association new perspective cycle association new perspective domain association new perspective domain adaptive new perspective domain adaptive semantic perspective domain adaptive semantic segmentation',\n",
              " '',\n",
              " 'learning global transparent models consistent global transparent models consistent local transparent models consistent local contrastive models consistent local contrastive explanations',\n",
              " '',\n",
              " 'diverse image captioning context object image captioning context object split captioning context object split latent context object split latent spaces',\n",
              " 'learning disentangled representations videos missing disentangled representations videos missing data',\n",
              " '',\n",
              " 'continual learning node importance based learning node importance based adaptive node importance based adaptive group importance based adaptive group sparse based adaptive group sparse regularization',\n",
              " 'towards crowdsourced training large neural crowdsourced training large neural networks training large neural networks using large neural networks using decentralized neural networks using decentralized mixture networks using decentralized mixture of using decentralized mixture of experts',\n",
              " 'bidirectional convolutional poisson gamma dynamical convolutional poisson gamma dynamical systems',\n",
              " '',\n",
              " 'ranking via sorting estimated expected via sorting estimated expected utility',\n",
              " 'distribution free binary classification prediction free binary classification prediction sets binary classification prediction sets confidence classification prediction sets confidence intervals prediction sets confidence intervals calibration',\n",
              " 'closing dequantization gap pixelcnn single dequantization gap pixelcnn single layer gap pixelcnn single layer flow',\n",
              " 'sequence multi sequence learning via multi sequence learning via conditional sequence learning via conditional chain learning via conditional chain mapping via conditional chain mapping mixture conditional chain mapping mixture signals',\n",
              " 'variance reduction random coordinate descent reduction random coordinate descent langevin random coordinate descent langevin monte coordinate descent langevin monte carlo',\n",
              " 'language cognitive tool imagine goals cognitive tool imagine goals curiosity tool imagine goals curiosity driven imagine goals curiosity driven exploration',\n",
              " '',\n",
              " 'primal dual interpretation proximal stochastic dual interpretation proximal stochastic gradient interpretation proximal stochastic gradient langevin proximal stochastic gradient langevin algorithm',\n",
              " 'characterize landscape overparameterized convolutional neural landscape overparameterized convolutional neural networks',\n",
              " 'tightness semidefinite relaxations certifying robustness semidefinite relaxations certifying robustness adversarial relaxations certifying robustness adversarial examples',\n",
              " '',\n",
              " 'rethinking pre training self training',\n",
              " 'unsupervised sound separation using mixture sound separation using mixture invariant separation using mixture invariant training',\n",
              " 'adaptive discretization model based reinforcement discretization model based reinforcement learning',\n",
              " 'codecmr cross modal retrieval function cross modal retrieval function level modal retrieval function level binary retrieval function level binary source function level binary source code level binary source code matching',\n",
              " 'warm starting neural network training',\n",
              " 'dags fears closer look continuous fears closer look continuous optimization closer look continuous optimization learning look continuous optimization learning bayesian continuous optimization learning bayesian networks',\n",
              " 'ood maml meta learning few maml meta learning few shot meta learning few shot out learning few shot out of few shot out of distribution shot out of distribution detection out of distribution detection classification',\n",
              " 'imitation observation approach transfer learning observation approach transfer learning dynamics approach transfer learning dynamics mismatch',\n",
              " '',\n",
              " 'learning discrete distributions infinite support',\n",
              " '',\n",
              " '',\n",
              " 'counterfactual data augmentation using locally data augmentation using locally factored augmentation using locally factored dynamics',\n",
              " 'rethinking learnable tree filter generic learnable tree filter generic feature tree filter generic feature transform',\n",
              " 'self supervised relational reasoning representation supervised relational reasoning representation learning',\n",
              " 'sufficient dimension reduction classification using dimension reduction classification using principal reduction classification using principal optimal classification using principal optimal transport using principal optimal transport direction',\n",
              " 'fast epigraphical projection based incremental epigraphical projection based incremental algorithms projection based incremental algorithms wasserstein based incremental algorithms wasserstein distributionally incremental algorithms wasserstein distributionally robust algorithms wasserstein distributionally robust support wasserstein distributionally robust support vector distributionally robust support vector machine',\n",
              " 'differentially private clustering tight approximation private clustering tight approximation ratios',\n",
              " 'power louvain stochastic block model',\n",
              " 'fairness overlapping groups probabilistic perspective',\n",
              " 'attendlight universal attention based reinforcement universal attention based reinforcement learning attention based reinforcement learning model based reinforcement learning model traffic reinforcement learning model traffic signal learning model traffic signal control',\n",
              " 'searching low bit weights quantized low bit weights quantized neural bit weights quantized neural networks',\n",
              " '',\n",
              " 'predictions decisions using lookahead regularization',\n",
              " 'sequential bayesian experimental design variable bayesian experimental design variable cost experimental design variable cost structure',\n",
              " 'predictive inference free jackknife after inference free jackknife after bootstrap',\n",
              " '',\n",
              " 'learning loss test time augmentation',\n",
              " 'balanced meta softmax long tailed meta softmax long tailed visual softmax long tailed visual recognition',\n",
              " 'efficient exploration reward functions inverse exploration reward functions inverse reinforcement reward functions inverse reinforcement learning functions inverse reinforcement learning via inverse reinforcement learning via bayesian reinforcement learning via bayesian optimization',\n",
              " 'mdp homomorphic networks group symmetries homomorphic networks group symmetries reinforcement networks group symmetries reinforcement learning',\n",
              " 'explain empirical study deep neural empirical study deep neural network study deep neural network explanation deep neural network explanation methods',\n",
              " 'error resistance hinge loss minimization',\n",
              " '',\n",
              " 'object goal navigation using goal goal navigation using goal oriented navigation using goal oriented semantic using goal oriented semantic exploration',\n",
              " 'efficient semidefinite programming based inference semidefinite programming based inference binary programming based inference binary multi based inference binary multi class inference binary multi class mrfs',\n",
              " 'funnel transformer filtering sequential redundancy transformer filtering sequential redundancy efficient filtering sequential redundancy efficient language sequential redundancy efficient language processing',\n",
              " 'semantic visual navigation watching youtube visual navigation watching youtube videos',\n",
              " 'heavy tailed representations text polarity tailed representations text polarity classification representations text polarity classification data text polarity classification data augmentation',\n",
              " 'superloss generic loss robust curriculum generic loss robust curriculum learning',\n",
              " 'cogmol target specific selective drug target specific selective drug design specific selective drug design covid selective drug design covid 19 drug design covid 19 using design covid 19 using deep covid 19 using deep generative 19 using deep generative models',\n",
              " 'memory based trajectory conditioned policies based trajectory conditioned policies learning trajectory conditioned policies learning sparse conditioned policies learning sparse rewards',\n",
              " 'liberty depth deep bayesian neural depth deep bayesian neural nets deep bayesian neural nets need bayesian neural nets need complex neural nets need complex weight nets need complex weight posterior need complex weight posterior approximations',\n",
              " 'improving sample complexity bounds natural sample complexity bounds natural actor complexity bounds natural actor critic bounds natural actor critic algorithms',\n",
              " 'learning differential equations easy solve',\n",
              " 'stability stochastic gradient descent nonsmooth stochastic gradient descent nonsmooth convex gradient descent nonsmooth convex losses',\n",
              " 'influence augmented online planning complex augmented online planning complex environments',\n",
              " 'pac bayes learning bounds sample bayes learning bounds sample dependent learning bounds sample dependent priors',\n",
              " 'reward rational implicit choice unifying rational implicit choice unifying formalism implicit choice unifying formalism reward choice unifying formalism reward learning',\n",
              " 'probabilistic time series forecasting shape time series forecasting shape temporal series forecasting shape temporal diversity',\n",
              " 'low distortion block resampling spatially distortion block resampling spatially stochastic block resampling spatially stochastic networks',\n",
              " 'continual deep learning functional regularisation deep learning functional regularisation memorable learning functional regularisation memorable past',\n",
              " 'distance encoding design provably powerful encoding design provably powerful neural design provably powerful neural networks provably powerful neural networks graph powerful neural networks graph representation neural networks graph representation learning',\n",
              " '',\n",
              " 'unsupervised learning dense visual representations',\n",
              " 'higher order certification randomized smoothing',\n",
              " 'learning structured distributions untrusted batches structured distributions untrusted batches faster distributions untrusted batches faster simpler',\n",
              " '',\n",
              " 'diversity transferred output diversification white transferred output diversification white black output diversification white black box diversification white black box attacks',\n",
              " 'poly hoot monte carlo planning hoot monte carlo planning continuous monte carlo planning continuous space carlo planning continuous space mdps planning continuous space mdps non continuous space mdps non asymptotic space mdps non asymptotic analysis',\n",
              " '',\n",
              " 'variational policy gradient method reinforcement policy gradient method reinforcement learning gradient method reinforcement learning general method reinforcement learning general utilities',\n",
              " 'reverse engineering recurrent neural network engineering recurrent neural network solutions recurrent neural network solutions hierarchical neural network solutions hierarchical inference network solutions hierarchical inference task solutions hierarchical inference task mice',\n",
              " 'temporal positive unlabeled learning biomedical positive unlabeled learning biomedical hypothesis unlabeled learning biomedical hypothesis generation learning biomedical hypothesis generation via biomedical hypothesis generation via risk hypothesis generation via risk estimation',\n",
              " 'efficient low rank gaussian variational low rank gaussian variational inference rank gaussian variational inference neural gaussian variational inference neural networks',\n",
              " 'privacy amplification via random check amplification via random check ins',\n",
              " 'probabilistic circuits variational inference discrete circuits variational inference discrete graphical variational inference discrete graphical models',\n",
              " 'classifier secretly suffice multi source secretly suffice multi source domain suffice multi source domain adaptation',\n",
              " 'labelling unlabelled videos scratch multi unlabelled videos scratch multi modal videos scratch multi modal self scratch multi modal self supervision',\n",
              " 'non asymptotic analysis stein variational asymptotic analysis stein variational gradient analysis stein variational gradient descent',\n",
              " 'robust meta learning mixed linear meta learning mixed linear regression learning mixed linear regression small mixed linear regression small batches',\n",
              " 'bayesian deep learning probabilistic perspective deep learning probabilistic perspective generalization',\n",
              " 'unsupervised learning object landmarks via learning object landmarks via self object landmarks via self training landmarks via self training correspondence',\n",
              " 'randomized tests high dimensional regression tests high dimensional regression efficient high dimensional regression efficient powerful dimensional regression efficient powerful solution',\n",
              " 'learning representations audio visual spatial representations audio visual spatial alignment',\n",
              " 'generative view synthesis single view view synthesis single view semantics synthesis single view semantics novel single view semantics novel view view semantics novel view images',\n",
              " 'towards practical adversarial attacks graph practical adversarial attacks graph neural adversarial attacks graph neural networks',\n",
              " 'multi task reinforcement learning soft task reinforcement learning soft modularization',\n",
              " 'causal shapley values exploiting causal shapley values exploiting causal knowledge values exploiting causal knowledge explain exploiting causal knowledge explain individual causal knowledge explain individual predictions knowledge explain individual predictions complex explain individual predictions complex models',\n",
              " 'training dynamics deep networks l dynamics deep networks l 2 deep networks l 2 regularization',\n",
              " 'improved algorithms convex concave minimax algorithms convex concave minimax optimization',\n",
              " '',\n",
              " 'learning implicit functions topology varying implicit functions topology varying dense functions topology varying dense 3d topology varying dense 3d shape varying dense 3d shape correspondence',\n",
              " 'deep multimodal fusion channel exchanging',\n",
              " 'hierarchically organized latent modules exploratory organized latent modules exploratory search latent modules exploratory search morphogenetic modules exploratory search morphogenetic systems',\n",
              " 'ai feynman 2 0 pareto feynman 2 0 pareto optimal 2 0 pareto optimal symbolic 0 pareto optimal symbolic regression pareto optimal symbolic regression exploiting optimal symbolic regression exploiting graph symbolic regression exploiting graph modularity',\n",
              " 'delay cooperation nonstochastic linear bandits',\n",
              " 'probabilistic orientation estimation matrix fisher orientation estimation matrix fisher distributions',\n",
              " 'minimax dynamics optimally balanced spiking dynamics optimally balanced spiking networks optimally balanced spiking networks excitatory balanced spiking networks excitatory inhibitory spiking networks excitatory inhibitory neurons',\n",
              " '',\n",
              " 'towards deeper graph neural networks deeper graph neural networks differentiable graph neural networks differentiable group neural networks differentiable group normalization',\n",
              " '',\n",
              " 'learning differentiable programs admissible neural differentiable programs admissible neural heuristics',\n",
              " 'improved guarantees multiple descent curve guarantees multiple descent curve column multiple descent curve column subset descent curve column subset selection curve column subset selection nystrom column subset selection nystrom method',\n",
              " 'domain adaptation problem inference graphical adaptation problem inference graphical models',\n",
              " 'network size size weights memorization size size weights memorization two size weights memorization two layers weights memorization two layers neural memorization two layers neural networks',\n",
              " '',\n",
              " 'continual learning control primitives skill learning control primitives skill discovery control primitives skill discovery via primitives skill discovery via reset skill discovery via reset games',\n",
              " 'hoi analysis integrating decomposing human analysis integrating decomposing human object integrating decomposing human object interaction',\n",
              " 'strongly local p norm cut local p norm cut algorithms p norm cut algorithms semi norm cut algorithms semi supervised cut algorithms semi supervised learning algorithms semi supervised learning local semi supervised learning local graph supervised learning local graph clustering',\n",
              " '',\n",
              " '',\n",
              " 'neural dynamic policies end to dynamic policies end to end policies end to end sensorimotor end to end sensorimotor learning',\n",
              " 'new inference approach training shallow inference approach training shallow deep approach training shallow deep generalized training shallow deep generalized linear shallow deep generalized linear models deep generalized linear models noisy generalized linear models noisy interacting linear models noisy interacting neurons',\n",
              " 'decision making auto encoding variational making auto encoding variational bayes',\n",
              " 'attribution preservation network compression reliable preservation network compression reliable network network compression reliable network interpretation',\n",
              " 'feature importance ranking deep learning',\n",
              " '',\n",
              " 'model inversion networks model based inversion networks model based optimization',\n",
              " 'hausdorff dimension heavy tails generalization dimension heavy tails generalization neural heavy tails generalization neural networks',\n",
              " 'exact expressions double descent implicit expressions double descent implicit regularization double descent implicit regularization via descent implicit regularization via surrogate implicit regularization via surrogate random regularization via surrogate random design',\n",
              " 'certifying confidence via randomized smoothing',\n",
              " 'learning physical constraints neural projections',\n",
              " 'robust optimization fairness noisy protected optimization fairness noisy protected groups',\n",
              " 'noise contrastive estimation multivariate point contrastive estimation multivariate point processes',\n",
              " 'game theoretic analysis empirical revenue theoretic analysis empirical revenue maximization analysis empirical revenue maximization algorithm empirical revenue maximization algorithm endogenous revenue maximization algorithm endogenous sampling',\n",
              " 'neural path features neural path path features neural path kernel features neural path kernel understanding neural path kernel understanding role path kernel understanding role gates kernel understanding role gates deep understanding role gates deep learning',\n",
              " '',\n",
              " 'sparse graphical memory robust planning',\n",
              " 'second order pac bayesian bounds order pac bayesian bounds weighted pac bayesian bounds weighted majority bayesian bounds weighted majority vote',\n",
              " '',\n",
              " 'modeling task effects meaning representation task effects meaning representation brain effects meaning representation brain via meaning representation brain via zero representation brain via zero shot brain via zero shot meg via zero shot meg prediction',\n",
              " 'counterfactual vision and language navigation vision and language navigation unravelling and language navigation unravelling unseen',\n",
              " 'robust quantization one model rule',\n",
              " 'enabling certification verification agnostic networks certification verification agnostic networks via verification agnostic networks via memory agnostic networks via memory efficient networks via memory efficient semidefinite via memory efficient semidefinite programming',\n",
              " 'federated accelerated stochastic gradient descent',\n",
              " 'robust density estimation besov ipm density estimation besov ipm losses',\n",
              " 'analytic theory shallow networks dynamics theory shallow networks dynamics hinge shallow networks dynamics hinge loss networks dynamics hinge loss classification',\n",
              " 'fixed support wasserstein barycenters computational support wasserstein barycenters computational hardness wasserstein barycenters computational hardness fast barycenters computational hardness fast algorithm',\n",
              " 'learning orient surfaces self supervised orient surfaces self supervised spherical surfaces self supervised spherical cnns',\n",
              " 'adam bandit sampling deep learning',\n",
              " 'parabolic approximation line search dnns',\n",
              " 'agnostic learning single neuron gradient learning single neuron gradient descent',\n",
              " 'statistical efficiency thompson sampling combinatorial efficiency thompson sampling combinatorial semi thompson sampling combinatorial semi bandits',\n",
              " 'analytic characterization hessian shallow relu characterization hessian shallow relu models hessian shallow relu models tale shallow relu models tale symmetry',\n",
              " 'generative causal explanations black box causal explanations black box classifiers',\n",
              " 'sub sampling efficient non parametric sampling efficient non parametric bandit efficient non parametric bandit exploration',\n",
              " 'learning model misspecification applications variational model misspecification applications variational ensemble misspecification applications variational ensemble methods',\n",
              " 'language prism spectral approach multiscale prism spectral approach multiscale language spectral approach multiscale language representations',\n",
              " 'dverge diversifying vulnerabilities enhanced robust diversifying vulnerabilities enhanced robust generation vulnerabilities enhanced robust generation ensembles',\n",
              " 'towards practical differentially private causal practical differentially private causal graph differentially private causal graph discovery',\n",
              " 'independent policy gradient methods competitive policy gradient methods competitive reinforcement gradient methods competitive reinforcement learning',\n",
              " 'value equivalence principle model based equivalence principle model based reinforcement principle model based reinforcement learning',\n",
              " 'structured convolutions efficient neural network convolutions efficient neural network design',\n",
              " 'latent world models intrinsically motivated world models intrinsically motivated exploration',\n",
              " 'estimating rank one spikes heavy rank one spikes heavy tailed one spikes heavy tailed noise spikes heavy tailed noise via heavy tailed noise via self tailed noise via self avoiding noise via self avoiding walks',\n",
              " 'policy improvement via imitation multiple improvement via imitation multiple oracles',\n",
              " 'training generative adversarial networks solving generative adversarial networks solving ordinary adversarial networks solving ordinary differential networks solving ordinary differential equations',\n",
              " 'learning discrete graphical models neural discrete graphical models neural networks',\n",
              " 'reppoints v2 verification meets regression v2 verification meets regression object verification meets regression object detection',\n",
              " 'unfolding alternating optimization blind super alternating optimization blind super resolution',\n",
              " 'entrywise convergence iterative methods eigenproblems',\n",
              " 'learning object centric representations multi object centric representations multi object centric representations multi object scenes representations multi object scenes multiple multi object scenes multiple views',\n",
              " '',\n",
              " 'self supervised co training video supervised co training video representation co training video representation learning',\n",
              " 'gradient estimation stochastic softmax tricks',\n",
              " 'meta learning requires meta augmentation',\n",
              " 'slip learning predict unknown dynamical learning predict unknown dynamical systems predict unknown dynamical systems long unknown dynamical systems long term dynamical systems long term memory',\n",
              " 'improving gan training probability ratio gan training probability ratio clipping training probability ratio clipping sample probability ratio clipping sample reweighting',\n",
              " 'bayesian bits unifying quantization pruning',\n",
              " '',\n",
              " 'gaussian process bandit optimization thermodynamic process bandit optimization thermodynamic variational bandit optimization thermodynamic variational objective',\n",
              " 'minilm deep self attention distillation deep self attention distillation task self attention distillation task agnostic attention distillation task agnostic compression distillation task agnostic compression pre task agnostic compression pre trained agnostic compression pre trained transformers',\n",
              " 'optimal epoch stochastic gradient descent epoch stochastic gradient descent ascent stochastic gradient descent ascent methods gradient descent ascent methods min descent ascent methods min max ascent methods min max optimization',\n",
              " 'woodbury transformations deep generative flows',\n",
              " '',\n",
              " 'gradient surgery multi task learning',\n",
              " 'bayesian probabilistic numerical integration tree probabilistic numerical integration tree based numerical integration tree based models',\n",
              " 'deep learning versus kernel learning learning versus kernel learning empirical versus kernel learning empirical study kernel learning empirical study loss learning empirical study loss landscape empirical study loss landscape geometry study loss landscape geometry time loss landscape geometry time evolution landscape geometry time evolution neural geometry time evolution neural tangent time evolution neural tangent kernel',\n",
              " 'graph meta learning via local meta learning via local subgraphs',\n",
              " 'stochastic deep gaussian processes graphs',\n",
              " 'bayesian causal structural learning zero causal structural learning zero inflated structural learning zero inflated poisson learning zero inflated poisson bayesian zero inflated poisson bayesian networks',\n",
              " 'evaluating attribution graph neural networks',\n",
              " 'second order behaviour augmented neural order behaviour augmented neural odes',\n",
              " 'neuron shapley discovering responsible neurons',\n",
              " '',\n",
              " 'gpu accelerated primal learning extremely accelerated primal learning extremely fast primal learning extremely fast large learning extremely fast large scale extremely fast large scale classification',\n",
              " '',\n",
              " '',\n",
              " 'neumiss networks differentiable programming supervised networks differentiable programming supervised learning differentiable programming supervised learning missing programming supervised learning missing values',\n",
              " 'revisiting parameter sharing automatic neural parameter sharing automatic neural channel sharing automatic neural channel number automatic neural channel number search',\n",
              " 'differentially private federated linear bandits',\n",
              " 'plug in solver sample efficient in solver sample efficient feature solver sample efficient feature based sample efficient feature based reinforcement efficient feature based reinforcement learning',\n",
              " 'learning physical graph representations visual physical graph representations visual scenes',\n",
              " 'deep graph pose semi supervised graph pose semi supervised deep pose semi supervised deep graphical semi supervised deep graphical model supervised deep graphical model improved deep graphical model improved animal graphical model improved animal pose model improved animal pose tracking',\n",
              " 'meta learning tasks heterogeneous attribute learning tasks heterogeneous attribute spaces',\n",
              " 'estimating decision tree learnability polylogarithmic decision tree learnability polylogarithmic sample tree learnability polylogarithmic sample complexity',\n",
              " 'sparse symplectically integrated neural networks',\n",
              " 'continuous object representation networks novel object representation networks novel view representation networks novel view synthesis networks novel view synthesis without novel view synthesis without target view synthesis without target view synthesis without target view supervision',\n",
              " 'multimodal generative learning utilizing jensen generative learning utilizing jensen shannon learning utilizing jensen shannon divergence',\n",
              " 'solver in the loop learning in the loop learning differentiable the loop learning differentiable physics loop learning differentiable physics interact learning differentiable physics interact iterative differentiable physics interact iterative pde physics interact iterative pde solvers',\n",
              " 'reinforcement learning general value function learning general value function approximation general value function approximation provably value function approximation provably efficient function approximation provably efficient approach approximation provably efficient approach via provably efficient approach via bounded efficient approach via bounded eluder approach via bounded eluder dimension',\n",
              " 'predicting training time without training',\n",
              " 'interaction affect interpretable attribution feature affect interpretable attribution feature interactions',\n",
              " 'optimal adaptive electrode selection maximize adaptive electrode selection maximize simultaneously electrode selection maximize simultaneously recorded selection maximize simultaneously recorded neuron maximize simultaneously recorded neuron yield',\n",
              " 'neurosymbolic reinforcement learning formally verified reinforcement learning formally verified exploration',\n",
              " 'wavelet flow fast training high flow fast training high resolution fast training high resolution normalizing training high resolution normalizing flows',\n",
              " 'multi task batch reinforcement learning task batch reinforcement learning metric batch reinforcement learning metric learning',\n",
              " '1 n neural representation robustness',\n",
              " 'boundary thickness robustness learning models',\n",
              " 'demixed shared component analysis neural shared component analysis neural population component analysis neural population data analysis neural population data multiple neural population data multiple brain population data multiple brain areas',\n",
              " 'learning kernel tests without data kernel tests without data splitting',\n",
              " 'unsupervised data augmentation consistency training',\n",
              " 'subgroup based rank 1 lattice based rank 1 lattice quasi rank 1 lattice quasi monte 1 lattice quasi monte carlo',\n",
              " 'minibatch vs local sgd heterogeneous vs local sgd heterogeneous distributed local sgd heterogeneous distributed learning',\n",
              " 'multi task causal learning gaussian task causal learning gaussian processes',\n",
              " 'proximity operator matrix perspective function operator matrix perspective function applications',\n",
              " 'generative 3d part assembly via 3d part assembly via dynamic part assembly via dynamic graph assembly via dynamic graph learning',\n",
              " 'improving natural language processing tasks natural language processing tasks human language processing tasks human gaze processing tasks human gaze guided tasks human gaze guided neural human gaze guided neural attention',\n",
              " 'power comparisons actively learning linear comparisons actively learning linear classifiers',\n",
              " 'boltzmann machines neural networks back',\n",
              " 'crush optimism pessimism structured bandits optimism pessimism structured bandits beyond pessimism structured bandits beyond asymptotic structured bandits beyond asymptotic optimality',\n",
              " 'pruning neural networks without data neural networks without data iteratively networks without data iteratively conserving without data iteratively conserving synaptic data iteratively conserving synaptic flow',\n",
              " 'detecting interactions neural networks via interactions neural networks via topological neural networks via topological analysis',\n",
              " 'neural bridge sampling evaluating safety bridge sampling evaluating safety critical sampling evaluating safety critical autonomous evaluating safety critical autonomous systems',\n",
              " 'interpretable personalized apprenticeship scheduling learning personalized apprenticeship scheduling learning interpretable apprenticeship scheduling learning interpretable scheduling scheduling learning interpretable scheduling policies learning interpretable scheduling policies heterogeneous interpretable scheduling policies heterogeneous user scheduling policies heterogeneous user demonstrations',\n",
              " 'task agnostic online reinforcement learning agnostic online reinforcement learning infinite online reinforcement learning infinite mixture reinforcement learning infinite mixture gaussian learning infinite mixture gaussian processes',\n",
              " 'benchmarking deep learning interpretability time deep learning interpretability time series learning interpretability time series predictions',\n",
              " '',\n",
              " 'de randomized smoothing certifiable defense randomized smoothing certifiable defense patch smoothing certifiable defense patch attacks',\n",
              " 'smyrf efficient attention using asymmetric efficient attention using asymmetric clustering',\n",
              " 'introducing routing uncertainty capsule networks',\n",
              " 'simple efficient smoothing method faster efficient smoothing method faster optimization smoothing method faster optimization local method faster optimization local exploration',\n",
              " 'hyperparameter ensembles robustness uncertainty quantification',\n",
              " 'neutralizing self selection bias sampling self selection bias sampling sortition',\n",
              " 'convergence smooth regularized approximate value smooth regularized approximate value iteration regularized approximate value iteration schemes',\n",
              " 'off policy evaluation via regularized policy evaluation via regularized lagrangian',\n",
              " 'loca regret consistent metric evaluate regret consistent metric evaluate model consistent metric evaluate model based metric evaluate model based behavior evaluate model based behavior reinforcement model based behavior reinforcement learning',\n",
              " '',\n",
              " 'towards scalable bayesian learning causal scalable bayesian learning causal dags',\n",
              " 'dictionary approach domain invariant learning approach domain invariant learning deep domain invariant learning deep networks',\n",
              " '',\n",
              " 'large scale adversarial training vision scale adversarial training vision and adversarial training vision and language training vision and language representation vision and language representation learning',\n",
              " 'relu networks suffer ell 2 networks suffer ell 2 adversarial suffer ell 2 adversarial perturbations',\n",
              " 'compositional visual generation energy based visual generation energy based models',\n",
              " '',\n",
              " 'erdos goes neural unsupervised learning goes neural unsupervised learning framework neural unsupervised learning framework combinatorial unsupervised learning framework combinatorial optimization learning framework combinatorial optimization graphs',\n",
              " '',\n",
              " 'debiasing distributed second order optimization distributed second order optimization surrogate second order optimization surrogate sketching order optimization surrogate sketching scaled optimization surrogate sketching scaled regularization',\n",
              " 'neural controlled differential equations irregular controlled differential equations irregular time differential equations irregular time series',\n",
              " '',\n",
              " 'correctness automatic differentiation non differentiable automatic differentiation non differentiable functions',\n",
              " 'probabilistic linear solvers machine learning',\n",
              " 'dynamic regret policy optimization non regret policy optimization non stationary policy optimization non stationary environments',\n",
              " 'multipole graph neural operator parametric graph neural operator parametric partial neural operator parametric partial differential operator parametric partial differential equations',\n",
              " 'blockgan learning 3d object aware learning 3d object aware scene 3d object aware scene representations object aware scene representations unlabelled aware scene representations unlabelled images',\n",
              " '',\n",
              " 'learning strategic network emergence games',\n",
              " 'towards interpretable natural language understanding interpretable natural language understanding explanations natural language understanding explanations latent language understanding explanations latent variables',\n",
              " 'mean squared error double q squared error double q learning',\n",
              " 'makes good views contrastive learning',\n",
              " '',\n",
              " 'barking right tree approach search right tree approach search molecule tree approach search molecule synthesis approach search molecule synthesis dags',\n",
              " 'uniform convergence low norm interpolation convergence low norm interpolation learning',\n",
              " 'bandit samplers training graph neural samplers training graph neural networks',\n",
              " 'sampling k dpp without looking k dpp without looking items',\n",
              " 'uncovering topology time varying fmri topology time varying fmri data time varying fmri data using varying fmri data using cubical fmri data using cubical persistence',\n",
              " 'hierarchical poset decoding compositional generalization poset decoding compositional generalization language',\n",
              " 'evaluating rewarding teamwork using cooperative rewarding teamwork using cooperative game teamwork using cooperative game abstractions',\n",
              " 'exchangeable neural ode set modeling',\n",
              " 'profile entropy fundamental measure learnability entropy fundamental measure learnability compressibility fundamental measure learnability compressibility distributions',\n",
              " 'coadnet collaborative aggregation and distribution collaborative aggregation and distribution networks aggregation and distribution networks co and distribution networks co salient distribution networks co salient object networks co salient object detection',\n",
              " 'regularized linear autoencoders recover principal linear autoencoders recover principal components autoencoders recover principal components eventually',\n",
              " 'semi supervised partial label learning supervised partial label learning via partial label learning via confidence label learning via confidence rated learning via confidence rated margin via confidence rated margin maximization',\n",
              " 'gramgan deep 3d texture synthesis deep 3d texture synthesis 2d 3d texture synthesis 2d exemplars',\n",
              " 'uwsod toward fully supervised level toward fully supervised level capacity fully supervised level capacity weakly supervised level capacity weakly supervised level capacity weakly supervised object capacity weakly supervised object detection',\n",
              " 'learning restricted boltzmann machines sparse restricted boltzmann machines sparse latent boltzmann machines sparse latent variables',\n",
              " 'sample complexity asynchronous q learning complexity asynchronous q learning sharper asynchronous q learning sharper analysis q learning sharper analysis variance learning sharper analysis variance reduction',\n",
              " 'curriculum learning multilevel budgeted combinatorial learning multilevel budgeted combinatorial problems',\n",
              " 'fedsplit algorithmic framework fast federated algorithmic framework fast federated optimization',\n",
              " 'estimation imputation probabilistic principal component imputation probabilistic principal component analysis probabilistic principal component analysis missing principal component analysis missing random component analysis missing random data',\n",
              " '',\n",
              " '',\n",
              " 'nonconvex sparse graph learning laplacian sparse graph learning laplacian constrained graph learning laplacian constrained graphical learning laplacian constrained graphical model',\n",
              " 'synthetic data generators sequential private',\n",
              " 'uncertainty quantification inferring hawkes networks',\n",
              " '',\n",
              " 'auxiliary task reweighting minimum data task reweighting minimum data learning',\n",
              " 'small nash equilibrium certificates large nash equilibrium certificates large games',\n",
              " 'training linear finite state machines',\n",
              " 'efficient active learning sparse halfspaces active learning sparse halfspaces arbitrary learning sparse halfspaces arbitrary bounded sparse halfspaces arbitrary bounded noise',\n",
              " 'swapping autoencoder deep image manipulation',\n",
              " 'self supervised few shot learning supervised few shot learning point few shot learning point clouds',\n",
              " 'faster differentially private samplers via differentially private samplers via r private samplers via r nyi samplers via r nyi divergence via r nyi divergence analysis r nyi divergence analysis discretized nyi divergence analysis discretized langevin divergence analysis discretized langevin mcmc',\n",
              " 'learning identifiable interpretable latent models identifiable interpretable latent models high interpretable latent models high dimensional latent models high dimensional neural models high dimensional neural activity high dimensional neural activity using dimensional neural activity using pi neural activity using pi vae',\n",
              " 'rl unplugged suite benchmarks offline unplugged suite benchmarks offline reinforcement suite benchmarks offline reinforcement learning',\n",
              " 'dual reducing estimation error transition reducing estimation error transition matrix estimation error transition matrix label error transition matrix label noise transition matrix label noise learning',\n",
              " 'interior point solving lp based point solving lp based prediction solving lp based prediction optimisation',\n",
              " 'simple normative network approximates local normative network approximates local non network approximates local non hebbian approximates local non hebbian learning local non hebbian learning cortex',\n",
              " 'kernelized information bottleneck leads biologically information bottleneck leads biologically plausible bottleneck leads biologically plausible 3 leads biologically plausible 3 factor biologically plausible 3 factor hebbian plausible 3 factor hebbian learning 3 factor hebbian learning deep factor hebbian learning deep networks',\n",
              " 'understanding role training regimes continual role training regimes continual learning',\n",
              " '',\n",
              " 'training stronger baselines learning optimize',\n",
              " 'exactly computing local lipschitz constant computing local lipschitz constant relu local lipschitz constant relu networks',\n",
              " 'strictly batch imitation learning energy batch imitation learning energy based imitation learning energy based distribution learning energy based distribution matching',\n",
              " 'ergodicity bias asymptotic normality randomized bias asymptotic normality randomized midpoint asymptotic normality randomized midpoint sampling normality randomized midpoint sampling method',\n",
              " 'single loop smoothed gradient descent loop smoothed gradient descent ascent smoothed gradient descent ascent algorithm gradient descent ascent algorithm nonconvex descent ascent algorithm nonconvex concave ascent algorithm nonconvex concave min algorithm nonconvex concave min max nonconvex concave min max problems',\n",
              " 'generating correct answers progressive matrices correct answers progressive matrices intelligence answers progressive matrices intelligence tests',\n",
              " 'hynet learning local descriptor hybrid learning local descriptor hybrid similarity local descriptor hybrid similarity measure descriptor hybrid similarity measure triplet hybrid similarity measure triplet loss',\n",
              " 'preference learning along multiple criteria learning along multiple criteria game along multiple criteria game theoretic multiple criteria game theoretic perspective',\n",
              " 'multi plane program induction 3d plane program induction 3d box program induction 3d box priors',\n",
              " 'online neural connectivity estimation noisy neural connectivity estimation noisy group connectivity estimation noisy group testing',\n",
              " 'once for all adversarial training for all adversarial training in all adversarial training in situ adversarial training in situ tradeoff training in situ tradeoff robustness in situ tradeoff robustness accuracy situ tradeoff robustness accuracy free',\n",
              " 'implicit neural representations periodic activation neural representations periodic activation functions',\n",
              " '',\n",
              " 'community detection sparse time evolving detection sparse time evolving graphs sparse time evolving graphs dynamical time evolving graphs dynamical bethe evolving graphs dynamical bethe hessian',\n",
              " 'simple principled uncertainty estimation deterministic principled uncertainty estimation deterministic deep uncertainty estimation deterministic deep learning estimation deterministic deep learning via deterministic deep learning via distance deep learning via distance awareness',\n",
              " 'adaptive learning rank one models learning rank one models efficient rank one models efficient pairwise one models efficient pairwise sequence models efficient pairwise sequence alignment',\n",
              " 'hierarchical nucleation deep neural networks',\n",
              " 'fourier features let networks learn features let networks learn high let networks learn high frequency networks learn high frequency functions learn high frequency functions low high frequency functions low dimensional frequency functions low dimensional domains',\n",
              " '',\n",
              " 'differentiable augmentation data efficient gan augmentation data efficient gan training',\n",
              " '',\n",
              " 'learning certified individually fair representations',\n",
              " 'part dependent label noise towards dependent label noise towards instance label noise towards instance dependent noise towards instance dependent label towards instance dependent label noise',\n",
              " 'tackling objective inconsistency problem heterogeneous objective inconsistency problem heterogeneous federated inconsistency problem heterogeneous federated optimization',\n",
              " 'improved analysis variance reduced policy analysis variance reduced policy gradient variance reduced policy gradient natural reduced policy gradient natural policy policy gradient natural policy gradient gradient natural policy gradient methods',\n",
              " '',\n",
              " 'automatic curriculum learning value disagreement',\n",
              " 'mri banding removal via adversarial banding removal via adversarial training',\n",
              " '',\n",
              " 'language visual entity relationship graph visual entity relationship graph agent entity relationship graph agent navigation',\n",
              " 'icam interpretable classification via disentangled interpretable classification via disentangled representations classification via disentangled representations feature via disentangled representations feature attribution disentangled representations feature attribution mapping',\n",
              " 'spectra conjugate kernel neural tangent conjugate kernel neural tangent kernel kernel neural tangent kernel linear neural tangent kernel linear width tangent kernel linear width neural kernel linear width neural networks',\n",
              " 'no regret learning dynamics extensive regret learning dynamics extensive form learning dynamics extensive form correlated dynamics extensive form correlated equilibrium',\n",
              " 'estimating weighted areas roc curve',\n",
              " 'implicit bias explain generalization stochastic bias explain generalization stochastic convex explain generalization stochastic convex optimization generalization stochastic convex optimization case stochastic convex optimization case study',\n",
              " '',\n",
              " '',\n",
              " 'boosting adversarial training hypersphere embedding',\n",
              " 'beyond homophily graph neural networks homophily graph neural networks current graph neural networks current limitations neural networks current limitations effective networks current limitations effective designs',\n",
              " 'modeling continuous stochastic processes dynamic continuous stochastic processes dynamic normalizing stochastic processes dynamic normalizing flows',\n",
              " 'efficient online learning optimal rankings online learning optimal rankings dimensionality learning optimal rankings dimensionality reduction optimal rankings dimensionality reduction via rankings dimensionality reduction via gradient dimensionality reduction via gradient descent',\n",
              " 'training normalizing flows information bottleneck normalizing flows information bottleneck competitive flows information bottleneck competitive generative information bottleneck competitive generative classification',\n",
              " 'detecting hands recognizing physical contact hands recognizing physical contact wild',\n",
              " 'theory transfer learning importance task transfer learning importance task diversity',\n",
              " 'finite time analysis round robin time analysis round robin kullback analysis round robin kullback leibler round robin kullback leibler upper robin kullback leibler upper confidence kullback leibler upper confidence bounds leibler upper confidence bounds optimal upper confidence bounds optimal adaptive confidence bounds optimal adaptive allocation bounds optimal adaptive allocation multiple optimal adaptive allocation multiple plays adaptive allocation multiple plays markovian allocation multiple plays markovian rewards',\n",
              " 'neural star domain primitive representation',\n",
              " 'off policy interval estimation lipschitz policy interval estimation lipschitz value interval estimation lipschitz value iteration',\n",
              " 'inverse rational control partially observable rational control partially observable continuous control partially observable continuous nonlinear partially observable continuous nonlinear dynamics',\n",
              " '',\n",
              " 'distributionally robust parametric maximum likelihood robust parametric maximum likelihood estimation',\n",
              " 'secretary online matching problems machine online matching problems machine learned matching problems machine learned advice',\n",
              " '',\n",
              " 'overfitting harmless basis pursuit degree',\n",
              " 'improving generalization reinforcement learning mixture generalization reinforcement learning mixture regularization',\n",
              " 'pontryagin differentiable programming end to differentiable programming end to end programming end to end learning end to end learning control to end learning control framework',\n",
              " '',\n",
              " 'devil detail framework macroscopic prediction detail framework macroscopic prediction via framework macroscopic prediction via microscopic macroscopic prediction via microscopic models',\n",
              " '',\n",
              " 'demystifying orthogonal monte carlo beyond',\n",
              " 'optimal robustness consistency trade offs robustness consistency trade offs learning consistency trade offs learning augmented trade offs learning augmented online offs learning augmented online algorithms',\n",
              " 'scalable approach privacy preserving collaborative approach privacy preserving collaborative machine privacy preserving collaborative machine learning',\n",
              " 'glow tts generative flow text tts generative flow text to generative flow text to speech flow text to speech via text to speech via monotonic to speech via monotonic alignment speech via monotonic alignment search',\n",
              " '',\n",
              " 'cycle contrast self supervised video contrast self supervised video representation self supervised video representation learning',\n",
              " 'posterior re calibration imbalanced datasets',\n",
              " 'novelty search representational space sample search representational space sample efficient representational space sample efficient exploration',\n",
              " 'robust reinforcement learning via adversarial reinforcement learning via adversarial training learning via adversarial training langevin via adversarial training langevin dynamics',\n",
              " '',\n",
              " 'online algorithms multi shop ski algorithms multi shop ski rental multi shop ski rental machine shop ski rental machine learned ski rental machine learned advice',\n",
              " 'multi label contrastive predictive coding',\n",
              " 'rotation invariant local to global invariant local to global representation local to global representation learning to global representation learning 3d global representation learning 3d point representation learning 3d point cloud',\n",
              " '',\n",
              " 'one solution need few shot solution need few shot extrapolation need few shot extrapolation via few shot extrapolation via structured shot extrapolation via structured maxent extrapolation via structured maxent rl',\n",
              " 'variational bayesian monte carlo noisy bayesian monte carlo noisy likelihoods',\n",
              " 'finite sample analysis contractive stochastic sample analysis contractive stochastic approximation analysis contractive stochastic approximation using contractive stochastic approximation using smooth stochastic approximation using smooth convex approximation using smooth convex envelopes',\n",
              " 'self supervised generative adversarial compression',\n",
              " 'efficient nonconvex reformulation stagewise convex nonconvex reformulation stagewise convex optimization reformulation stagewise convex optimization problems',\n",
              " '',\n",
              " 'adversarial distributional training robust deep distributional training robust deep learning',\n",
              " 'meta learning stationary stochastic process learning stationary stochastic process prediction stationary stochastic process prediction convolutional stochastic process prediction convolutional neural process prediction convolutional neural processes',\n",
              " 'theory inspired path regularized differential inspired path regularized differential network path regularized differential network architecture regularized differential network architecture search',\n",
              " 'conic descent application memory efficient descent application memory efficient optimization application memory efficient optimization positive memory efficient optimization positive semidefinite efficient optimization positive semidefinite matrices',\n",
              " 'learning geometry wave based imaging',\n",
              " 'greedy inference structure exploiting lazy inference structure exploiting lazy maps',\n",
              " 'nimble lightweight parallel gpu task lightweight parallel gpu task scheduling parallel gpu task scheduling deep gpu task scheduling deep learning',\n",
              " 'finding homology decision boundaries active homology decision boundaries active learning',\n",
              " 'reinforced molecular optimization neighborhood controlled molecular optimization neighborhood controlled grammars',\n",
              " 'natural policy gradient primal dual policy gradient primal dual method gradient primal dual method constrained primal dual method constrained markov dual method constrained markov decision method constrained markov decision processes',\n",
              " 'classification misspecification halfspaces generalized linear misspecification halfspaces generalized linear models halfspaces generalized linear models evolvability',\n",
              " 'certified defense image transformations via defense image transformations via randomized image transformations via randomized smoothing',\n",
              " '',\n",
              " 'reparameterizing mirror descent gradient descent',\n",
              " 'general control functions causal effect control functions causal effect estimation functions causal effect estimation ivs',\n",
              " 'optimal algorithms stochastic multi armed algorithms stochastic multi armed bandits stochastic multi armed bandits heavy multi armed bandits heavy tailed armed bandits heavy tailed rewards',\n",
              " 'certified robustness graph convolution networks robustness graph convolution networks graph graph convolution networks graph classification convolution networks graph classification topological networks graph classification topological attacks',\n",
              " 'zero resource knowledge grounded dialogue resource knowledge grounded dialogue generation',\n",
              " 'targeted adversarial perturbations monocular depth adversarial perturbations monocular depth prediction',\n",
              " 'beyond mean field structured deep mean field structured deep gaussian field structured deep gaussian processes structured deep gaussian processes improve deep gaussian processes improve predictive gaussian processes improve predictive uncertainties',\n",
              " 'offline imitation learning misspecified simulator',\n",
              " 'multi fidelity bayesian optimization via fidelity bayesian optimization via deep bayesian optimization via deep neural optimization via deep neural networks',\n",
              " 'plangan model based planning sparse model based planning sparse rewards based planning sparse rewards multiple planning sparse rewards multiple goals',\n",
              " 'bad global minima exist sgd global minima exist sgd reach',\n",
              " 'optimal prediction number unseen species prediction number unseen species multiplicity',\n",
              " 'characterizing optimal mixed policies intervene optimal mixed policies intervene observe',\n",
              " '',\n",
              " 'closer look accuracy vs robustness',\n",
              " 'curriculum learning dynamic instance hardness',\n",
              " '',\n",
              " 'learning execute programs instruction pointer execute programs instruction pointer attention programs instruction pointer attention graph instruction pointer attention graph neural pointer attention graph neural networks',\n",
              " 'autoprivacy automated layer wise parameter automated layer wise parameter selection layer wise parameter selection secure wise parameter selection secure neural parameter selection secure neural network selection secure neural network inference',\n",
              " '',\n",
              " 'characterizing emergent representations space candidate emergent representations space candidate learning representations space candidate learning rules space candidate learning rules deep candidate learning rules deep networks',\n",
              " 'fast accurate simple models tabular accurate simple models tabular data simple models tabular data via models tabular data via augmented tabular data via augmented distillation',\n",
              " 'adaptive probing policies shortest path probing policies shortest path routing',\n",
              " 'approximate heavily constrained learning lagrange heavily constrained learning lagrange multiplier constrained learning lagrange multiplier models',\n",
              " 'faster randomized infeasible interior point randomized infeasible interior point methods infeasible interior point methods tall interior point methods tall wide point methods tall wide linear methods tall wide linear programs',\n",
              " 'sliding window algorithms k clustering window algorithms k clustering problems',\n",
              " 'adashare learning share efficient deep learning share efficient deep multi share efficient deep multi task efficient deep multi task learning',\n",
              " 'approximate cross validation structured models',\n",
              " 'exemplar vae linking generative models vae linking generative models nearest linking generative models nearest neighbor generative models nearest neighbor retrieval models nearest neighbor retrieval data nearest neighbor retrieval data augmentation',\n",
              " '',\n",
              " 'ucsg net unsupervised discovering constructive net unsupervised discovering constructive solid unsupervised discovering constructive solid geometry discovering constructive solid geometry tree',\n",
              " '',\n",
              " 'cot gan generating sequential data gan generating sequential data via generating sequential data via causal sequential data via causal optimal data via causal optimal transport',\n",
              " 'impossibility results grammar compressed linear results grammar compressed linear algebra',\n",
              " 'understanding spiking networks convex optimization',\n",
              " 'better full matrix regret via full matrix regret via parameter matrix regret via parameter free regret via parameter free online via parameter free online learning',\n",
              " 'large scale methods distributionally robust scale methods distributionally robust optimization',\n",
              " 'analysis design thompson sampling stochastic design thompson sampling stochastic partial thompson sampling stochastic partial monitoring',\n",
              " '',\n",
              " 'refactoring policy compositional generalizability using policy compositional generalizability using self compositional generalizability using self supervised generalizability using self supervised object using self supervised object proposals',\n",
              " '',\n",
              " 'theoretical insights multiclass classification high insights multiclass classification high dimensional multiclass classification high dimensional asymptotic classification high dimensional asymptotic view',\n",
              " '',\n",
              " 'residual distillation towards portable deep distillation towards portable deep neural towards portable deep neural networks portable deep neural networks without deep neural networks without shortcuts',\n",
              " 'provably efficient neural estimation structural efficient neural estimation structural equation neural estimation structural equation models estimation structural equation models adversarial structural equation models adversarial approach',\n",
              " 'security analysis safe seldonian reinforcement analysis safe seldonian reinforcement learning safe seldonian reinforcement learning algorithms',\n",
              " 'learning play sequential games versus play sequential games versus unknown sequential games versus unknown opponents',\n",
              " 'analysis outlier detection deep generative outlier detection deep generative models',\n",
              " 'bridging imagination reality model based imagination reality model based deep reality model based deep reinforcement model based deep reinforcement learning',\n",
              " 'neural networks learning memorization almost networks learning memorization almost over learning memorization almost over parameterization',\n",
              " 'exploiting higher order smoothness derivative higher order smoothness derivative free order smoothness derivative free optimization smoothness derivative free optimization continuous derivative free optimization continuous bandits',\n",
              " 'towards combinatorial characterization bounded memory combinatorial characterization bounded memory learning',\n",
              " 'chaos extremism optimism volume analysis extremism optimism volume analysis learning optimism volume analysis learning games',\n",
              " '',\n",
              " 'matrix completion hierarchical graph side completion hierarchical graph side information',\n",
              " 'long horizon rl difficult short horizon rl difficult short horizon rl difficult short horizon rl',\n",
              " 'hamiltonian monte carlo using adjoint monte carlo using adjoint differentiated carlo using adjoint differentiated laplace using adjoint differentiated laplace approximation adjoint differentiated laplace approximation bayesian differentiated laplace approximation bayesian inference laplace approximation bayesian inference latent approximation bayesian inference latent gaussian bayesian inference latent gaussian models inference latent gaussian models beyond',\n",
              " 'adversarial learning robust deep clustering',\n",
              " '',\n",
              " 'learning learn variational semantic memory',\n",
              " '',\n",
              " '',\n",
              " 'towards safe policy improvement non safe policy improvement non stationary policy improvement non stationary mdps',\n",
              " 'finer metagenomic reconstruction via biodiversity metagenomic reconstruction via biodiversity optimization',\n",
              " 'causal discovery physical systems videos',\n",
              " 'glyph fast accurately training deep fast accurately training deep neural accurately training deep neural networks training deep neural networks encrypted deep neural networks encrypted data',\n",
              " 'smoothed analysis online differentially private analysis online differentially private learning',\n",
              " 'self paced deep reinforcement learning',\n",
              " 'kalman filtering attention user behavior filtering attention user behavior modeling attention user behavior modeling ctr user behavior modeling ctr prediction',\n",
              " 'towards maximizing representation gap in maximizing representation gap in domain representation gap in domain out gap in domain out of in domain out of distribution domain out of distribution examples',\n",
              " 'fully convolutional mesh autoencoder using convolutional mesh autoencoder using efficient mesh autoencoder using efficient spatially autoencoder using efficient spatially varying using efficient spatially varying kernels',\n",
              " 'gnnguard defending graph neural networks defending graph neural networks adversarial graph neural networks adversarial attacks',\n",
              " 'geo pifu geometry pixel aligned pifu geometry pixel aligned implicit geometry pixel aligned implicit functions pixel aligned implicit functions single aligned implicit functions single view implicit functions single view human functions single view human reconstruction',\n",
              " 'optimal visual search based model visual search based model target search based model target detectability based model target detectability natural model target detectability natural images',\n",
              " 'towards convergence rate analysis random convergence rate analysis random forests rate analysis random forests classification',\n",
              " 'list decodable mean estimation via decodable mean estimation via iterative mean estimation via iterative multi estimation via iterative multi filtering',\n",
              " 'exact recovery mangled clusters same recovery mangled clusters same cluster mangled clusters same cluster queries',\n",
              " 'steady state analysis episodic reinforcement state analysis episodic reinforcement learning',\n",
              " 'direct feedback alignment scales modern feedback alignment scales modern deep alignment scales modern deep learning scales modern deep learning tasks modern deep learning tasks architectures',\n",
              " '',\n",
              " 'minimax bounds generalized linear models',\n",
              " 'projection robust wasserstein distance riemannian robust wasserstein distance riemannian optimization',\n",
              " 'coindice off policy confidence interval off policy confidence interval estimation',\n",
              " 'simple fast algorithm binary integer fast algorithm binary integer online algorithm binary integer online linear binary integer online linear programming',\n",
              " 'learning diverse discriminative representations via diverse discriminative representations via principle discriminative representations via principle maximal representations via principle maximal coding via principle maximal coding rate principle maximal coding rate reduction',\n",
              " '',\n",
              " 'color visual illusions statistics based visual illusions statistics based computational illusions statistics based computational model',\n",
              " 'retrieval augmented generation knowledge intensive augmented generation knowledge intensive nlp generation knowledge intensive nlp tasks',\n",
              " 'universal guarantees decision tree induction guarantees decision tree induction via decision tree induction via higher tree induction via higher order induction via higher order splitting via higher order splitting criterion',\n",
              " 'trade offs guarantees adversarial representation offs guarantees adversarial representation learning guarantees adversarial representation learning information adversarial representation learning information obfuscation',\n",
              " 'boolean task algebra reinforcement learning',\n",
              " '',\n",
              " 'optimal learning verified training data',\n",
              " 'online linear optimization many hints',\n",
              " 'dynamical mean field theory stochastic mean field theory stochastic gradient field theory stochastic gradient descent theory stochastic gradient descent gaussian stochastic gradient descent gaussian mixture gradient descent gaussian mixture classification',\n",
              " 'causal discovery soft interventions unknown discovery soft interventions unknown targets soft interventions unknown targets characterization interventions unknown targets characterization learning',\n",
              " 'exploiting surrogate gap online multiclass surrogate gap online multiclass classification',\n",
              " 'pitfalls simplicity bias neural networks',\n",
              " 'automatically learning compact quality aware learning compact quality aware surrogates compact quality aware surrogates optimization quality aware surrogates optimization problems',\n",
              " '',\n",
              " 'q learning graph networks learn learning graph networks learn generalizable graph networks learn generalizable branching networks learn generalizable branching heuristic learn generalizable branching heuristic sat generalizable branching heuristic sat solver',\n",
              " 'non reversible gaussian processes identifying reversible gaussian processes identifying latent gaussian processes identifying latent dynamical processes identifying latent dynamical structure identifying latent dynamical structure neural latent dynamical structure neural data',\n",
              " 'listening sounds silence speech denoising',\n",
              " 'boxe box embedding model knowledge box embedding model knowledge base embedding model knowledge base completion',\n",
              " 'coherent hierarchical multi label classification hierarchical multi label classification networks',\n",
              " 'walsh hadamard variational inference bayesian hadamard variational inference bayesian deep variational inference bayesian deep learning',\n",
              " 'federated bayesian optimization via thompson bayesian optimization via thompson sampling',\n",
              " 'multion benchmarking semantic map memory benchmarking semantic map memory using semantic map memory using multi map memory using multi object memory using multi object navigation',\n",
              " '',\n",
              " 'optimal iterative sketching methods subsampled iterative sketching methods subsampled randomized sketching methods subsampled randomized hadamard methods subsampled randomized hadamard transform',\n",
              " 'provably adaptive reinforcement learning metric adaptive reinforcement learning metric spaces',\n",
              " 'shapeflow learnable deformation flows among learnable deformation flows among 3d deformation flows among 3d shapes',\n",
              " 'self supervised learning cross modal supervised learning cross modal audio learning cross modal audio video cross modal audio video clustering',\n",
              " 'optimal query complexity secure stochastic query complexity secure stochastic convex complexity secure stochastic convex optimization',\n",
              " 'dynabert dynamic bert adaptive width dynamic bert adaptive width depth',\n",
              " 'generalization bound gradient descent non bound gradient descent non convex gradient descent non convex metric descent non convex metric learning',\n",
              " '',\n",
              " '',\n",
              " 'approximate cross validation low rank cross validation low rank data validation low rank data high low rank data high dimensions',\n",
              " 'ganspace discovering interpretable gan controls',\n",
              " 'differentiable expected hypervolume improvement parallel expected hypervolume improvement parallel multi hypervolume improvement parallel multi objective improvement parallel multi objective bayesian parallel multi objective bayesian optimization',\n",
              " 'neuron level structured pruning using level structured pruning using polarization structured pruning using polarization regularizer',\n",
              " 'limits testing structural changes ising testing structural changes ising models',\n",
              " 'field wise learning multi field wise learning multi field categorical learning multi field categorical data',\n",
              " 'continual learning low rank orthogonal learning low rank orthogonal subspaces',\n",
              " 'unsupervised learning visual features contrasting learning visual features contrasting cluster visual features contrasting cluster assignments',\n",
              " 'sharpened generalization bounds based conditional generalization bounds based conditional mutual bounds based conditional mutual information based conditional mutual information application conditional mutual information application noisy mutual information application noisy iterative information application noisy iterative algorithms',\n",
              " 'learning deformable tetrahedral meshes 3d deformable tetrahedral meshes 3d reconstruction',\n",
              " 'information theoretic limits learning sparse theoretic limits learning sparse rule',\n",
              " 'self supervised learning eyes child',\n",
              " 'unsupervised semantic aggregation deformable template semantic aggregation deformable template matching aggregation deformable template matching semi deformable template matching semi supervised template matching semi supervised learning',\n",
              " 'game theoretic analysis networked system theoretic analysis networked system control analysis networked system control common networked system control common pool system control common pool resource control common pool resource management common pool resource management using pool resource management using multi resource management using multi agent management using multi agent reinforcement using multi agent reinforcement learning',\n",
              " 'shapes feature representations exploring datasets feature representations exploring datasets architectures representations exploring datasets architectures training',\n",
              " 'optimal best arm identification linear best arm identification linear bandits',\n",
              " 'data diversification simple strategy neural diversification simple strategy neural machine simple strategy neural machine translation',\n",
              " 'interstellar searching recurrent architecture knowledge searching recurrent architecture knowledge graph recurrent architecture knowledge graph embedding',\n",
              " '',\n",
              " 'learning multi agent coordination enhancing multi agent coordination enhancing target agent coordination enhancing target coverage coordination enhancing target coverage directional enhancing target coverage directional sensor target coverage directional sensor networks',\n",
              " 'biological credit assignment dynamic inversion credit assignment dynamic inversion feedforward assignment dynamic inversion feedforward networks',\n",
              " 'discriminative sounding objects localization via sounding objects localization via self objects localization via self supervised localization via self supervised audiovisual via self supervised audiovisual matching',\n",
              " 'learning multi agent communication structured multi agent communication structured attentive agent communication structured attentive reasoning',\n",
              " 'private identity testing high dimensional identity testing high dimensional distributions',\n",
              " 'optimal weighted ell 2 regularization weighted ell 2 regularization overparameterized ell 2 regularization overparameterized linear 2 regularization overparameterized linear regression',\n",
              " 'efficient asynchronous method integrating evolutionary asynchronous method integrating evolutionary gradient method integrating evolutionary gradient based integrating evolutionary gradient based policy evolutionary gradient based policy search',\n",
              " 'metasdf meta learning signed distance meta learning signed distance functions',\n",
              " 'simple scalable sparse k means scalable sparse k means clustering sparse k means clustering via k means clustering via feature means clustering via feature ranking',\n",
              " 'model based adversarial meta reinforcement based adversarial meta reinforcement learning',\n",
              " 'graph policy network transferable active policy network transferable active learning network transferable active learning graphs',\n",
              " 'towards better global loss landscape better global loss landscape gans',\n",
              " 'weighted qmix expanding monotonic value qmix expanding monotonic value function expanding monotonic value function factorisation monotonic value function factorisation deep value function factorisation deep multi function factorisation deep multi agent factorisation deep multi agent reinforcement deep multi agent reinforcement learning',\n",
              " 'banditpam almost linear time k almost linear time k medoids linear time k medoids clustering time k medoids clustering via k medoids clustering via multi medoids clustering via multi armed clustering via multi armed bandits',\n",
              " 'udh universal deep hiding steganography universal deep hiding steganography watermarking deep hiding steganography watermarking light hiding steganography watermarking light field steganography watermarking light field messaging',\n",
              " 'evidential sparsification multimodal latent spaces sparsification multimodal latent spaces conditional multimodal latent spaces conditional variational latent spaces conditional variational autoencoders',\n",
              " 'unbiased risk estimator learning augmented risk estimator learning augmented classes',\n",
              " 'autobss efficient algorithm block stacking efficient algorithm block stacking style algorithm block stacking style search',\n",
              " 'pushing limits narrow precision inferencing limits narrow precision inferencing cloud narrow precision inferencing cloud scale precision inferencing cloud scale microsoft inferencing cloud scale microsoft floating cloud scale microsoft floating point',\n",
              " 'stochastic optimization laggard data pipelines',\n",
              " 'self supervised auxiliary learning meta supervised auxiliary learning meta paths auxiliary learning meta paths heterogeneous learning meta paths heterogeneous graphs',\n",
              " 'gps net graph based photometric net graph based photometric stereo graph based photometric stereo network',\n",
              " 'consistent structural relation learning zero structural relation learning zero shot relation learning zero shot segmentation',\n",
              " 'model selection contextual stochastic bandit selection contextual stochastic bandit problems',\n",
              " 'truncated linear regression high dimensions',\n",
              " 'incorporating pragmatic reasoning communication emergent pragmatic reasoning communication emergent language',\n",
              " 'deep subspace clustering data augmentation',\n",
              " 'empirical process approach union bound process approach union bound practical approach union bound practical algorithms union bound practical algorithms combinatorial bound practical algorithms combinatorial linear practical algorithms combinatorial linear bandits',\n",
              " 'graph neural networks count substructures',\n",
              " 'bayesian perspective training speed model perspective training speed model selection',\n",
              " '',\n",
              " 'doubly robust off policy value robust off policy value gradient off policy value gradient estimation policy value gradient estimation deterministic value gradient estimation deterministic policies',\n",
              " 'provably efficient neural gtd off efficient neural gtd off policy neural gtd off policy learning',\n",
              " 'learning discrete energy based models discrete energy based models via energy based models via auxiliary based models via auxiliary variable models via auxiliary variable local via auxiliary variable local exploration',\n",
              " 'stable expressive recurrent vision models',\n",
              " 'entropic optimal transport unbalanced gaussian optimal transport unbalanced gaussian measures transport unbalanced gaussian measures closed unbalanced gaussian measures closed form',\n",
              " 'brp nas prediction based nas nas prediction based nas using prediction based nas using gcns',\n",
              " 'deep shells unsupervised shape correspondence shells unsupervised shape correspondence optimal unsupervised shape correspondence optimal transport',\n",
              " 'ista nas efficient consistent neural nas efficient consistent neural architecture efficient consistent neural architecture search consistent neural architecture search sparse neural architecture search sparse coding',\n",
              " 'rel3d minimally contrastive benchmark grounding minimally contrastive benchmark grounding spatial contrastive benchmark grounding spatial relations benchmark grounding spatial relations 3d',\n",
              " 'regularizing black box models improved black box models improved interpretability',\n",
              " 'trust model confident masked model model confident masked model based confident masked model based actor masked model based actor critic',\n",
              " 'semi supervised neural architecture search',\n",
              " 'consistency regularization certified robustness smoothed regularization certified robustness smoothed classifiers',\n",
              " 'robust multi agent reinforcement learning multi agent reinforcement learning model agent reinforcement learning model uncertainty',\n",
              " 'siri spatial relation induced network spatial relation induced network spatial relation induced network spatial description induced network spatial description resolution',\n",
              " 'adaptive shrinkage estimation streaming graphs',\n",
              " 'make one shot video object one shot video object segmentation shot video object segmentation efficient',\n",
              " '',\n",
              " '',\n",
              " 'constraining variational inference geometric jensen variational inference geometric jensen shannon inference geometric jensen shannon divergence',\n",
              " '',\n",
              " 'hm ann efficient billion point ann efficient billion point nearest efficient billion point nearest neighbor billion point nearest neighbor search point nearest neighbor search heterogeneous nearest neighbor search heterogeneous memory',\n",
              " 'frugalml use ml prediction apis use ml prediction apis accurately ml prediction apis accurately cheaply',\n",
              " 'sharp representation theorems relu networks representation theorems relu networks precise theorems relu networks precise dependence relu networks precise dependence depth',\n",
              " 'shared experience actor critic multi experience actor critic multi agent actor critic multi agent reinforcement critic multi agent reinforcement learning',\n",
              " '',\n",
              " 'lift lockdown global covid 19 lockdown global covid 19 scenario global covid 19 scenario analysis covid 19 scenario analysis policy 19 scenario analysis policy assessment scenario analysis policy assessment using analysis policy assessment using compartmental policy assessment using compartmental gaussian assessment using compartmental gaussian processes',\n",
              " 'unsupervised learning lagrangian dynamics images learning lagrangian dynamics images prediction lagrangian dynamics images prediction control',\n",
              " 'high dimensional sparse linear bandits',\n",
              " 'non stochastic control bandit feedback',\n",
              " 'generalized leverage score sampling neural leverage score sampling neural networks',\n",
              " 'optimal elimination algorithm learning best elimination algorithm learning best arm',\n",
              " 'efficient projection free algorithms saddle projection free algorithms saddle point free algorithms saddle point problems',\n",
              " 'mathematical model automatic differentiation machine model automatic differentiation machine learning',\n",
              " 'unsupervised text generation learning search',\n",
              " 'learning compositional rules via neural compositional rules via neural program rules via neural program synthesis',\n",
              " 'incorporating bert parallel sequence decoding bert parallel sequence decoding adapters',\n",
              " 'estimating fluctuations neural representations uncertain fluctuations neural representations uncertain environments',\n",
              " 'discover hallucinate adapt open compound hallucinate adapt open compound domain adapt open compound domain adaptation open compound domain adaptation semantic compound domain adaptation semantic segmentation',\n",
              " 'surf simple universal robust fast simple universal robust fast distribution universal robust fast distribution learning robust fast distribution learning algorithm',\n",
              " 'understanding approximate fisher information fast approximate fisher information fast convergence fisher information fast convergence natural information fast convergence natural gradient fast convergence natural gradient descent convergence natural gradient descent wide natural gradient descent wide neural gradient descent wide neural networks',\n",
              " 'general transportability soft interventions completeness transportability soft interventions completeness results',\n",
              " 'gait prop biologically plausible learning prop biologically plausible learning rule biologically plausible learning rule derived plausible learning rule derived backpropagation learning rule derived backpropagation error',\n",
              " 'lipschitz bounds provably robust training bounds provably robust training laplacian provably robust training laplacian smoothing',\n",
              " 'scop scientific control reliable neural scientific control reliable neural network control reliable neural network pruning',\n",
              " 'provably consistent partial label learning',\n",
              " 'robust accurate stochastic optimization variational accurate stochastic optimization variational inference',\n",
              " 'discovering conflicting groups signed networks',\n",
              " 'learning popular gaussian graphical models popular gaussian graphical models without gaussian graphical models without condition graphical models without condition number models without condition number bounds',\n",
              " 'sense sensitivity analysis simple post sensitivity analysis simple post hoc analysis simple post hoc analysis simple post hoc analysis bias post hoc analysis bias due hoc analysis bias due unobserved analysis bias due unobserved confounding',\n",
              " 'mix match optimistic tree search match optimistic tree search approach optimistic tree search approach learning tree search approach learning models search approach learning models mixture approach learning models mixture distributions',\n",
              " 'understanding double descent requires fine double descent requires fine grained descent requires fine grained bias requires fine grained bias variance fine grained bias variance decomposition',\n",
              " 'vime extending success self semi extending success self semi supervised success self semi supervised learning self semi supervised learning tabular semi supervised learning tabular domain',\n",
              " '',\n",
              " 'decentralized parallel algorithm training generative parallel algorithm training generative adversarial algorithm training generative adversarial nets',\n",
              " 'phase retrieval high dimensions statistical retrieval high dimensions statistical computational high dimensions statistical computational phase dimensions statistical computational phase transitions',\n",
              " '',\n",
              " 'hybrid variance reduced sgd algorithms variance reduced sgd algorithms minimax reduced sgd algorithms minimax problems sgd algorithms minimax problems nonconvex algorithms minimax problems nonconvex linear minimax problems nonconvex linear function',\n",
              " 'belief dependent macro action discovery dependent macro action discovery pomdps macro action discovery pomdps using action discovery pomdps using value discovery pomdps using value information',\n",
              " 'soft contrastive learning visual localization',\n",
              " 'fine grained dynamic head object grained dynamic head object detection',\n",
              " 'loco local contrastive representation learning',\n",
              " 'modeling optimization trade off meta optimization trade off meta learning',\n",
              " '',\n",
              " '',\n",
              " 'stage wise conservative linear bandits',\n",
              " 'relate physically plausible multi object physically plausible multi object scene plausible multi object scene synthesis multi object scene synthesis using object scene synthesis using structured scene synthesis using structured latent synthesis using structured latent spaces',\n",
              " 'metric free individual fairness online free individual fairness online learning',\n",
              " 'greedyfool distortion aware sparse adversarial distortion aware sparse adversarial attack',\n",
              " 'vaem deep generative model heterogeneous deep generative model heterogeneous mixed generative model heterogeneous mixed type model heterogeneous mixed type data',\n",
              " 'retroxpert decompose retrosynthesis prediction like decompose retrosynthesis prediction like chemist',\n",
              " 'sample efficient optimization latent space efficient optimization latent space deep optimization latent space deep generative latent space deep generative models space deep generative models via deep generative models via weighted generative models via weighted retraining',\n",
              " 'improved sample complexity incremental autonomous sample complexity incremental autonomous exploration complexity incremental autonomous exploration mdps',\n",
              " 'tinytl reduce memory parameters efficient reduce memory parameters efficient on memory parameters efficient on device parameters efficient on device learning',\n",
              " 'rd 2 reward decomposition representation 2 reward decomposition representation decomposition',\n",
              " 'self paced contrastive learning hybrid paced contrastive learning hybrid memory contrastive learning hybrid memory domain learning hybrid memory domain adaptive hybrid memory domain adaptive object memory domain adaptive object re domain adaptive object re id',\n",
              " 'fairness constraints help exact inference constraints help exact inference structured help exact inference structured prediction',\n",
              " 'instance based generalization reinforcement learning',\n",
              " 'smooth consistent probabilistic regression trees',\n",
              " 'computing valid p value optimal valid p value optimal changepoint p value optimal changepoint selective value optimal changepoint selective inference optimal changepoint selective inference using changepoint selective inference using dynamic selective inference using dynamic programming',\n",
              " 'factorized neural processes neural processes neural processes neural processes k processes neural processes k shot neural processes k shot prediction processes k shot prediction neural k shot prediction neural responses',\n",
              " '',\n",
              " 'adversarial robustness via robust low robustness via robust low rank via robust low rank representations',\n",
              " '',\n",
              " 'compositional generalization learning analytical expressions',\n",
              " 'jax md framework differentiable physics',\n",
              " 'implicit function learning approach parametric function learning approach parametric modal learning approach parametric modal regression',\n",
              " 'sdf srn learning signed distance srn learning signed distance 3d learning signed distance 3d object signed distance 3d object reconstruction distance 3d object reconstruction static 3d object reconstruction static images',\n",
              " 'coresets robust training deep neural robust training deep neural networks training deep neural networks noisy deep neural networks noisy labels',\n",
              " '',\n",
              " 'convergence meta learning task specific meta learning task specific adaptation learning task specific adaptation partial task specific adaptation partial parameters',\n",
              " 'metaperturb transferable regularizer heterogeneous tasks transferable regularizer heterogeneous tasks architectures',\n",
              " 'learning solve tv regularised problems solve tv regularised problems unrolled tv regularised problems unrolled algorithms',\n",
              " 'object centric learning slot attention',\n",
              " 'improving robustness common corruptions covariate robustness common corruptions covariate shift common corruptions covariate shift adaptation',\n",
              " 'deep smoothing implied volatility surface',\n",
              " 'probabilistic inference algebraic constraints theoretical inference algebraic constraints theoretical limits algebraic constraints theoretical limits practical constraints theoretical limits practical approximations',\n",
              " 'provable online cp parafac decomposition online cp parafac decomposition structured cp parafac decomposition structured tensor parafac decomposition structured tensor via decomposition structured tensor via dictionary structured tensor via dictionary learning',\n",
              " 'look ahead meta learning continual ahead meta learning continual learning',\n",
              " 'polynomial time algorithm learning nonparametric time algorithm learning nonparametric causal algorithm learning nonparametric causal graphs',\n",
              " '',\n",
              " '',\n",
              " 'identifying causal effect inference failure causal effect inference failure uncertainty effect inference failure uncertainty aware inference failure uncertainty aware models',\n",
              " '',\n",
              " 'deep active inference agents using active inference agents using monte inference agents using monte carlo agents using monte carlo methods',\n",
              " 'consistent estimation identifiable nonparametric mixture estimation identifiable nonparametric mixture models identifiable nonparametric mixture models grouped nonparametric mixture models grouped observations',\n",
              " '',\n",
              " 'adaptive learned bloom filter ada learned bloom filter ada bf bloom filter ada bf efficient filter ada bf efficient utilization ada bf efficient utilization classifier bf efficient utilization classifier application efficient utilization classifier application real utilization classifier application real time classifier application real time information application real time information filtering real time information filtering web',\n",
              " 'mcunet tiny deep learning iot tiny deep learning iot devices',\n",
              " '',\n",
              " 'task agnostic exploration reinforcement learning',\n",
              " 'multi task additive models robust task additive models robust estimation additive models robust estimation automatic models robust estimation automatic structure robust estimation automatic structure discovery',\n",
              " 'provably efficient reward agnostic navigation efficient reward agnostic navigation linear reward agnostic navigation linear value agnostic navigation linear value iteration',\n",
              " 'softmax deep double deterministic policy deep double deterministic policy gradients',\n",
              " 'online decision based visual tracking decision based visual tracking via based visual tracking via reinforcement visual tracking via reinforcement learning',\n",
              " 'efficient marginalization discrete structured latent marginalization discrete structured latent variables discrete structured latent variables via structured latent variables via sparsity',\n",
              " 'deepi2i enabling deep hierarchical image enabling deep hierarchical image to deep hierarchical image to image hierarchical image to image translation image to image translation transferring to image translation transferring gans',\n",
              " 'distributional robustness ipms links regularization robustness ipms links regularization gans',\n",
              " '',\n",
              " 'csi novelty detection via contrastive novelty detection via contrastive learning detection via contrastive learning distributionally via contrastive learning distributionally shifted contrastive learning distributionally shifted instances',\n",
              " 'learning implicit credit assignment cooperative implicit credit assignment cooperative multi credit assignment cooperative multi agent assignment cooperative multi agent reinforcement cooperative multi agent reinforcement learning',\n",
              " 'mate plugging model awareness task plugging model awareness task embedding model awareness task embedding meta awareness task embedding meta learning',\n",
              " 'restless ucb efficient low complexity ucb efficient low complexity algorithm efficient low complexity algorithm online low complexity algorithm online restless complexity algorithm online restless bandits',\n",
              " 'predictive information accelerates learning rl',\n",
              " 'robust heavy tailed mean estimation heavy tailed mean estimation made tailed mean estimation made simple mean estimation made simple via estimation made simple via regret made simple via regret minimization',\n",
              " 'high fidelity generative image compression',\n",
              " 'statistical mechanics framework task agnostic mechanics framework task agnostic sample framework task agnostic sample design task agnostic sample design machine agnostic sample design machine learning',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRN9P98zRXU-"
      },
      "source": [
        "#### Remove Redundant Word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2KOSbo-RWng"
      },
      "source": [
        "# Program without using any external library\n",
        "s = 'neural methods point methods point wise point wise dependency wise dependency estimation'\n",
        "\n",
        "def remove_duplicate_word(s):\n",
        "  l = s.split()\n",
        "  k = []\n",
        "  for i in l:\n",
        "      # If condition is used to store unique string \n",
        "      # in another list 'k' \n",
        "      if (s.count(i)>1 and (i not in k) or s.count(i)==1):\n",
        "          k.append(i)\n",
        "  #print(' '.join(k))\n",
        "  return ' '.join(k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgn5QwNFS-we"
      },
      "source": [
        "for i in range(len(topic_list)):\n",
        "  topic_list[i] = remove_duplicate_word(topic_list[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoewYEHRTUCh",
        "outputId": "b8cc1c41-4994-4e57-9910-f5b6a9e30056"
      },
      "source": [
        "topic_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " 'unsupervised information theoretic perceptual quality metric',\n",
              " 'self supervised multimodal versatile networks',\n",
              " 'benchmarking deep inverse models time neural adjoint method',\n",
              " 'off policy evaluation learning external validity covariate shift',\n",
              " 'neural methods point wise dependency estimation',\n",
              " 'fast flexible temporal point processes triangular maps',\n",
              " 'backpropagating linearly improves transferability adversarial examples',\n",
              " 'pyglove symbolic programming automated machine learning',\n",
              " 'fourier sparse leverage scores approximate kernel learning',\n",
              " 'improved algorithms online submodular maximization via first order regret bounds',\n",
              " 'synbols probing learning algorithms synthetic datasets',\n",
              " 'adversarially robust streaming algorithms via differential privacy',\n",
              " 'trading personalization accuracy data debugging collaborative filtering',\n",
              " 'cascaded text generation markov transformers',\n",
              " 'improving local identifiability probabilistic box embeddings',\n",
              " 'permute and flip new mechanism differentially private selection',\n",
              " 'deep reconstruction strange attractors time series',\n",
              " 'reciprocal adversarial learning via characteristic functions',\n",
              " 'statistical guarantees distributed nearest neighbor classification',\n",
              " 'stein self repulsive dynamics benefits past samples',\n",
              " 'statistical complexity early stopped mirror descent',\n",
              " 'algorithmic recourse imperfect causal knowledge probabilistic approach',\n",
              " 'quantitative propagation chaos sgd wide neural networks',\n",
              " 'causal view robustness neural networks',\n",
              " 'minimax classification 0 1 loss performance guarantees',\n",
              " 'learn useful critic model based action gradient estimator policy optimization',\n",
              " '',\n",
              " 'learning composable energy surrogates pde order reduction',\n",
              " 'efficient contextual bandits continuous actions',\n",
              " 'achieving equalized odds resampling sensitive attributes',\n",
              " 'multi robot collision avoidance uncertainty probabilistic safety barrier certificates',\n",
              " 'hard shape constrained kernel machines',\n",
              " 'closer look training strategy modern meta learning',\n",
              " 'value out of distribution testing example goodhart s law',\n",
              " 'generalised bayesian filtering via sequential monte carlo',\n",
              " 'deterministic approximation submodular maximization matroid nearly linear time',\n",
              " 'flows simultaneous manifold learning density estimation',\n",
              " 'simultaneous preference metric learning paired comparisons',\n",
              " 'efficient variational inference sparse deep learning theoretical guarantee',\n",
              " 'learning manifold implicitly via explicit heat kernel',\n",
              " 'deep relational topic modeling via graph poisson gamma belief network',\n",
              " 'one bit supervision image classification',\n",
              " '',\n",
              " '',\n",
              " 'neural networks recurrent generative feedback',\n",
              " 'learning extrapolate knowledge transductive few shot out of graph link prediction',\n",
              " 'exploiting weakly supervised visual patterns learn partial annotations',\n",
              " 'improving inference neural image compression',\n",
              " 'neuron merging compensating pruned neurons',\n",
              " 'fixmatch simplifying semi supervised learning consistency confidence',\n",
              " 'reinforcement learning combinatorial actions application vehicle routing',\n",
              " 'towards playing full moba games deep reinforcement learning',\n",
              " 'rankmax adaptive projection alternative softmax function',\n",
              " 'online agnostic boosting via regret minimization',\n",
              " 'causal intervention weakly supervised semantic segmentation',\n",
              " '',\n",
              " 'over parameterized adversarial training analysis overcoming curse dimensionality',\n",
              " 'post training iterative hierarchical data augmentation deep networks',\n",
              " '',\n",
              " 'robust compressed sensing using generative models',\n",
              " 'fairness without demographics adversarially reweighted learning',\n",
              " 'stochastic latent actor critic deep reinforcement learning variable model',\n",
              " 'ridge rider finding diverse solutions following eigenvectors hessian',\n",
              " 'route chaos routing games price anarchy optimistic',\n",
              " 'online algorithm unsupervised sequential selection contextual information',\n",
              " '',\n",
              " 'went wrong instance wise feature importance time series black box models',\n",
              " 'towards better generalization adaptive gradient methods',\n",
              " 'learning guidance rewards trajectory space smoothing',\n",
              " 'variance reduction via accelerated dual averaging finite sum optimization',\n",
              " 'tree low dimensional hyperbolic embedding',\n",
              " 'deep structural causal models tractable counterfactual inference',\n",
              " 'convolutional generation textured 3d meshes',\n",
              " 'statistical framework low bitwidth training deep neural networks',\n",
              " 'better set representations relational reasoning',\n",
              " 'autosync learning synchronize data parallel distributed deep',\n",
              " '',\n",
              " 'hardness learning neural networks natural weights',\n",
              " 'higher order spectral clustering directed graphs',\n",
              " 'primal dual mesh convolutional neural networks',\n",
              " 'advantage conditional meta learning biased regularization fine tuning',\n",
              " 'watch motion blurring vision deep neural networks',\n",
              " 'sinkhorn barycenter via functional gradient descent',\n",
              " '',\n",
              " 'bayesian deep ensembles via neural tangent kernel',\n",
              " 'improved schemes episodic memory based lifelong learning',\n",
              " 'adaptive sampling stochastic risk averse learning',\n",
              " 'deep wiener deconvolution meets learning image deblurring',\n",
              " '',\n",
              " 'taming discrete integration via boon dimensionality',\n",
              " 'blind video temporal consistency via deep prior',\n",
              " 'simplify robustify negative sampling implicit collaborative filtering',\n",
              " 'model selection production system via automated online experiments',\n",
              " 'almost sure convergence stochastic gradient descent non convex problems',\n",
              " 'automatic perturbation analysis scalable certified robustness beyond',\n",
              " 'adaptation properties allow identification optimized neural codes',\n",
              " 'global convergence variance reduction class nonconvex nonconcave minimax problems',\n",
              " 'model based multi agent rl zero sum markov games near optimal sample complexity',\n",
              " 'conservative q learning offline reinforcement',\n",
              " 'online influence maximization linear threshold model',\n",
              " 'ensembling geophysical models bayesian neural networks',\n",
              " 'delving cyclic mechanism semi supervised video object segmentation',\n",
              " 'asymmetric shapley values incorporating causal knowledge model agnostic explainability',\n",
              " 'understanding deep architecture reasoning layer',\n",
              " 'planning markov decision processes gap dependent sample complexity',\n",
              " 'provably good batch off policy reinforcement learning without great exploration',\n",
              " 'detection regression certified object median smoothing',\n",
              " 'contextual reserve price optimization auctions via mixed integer programming',\n",
              " 'expandnets linear over parameterization train compact convolutional networks',\n",
              " '',\n",
              " 'implications local correlation learning deep functions',\n",
              " 'learning search efficiently causally near optimal treatments',\n",
              " 'game theoretic analysis additive adversarial attacks defenses',\n",
              " 'posterior network uncertainty estimation without ood samples via density based pseudo counts',\n",
              " '',\n",
              " 'no regret learning mixed nash equilibria mix',\n",
              " 'unifying view optimism episodic reinforcement learning',\n",
              " 'continuous submodular maximization beyond dr submodularity',\n",
              " 'asymptotically optimal primal dual incremental algorithm contextual linear bandits',\n",
              " 'assessing satnet s ability solve symbol grounding problem',\n",
              " 'bayesian nonparametrics view deep representations',\n",
              " 'similarity laplace neural tangent kernels',\n",
              " 'causal view compositional zero shot recognition',\n",
              " 'hippo recurrent memory optimal polynomial projections',\n",
              " '',\n",
              " 'castle regularization via auxiliary causal graph discovery',\n",
              " 'long tailed classification keeping good removing bad momentum causal effect',\n",
              " '',\n",
              " '',\n",
              " 're examining linear embeddings high dimensional bayesian optimization',\n",
              " 'unmodnet learning unwrap modulo image high dynamic range imaging',\n",
              " 'thunder fast coordinate selection solver sparse learning',\n",
              " 'neural networks fail learn periodic functions fix',\n",
              " '',\n",
              " 'correspondence learning via linearly invariant embedding',\n",
              " 'learning dispatch job shop scheduling via deep reinforcement',\n",
              " 'adaptive attacks adversarial example defenses',\n",
              " 'sinkhorn natural gradient generative models',\n",
              " 'online sinkhorn optimal transport distances sample streams',\n",
              " '',\n",
              " 'locally adaptive nonparametric online learning',\n",
              " 'compositional generalization via neural symbolic stack machines',\n",
              " 'graphon neural networks transferability graph',\n",
              " 'unreasonable effectiveness greedy algorithms multi armed bandit many arms',\n",
              " 'gamma models generative temporal difference learning infinite horizon prediction',\n",
              " '',\n",
              " 'neural mesh flow 3d manifold generation via diffeomorphic flows',\n",
              " 'statistical control spatio temporal meg eeg source imaging desparsified mutli task lasso',\n",
              " 'scalable mip based method learning optimal multivariate decision trees',\n",
              " 'efficient exact verification binarized neural networks',\n",
              " 'ultra low precision 4 bit training deep neural networks',\n",
              " 'bridging gap sample based one shot neural architecture search bonas',\n",
              " '',\n",
              " 'outlier robust mean estimation subgaussian rates via stability',\n",
              " '',\n",
              " 'information theoretic counterfactual learning missing not at random feedback',\n",
              " 'prophet attention predicting future',\n",
              " 'language models few shot learners',\n",
              " 'margins insufficient explaining gradient boosting',\n",
              " 'fourier transform based attribution priors improve interpretability stability deep learning models genomics',\n",
              " 'momentumrnn integrating momentum recurrent neural networks',\n",
              " 'marginal utility planning continuous large discrete action spaces',\n",
              " 'projected stein variational gradient descent',\n",
              " 'minimax lower bounds transfer learning linear one hidden layer neural networks',\n",
              " 'se 3 transformers 3d roto translation equivariant attention networks',\n",
              " 'equivalence molecular graph convolution wave function poor basis set',\n",
              " '',\n",
              " 'learning affordance landscapes interaction exploration 3d environments',\n",
              " 'cooperative multi player bandit optimization',\n",
              " 'tight first second order regret bounds adversarial linear bandits',\n",
              " 'pick sign optimizing deep multitask models gradient dropout',\n",
              " 'loss function generative neural networks based watson perceptual model',\n",
              " 'dynamic fusion eye movement data verbal narrations knowledge rich domains',\n",
              " 'scalable multi agent reinforcement learning networked systems average reward',\n",
              " 'optimizing neural networks via koopman operator theory',\n",
              " 'svgd kernelized wasserstein gradient flow chi squared divergence',\n",
              " 'adversarial robustness supervised sparse coding',\n",
              " 'differentiable meta learning bandit policies',\n",
              " 'biologically inspired mechanisms adversarial robustness',\n",
              " 'statistical query lower bounds via functional gradients',\n",
              " 'near optimal reinforcement learning self play',\n",
              " 'network diffusions via neural mean field dynamics',\n",
              " 'self distillation instance specific label smoothing',\n",
              " 'towards problem dependent optimal learning rates',\n",
              " 'cross lingual retrieval iterative self supervised training',\n",
              " 'rethinking pooling graph neural networks',\n",
              " '',\n",
              " 'gradient regularized v learning dynamic treatment regimes',\n",
              " 'faster wasserstein distance estimation sinkhorn divergence',\n",
              " '',\n",
              " 'robust recursive partitioning heterogeneous treatment effects uncertainty quantification',\n",
              " 'rescuing neural spike train models bad mle',\n",
              " 'lower bounds optimal algorithms personalized federated learning',\n",
              " 'black box certification randomized smoothing functional optimization based framework',\n",
              " 'deep imitation learning bimanual robotic manipulation',\n",
              " 'stationary activations uncertainty calibration deep learning',\n",
              " 'ensemble distillation robust model fusion federated learning',\n",
              " 'falcon fast spectral inference encrypted data',\n",
              " '',\n",
              " 'practical quasi newton methods training deep neural networks',\n",
              " 'approximation based variance reduction reparameterization gradients',\n",
              " 'inference stage optimization cross scenario 3d human pose estimation',\n",
              " 'consistent feature selection analytic deep neural networks',\n",
              " 'glance focus dynamic approach reducing spatial redundancy image classification',\n",
              " 'information maximization few shot learning',\n",
              " 'inverse reinforcement learning gradient based learner',\n",
              " 'bayesian multi type mean field agent imitation learning',\n",
              " 'bayesian robust optimization imitation learning',\n",
              " 'multiview neural surface reconstruction disentangling geometry appearance',\n",
              " '',\n",
              " 'attention gated brain propagation implement reward based error backpropagation',\n",
              " 'asymptotic guarantees generative modeling based smooth wasserstein distance',\n",
              " 'online robust regression via sgd l1 loss',\n",
              " 'prank motion prediction based ranking',\n",
              " 'fighting copycat agents behavioral cloning observation histories',\n",
              " 'tight nonparametric convergence rates stochastic gradient descent noiseless linear model',\n",
              " 'structured prediction conditional meta learning',\n",
              " 'optimal lottery tickets via subset sum logarithmic over parameterization sufficient',\n",
              " 'hateful memes challenge detecting hate speech multimodal',\n",
              " 'stochasticity deterministic gradient descent large learning rate multiscale objective function',\n",
              " 'identifying learning rules neural network observables',\n",
              " 'optimal approximation smoothness tradeoffs soft max functions',\n",
              " 'weakly supervised reinforcement learning controllable behavior',\n",
              " 'improving policy constrained kidney exchange via pre screening',\n",
              " 'learning abstract structure drawing efficient motor program induction',\n",
              " 'deep residual networks generalize better feedforward neural tangent kernel perspective',\n",
              " '',\n",
              " 'stochastic gradient descent correlated settings study gaussian processes',\n",
              " '',\n",
              " 'minimax value interval off policy evaluation optimization',\n",
              " 'biased stochastic first order methods conditional optimization applications meta learning',\n",
              " 'shiftaddnet hardware inspired deep network',\n",
              " 'network to translation conditional invertible neural networks',\n",
              " 'intra processing methods debiasing neural networks',\n",
              " 'finding second order stationary points efficiently smooth nonconvex linearly constrained optimization problems',\n",
              " 'model based policy optimization unsupervised adaptation',\n",
              " 'implicit regularization convergence weight normalization',\n",
              " 'geometric all way boolean tensor decomposition',\n",
              " '',\n",
              " 'a b testing dense large scale networks design inference',\n",
              " 'neural networks memorize discovering long tail via influence estimation',\n",
              " '',\n",
              " 'partial optimal tranport applications positive unlabeled learning',\n",
              " 'toward fundamental limits imitation learning',\n",
              " '',\n",
              " 'hold tight influence discriminative features deep network boundaries',\n",
              " 'learning mixtures private public populations',\n",
              " 'adversarial weight perturbation helps robust generalization',\n",
              " 'stateful posted pricing vanishing regret via dynamic deterministic markov decision processes',\n",
              " 'adversarial self supervised contrastive learning',\n",
              " 'normalizing kalman filters multivariate time series analysis',\n",
              " '',\n",
              " 'fourier spectrum discrepancies deep network generated images',\n",
              " 'lamina specific neuronal properties promote robust stable signal propagation feedforward networks',\n",
              " 'learning dynamic belief graphs generalize text based games',\n",
              " 'triple descent two kinds overfitting appear',\n",
              " 'multimodal graph networks compositional generalization visual question answering',\n",
              " 'learning graph structure finite state automaton layer',\n",
              " 'universal approximation theorem deep neural networks expressing probability distributions',\n",
              " 'unsupervised object centric video generation decomposition 3d',\n",
              " 'domain generalization medical imaging classification linear dependency regularization',\n",
              " 'multi label classification hamming loss subset accuracy really conflict',\n",
              " 'novel automated curriculum strategy solve hard sokoban planning instances',\n",
              " 'causal analysis covid 19 spread germany',\n",
              " 'locally private non asymptotic testing discrete distributions faster using interactive mechanisms',\n",
              " 'adaptive gradient quantization data parallel sgd',\n",
              " '',\n",
              " 'removing bias multi modal classifiers regularization maximizing functional entropies',\n",
              " 'compact task representations normative model higher order brain activity',\n",
              " 'robust adaptive control linear systems beyond quadratic costs',\n",
              " 'co exposure maximization online social networks',\n",
              " 'uclid net single view reconstruction object space',\n",
              " 'reinforcement learning control multiple frequencies',\n",
              " 'complex dynamics simple neural networks understanding gradient flow phase retrieval',\n",
              " 'neural message passing multi relational ordered recursive hypergraphs',\n",
              " 'unified view label shift estimation',\n",
              " 'optimal private median estimation minimal distributional assumptions',\n",
              " 'breaking communication privacy accuracy trilemma',\n",
              " 'audeo audio generation silent performance video',\n",
              " '',\n",
              " 'self distillation amplifies regularization hilbert space',\n",
              " 'coupling based invertible neural networks universal diffeomorphism approximators',\n",
              " 'community detection using fast low cardinality semidefinite programming',\n",
              " 'modeling noisy annotations crowd counting',\n",
              " 'operator view policy gradient methods',\n",
              " 'demystifying contrastive self supervised learning invariances augmentations dataset biases',\n",
              " 'online map inference determinantal point processes',\n",
              " 'video object segmentation adaptive feature bank uncertain region refinement',\n",
              " 'inferring learning rules animal decision making',\n",
              " 'input aware dynamic backdoor attack',\n",
              " 'hard distinguish graphs graph neural networks',\n",
              " 'minimax regret switching constrained online convex optimization phase transition',\n",
              " 'dual manifold adversarial robustness defense lp non attacks',\n",
              " 'cross scale internal graph neural network image super resolution',\n",
              " 'unsupervised representation learning invariance propagation',\n",
              " 'restoring negative information few shot object detection',\n",
              " 'adversarially robust imagenet models transfer better',\n",
              " 'robust correction sampling bias using cumulative distribution functions',\n",
              " 'personalized federated learning theoretical guarantees model agnostic meta approach',\n",
              " 'pixel level cycle association new perspective domain adaptive semantic segmentation',\n",
              " '',\n",
              " 'learning global transparent models consistent local contrastive explanations',\n",
              " '',\n",
              " 'diverse image captioning context object split latent spaces',\n",
              " 'learning disentangled representations videos missing data',\n",
              " '',\n",
              " 'continual learning node importance based adaptive group sparse regularization',\n",
              " 'towards crowdsourced training large neural networks using decentralized mixture of experts',\n",
              " 'bidirectional convolutional poisson gamma dynamical systems',\n",
              " '',\n",
              " 'ranking via sorting estimated expected utility',\n",
              " 'distribution free binary classification prediction sets confidence intervals calibration',\n",
              " 'closing dequantization gap pixelcnn single layer flow',\n",
              " 'sequence multi learning via conditional chain mapping mixture signals',\n",
              " 'variance reduction random coordinate descent langevin monte carlo',\n",
              " 'language cognitive tool imagine goals curiosity driven exploration',\n",
              " '',\n",
              " 'primal dual interpretation proximal stochastic gradient langevin algorithm',\n",
              " 'characterize landscape overparameterized convolutional neural networks',\n",
              " 'tightness semidefinite relaxations certifying robustness adversarial examples',\n",
              " '',\n",
              " 'rethinking pre training self',\n",
              " 'unsupervised sound separation using mixture invariant training',\n",
              " 'adaptive discretization model based reinforcement learning',\n",
              " 'codecmr cross modal retrieval function level binary source code matching',\n",
              " 'warm starting neural network training',\n",
              " 'dags fears closer look continuous optimization learning bayesian networks',\n",
              " 'ood maml meta learning few shot out of distribution detection classification',\n",
              " 'imitation observation approach transfer learning dynamics mismatch',\n",
              " '',\n",
              " 'learning discrete distributions infinite support',\n",
              " '',\n",
              " '',\n",
              " 'counterfactual data augmentation using locally factored dynamics',\n",
              " 'rethinking learnable tree filter generic feature transform',\n",
              " 'self supervised relational reasoning representation learning',\n",
              " 'sufficient dimension reduction classification using principal optimal transport direction',\n",
              " 'fast epigraphical projection based incremental algorithms wasserstein distributionally robust support vector machine',\n",
              " 'differentially private clustering tight approximation ratios',\n",
              " 'power louvain stochastic block model',\n",
              " 'fairness overlapping groups probabilistic perspective',\n",
              " 'attendlight universal attention based reinforcement learning model traffic signal control',\n",
              " 'searching low bit weights quantized neural networks',\n",
              " '',\n",
              " 'predictions decisions using lookahead regularization',\n",
              " 'sequential bayesian experimental design variable cost structure',\n",
              " 'predictive inference free jackknife after bootstrap',\n",
              " '',\n",
              " 'learning loss test time augmentation',\n",
              " 'balanced meta softmax long tailed visual recognition',\n",
              " 'efficient exploration reward functions inverse reinforcement learning via bayesian optimization',\n",
              " 'mdp homomorphic networks group symmetries reinforcement learning',\n",
              " 'explain empirical study deep neural network explanation methods',\n",
              " 'error resistance hinge loss minimization',\n",
              " '',\n",
              " 'object goal navigation using oriented semantic exploration',\n",
              " 'efficient semidefinite programming based inference binary multi class mrfs',\n",
              " 'funnel transformer filtering sequential redundancy efficient language processing',\n",
              " 'semantic visual navigation watching youtube videos',\n",
              " 'heavy tailed representations text polarity classification data augmentation',\n",
              " 'superloss generic loss robust curriculum learning',\n",
              " 'cogmol target specific selective drug design covid 19 using deep generative models',\n",
              " 'memory based trajectory conditioned policies learning sparse rewards',\n",
              " 'liberty depth deep bayesian neural nets need complex weight posterior approximations',\n",
              " 'improving sample complexity bounds natural actor critic algorithms',\n",
              " 'learning differential equations easy solve',\n",
              " 'stability stochastic gradient descent nonsmooth convex losses',\n",
              " 'influence augmented online planning complex environments',\n",
              " 'pac bayes learning bounds sample dependent priors',\n",
              " 'reward rational implicit choice unifying formalism learning',\n",
              " 'probabilistic time series forecasting shape temporal diversity',\n",
              " 'low distortion block resampling spatially stochastic networks',\n",
              " 'continual deep learning functional regularisation memorable past',\n",
              " 'distance encoding design provably powerful neural networks graph representation learning',\n",
              " '',\n",
              " 'unsupervised learning dense visual representations',\n",
              " 'higher order certification randomized smoothing',\n",
              " 'learning structured distributions untrusted batches faster simpler',\n",
              " '',\n",
              " 'diversity transferred output diversification white black box attacks',\n",
              " 'poly hoot monte carlo planning continuous space mdps non asymptotic analysis',\n",
              " '',\n",
              " 'variational policy gradient method reinforcement learning general utilities',\n",
              " 'reverse engineering recurrent neural network solutions hierarchical inference task mice',\n",
              " 'temporal positive unlabeled learning biomedical hypothesis generation via risk estimation',\n",
              " 'efficient low rank gaussian variational inference neural networks',\n",
              " 'privacy amplification via random check ins',\n",
              " 'probabilistic circuits variational inference discrete graphical models',\n",
              " 'classifier secretly suffice multi source domain adaptation',\n",
              " 'labelling unlabelled videos scratch multi modal self supervision',\n",
              " 'non asymptotic analysis stein variational gradient descent',\n",
              " 'robust meta learning mixed linear regression small batches',\n",
              " 'bayesian deep learning probabilistic perspective generalization',\n",
              " 'unsupervised learning object landmarks via self training correspondence',\n",
              " 'randomized tests high dimensional regression efficient powerful solution',\n",
              " 'learning representations audio visual spatial alignment',\n",
              " 'generative view synthesis single semantics novel images',\n",
              " 'towards practical adversarial attacks graph neural networks',\n",
              " 'multi task reinforcement learning soft modularization',\n",
              " 'causal shapley values exploiting knowledge explain individual predictions complex models',\n",
              " 'training dynamics deep networks l 2 regularization',\n",
              " 'improved algorithms convex concave minimax optimization',\n",
              " '',\n",
              " 'learning implicit functions topology varying dense 3d shape correspondence',\n",
              " 'deep multimodal fusion channel exchanging',\n",
              " 'hierarchically organized latent modules exploratory search morphogenetic systems',\n",
              " 'ai feynman 2 0 pareto optimal symbolic regression exploiting graph modularity',\n",
              " 'delay cooperation nonstochastic linear bandits',\n",
              " 'probabilistic orientation estimation matrix fisher distributions',\n",
              " 'minimax dynamics optimally balanced spiking networks excitatory inhibitory neurons',\n",
              " '',\n",
              " 'towards deeper graph neural networks differentiable group normalization',\n",
              " '',\n",
              " 'learning differentiable programs admissible neural heuristics',\n",
              " 'improved guarantees multiple descent curve column subset selection nystrom method',\n",
              " 'domain adaptation problem inference graphical models',\n",
              " 'network size weights memorization two layers neural networks',\n",
              " '',\n",
              " 'continual learning control primitives skill discovery via reset games',\n",
              " 'hoi analysis integrating decomposing human object interaction',\n",
              " 'strongly local p norm cut algorithms semi supervised learning graph clustering',\n",
              " '',\n",
              " '',\n",
              " 'neural dynamic policies end to sensorimotor learning',\n",
              " 'new inference approach training shallow deep generalized linear models noisy interacting neurons',\n",
              " 'decision making auto encoding variational bayes',\n",
              " 'attribution preservation network compression reliable interpretation',\n",
              " 'feature importance ranking deep learning',\n",
              " '',\n",
              " 'model inversion networks based optimization',\n",
              " 'hausdorff dimension heavy tails generalization neural networks',\n",
              " 'exact expressions double descent implicit regularization via surrogate random design',\n",
              " 'certifying confidence via randomized smoothing',\n",
              " 'learning physical constraints neural projections',\n",
              " 'robust optimization fairness noisy protected groups',\n",
              " 'noise contrastive estimation multivariate point processes',\n",
              " 'game theoretic analysis empirical revenue maximization algorithm endogenous sampling',\n",
              " 'neural path features kernel understanding role gates deep learning',\n",
              " '',\n",
              " 'sparse graphical memory robust planning',\n",
              " 'second order pac bayesian bounds weighted majority vote',\n",
              " '',\n",
              " 'modeling task effects meaning representation brain via zero shot meg prediction',\n",
              " 'counterfactual vision and language navigation unravelling unseen',\n",
              " 'robust quantization one model rule',\n",
              " 'enabling certification verification agnostic networks via memory efficient semidefinite programming',\n",
              " 'federated accelerated stochastic gradient descent',\n",
              " 'robust density estimation besov ipm losses',\n",
              " 'analytic theory shallow networks dynamics hinge loss classification',\n",
              " 'fixed support wasserstein barycenters computational hardness fast algorithm',\n",
              " 'learning orient surfaces self supervised spherical cnns',\n",
              " 'adam bandit sampling deep learning',\n",
              " 'parabolic approximation line search dnns',\n",
              " 'agnostic learning single neuron gradient descent',\n",
              " 'statistical efficiency thompson sampling combinatorial semi bandits',\n",
              " 'analytic characterization hessian shallow relu models tale symmetry',\n",
              " 'generative causal explanations black box classifiers',\n",
              " 'sub sampling efficient non parametric bandit exploration',\n",
              " 'learning model misspecification applications variational ensemble methods',\n",
              " 'language prism spectral approach multiscale representations',\n",
              " 'dverge diversifying vulnerabilities enhanced robust generation ensembles',\n",
              " 'towards practical differentially private causal graph discovery',\n",
              " 'independent policy gradient methods competitive reinforcement learning',\n",
              " 'value equivalence principle model based reinforcement learning',\n",
              " 'structured convolutions efficient neural network design',\n",
              " 'latent world models intrinsically motivated exploration',\n",
              " 'estimating rank one spikes heavy tailed noise via self avoiding walks',\n",
              " 'policy improvement via imitation multiple oracles',\n",
              " 'training generative adversarial networks solving ordinary differential equations',\n",
              " 'learning discrete graphical models neural networks',\n",
              " 'reppoints v2 verification meets regression object detection',\n",
              " 'unfolding alternating optimization blind super resolution',\n",
              " 'entrywise convergence iterative methods eigenproblems',\n",
              " 'learning object centric representations multi scenes multiple views',\n",
              " '',\n",
              " 'self supervised co training video representation learning',\n",
              " 'gradient estimation stochastic softmax tricks',\n",
              " 'meta learning requires augmentation',\n",
              " 'slip learning predict unknown dynamical systems long term memory',\n",
              " 'improving gan training probability ratio clipping sample reweighting',\n",
              " 'bayesian bits unifying quantization pruning',\n",
              " '',\n",
              " 'gaussian process bandit optimization thermodynamic variational objective',\n",
              " 'minilm deep self attention distillation task agnostic compression pre trained transformers',\n",
              " 'optimal epoch stochastic gradient descent ascent methods min max optimization',\n",
              " 'woodbury transformations deep generative flows',\n",
              " '',\n",
              " 'gradient surgery multi task learning',\n",
              " 'bayesian probabilistic numerical integration tree based models',\n",
              " 'deep learning versus kernel empirical study loss landscape geometry time evolution neural tangent',\n",
              " 'graph meta learning via local subgraphs',\n",
              " 'stochastic deep gaussian processes graphs',\n",
              " 'bayesian causal structural learning zero inflated poisson networks',\n",
              " 'evaluating attribution graph neural networks',\n",
              " 'second order behaviour augmented neural odes',\n",
              " 'neuron shapley discovering responsible neurons',\n",
              " '',\n",
              " 'gpu accelerated primal learning extremely fast large scale classification',\n",
              " '',\n",
              " '',\n",
              " 'neumiss networks differentiable programming supervised learning missing values',\n",
              " 'revisiting parameter sharing automatic neural channel number search',\n",
              " 'differentially private federated linear bandits',\n",
              " 'plug in solver sample efficient feature based reinforcement learning',\n",
              " 'learning physical graph representations visual scenes',\n",
              " 'deep graph pose semi supervised graphical model improved animal tracking',\n",
              " 'meta learning tasks heterogeneous attribute spaces',\n",
              " 'estimating decision tree learnability polylogarithmic sample complexity',\n",
              " 'sparse symplectically integrated neural networks',\n",
              " 'continuous object representation networks novel view synthesis without target supervision',\n",
              " 'multimodal generative learning utilizing jensen shannon divergence',\n",
              " 'solver in the loop learning differentiable physics interact iterative pde solvers',\n",
              " 'reinforcement learning general value function approximation provably efficient approach via bounded eluder dimension',\n",
              " 'predicting training time without',\n",
              " 'interaction affect interpretable attribution feature interactions',\n",
              " 'optimal adaptive electrode selection maximize simultaneously recorded neuron yield',\n",
              " 'neurosymbolic reinforcement learning formally verified exploration',\n",
              " 'wavelet flow fast training high resolution normalizing flows',\n",
              " 'multi task batch reinforcement learning metric',\n",
              " '1 n neural representation robustness',\n",
              " 'boundary thickness robustness learning models',\n",
              " 'demixed shared component analysis neural population data multiple brain areas',\n",
              " 'learning kernel tests without data splitting',\n",
              " 'unsupervised data augmentation consistency training',\n",
              " 'subgroup based rank 1 lattice quasi monte carlo',\n",
              " 'minibatch vs local sgd heterogeneous distributed learning',\n",
              " 'multi task causal learning gaussian processes',\n",
              " 'proximity operator matrix perspective function applications',\n",
              " 'generative 3d part assembly via dynamic graph learning',\n",
              " 'improving natural language processing tasks human gaze guided neural attention',\n",
              " 'power comparisons actively learning linear classifiers',\n",
              " 'boltzmann machines neural networks back',\n",
              " 'crush optimism pessimism structured bandits beyond asymptotic optimality',\n",
              " 'pruning neural networks without data iteratively conserving synaptic flow',\n",
              " 'detecting interactions neural networks via topological analysis',\n",
              " 'neural bridge sampling evaluating safety critical autonomous systems',\n",
              " 'interpretable personalized apprenticeship scheduling learning policies heterogeneous user demonstrations',\n",
              " 'task agnostic online reinforcement learning infinite mixture gaussian processes',\n",
              " 'benchmarking deep learning interpretability time series predictions',\n",
              " '',\n",
              " 'de randomized smoothing certifiable defense patch attacks',\n",
              " 'smyrf efficient attention using asymmetric clustering',\n",
              " 'introducing routing uncertainty capsule networks',\n",
              " 'simple efficient smoothing method faster optimization local exploration',\n",
              " 'hyperparameter ensembles robustness uncertainty quantification',\n",
              " 'neutralizing self selection bias sampling sortition',\n",
              " 'convergence smooth regularized approximate value iteration schemes',\n",
              " 'off policy evaluation via regularized lagrangian',\n",
              " 'loca regret consistent metric evaluate model based behavior reinforcement learning',\n",
              " '',\n",
              " 'towards scalable bayesian learning causal dags',\n",
              " 'dictionary approach domain invariant learning deep networks',\n",
              " '',\n",
              " 'large scale adversarial training vision and language representation learning',\n",
              " 'relu networks suffer ell 2 adversarial perturbations',\n",
              " 'compositional visual generation energy based models',\n",
              " '',\n",
              " 'erdos goes neural unsupervised learning framework combinatorial optimization graphs',\n",
              " '',\n",
              " 'debiasing distributed second order optimization surrogate sketching scaled regularization',\n",
              " 'neural controlled differential equations irregular time series',\n",
              " '',\n",
              " 'correctness automatic differentiation non differentiable functions',\n",
              " 'probabilistic linear solvers machine learning',\n",
              " 'dynamic regret policy optimization non stationary environments',\n",
              " 'multipole graph neural operator parametric partial differential equations',\n",
              " 'blockgan learning 3d object aware scene representations unlabelled images',\n",
              " '',\n",
              " 'learning strategic network emergence games',\n",
              " 'towards interpretable natural language understanding explanations latent variables',\n",
              " 'mean squared error double q learning',\n",
              " 'makes good views contrastive learning',\n",
              " '',\n",
              " 'barking right tree approach search molecule synthesis dags',\n",
              " 'uniform convergence low norm interpolation learning',\n",
              " 'bandit samplers training graph neural networks',\n",
              " 'sampling k dpp without looking items',\n",
              " 'uncovering topology time varying fmri data using cubical persistence',\n",
              " 'hierarchical poset decoding compositional generalization language',\n",
              " 'evaluating rewarding teamwork using cooperative game abstractions',\n",
              " 'exchangeable neural ode set modeling',\n",
              " 'profile entropy fundamental measure learnability compressibility distributions',\n",
              " 'coadnet collaborative aggregation and distribution networks co salient object detection',\n",
              " 'regularized linear autoencoders recover principal components eventually',\n",
              " 'semi supervised partial label learning via confidence rated margin maximization',\n",
              " 'gramgan deep 3d texture synthesis 2d exemplars',\n",
              " 'uwsod toward fully supervised level capacity weakly object detection',\n",
              " 'learning restricted boltzmann machines sparse latent variables',\n",
              " 'sample complexity asynchronous q learning sharper analysis variance reduction',\n",
              " 'curriculum learning multilevel budgeted combinatorial problems',\n",
              " 'fedsplit algorithmic framework fast federated optimization',\n",
              " 'estimation imputation probabilistic principal component analysis missing random data',\n",
              " '',\n",
              " '',\n",
              " 'nonconvex sparse graph learning laplacian constrained graphical model',\n",
              " 'synthetic data generators sequential private',\n",
              " 'uncertainty quantification inferring hawkes networks',\n",
              " '',\n",
              " 'auxiliary task reweighting minimum data learning',\n",
              " 'small nash equilibrium certificates large games',\n",
              " 'training linear finite state machines',\n",
              " 'efficient active learning sparse halfspaces arbitrary bounded noise',\n",
              " 'swapping autoencoder deep image manipulation',\n",
              " 'self supervised few shot learning point clouds',\n",
              " 'faster differentially private samplers via r nyi divergence analysis discretized langevin mcmc',\n",
              " 'learning identifiable interpretable latent models high dimensional neural activity using pi vae',\n",
              " 'rl unplugged suite benchmarks offline reinforcement learning',\n",
              " 'dual reducing estimation error transition matrix label noise learning',\n",
              " 'interior point solving lp based prediction optimisation',\n",
              " 'simple normative network approximates local non hebbian learning cortex',\n",
              " 'kernelized information bottleneck leads biologically plausible 3 factor hebbian learning deep networks',\n",
              " 'understanding role training regimes continual learning',\n",
              " '',\n",
              " 'training stronger baselines learning optimize',\n",
              " 'exactly computing local lipschitz constant relu networks',\n",
              " 'strictly batch imitation learning energy based distribution matching',\n",
              " 'ergodicity bias asymptotic normality randomized midpoint sampling method',\n",
              " 'single loop smoothed gradient descent ascent algorithm nonconvex concave min max problems',\n",
              " 'generating correct answers progressive matrices intelligence tests',\n",
              " 'hynet learning local descriptor hybrid similarity measure triplet loss',\n",
              " 'preference learning along multiple criteria game theoretic perspective',\n",
              " 'multi plane program induction 3d box priors',\n",
              " 'online neural connectivity estimation noisy group testing',\n",
              " 'once for all adversarial training in situ tradeoff robustness accuracy free',\n",
              " 'implicit neural representations periodic activation functions',\n",
              " '',\n",
              " 'community detection sparse time evolving graphs dynamical bethe hessian',\n",
              " 'simple principled uncertainty estimation deterministic deep learning via distance awareness',\n",
              " 'adaptive learning rank one models efficient pairwise sequence alignment',\n",
              " 'hierarchical nucleation deep neural networks',\n",
              " 'fourier features let networks learn high frequency functions low dimensional domains',\n",
              " '',\n",
              " 'differentiable augmentation data efficient gan training',\n",
              " '',\n",
              " 'learning certified individually fair representations',\n",
              " 'part dependent label noise towards instance',\n",
              " 'tackling objective inconsistency problem heterogeneous federated optimization',\n",
              " 'improved analysis variance reduced policy gradient natural methods',\n",
              " '',\n",
              " 'automatic curriculum learning value disagreement',\n",
              " 'mri banding removal via adversarial training',\n",
              " '',\n",
              " 'language visual entity relationship graph agent navigation',\n",
              " 'icam interpretable classification via disentangled representations feature attribution mapping',\n",
              " 'spectra conjugate kernel neural tangent linear width networks',\n",
              " 'no regret learning dynamics extensive form correlated equilibrium',\n",
              " 'estimating weighted areas roc curve',\n",
              " 'implicit bias explain generalization stochastic convex optimization case study',\n",
              " '',\n",
              " '',\n",
              " 'boosting adversarial training hypersphere embedding',\n",
              " 'beyond homophily graph neural networks current limitations effective designs',\n",
              " 'modeling continuous stochastic processes dynamic normalizing flows',\n",
              " 'efficient online learning optimal rankings dimensionality reduction via gradient descent',\n",
              " 'training normalizing flows information bottleneck competitive generative classification',\n",
              " 'detecting hands recognizing physical contact wild',\n",
              " 'theory transfer learning importance task diversity',\n",
              " 'finite time analysis round robin kullback leibler upper confidence bounds optimal adaptive allocation multiple plays markovian rewards',\n",
              " 'neural star domain primitive representation',\n",
              " 'off policy interval estimation lipschitz value iteration',\n",
              " 'inverse rational control partially observable continuous nonlinear dynamics',\n",
              " '',\n",
              " 'distributionally robust parametric maximum likelihood estimation',\n",
              " 'secretary online matching problems machine learned advice',\n",
              " '',\n",
              " 'overfitting harmless basis pursuit degree',\n",
              " 'improving generalization reinforcement learning mixture regularization',\n",
              " 'pontryagin differentiable programming end to learning control framework',\n",
              " '',\n",
              " 'devil detail framework macroscopic prediction via microscopic models',\n",
              " '',\n",
              " 'demystifying orthogonal monte carlo beyond',\n",
              " 'optimal robustness consistency trade offs learning augmented online algorithms',\n",
              " 'scalable approach privacy preserving collaborative machine learning',\n",
              " 'glow tts generative flow text to speech via monotonic alignment search',\n",
              " '',\n",
              " 'cycle contrast self supervised video representation learning',\n",
              " 'posterior re calibration imbalanced datasets',\n",
              " 'novelty search representational space sample efficient exploration',\n",
              " 'robust reinforcement learning via adversarial training langevin dynamics',\n",
              " '',\n",
              " 'online algorithms multi shop ski rental machine learned advice',\n",
              " 'multi label contrastive predictive coding',\n",
              " 'rotation invariant local to global representation learning 3d point cloud',\n",
              " '',\n",
              " 'one solution need few shot extrapolation via structured maxent rl',\n",
              " 'variational bayesian monte carlo noisy likelihoods',\n",
              " 'finite sample analysis contractive stochastic approximation using smooth convex envelopes',\n",
              " 'self supervised generative adversarial compression',\n",
              " 'efficient nonconvex reformulation stagewise convex optimization problems',\n",
              " '',\n",
              " 'adversarial distributional training robust deep learning',\n",
              " 'meta learning stationary stochastic process prediction convolutional neural processes',\n",
              " 'theory inspired path regularized differential network architecture search',\n",
              " 'conic descent application memory efficient optimization positive semidefinite matrices',\n",
              " 'learning geometry wave based imaging',\n",
              " 'greedy inference structure exploiting lazy maps',\n",
              " 'nimble lightweight parallel gpu task scheduling deep learning',\n",
              " 'finding homology decision boundaries active learning',\n",
              " 'reinforced molecular optimization neighborhood controlled grammars',\n",
              " 'natural policy gradient primal dual method constrained markov decision processes',\n",
              " 'classification misspecification halfspaces generalized linear models evolvability',\n",
              " 'certified defense image transformations via randomized smoothing',\n",
              " '',\n",
              " 'reparameterizing mirror descent gradient',\n",
              " 'general control functions causal effect estimation ivs',\n",
              " 'optimal algorithms stochastic multi armed bandits heavy tailed rewards',\n",
              " 'certified robustness graph convolution networks classification topological attacks',\n",
              " 'zero resource knowledge grounded dialogue generation',\n",
              " 'targeted adversarial perturbations monocular depth prediction',\n",
              " 'beyond mean field structured deep gaussian processes improve predictive uncertainties',\n",
              " 'offline imitation learning misspecified simulator',\n",
              " 'multi fidelity bayesian optimization via deep neural networks',\n",
              " 'plangan model based planning sparse rewards multiple goals',\n",
              " 'bad global minima exist sgd reach',\n",
              " 'optimal prediction number unseen species multiplicity',\n",
              " 'characterizing optimal mixed policies intervene observe',\n",
              " '',\n",
              " 'closer look accuracy vs robustness',\n",
              " 'curriculum learning dynamic instance hardness',\n",
              " '',\n",
              " 'learning execute programs instruction pointer attention graph neural networks',\n",
              " 'autoprivacy automated layer wise parameter selection secure neural network inference',\n",
              " '',\n",
              " 'characterizing emergent representations space candidate learning rules deep networks',\n",
              " 'fast accurate simple models tabular data via augmented distillation',\n",
              " 'adaptive probing policies shortest path routing',\n",
              " 'approximate heavily constrained learning lagrange multiplier models',\n",
              " 'faster randomized infeasible interior point methods tall wide linear programs',\n",
              " 'sliding window algorithms k clustering problems',\n",
              " 'adashare learning share efficient deep multi task',\n",
              " 'approximate cross validation structured models',\n",
              " 'exemplar vae linking generative models nearest neighbor retrieval data augmentation',\n",
              " '',\n",
              " 'ucsg net unsupervised discovering constructive solid geometry tree',\n",
              " '',\n",
              " 'cot gan generating sequential data via causal optimal transport',\n",
              " 'impossibility results grammar compressed linear algebra',\n",
              " 'understanding spiking networks convex optimization',\n",
              " 'better full matrix regret via parameter free online learning',\n",
              " 'large scale methods distributionally robust optimization',\n",
              " 'analysis design thompson sampling stochastic partial monitoring',\n",
              " '',\n",
              " 'refactoring policy compositional generalizability using self supervised object proposals',\n",
              " '',\n",
              " 'theoretical insights multiclass classification high dimensional asymptotic view',\n",
              " '',\n",
              " 'residual distillation towards portable deep neural networks without shortcuts',\n",
              " 'provably efficient neural estimation structural equation models adversarial approach',\n",
              " 'security analysis safe seldonian reinforcement learning algorithms',\n",
              " 'learning play sequential games versus unknown opponents',\n",
              " 'analysis outlier detection deep generative models',\n",
              " 'bridging imagination reality model based deep reinforcement learning',\n",
              " 'neural networks learning memorization almost over parameterization',\n",
              " 'exploiting higher order smoothness derivative free optimization continuous bandits',\n",
              " 'towards combinatorial characterization bounded memory learning',\n",
              " 'chaos extremism optimism volume analysis learning games',\n",
              " '',\n",
              " 'matrix completion hierarchical graph side information',\n",
              " 'long horizon rl difficult short',\n",
              " 'hamiltonian monte carlo using adjoint differentiated laplace approximation bayesian inference latent gaussian models beyond',\n",
              " 'adversarial learning robust deep clustering',\n",
              " '',\n",
              " 'learning learn variational semantic memory',\n",
              " '',\n",
              " '',\n",
              " 'towards safe policy improvement non stationary mdps',\n",
              " 'finer metagenomic reconstruction via biodiversity optimization',\n",
              " 'causal discovery physical systems videos',\n",
              " 'glyph fast accurately training deep neural networks encrypted data',\n",
              " 'smoothed analysis online differentially private learning',\n",
              " 'self paced deep reinforcement learning',\n",
              " 'kalman filtering attention user behavior modeling ctr prediction',\n",
              " 'towards maximizing representation gap in domain out of distribution examples',\n",
              " 'fully convolutional mesh autoencoder using efficient spatially varying kernels',\n",
              " 'gnnguard defending graph neural networks adversarial attacks',\n",
              " 'geo pifu geometry pixel aligned implicit functions single view human reconstruction',\n",
              " 'optimal visual search based model target detectability natural images',\n",
              " 'towards convergence rate analysis random forests classification',\n",
              " 'list decodable mean estimation via iterative multi filtering',\n",
              " 'exact recovery mangled clusters same cluster queries',\n",
              " 'steady state analysis episodic reinforcement learning',\n",
              " 'direct feedback alignment scales modern deep learning tasks architectures',\n",
              " '',\n",
              " 'minimax bounds generalized linear models',\n",
              " 'projection robust wasserstein distance riemannian optimization',\n",
              " 'coindice off policy confidence interval estimation',\n",
              " 'simple fast algorithm binary integer online linear programming',\n",
              " 'learning diverse discriminative representations via principle maximal coding rate reduction',\n",
              " '',\n",
              " 'color visual illusions statistics based computational model',\n",
              " 'retrieval augmented generation knowledge intensive nlp tasks',\n",
              " 'universal guarantees decision tree induction via higher order splitting criterion',\n",
              " 'trade offs guarantees adversarial representation learning information obfuscation',\n",
              " 'boolean task algebra reinforcement learning',\n",
              " '',\n",
              " 'optimal learning verified training data',\n",
              " 'online linear optimization many hints',\n",
              " 'dynamical mean field theory stochastic gradient descent gaussian mixture classification',\n",
              " 'causal discovery soft interventions unknown targets characterization learning',\n",
              " 'exploiting surrogate gap online multiclass classification',\n",
              " 'pitfalls simplicity bias neural networks',\n",
              " 'automatically learning compact quality aware surrogates optimization problems',\n",
              " '',\n",
              " 'q learning graph networks learn generalizable branching heuristic sat solver',\n",
              " 'non reversible gaussian processes identifying latent dynamical structure neural data',\n",
              " 'listening sounds silence speech denoising',\n",
              " 'boxe box embedding model knowledge base completion',\n",
              " 'coherent hierarchical multi label classification networks',\n",
              " 'walsh hadamard variational inference bayesian deep learning',\n",
              " 'federated bayesian optimization via thompson sampling',\n",
              " 'multion benchmarking semantic map memory using multi object navigation',\n",
              " '',\n",
              " 'optimal iterative sketching methods subsampled randomized hadamard transform',\n",
              " 'provably adaptive reinforcement learning metric spaces',\n",
              " 'shapeflow learnable deformation flows among 3d shapes',\n",
              " 'self supervised learning cross modal audio video clustering',\n",
              " 'optimal query complexity secure stochastic convex optimization',\n",
              " 'dynabert dynamic bert adaptive width depth',\n",
              " 'generalization bound gradient descent non convex metric learning',\n",
              " '',\n",
              " '',\n",
              " 'approximate cross validation low rank data high dimensions',\n",
              " 'ganspace discovering interpretable gan controls',\n",
              " 'differentiable expected hypervolume improvement parallel multi objective bayesian optimization',\n",
              " 'neuron level structured pruning using polarization regularizer',\n",
              " 'limits testing structural changes ising models',\n",
              " 'field wise learning multi categorical data',\n",
              " 'continual learning low rank orthogonal subspaces',\n",
              " 'unsupervised learning visual features contrasting cluster assignments',\n",
              " 'sharpened generalization bounds based conditional mutual information application noisy iterative algorithms',\n",
              " 'learning deformable tetrahedral meshes 3d reconstruction',\n",
              " 'information theoretic limits learning sparse rule',\n",
              " 'self supervised learning eyes child',\n",
              " 'unsupervised semantic aggregation deformable template matching semi supervised learning',\n",
              " 'game theoretic analysis networked system control common pool resource management using multi agent reinforcement learning',\n",
              " 'shapes feature representations exploring datasets architectures training',\n",
              " 'optimal best arm identification linear bandits',\n",
              " 'data diversification simple strategy neural machine translation',\n",
              " 'interstellar searching recurrent architecture knowledge graph embedding',\n",
              " '',\n",
              " 'learning multi agent coordination enhancing target coverage directional sensor networks',\n",
              " 'biological credit assignment dynamic inversion feedforward networks',\n",
              " 'discriminative sounding objects localization via self supervised audiovisual matching',\n",
              " 'learning multi agent communication structured attentive reasoning',\n",
              " 'private identity testing high dimensional distributions',\n",
              " 'optimal weighted ell 2 regularization overparameterized linear regression',\n",
              " 'efficient asynchronous method integrating evolutionary gradient based policy search',\n",
              " 'metasdf meta learning signed distance functions',\n",
              " 'simple scalable sparse k means clustering via feature ranking',\n",
              " 'model based adversarial meta reinforcement learning',\n",
              " 'graph policy network transferable active learning graphs',\n",
              " 'towards better global loss landscape gans',\n",
              " 'weighted qmix expanding monotonic value function factorisation deep multi agent reinforcement learning',\n",
              " 'banditpam almost linear time k medoids clustering via multi armed bandits',\n",
              " 'udh universal deep hiding steganography watermarking light field messaging',\n",
              " 'evidential sparsification multimodal latent spaces conditional variational autoencoders',\n",
              " 'unbiased risk estimator learning augmented classes',\n",
              " 'autobss efficient algorithm block stacking style search',\n",
              " 'pushing limits narrow precision inferencing cloud scale microsoft floating point',\n",
              " 'stochastic optimization laggard data pipelines',\n",
              " 'self supervised auxiliary learning meta paths heterogeneous graphs',\n",
              " 'gps net graph based photometric stereo network',\n",
              " 'consistent structural relation learning zero shot segmentation',\n",
              " 'model selection contextual stochastic bandit problems',\n",
              " 'truncated linear regression high dimensions',\n",
              " 'incorporating pragmatic reasoning communication emergent language',\n",
              " 'deep subspace clustering data augmentation',\n",
              " 'empirical process approach union bound practical algorithms combinatorial linear bandits',\n",
              " 'graph neural networks count substructures',\n",
              " 'bayesian perspective training speed model selection',\n",
              " '',\n",
              " 'doubly robust off policy value gradient estimation deterministic policies',\n",
              " 'provably efficient neural gtd off policy learning',\n",
              " 'learning discrete energy based models via auxiliary variable local exploration',\n",
              " 'stable expressive recurrent vision models',\n",
              " 'entropic optimal transport unbalanced gaussian measures closed form',\n",
              " 'brp nas prediction based using gcns',\n",
              " 'deep shells unsupervised shape correspondence optimal transport',\n",
              " 'ista nas efficient consistent neural architecture search sparse coding',\n",
              " 'rel3d minimally contrastive benchmark grounding spatial relations 3d',\n",
              " 'regularizing black box models improved interpretability',\n",
              " 'trust model confident masked based actor critic',\n",
              " 'semi supervised neural architecture search',\n",
              " 'consistency regularization certified robustness smoothed classifiers',\n",
              " 'robust multi agent reinforcement learning model uncertainty',\n",
              " 'siri spatial relation induced network description resolution',\n",
              " 'adaptive shrinkage estimation streaming graphs',\n",
              " 'make one shot video object segmentation efficient',\n",
              " '',\n",
              " '',\n",
              " 'constraining variational inference geometric jensen shannon divergence',\n",
              " '',\n",
              " 'hm ann efficient billion point nearest neighbor search heterogeneous memory',\n",
              " 'frugalml use ml prediction apis accurately cheaply',\n",
              " 'sharp representation theorems relu networks precise dependence depth',\n",
              " 'shared experience actor critic multi agent reinforcement learning',\n",
              " '',\n",
              " 'lift lockdown global covid 19 scenario analysis policy assessment using compartmental gaussian processes',\n",
              " 'unsupervised learning lagrangian dynamics images prediction control',\n",
              " 'high dimensional sparse linear bandits',\n",
              " 'non stochastic control bandit feedback',\n",
              " 'generalized leverage score sampling neural networks',\n",
              " 'optimal elimination algorithm learning best arm',\n",
              " 'efficient projection free algorithms saddle point problems',\n",
              " 'mathematical model automatic differentiation machine learning',\n",
              " 'unsupervised text generation learning search',\n",
              " 'learning compositional rules via neural program synthesis',\n",
              " 'incorporating bert parallel sequence decoding adapters',\n",
              " 'estimating fluctuations neural representations uncertain environments',\n",
              " 'discover hallucinate adapt open compound domain adaptation semantic segmentation',\n",
              " 'surf simple universal robust fast distribution learning algorithm',\n",
              " 'understanding approximate fisher information fast convergence natural gradient descent wide neural networks',\n",
              " 'general transportability soft interventions completeness results',\n",
              " 'gait prop biologically plausible learning rule derived backpropagation error',\n",
              " 'lipschitz bounds provably robust training laplacian smoothing',\n",
              " 'scop scientific control reliable neural network pruning',\n",
              " 'provably consistent partial label learning',\n",
              " 'robust accurate stochastic optimization variational inference',\n",
              " 'discovering conflicting groups signed networks',\n",
              " 'learning popular gaussian graphical models without condition number bounds',\n",
              " 'sense sensitivity analysis simple post hoc bias due unobserved confounding',\n",
              " 'mix match optimistic tree search approach learning models mixture distributions',\n",
              " 'understanding double descent requires fine grained bias variance decomposition',\n",
              " 'vime extending success self semi supervised learning tabular domain',\n",
              " '',\n",
              " 'decentralized parallel algorithm training generative adversarial nets',\n",
              " 'phase retrieval high dimensions statistical computational transitions',\n",
              " '',\n",
              " 'hybrid variance reduced sgd algorithms minimax problems nonconvex linear function',\n",
              " 'belief dependent macro action discovery pomdps using value information',\n",
              " 'soft contrastive learning visual localization',\n",
              " 'fine grained dynamic head object detection',\n",
              " 'loco local contrastive representation learning',\n",
              " 'modeling optimization trade off meta learning',\n",
              " '',\n",
              " '',\n",
              " 'stage wise conservative linear bandits',\n",
              " 'relate physically plausible multi object scene synthesis using structured latent spaces',\n",
              " 'metric free individual fairness online learning',\n",
              " 'greedyfool distortion aware sparse adversarial attack',\n",
              " 'vaem deep generative model heterogeneous mixed type data',\n",
              " 'retroxpert decompose retrosynthesis prediction like chemist',\n",
              " 'sample efficient optimization latent space deep generative models via weighted retraining',\n",
              " 'improved sample complexity incremental autonomous exploration mdps',\n",
              " 'tinytl reduce memory parameters efficient on device learning',\n",
              " 'rd 2 reward decomposition representation',\n",
              " 'self paced contrastive learning hybrid memory domain adaptive object re id',\n",
              " 'fairness constraints help exact inference structured prediction',\n",
              " 'instance based generalization reinforcement learning',\n",
              " 'smooth consistent probabilistic regression trees',\n",
              " 'computing valid p value optimal changepoint selective inference using dynamic programming',\n",
              " 'factorized neural processes k shot prediction responses',\n",
              " '',\n",
              " 'adversarial robustness via robust low rank representations',\n",
              " '',\n",
              " 'compositional generalization learning analytical expressions',\n",
              " 'jax md framework differentiable physics',\n",
              " 'implicit function learning approach parametric modal regression',\n",
              " 'sdf srn learning signed distance 3d object reconstruction static images',\n",
              " 'coresets robust training deep neural networks noisy labels',\n",
              " '',\n",
              " 'convergence meta learning task specific adaptation partial parameters',\n",
              " 'metaperturb transferable regularizer heterogeneous tasks architectures',\n",
              " 'learning solve tv regularised problems unrolled algorithms',\n",
              " 'object centric learning slot attention',\n",
              " 'improving robustness common corruptions covariate shift adaptation',\n",
              " 'deep smoothing implied volatility surface',\n",
              " 'probabilistic inference algebraic constraints theoretical limits practical approximations',\n",
              " 'provable online cp parafac decomposition structured tensor via dictionary learning',\n",
              " 'look ahead meta learning continual',\n",
              " 'polynomial time algorithm learning nonparametric causal graphs',\n",
              " '',\n",
              " '',\n",
              " 'identifying causal effect inference failure uncertainty aware models',\n",
              " '',\n",
              " 'deep active inference agents using monte carlo methods',\n",
              " 'consistent estimation identifiable nonparametric mixture models grouped observations',\n",
              " '',\n",
              " 'adaptive learned bloom filter ada bf efficient utilization classifier application real time information filtering web',\n",
              " 'mcunet tiny deep learning iot devices',\n",
              " '',\n",
              " 'task agnostic exploration reinforcement learning',\n",
              " 'multi task additive models robust estimation automatic structure discovery',\n",
              " 'provably efficient reward agnostic navigation linear value iteration',\n",
              " 'softmax deep double deterministic policy gradients',\n",
              " 'online decision based visual tracking via reinforcement learning',\n",
              " 'efficient marginalization discrete structured latent variables via sparsity',\n",
              " 'deepi2i enabling deep hierarchical image to translation transferring gans',\n",
              " 'distributional robustness ipms links regularization gans',\n",
              " '',\n",
              " 'csi novelty detection via contrastive learning distributionally shifted instances',\n",
              " 'learning implicit credit assignment cooperative multi agent reinforcement',\n",
              " 'mate plugging model awareness task embedding meta learning',\n",
              " 'restless ucb efficient low complexity algorithm online bandits',\n",
              " 'predictive information accelerates learning rl',\n",
              " 'robust heavy tailed mean estimation made simple via regret minimization',\n",
              " 'high fidelity generative image compression',\n",
              " 'statistical mechanics framework task agnostic sample design machine learning',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeYyWvkyTpFF"
      },
      "source": [
        "#### Store Data- Topics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "8uBeBb5eTrcd",
        "outputId": "29949cef-1f40-48de-9c40-d3ce831f4f6b"
      },
      "source": [
        "#Create a new dataFrame \n",
        "data = pd.DataFrame(columns = ['topic']) \n",
        "data['topic'] = topic_list\n",
        "\n",
        "#Show the data set\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>unsupervised information theoretic perceptual ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>self supervised multimodal versatile networks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>benchmarking deep inverse models time neural a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>off policy evaluation learning external validi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1893</th>\n",
              "      <td>distributed distillation on device learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1894</th>\n",
              "      <td>coot cooperative hierarchical transformer vide...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1895</th>\n",
              "      <td>passport aware normalization deep model protec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1896</th>\n",
              "      <td>sampling decomposable generative adversarial r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1897</th>\n",
              "      <td>limits depth efficiencies self attention</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1898 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  topic\n",
              "0                                                      \n",
              "1     unsupervised information theoretic perceptual ...\n",
              "2         self supervised multimodal versatile networks\n",
              "3     benchmarking deep inverse models time neural a...\n",
              "4     off policy evaluation learning external validi...\n",
              "...                                                 ...\n",
              "1893        distributed distillation on device learning\n",
              "1894  coot cooperative hierarchical transformer vide...\n",
              "1895  passport aware normalization deep model protec...\n",
              "1896  sampling decomposable generative adversarial r...\n",
              "1897           limits depth efficiencies self attention\n",
              "\n",
              "[1898 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-gG02snUV_m"
      },
      "source": [
        "#file_path = '/content/drive/Shared drives/1DeepContextGraph/1DeepContextGraph/code/data/'\n",
        "file_path = './data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWxP2vL_UZzd"
      },
      "source": [
        "data.to_csv(file_path+topic_file_name+str(ngramsCount)+'grams.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Sug89X_RnOR"
      },
      "source": [
        "### Topic Count Param Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBvxFt0dRqTL"
      },
      "source": [
        "#topic_count = data.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXj_1vCiPvKQ"
      },
      "source": [
        "## 4.Topic Related Paper Search [.getRelatedPaper()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rahs7nD9y1Yd"
      },
      "source": [
        "### Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPq79bidTnH4",
        "outputId": "424f0703-3e1d-4b6d-a9d3-36b2103792ab"
      },
      "source": [
        "!pip install newspaper3k"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: newspaper3k in /opt/conda/lib/python3.7/site-packages (0.2.8)\n",
            "Requirement already satisfied: requests>=2.10.0 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (2.25.1)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (4.9.3)\n",
            "Requirement already satisfied: cssselect>=0.9.2 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (1.1.0)\n",
            "Requirement already satisfied: nltk>=3.2.1 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (3.6.2)\n",
            "Requirement already satisfied: tldextract>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (3.1.0)\n",
            "Requirement already satisfied: jieba3k>=0.35.1 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (0.35.1)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (5.4.1)\n",
            "Requirement already satisfied: tinysegmenter==0.3 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (0.3)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (4.6.3)\n",
            "Requirement already satisfied: feedparser>=5.2.1 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (6.0.8)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (2.8.1)\n",
            "Requirement already satisfied: feedfinder2>=0.0.4 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (0.0.4)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (8.3.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.2.1)\n",
            "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from feedfinder2>=0.0.4->newspaper3k) (1.16.0)\n",
            "Requirement already satisfied: sgmllib3k in /opt/conda/lib/python3.7/site-packages (from feedparser>=5.2.1->newspaper3k) (1.0.0)\n",
            "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from nltk>=3.2.1->newspaper3k) (4.61.2)\n",
            "Requirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from nltk>=3.2.1->newspaper3k) (2019.8.19)\n",
            "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from nltk>=3.2.1->newspaper3k) (1.0.1)\n",
            "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk>=3.2.1->newspaper3k) (8.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.10.0->newspaper3k) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.10.0->newspaper3k) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.10.0->newspaper3k) (2021.5.30)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.10.0->newspaper3k) (1.26.6)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /opt/conda/lib/python3.7/site-packages (from tldextract>=2.0.1->newspaper3k) (3.0.12)\n",
            "Requirement already satisfied: requests-file>=1.4 in /opt/conda/lib/python3.7/site-packages (from tldextract>=2.0.1->newspaper3k) (1.5.1)\n",
            "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click->nltk>=3.2.1->newspaper3k) (3.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->nltk>=3.2.1->newspaper3k) (3.10.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->nltk>=3.2.1->newspaper3k) (3.5.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DGjgrtrVNfv",
        "outputId": "ac7d3c55-5b9d-46d9-c1b9-63a4d02847c4"
      },
      "source": [
        "!pip install sent2vec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sent2vec in /opt/conda/lib/python3.7/site-packages (0.2.0)\n",
            "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from sent2vec) (1.19.5)\n",
            "Requirement already satisfied: spacy in /opt/conda/lib/python3.7/site-packages (from sent2vec) (2.3.4)\n",
            "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from sent2vec) (1.9.0)\n",
            "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (from sent2vec) (4.9.1)\n",
            "Requirement already satisfied: gensim in /opt/conda/lib/python3.7/site-packages (from sent2vec) (4.0.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from gensim->sent2vec) (5.1.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.7/site-packages (from gensim->sent2vec) (1.7.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy->sent2vec) (0.8.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy->sent2vec) (4.61.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy->sent2vec) (0.7.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy->sent2vec) (1.0.5)\n",
            "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy->sent2vec) (7.4.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy->sent2vec) (2.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy->sent2vec) (2.25.1)\n",
            "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy->sent2vec) (49.6.0.post20210108)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/conda/lib/python3.7/site-packages (from spacy->sent2vec) (1.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy->sent2vec) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy->sent2vec) (3.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/conda/lib/python3.7/site-packages (from spacy->sent2vec) (1.1.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /opt/conda/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy->sent2vec) (3.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy->sent2vec) (3.10.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy->sent2vec) (3.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy->sent2vec) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy->sent2vec) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy->sent2vec) (1.26.6)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy->sent2vec) (3.0.4)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /opt/conda/lib/python3.7/site-packages (from transformers->sent2vec) (0.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers->sent2vec) (2019.8.19)\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers->sent2vec) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers->sent2vec) (0.0.13)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers->sent2vec) (0.10.3)\n",
            "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers->sent2vec) (21.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers->sent2vec) (5.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers->sent2vec) (2.4.7)\n",
            "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers->sent2vec) (1.16.0)\n",
            "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers->sent2vec) (1.0.1)\n",
            "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers->sent2vec) (8.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIpGURz6ZkHi",
        "outputId": "3059b1d4-516d-482b-ef43-7111f98619c7"
      },
      "source": [
        "import json\n",
        "import os\n",
        "# For caculating approximate time to process notebook (IGNORE)\n",
        "import datetime\n",
        "datetime.datetime.now()\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import operator\n",
        "import pickle as pkl \n",
        "import matplotlib.pyplot as plt\n",
        "import nltk as nl\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "import statistics\n",
        "import random\n",
        "import warnings\n",
        "from string import punctuation\n",
        "from matplotlib import pyplot\n",
        "from pandas import Series, datetime\n",
        "from pandas.plotting import scatter_matrix, autocorrelation_plot\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV, TimeSeriesSplit\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, mean_squared_error\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "import nltk\n",
        "import re\n",
        "import io\n",
        "import requests\n",
        "import time\n",
        "import gensim\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "import nltk.sentiment\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('vader_lexicon')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:20: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
            "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/jupyter/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /home/jupyter/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /home/jupyter/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     /home/jupyter/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYX-M6bRTqcF"
      },
      "source": [
        "from newspaper import fulltext\n",
        "import requests"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XscK1daMVQo8"
      },
      "source": [
        "from scipy import spatial\n",
        "from sent2vec.vectorizer import Vectorizer\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFu-NFDKAY1b"
      },
      "source": [
        "#### LDA setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vabu7Te_AbFD",
        "outputId": "5df60c68-73f0-454a-c18a-26223ec2024b"
      },
      "source": [
        "!pip install sentence-transformers\n",
        "!pip install LexRank\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "\n",
        "from lexrank import STOPWORDS, LexRank\n",
        "from path import Path\n",
        "import json\n",
        "import os\n",
        "# For caculating approximate time to process notebook (IGNORE)\n",
        "import datetime\n",
        "datetime.datetime.now()\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import operator\n",
        "import pickle as pkl \n",
        "import matplotlib.pyplot as plt\n",
        "import nltk as nl\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "import statistics\n",
        "import random\n",
        "import warnings\n",
        "from string import punctuation\n",
        "from matplotlib import pyplot\n",
        "from pandas import Series, datetime\n",
        "from pandas.plotting import scatter_matrix, autocorrelation_plot\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV, TimeSeriesSplit\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, mean_squared_error\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from spacy import displacy \n",
        "import nltk\n",
        "import re\n",
        "import io\n",
        "import requests\n",
        "import time\n",
        "import gensim\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "import nltk.sentiment\n",
        "#from sentence_transformers import SentenceTransformer, util\n",
        "import numpy as np\n",
        "import spacy\n",
        "from spacy.lang.en import English\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('brown')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentence-transformers in /opt/conda/lib/python3.7/site-packages (2.0.0)\n",
            "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (4.61.2)\n",
            "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.7.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (4.9.1)\n",
            "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.1.96)\n",
            "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.23.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.9.0)\n",
            "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.10.0)\n",
            "Requirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (3.6.2)\n",
            "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.19.5)\n",
            "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.0.12)\n",
            "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.6.0->sentence-transformers) (3.10.0.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2019.8.19)\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.0.13)\n",
            "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.0)\n",
            "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.25.1)\n",
            "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.10.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (5.4.1)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.10.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk->sentence-transformers) (8.0.1)\n",
            "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from nltk->sentence-transformers) (1.0.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.26.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.5.30)\n",
            "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->sentence-transformers) (8.3.1)\n",
            "Requirement already satisfied: LexRank in /opt/conda/lib/python3.7/site-packages (0.1.0)\n",
            "Requirement already satisfied: regex>=2017.11.9 in /opt/conda/lib/python3.7/site-packages (from LexRank) (2019.8.19)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from LexRank) (0.17.3)\n",
            "Requirement already satisfied: urlextract>=0.7 in /opt/conda/lib/python3.7/site-packages (from LexRank) (1.3.0)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /opt/conda/lib/python3.7/site-packages (from LexRank) (1.7.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from LexRank) (1.19.5)\n",
            "Requirement already satisfied: path.py>=10.5 in /opt/conda/lib/python3.7/site-packages (from LexRank) (12.5.0)\n",
            "Requirement already satisfied: path in /opt/conda/lib/python3.7/site-packages (from path.py>=10.5->LexRank) (16.2.0)\n",
            "Requirement already satisfied: idna in /opt/conda/lib/python3.7/site-packages (from urlextract>=0.7->LexRank) (2.10)\n",
            "Requirement already satisfied: uritools in /opt/conda/lib/python3.7/site-packages (from urlextract>=0.7->LexRank) (3.0.2)\n",
            "Requirement already satisfied: appdirs in /opt/conda/lib/python3.7/site-packages (from urlextract>=0.7->LexRank) (1.4.4)\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from urlextract>=0.7->LexRank) (3.0.12)\n",
            "Collecting en_core_web_sm==2.3.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 7.0 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: spacy<2.4.0,>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from en_core_web_sm==2.3.1) (2.3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.7.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.2)\n",
            "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.61.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.19.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.25.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (49.6.0.post20210108)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /opt/conda/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.10.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.26.6)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2021.5.30)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:27: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
            "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/jupyter/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /home/jupyter/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /home/jupyter/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     /home/jupyter/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package brown to /home/jupyter/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StXkVX4FQBDK"
      },
      "source": [
        "### Data Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1nZLsfSQC-H"
      },
      "source": [
        "df = data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bb7TyZj6f2K"
      },
      "source": [
        "### Google Custom Search API\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw0vW6TDH0e5"
      },
      "source": [
        "* Ref:  https://www.simplifiedpython.net/google-custom-search-api-python/#:~:text=The%20Custom%20Search%20JSON%20API,search%20results%20in%20JSON%20format.\n",
        "\n",
        "* CSE link: https://cse.google.com/cse/setup/basic?cx=d0515d2f05012bdbc\n",
        "\n",
        "* Google Search API: https://console.cloud.google.com/apis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSl5t_lKIH2i"
      },
      "source": [
        "#### Information\n",
        "\n",
        "projectname: deepcontext\n",
        "api key name: APIkey1\n",
        "api key= AIzaSyBDX5Zv8L1Pk-XuTNQ0qd2uPXpf_-xFIhE\n",
        "custom search engine name: custom_search_engine\n",
        "search engine id: d0515d2f05012bdbc\n",
        "Public URL= https://cse.google.com/cse?cx=d0515d2f05012bdbc "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waXPXuuoILfa"
      },
      "source": [
        "#### Env Set-up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RRSjqQ4G2wz",
        "outputId": "7a17d34c-781e-46f9-beb0-9d46f2d81b4b"
      },
      "source": [
        "pip install google-api-python-client"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google-api-python-client in /opt/conda/lib/python3.7/site-packages (2.12.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client) (3.0.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client) (0.1.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client) (0.19.1)\n",
            "Requirement already satisfied: six<2dev,>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client) (1.16.0)\n",
            "Requirement already satisfied: google-auth<2dev,>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client) (1.32.1)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client) (1.30.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client) (3.16.0)\n",
            "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client) (2021.1)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client) (49.6.0.post20210108)\n",
            "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client) (21.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client) (2.25.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client) (1.53.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2dev,>=1.16.0->google-api-python-client) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2dev,>=1.16.0->google-api-python-client) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2dev,>=1.16.0->google-api-python-client) (0.2.7)\n",
            "Requirement already satisfied: pyparsing<3,>=2.4.2 in /opt/conda/lib/python3.7/site-packages (from httplib2<1dev,>=0.15.0->google-api-python-client) (2.4.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2dev,>=1.16.0->google-api-python-client) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client) (2021.5.30)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client) (1.26.6)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client) (2.10)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "st_3KZq4pmge"
      },
      "source": [
        "from googleapiclient.discovery import build\n",
        "import pprint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcpfXuTRIeCb"
      },
      "source": [
        "####  Custom Search Engine Key Set-up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75Ttz_nMG7Ki"
      },
      "source": [
        "#define key\n",
        "api_key = \"AIzaSyBbL96aJjiBbDkqGj8qB-cTfzd3Pq6XBLs\"#\"AIzaSyBDX5Zv8L1Pk-XuTNQ0qd2uPXpf_-xFIhE\"\n",
        "cse_key = \"4fb333d2d04344b4c\" #\"d0515d2f05012bdbc\"\n",
        " \n",
        "resource = build(\"customsearch\", 'v1', developerKey=api_key).cse()\n",
        "\n",
        " \n",
        "#pprint.pprint(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5BuIUfZ1X5g"
      },
      "source": [
        "### Text Distillation Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9zg6DzVyV1Q"
      },
      "source": [
        "#### Lemmatization\n",
        "  \n",
        "First, the raw words must be converted to root forms.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qs9YyZ8WygUo"
      },
      "source": [
        "def lemmatize(tokenized_words):\n",
        "  text = [nltk.WordNetLemmatizer().lemmatize(word) for word in tokenized_words]\n",
        "  return text\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRnq7Orw5sSW"
      },
      "source": [
        "#### Removing Stop words\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7axUBcsp5yXD"
      },
      "source": [
        "english_stopwords = set(stopwords.words('english') + list(punctuation) + [''])\n",
        "\n",
        "def remove_stopwords(tokenized_words):\n",
        "  text = [word for word in tokenized_words if word not in english_stopwords]\n",
        "  return text\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejCglovYHwyb"
      },
      "source": [
        "#### Custom Filtering\n",
        "\n",
        "Some of the one or two-letter words from the tokenized words are also removed to further cleanse the raw text. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9ujoC42HwGM"
      },
      "source": [
        "whitelist = set(['ai', 'ax', 'ca', 'eu', 'go', 'io', 'la', 'ox', 'us', 'uk', \n",
        "                 'al', 'ak', 'az', 'ar', 'ca', 'co', 'ct', 'de', 'fl', 'ga', 'hi', \n",
        "                 'id', 'il', 'in', 'ia', 'ks', 'ky', 'la', 'me', 'md', 'ma', 'mi',\n",
        "                 'mn', 'ms', 'mo', 'mt', 'ne', 'nv', 'nh', 'nj', 'nm', 'ny',\n",
        "                 'nc', 'nd', 'oh', 'ok', 'or', 'pa', 'ri', 'sc', 'sd', 'tn',\n",
        "                 'tx', 'ut', 'vt', 'va', 'wa', 'wv', 'wi', 'wy' ])\n",
        "def remove_too_short(tokenized_words):\n",
        "  text = [word for word in tokenized_words if (len(word) >= 3 or word not in whitelist) ]\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGmEhyrkC0e5"
      },
      "source": [
        "#### LDA Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7Fdvch1EjQ4"
      },
      "source": [
        "from gensim.models.ldamodel import LdaModel\n",
        "from gensim.corpora import Dictionary\n",
        "\n",
        "def topics(tokenized_words):\n",
        "    d = Dictionary([tokenized_words])\n",
        "    c = [d.doc2bow(tokenized_words)]\n",
        "    m = LdaModel(c, num_topics=1, id2word=d)\n",
        "    return list(m.print_topics(num_words=2))\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ze4YTpBLultl"
      },
      "source": [
        "#### Topics as Simple List of Words\n",
        "\n",
        "A list of topic terms is compiled as show below. The coefficients in front of each word are dropped as part of simplification. The assumption is that the top two words comprising the topic, are both significant enough to be treated equally. It is important that the goal is to build a reliable prediction model. While there is a risk of oversimplification, if the final model results in a poor accuracy score, the coefficient can always be reintroduced here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1fxmdcyuqoB"
      },
      "source": [
        "def parseTopics(topics):\n",
        "   output = []\n",
        "   words = topics[0][1].split( '+' )\n",
        "   for word in words:\n",
        "       output.append( word.split('*')[1].replace( '\"', '' ) )\n",
        "   return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCwJ0YL7WMEX"
      },
      "source": [
        "#### similarity computation method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txrkD2BxFgUQ"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def method_3_with_sentence_sim_avg(topic,data_2,column_name):\n",
        "  similarity_list = []\n",
        "  i = 0\n",
        "  j= 0\n",
        "\n",
        "  #id = row['most_similar'][0][0]\n",
        "  max_sim = (-math.inf)\n",
        "  max_index = -1\n",
        "  #print(\"\\njoin(row1['text_distilled']=\" , text1)\n",
        "\n",
        "  #vectorize for bert\n",
        "  vectorizer.bert(data_1.iloc[0]['topic'])\n",
        "  vectors_bert1 = vectorizer.vectors\n",
        "  for index2, row2 in data_2.iterrows():\n",
        "    text2 = \"\".join(row2[column_name])\n",
        "\n",
        "    #vectorize for bert\n",
        "    vectorizer.bert(row2[column_name])\n",
        "    vectors_bert2 = vectorizer.vectors\n",
        "\n",
        "    x = vectors_bert1.reshape(1,-1)\n",
        "    y = vectors_bert2.reshape(1,-1)\n",
        "    sim = cosine_similarity(vectors_bert1, vectors_bert2)\n",
        "    sim_reshape = sim.reshape(1,-1)\n",
        "    sim_avg = np.mean(sim_reshape)\n",
        "    #print(sim_avg)\n",
        "        \n",
        "    max_sim = sim_avg\n",
        "    max_index = index2\n",
        "    j= 1\n",
        "    similarity_list.append((max_index,max_sim))\n",
        "      \n",
        "  return similarity_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4zKGRhV97up"
      },
      "source": [
        "#### LDA Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etoUCdfO-ACD",
        "outputId": "8095b827-0b5a-40a1-8812-626acebdfa94"
      },
      "source": [
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stopwords = stopwords.words('english')\n",
        "\n",
        "def join_tokens(list_of_tokens):\n",
        "    outstr = TreebankWordDetokenizer().detokenize(list_of_tokens)\n",
        "    return outstr\n",
        "\n",
        "def filter_stopwords_from_list(titles):\n",
        "    word_list = titles\n",
        "    title_list = []\n",
        "    new_word_list = []\n",
        "    new_title_list= []\n",
        "    for title in titles:\n",
        "            #print (title)\n",
        "            title_list =  nltk.word_tokenize(title)\n",
        "            #print (words)\n",
        "            for word in title_list:\n",
        "                print (word)\n",
        "                if word.lower() not in stopwords:\n",
        "                    new_word_list.append(word)\n",
        "                    #print(\"joined {} :\".format(word))\n",
        "            #print (\"new title list :\",new_word_list)\n",
        "            new_title = join_tokens(new_word_list)\n",
        "            #print (\"\\n New title : \", new_title)\n",
        "            new_word_list =[]\n",
        "            # print (\"old : {}  \\n -----> new : {}\\n\\n\".format(title, new_title))\n",
        "            new_title_list.append(new_title)\n",
        "    # print (\"========================\\n\")\n",
        "    # print (\"new list of titles: \\n: ===> \",new_title_list )\n",
        "    return new_title_list\n",
        "        #print (new_line)\n",
        "        #filtered_words = [word for word in words if word.lower() not in stopwords]\n",
        "        #print (words)\n",
        "\n",
        "# receives a list of texts and creates n-grams for each of the text as well as for the entire corpus\n",
        "def getNGramsConcat(lstText, ngramsCount):\n",
        "  import re\n",
        "  from nltk.util import ngrams\n",
        "  s = \" \".join(lstText) # this may be needed to crea\n",
        "  s = s.lower()\n",
        "  s = re.sub(r'[^a-zA-Z0-9\\s]', ' ', s)\n",
        "  tokens = [token for token in s.split(\" \") if token != \"\"]\n",
        "  corpusNGrams = list(ngrams(tokens, ngramsCount))\n",
        "  corpusNGramsConcat = [\"-\".join(e) for e in corpusNGrams]\n",
        "\n",
        "  txtNGrams = []\n",
        "  txtNGramsConcat = []\n",
        "  for t in lstText:\n",
        "    t2 = t.lower()\n",
        "    t2 = re.sub(r'[^a-zA-Z0-9\\s]', ' ', t2)\n",
        "    tokens2 = [token2 for token2 in t2.split(\" \") if token2 != \"\"]\n",
        "    ng = list(ngrams(tokens2, ngramsCount))\n",
        "    txtNGrams.append(ng)\n",
        "    txtNGramsConcat.append( [\"-\".join(e) for e in ng])\n",
        "\n",
        "  return (txtNGramsConcat, corpusNGramsConcat)\n",
        "\n",
        "# titles = dfEvents[\"title\"]\n",
        "# filteredTitles = filter_stopwords_from_list(titles)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/jupyter/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gp86D59E_Aod"
      },
      "source": [
        "import numpy as np\n",
        "from gensim import corpora, models\n",
        "def runLDA(doc_set, numOfTopics): # source: https://rstudio-pubs-static.s3.amazonaws.com/79360_850b2a69980c4488b1db95987a24867a.html  (modified by Renato)\n",
        "    \n",
        "    np.random.seed(1) # LDA uses randomness in its calculation. Setting fixed seed to make sure we always get the same result\n",
        "    \n",
        "    from nltk.tokenize import RegexpTokenizer\n",
        "    from stop_words import get_stop_words\n",
        "    from nltk.stem.porter import PorterStemmer\n",
        "    from gensim import corpora, models\n",
        "    import gensim\n",
        "\n",
        "\n",
        "    tokenizer = RegexpTokenizer(r'[\\w-]+')\n",
        "\n",
        "    # create English stop words list\n",
        "    en_stop = get_stop_words('en')\n",
        "\n",
        "    # Create p_stemmer of class PorterStemmer\n",
        "    # p_stemmer = PorterStemmer()\n",
        "\n",
        "   \n",
        "    # list for tokenized documents in loop\n",
        "    texts = []\n",
        "\n",
        "    # loop through document list\n",
        "    for d in doc_set:\n",
        "        d = \" \".join(d)\n",
        "        # # removing \"'\"\n",
        "        # d = d.replace(\"'\", \"\")\n",
        "           \n",
        "        # clean and tokenize document string\n",
        "        raw = d.lower()\n",
        "        tokens = tokenizer.tokenize(raw)\n",
        "\n",
        "        # remove stop words from tokens\n",
        "        # stopped_tokens = [i for i in tokens if not i in en_stop]\n",
        "\n",
        "        # stem tokens\n",
        "        # stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
        "     \n",
        "        # add tokens to list\n",
        "        # texts.append(stemmed_tokens)\n",
        "        texts.append(tokens)\n",
        "\n",
        "    # turn our tokenized documents into a id <-> term dictionary\n",
        "    dictionary = corpora.Dictionary(texts)\n",
        "    \n",
        "    # TODO: removing high frequency words\n",
        "    #dictionary.filter_extremes(no_below=1, no_above=0.6, keep_n=1)\n",
        "\n",
        "    # convert tokenized documents into a document-term matrix\n",
        "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
        "\n",
        "    # generate LDA model\n",
        "    ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=numOfTopics, id2word = dictionary, passes=20)\n",
        "    \n",
        "    return ldamodel, texts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdFgH0eeB2ob"
      },
      "source": [
        "def topic_build(topn_words):\n",
        "  topic_list = []\n",
        "  for key in topn_words.keys():\n",
        "    temp_str = ''\n",
        "    j_len = len(topn_words[key])\n",
        "    #print(topn_words[key])\n",
        "    for j in range(j_len):\n",
        "      temp_str = temp_str +' ' +topn_words[key][j].replace('-', ' ')\n",
        "    #print(temp_str)\n",
        "    topic_list.append(temp_str.strip())\n",
        "  return topic_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvHMZbYBBtdT"
      },
      "source": [
        "#remove duplicate\n",
        "def remove_duplicate_word(s):\n",
        "  l = s.split()\n",
        "  k = []\n",
        "  for i in l:\n",
        "      # If condition is used to store unique string \n",
        "      # in another list 'k' \n",
        "      if (s.count(i)>1 and (i not in k) or s.count(i)==1):\n",
        "          k.append(i)\n",
        "  #print(' '.join(k))\n",
        "  return ' '.join(k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IF2j7Um7jp_z"
      },
      "source": [
        "#### Scrape from PDF Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUolm2M3kMCm",
        "outputId": "bbe01044-0270-4de6-9072-ee7af2086011"
      },
      "source": [
        "!pip install pdfminer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pdfminer in /opt/conda/lib/python3.7/site-packages (20191125)\n",
            "Requirement already satisfied: pycryptodome in /opt/conda/lib/python3.7/site-packages (from pdfminer) (3.10.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StMBMMy-j1Os"
      },
      "source": [
        "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
        "from pdfminer.converter import TextConverter\n",
        "from pdfminer.layout import LAParams\n",
        "from pdfminer.pdfpage import PDFPage\n",
        "from io import StringIO\n",
        "\n",
        "class PdfConverter:\n",
        "\n",
        "   def __init__(self, file_path):\n",
        "       self.file_path = file_path\n",
        "# convert pdf file to a string which has space among words \n",
        "   def convert_pdf_to_txt(self):\n",
        "       rsrcmgr = PDFResourceManager()\n",
        "       retstr = StringIO()\n",
        "       codec = 'utf-8'  # 'utf16','utf-8'\n",
        "       laparams = LAParams()\n",
        "       device = TextConverter(rsrcmgr, retstr,  laparams=laparams) #codec=codec,\n",
        "       fp = open(self.file_path, 'rb')\n",
        "       interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
        "       password = \"\"\n",
        "       maxpages = 0\n",
        "       caching = True\n",
        "       pagenos = set()\n",
        "       for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages, password=password, caching=caching, check_extractable=True):\n",
        "           interpreter.process_page(page)\n",
        "       fp.close()\n",
        "       device.close()\n",
        "       str = retstr.getvalue()\n",
        "       retstr.close()\n",
        "       \n",
        "       text =str\n",
        "       word1 = 'Abstract'\n",
        "       word2 = 'Introduction'\n",
        "       abstract_text = \"\"\n",
        "       #print(text.index(word1))\n",
        "       #print(text.index(word2))\n",
        "       try:\n",
        "          abstract_text = text[text.index(word1):text.index(word2)]\n",
        "          return abstract_text\n",
        "       #print(abstract_text)\n",
        "       except:\n",
        "          abstract_text = \"No Text\"\n",
        "          return abstract_text\n",
        "# convert pdf file text to string and save as a text_pdf.txt file\n",
        "   def save_convert_pdf_to_txt(self):\n",
        "       content = self.convert_pdf_to_txt()\n",
        "       txt_pdf = open('./example.txt', 'wb')\n",
        "       txt_pdf.write(content.encode('utf-8'))\n",
        "       txt_pdf.close()\n",
        "# if __name__ == '__main__':\n",
        "#     pdfConverter = PdfConverter(file_path='./example.pdf')\n",
        "#     print(pdfConverter.convert_pdf_to_txt())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKRO18actPQg"
      },
      "source": [
        "### Loop to find the topic related paper with rank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "5gHeQlTumLDt",
        "outputId": "1d980f68-450c-4b66-d547-dff15da4ac98"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>unsupervised information theoretic perceptual ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>self supervised multimodal versatile networks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>benchmarking deep inverse models time neural a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>off policy evaluation learning external validi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1893</th>\n",
              "      <td>distributed distillation on device learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1894</th>\n",
              "      <td>coot cooperative hierarchical transformer vide...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1895</th>\n",
              "      <td>passport aware normalization deep model protec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1896</th>\n",
              "      <td>sampling decomposable generative adversarial r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1897</th>\n",
              "      <td>limits depth efficiencies self attention</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1898 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  topic\n",
              "0                                                      \n",
              "1     unsupervised information theoretic perceptual ...\n",
              "2         self supervised multimodal versatile networks\n",
              "3     benchmarking deep inverse models time neural a...\n",
              "4     off policy evaluation learning external validi...\n",
              "...                                                 ...\n",
              "1893        distributed distillation on device learning\n",
              "1894  coot cooperative hierarchical transformer vide...\n",
              "1895  passport aware normalization deep model protec...\n",
              "1896  sampling decomposable generative adversarial r...\n",
              "1897           limits depth efficiencies self attention\n",
              "\n",
              "[1898 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKLOcws6mPBb"
      },
      "source": [
        "#topic_count =2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "A2QTSH1rXSjx",
        "outputId": "159f4b7c-4f2c-443c-d7ae-35acfd3c7171"
      },
      "source": [
        "cols = ['topic', 'title', 'text','url',  'similarity_score','rank',\n",
        "        'similarity_score_lda',\t'rank_lda']\n",
        "df_output = pd.DataFrame(columns=cols)\n",
        "df_output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>topic</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>url</th>\n",
              "      <th>similarity_score</th>\n",
              "      <th>rank</th>\n",
              "      <th>similarity_score_lda</th>\n",
              "      <th>rank_lda</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [topic, title, text, url, similarity_score, rank, similarity_score_lda, rank_lda]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3wdijWKnuD9"
      },
      "source": [
        "from joblib import Memory\n",
        "from pathlib import Path\n",
        "# !pip install requests\n",
        "import requests"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d51b511c737b41ab846a167d5e934f34",
            "c22662fda94f4efd92ae372e39a71687",
            "4e5202df885444e6b3126703b8140348",
            "f3d891c0ac3347a69785c86c716b1f1b",
            "5b9188ac63634b9dae09fba87c866254",
            "8966ddf543f8496eb11b96acf7ca83a6",
            "4fa7e53049d9418e97dee36155893f33",
            "4d54004f9bec42bf8386c72509d61fde",
            "72778c0f871d46ae8beb512a91b98c38",
            "c3446589739e4ae2828d1b11ae28cd9f",
            "a129ae5021364fc684759fbb7479e44e",
            "fd5da834d2da45a5bfb4af01bde800ed",
            "3eb0fa2c12474cc18b50c7cf70953916",
            "6af320a038b04e728a11fa4fd674f55a",
            "8821650883e245018bce02b7ff4f3ed8",
            "c159eea4fa90426a921df7d3c3d718e2",
            "4fc8279aadd94c07aa910a675a7bc1b9",
            "77819468aa694b05b5dd25b0ae852ed4",
            "10bc6b2da9ad44239f2b9edad12d7031",
            "0b39a048235a419d9626d2aed8a9addd",
            "164be9b1b41b422aa788fdbe8965f68c",
            "0b03595f6c594725ac159d2034114c3e",
            "1c1affee94054a63a6c43be9f48bd355",
            "167b764c57a54841823f8c163939b4f6",
            "a7e37c4e13d14672b930d61a86650299",
            "32a132887f5f427ebd89d39bd2ddc56c",
            "5e12f9cfc8a343ddb60f50c6de3275ed",
            "6faee1983f564d5993aee157c9deccc6",
            "0728253c9a0c44959e491c5d59061a72",
            "d96cf7785c304b2d97aed740e9a0dffe",
            "70769eb544f84c5fb688859594f2c635",
            "2ef86a3bd09143d897b6aed270c9f4bc",
            "bbeeed0f42b44431b2ae60f49526f4cc",
            "daf66f65ae614e3b8883b36ed0a2dce2",
            "502ed2954ecd4b4e8716749994f80a26",
            "ad5a760951964a1caa1a9ebdb5382df5",
            "62aa5006f8ac4876a918f2e7bd34d234",
            "a0db0184f95a426eac7b42d5d1654208",
            "d47392e81951406495627a879bc16911",
            "8d69df1e63804d55965233b99a2ffdf4"
          ]
        },
        "id": "21LubTeWprxH",
        "outputId": "831fbbea-46f2-45dd-8016-fdea2a097059"
      },
      "source": [
        "for id_ in range(topic_count):\n",
        "  topic = df['topic'][id_] + ' '+conf_name \n",
        "  print(\"topic: \", topic, \"id_=\", id_)\n",
        "  result = resource.list(q=topic, cx=cse_key).execute()\n",
        "  #print(len(result))\n",
        "  #print(result)\n",
        "\n",
        "  ## print the links\n",
        "  # i = 1\n",
        "  # for item in result['items']:\n",
        "  #   if 'pdf' not in item['link'] and '.pptx' not in item['link']:\n",
        "  #     print(i, \".\",item['title'], item['link'])\n",
        "  #     i+= 1\n",
        "  ##text extract\n",
        "  i = 1\n",
        "  topics = []\n",
        "  text = []\n",
        "  title = []\n",
        "  url = []\n",
        "  for item in result['items']:\n",
        "    if 'pdf' not in item['link'] and 'pptx' not in item['link'] and 'info' not in item['link'] and 'tfhub' not in item['link']:\n",
        "        print(i, \".\",item['title'], item['link'])\n",
        "        try:\n",
        "            article = fulltext(requests.get(item['link']).text)\n",
        "            #print(abstract_text)\n",
        "        except:\n",
        "            article = \"No Text\"\n",
        "\n",
        "        topics.append(topic)\n",
        "        title.append(item['title'])\n",
        "        url.append(item['link'])\n",
        "        text.append(article)\n",
        "        i+= 1\n",
        "        print(\"**********************************************\")\n",
        "\n",
        "    if 'pdf' in item['link']:\n",
        "      print(i, \".\",item['title'], item['link'])\n",
        "\n",
        "      path = Path('.')\n",
        "      CACHE_DIR =  path / '.jupyter_cache'\n",
        "      memory = Memory(CACHE_DIR, verbose=0)\n",
        "\n",
        "      @memory.cache\n",
        "      def download(url, dst):\n",
        "        response = requests.get(url, allow_redirects=True)\n",
        "        with open(dst, 'wb') as f:\n",
        "          f.write(response.content)\n",
        "\n",
        "      pdf_link = item['link']\n",
        "      fn = path / 'example.pdf'\n",
        "      download(pdf_link, fn)\n",
        "      print(fn)\n",
        "\n",
        "      #get pdf text\n",
        "      pdfConverter = PdfConverter(file_path='./example.pdf')\n",
        "      print(pdfConverter.convert_pdf_to_txt())\n",
        "      abstract_text = pdfConverter.convert_pdf_to_txt()\n",
        "\n",
        "      if abstract_text == \"No Text\":\n",
        "        continue\n",
        "      topics.append(topic)\n",
        "      title.append(item['title'])\n",
        "      url.append(item['link'])\n",
        "      text.append(abstract_text)\n",
        "      i+= 1\n",
        "      print(\"**********************************************\")\n",
        "\n",
        "  ## create new dataframe\n",
        "  #Create a new dataFrame \n",
        "  data = pd.DataFrame(columns = ['topic','title', 'text', 'url']) \n",
        "  data['topic'] = topics\n",
        "  data['title'] = title\n",
        "  data['text'] = text\n",
        "  data['url'] = url\n",
        "\n",
        "\n",
        "  #Show the data set\n",
        "  print(\"data:\", data)\n",
        "  print(\"**********************************************\")\n",
        "  ##distillation\n",
        "  data_all_news = data\n",
        "  data_all_news['text_distilled'] = data_all_news['text'].apply(lambda x : re.split('\\W+', str(x).lower()))\n",
        "  data_all_news['topic_distilled'] = data_all_news['title'].apply(lambda x : re.split('\\W+', str(x).lower()))\n",
        "  data_all_news['text_distilled'] = data_all_news['text_distilled'].apply(lemmatize)\n",
        "  data_all_news['topic_distilled'] = data_all_news['topic_distilled'].apply(lemmatize)\n",
        "  data_all_news['text_distilled'] = data_all_news['text_distilled'].apply(remove_stopwords)\n",
        "  data_all_news['topic_distilled'] = data_all_news['topic_distilled'].apply(remove_stopwords)\n",
        "  data_all_news['text_distilled'] = data_all_news['text_distilled'].apply(remove_too_short)\n",
        "  data_all_news['topic_distilled'] = data_all_news['topic_distilled'].apply(remove_too_short)\n",
        "\n",
        "\n",
        "  ## similarity computation \n",
        "  vectorizer = Vectorizer()\n",
        "  data_1 = data_all_news\n",
        "  data_2 = data_all_news\n",
        "  #print(\"data_2-------------\", data_all_news['text_distilled'])\n",
        "  similarity_list = method_3_with_sentence_sim_avg(topic,data_2, 'text_distilled')\n",
        "  data_1['most_similar'] = similarity_list\n",
        "\n",
        "  lst1 = []\n",
        "  for sim in similarity_list:\n",
        "    lst2 = []\n",
        "    id = sim[0]\n",
        "    score = sim[1]\n",
        "    lst1.append([data_1.iloc[id]['topic'], data_1.iloc[id]['title'], data_1.iloc[id]['text'], data_1.iloc[id]['url'],  score])\n",
        "\n",
        "  ##build a df\n",
        "  cols = ['topic', 'title', 'text','url',  'similarity_score']\n",
        "  df_final = pd.DataFrame(lst1, columns=cols)\n",
        "  print(df_final)\n",
        "\n",
        "  ##rank computation\n",
        "  df_final['rank'] = df_final['similarity_score'].rank(method='max' , ascending=False)\n",
        "  print(\"df_final after rank=\", df_final)\n",
        "\n",
        "  ##LDA text ranking\n",
        "  texts = data_all_news[\"text\"] \n",
        "  print(texts)\n",
        "  filteredTexts = filter_stopwords_from_list(texts)\n",
        "  (lstNGrams, corpusNGrams) = getNGramsConcat(filteredTexts, ngramsCount = 3)\n",
        "\n",
        "  ###LDA computing\n",
        "  numTopics = len(df_final)\n",
        "  (ldamodel, corpus) = runLDA(lstNGrams, numTopics) #(mid_grams, numTopics) #(lstNGrams, numTopics)\n",
        "  # print(f\"Top {numTopics} TOPICS:\")\n",
        "  # ldamodel.print_topics(num_topics=numTopics, num_words=5)\n",
        "  topn_words = {'Topic_' + str(i): [word for word, prob in ldamodel.show_topic(i, topn=10)] for i in range(0, ldamodel.num_topics)}\n",
        "  topic_list = topic_build(topn_words)\n",
        "  for i in range(len(topic_list)):\n",
        "    topic_list[i] = remove_duplicate_word(topic_list[i])\n",
        "  #adding lda distilled topic\n",
        "  data_all_news['lda_topic_distilled'] = topic_list\n",
        "\n",
        "  ##LDA-similarity computation\n",
        "  vectorizer = Vectorizer()\n",
        "  data_1 = data_all_news\n",
        "  data_2 = data_all_news\n",
        "  similarity_list = method_3_with_sentence_sim_avg(topic,data_2, 'lda_topic_distilled')\n",
        "  data_1['most_similar_lda'] = similarity_list\n",
        "  #similarity\n",
        "  lst1 = []\n",
        "  for sim in similarity_list:\n",
        "    lst2 = []\n",
        "    id = sim[0]\n",
        "    score = sim[1]\n",
        "    lst1.append(score)\n",
        "  df_final['similarity_score_lda'] = lst1\n",
        "  ##rank after lda\n",
        "  df_final['rank_lda'] = df_final['similarity_score_lda'].rank(method='max' , ascending=False)\n",
        "\n",
        "  ##append with result data drame\n",
        "  df_output = df_output.append(df_final)\n",
        "  print(\"df_output\", df_output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "topic:   neurips id_= 0\n",
            "1 . Training Generative Adversarial Networks with Limited Data https://papers.nips.cc/paper/2020/hash/8d30aa96e72440759f74bd2306c1fa3d-Abstract.html\n",
            "**********************************************\n",
            "2 . Estimating Training Data Influence by Tracing Gradient Descent https://papers.nips.cc/paper/2020/hash/e6385d39ec9394f2f3a354d9d2b88eec-Abstract.html\n",
            "**********************************************\n",
            "3 . Deep Evidential Regression https://papers.nips.cc/paper/2020/hash/aab085461de182608ee9f607f3f7d18f-Abstract.html\n",
            "**********************************************\n",
            "4 . Information Theoretic Regret Bounds for Online Nonlinear Control https://papers.nips.cc/paper/2020/hash/aee5620fa0432e528275b8668581d9a8-Abstract.html\n",
            "**********************************************\n",
            "5 . Universally Quantized Neural Compression https://papers.nips.cc/paper/2020/hash/92049debbe566ca5782a3045cf300a3c-Abstract.html\n",
            "**********************************************\n",
            "6 . Advances in Neural Information Processing Systems 33 (NeurIPS ... https://papers.nips.cc/paper/2020\n",
            "**********************************************\n",
            "7 . Graph Contrastive Learning with Augmentations https://papers.nips.cc/paper/2020/hash/3fe230348e9a12c13120749e3f9fa4cd-Abstract.html\n",
            "**********************************************\n",
            "8 . Efficient Exact Verification of Binarized Neural Networks https://papers.nips.cc/paper/2020/hash/1385974ed5904a438616ff7bdb3f7439-Abstract.html\n",
            "**********************************************\n",
            "9 . Path Sample-Analytic Gradient Estimators for Stochastic Binary ... https://papers.nips.cc/paper/2020/hash/96fca94df72984fc97ee5095410d4dec-Abstract.html\n",
            "**********************************************\n",
            "10 . Deep Archimedean Copulas https://papers.nips.cc/paper/2020/hash/10eb6500bd1e4a3704818012a1593cc3-Abstract.html\n",
            "**********************************************\n",
            "data:       topic                                              title  \\\n",
            "0   neurips  Training Generative Adversarial Networks with ...   \n",
            "1   neurips  Estimating Training Data Influence by Tracing ...   \n",
            "2   neurips                         Deep Evidential Regression   \n",
            "3   neurips  Information Theoretic Regret Bounds for Online...   \n",
            "4   neurips           Universally Quantized Neural Compression   \n",
            "5   neurips  Advances in Neural Information Processing Syst...   \n",
            "6   neurips      Graph Contrastive Learning with Augmentations   \n",
            "7   neurips  Efficient Exact Verification of Binarized Neur...   \n",
            "8   neurips  Path Sample-Analytic Gradient Estimators for S...   \n",
            "9   neurips                           Deep Archimedean Copulas   \n",
            "\n",
            "                                                text  \\\n",
            "0  Training Generative Adversarial Networks with ...   \n",
            "1  Estimating Training Data Influence by Tracing ...   \n",
            "2  Deep Evidential Regression\\n\\nPart of Advances...   \n",
            "3  Information Theoretic Regret Bounds for Online...   \n",
            "4  Universally Quantized Neural Compression\\n\\nPa...   \n",
            "5  Book\\n\\nDo not remove: This comment is monitor...   \n",
            "6  Graph Contrastive Learning with Augmentations\\...   \n",
            "7  Efficient Exact Verification of Binarized Neur...   \n",
            "8  Path Sample-Analytic Gradient Estimators for S...   \n",
            "9  Deep Archimedean Copulas\\n\\nPart of Advances i...   \n",
            "\n",
            "                                                 url  \n",
            "0  https://papers.nips.cc/paper/2020/hash/8d30aa9...  \n",
            "1  https://papers.nips.cc/paper/2020/hash/e6385d3...  \n",
            "2  https://papers.nips.cc/paper/2020/hash/aab0854...  \n",
            "3  https://papers.nips.cc/paper/2020/hash/aee5620...  \n",
            "4  https://papers.nips.cc/paper/2020/hash/92049de...  \n",
            "5                  https://papers.nips.cc/paper/2020  \n",
            "6  https://papers.nips.cc/paper/2020/hash/3fe2303...  \n",
            "7  https://papers.nips.cc/paper/2020/hash/1385974...  \n",
            "8  https://papers.nips.cc/paper/2020/hash/96fca94...  \n",
            "9  https://papers.nips.cc/paper/2020/hash/10eb650...  \n",
            "**********************************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "      topic                                              title  \\\n",
            "0   neurips  Training Generative Adversarial Networks with ...   \n",
            "1   neurips  Estimating Training Data Influence by Tracing ...   \n",
            "2   neurips                         Deep Evidential Regression   \n",
            "3   neurips  Information Theoretic Regret Bounds for Online...   \n",
            "4   neurips           Universally Quantized Neural Compression   \n",
            "5   neurips  Advances in Neural Information Processing Syst...   \n",
            "6   neurips      Graph Contrastive Learning with Augmentations   \n",
            "7   neurips  Efficient Exact Verification of Binarized Neur...   \n",
            "8   neurips  Path Sample-Analytic Gradient Estimators for S...   \n",
            "9   neurips                           Deep Archimedean Copulas   \n",
            "\n",
            "                                                text  \\\n",
            "0  Training Generative Adversarial Networks with ...   \n",
            "1  Estimating Training Data Influence by Tracing ...   \n",
            "2  Deep Evidential Regression\\n\\nPart of Advances...   \n",
            "3  Information Theoretic Regret Bounds for Online...   \n",
            "4  Universally Quantized Neural Compression\\n\\nPa...   \n",
            "5  Book\\n\\nDo not remove: This comment is monitor...   \n",
            "6  Graph Contrastive Learning with Augmentations\\...   \n",
            "7  Efficient Exact Verification of Binarized Neur...   \n",
            "8  Path Sample-Analytic Gradient Estimators for S...   \n",
            "9  Deep Archimedean Copulas\\n\\nPart of Advances i...   \n",
            "\n",
            "                                                 url  similarity_score  \n",
            "0  https://papers.nips.cc/paper/2020/hash/8d30aa9...          0.965153  \n",
            "1  https://papers.nips.cc/paper/2020/hash/e6385d3...          0.965144  \n",
            "2  https://papers.nips.cc/paper/2020/hash/aab0854...          0.965102  \n",
            "3  https://papers.nips.cc/paper/2020/hash/aee5620...          0.965130  \n",
            "4  https://papers.nips.cc/paper/2020/hash/92049de...          0.965285  \n",
            "5                  https://papers.nips.cc/paper/2020          0.965377  \n",
            "6  https://papers.nips.cc/paper/2020/hash/3fe2303...          0.960548  \n",
            "7  https://papers.nips.cc/paper/2020/hash/1385974...          0.962081  \n",
            "8  https://papers.nips.cc/paper/2020/hash/96fca94...          0.961407  \n",
            "9  https://papers.nips.cc/paper/2020/hash/10eb650...          0.961599  \n",
            "df_final after rank=       topic                                              title  \\\n",
            "0   neurips  Training Generative Adversarial Networks with ...   \n",
            "1   neurips  Estimating Training Data Influence by Tracing ...   \n",
            "2   neurips                         Deep Evidential Regression   \n",
            "3   neurips  Information Theoretic Regret Bounds for Online...   \n",
            "4   neurips           Universally Quantized Neural Compression   \n",
            "5   neurips  Advances in Neural Information Processing Syst...   \n",
            "6   neurips      Graph Contrastive Learning with Augmentations   \n",
            "7   neurips  Efficient Exact Verification of Binarized Neur...   \n",
            "8   neurips  Path Sample-Analytic Gradient Estimators for S...   \n",
            "9   neurips                           Deep Archimedean Copulas   \n",
            "\n",
            "                                                text  \\\n",
            "0  Training Generative Adversarial Networks with ...   \n",
            "1  Estimating Training Data Influence by Tracing ...   \n",
            "2  Deep Evidential Regression\\n\\nPart of Advances...   \n",
            "3  Information Theoretic Regret Bounds for Online...   \n",
            "4  Universally Quantized Neural Compression\\n\\nPa...   \n",
            "5  Book\\n\\nDo not remove: This comment is monitor...   \n",
            "6  Graph Contrastive Learning with Augmentations\\...   \n",
            "7  Efficient Exact Verification of Binarized Neur...   \n",
            "8  Path Sample-Analytic Gradient Estimators for S...   \n",
            "9  Deep Archimedean Copulas\\n\\nPart of Advances i...   \n",
            "\n",
            "                                                 url  similarity_score  rank  \n",
            "0  https://papers.nips.cc/paper/2020/hash/8d30aa9...          0.965153   3.0  \n",
            "1  https://papers.nips.cc/paper/2020/hash/e6385d3...          0.965144   4.0  \n",
            "2  https://papers.nips.cc/paper/2020/hash/aab0854...          0.965102   6.0  \n",
            "3  https://papers.nips.cc/paper/2020/hash/aee5620...          0.965130   5.0  \n",
            "4  https://papers.nips.cc/paper/2020/hash/92049de...          0.965285   2.0  \n",
            "5                  https://papers.nips.cc/paper/2020          0.965377   1.0  \n",
            "6  https://papers.nips.cc/paper/2020/hash/3fe2303...          0.960548  10.0  \n",
            "7  https://papers.nips.cc/paper/2020/hash/1385974...          0.962081   7.0  \n",
            "8  https://papers.nips.cc/paper/2020/hash/96fca94...          0.961407   9.0  \n",
            "9  https://papers.nips.cc/paper/2020/hash/10eb650...          0.961599   8.0  \n",
            "0    Training Generative Adversarial Networks with ...\n",
            "1    Estimating Training Data Influence by Tracing ...\n",
            "2    Deep Evidential Regression\\n\\nPart of Advances...\n",
            "3    Information Theoretic Regret Bounds for Online...\n",
            "4    Universally Quantized Neural Compression\\n\\nPa...\n",
            "5    Book\\n\\nDo not remove: This comment is monitor...\n",
            "6    Graph Contrastive Learning with Augmentations\\...\n",
            "7    Efficient Exact Verification of Binarized Neur...\n",
            "8    Path Sample-Analytic Gradient Estimators for S...\n",
            "9    Deep Archimedean Copulas\\n\\nPart of Advances i...\n",
            "Name: text, dtype: object\n",
            "Training\n",
            "Generative\n",
            "Adversarial\n",
            "Networks\n",
            "with\n",
            "Limited\n",
            "Data\n",
            "Part\n",
            "of\n",
            "Advances\n",
            "in\n",
            "Neural\n",
            "Information\n",
            "Processing\n",
            "Systems\n",
            "33\n",
            "(\n",
            "NeurIPS\n",
            "2020\n",
            ")\n",
            "Authors\n",
            "Tero\n",
            "Karras\n",
            ",\n",
            "Miika\n",
            "Aittala\n",
            ",\n",
            "Janne\n",
            "Hellsten\n",
            ",\n",
            "Samuli\n",
            "Laine\n",
            ",\n",
            "Jaakko\n",
            "Lehtinen\n",
            ",\n",
            "Timo\n",
            "Aila\n",
            "Abstract\n",
            "Training\n",
            "generative\n",
            "adversarial\n",
            "networks\n",
            "(\n",
            "GAN\n",
            ")\n",
            "using\n",
            "too\n",
            "little\n",
            "data\n",
            "typically\n",
            "leads\n",
            "to\n",
            "discriminator\n",
            "overfitting\n",
            ",\n",
            "causing\n",
            "training\n",
            "to\n",
            "diverge\n",
            ".\n",
            "We\n",
            "propose\n",
            "an\n",
            "adaptive\n",
            "discriminator\n",
            "augmentation\n",
            "mechanism\n",
            "that\n",
            "significantly\n",
            "stabilizes\n",
            "training\n",
            "in\n",
            "limited\n",
            "data\n",
            "regimes\n",
            ".\n",
            "The\n",
            "approach\n",
            "does\n",
            "not\n",
            "require\n",
            "changes\n",
            "to\n",
            "loss\n",
            "functions\n",
            "or\n",
            "network\n",
            "architectures\n",
            ",\n",
            "and\n",
            "is\n",
            "applicable\n",
            "both\n",
            "when\n",
            "training\n",
            "from\n",
            "scratch\n",
            "and\n",
            "when\n",
            "fine-tuning\n",
            "an\n",
            "existing\n",
            "GAN\n",
            "on\n",
            "another\n",
            "dataset\n",
            ".\n",
            "We\n",
            "demonstrate\n",
            ",\n",
            "on\n",
            "several\n",
            "datasets\n",
            ",\n",
            "that\n",
            "good\n",
            "results\n",
            "are\n",
            "now\n",
            "possible\n",
            "using\n",
            "only\n",
            "a\n",
            "few\n",
            "thousand\n",
            "training\n",
            "images\n",
            ",\n",
            "often\n",
            "matching\n",
            "StyleGAN2\n",
            "results\n",
            "with\n",
            "an\n",
            "order\n",
            "of\n",
            "magnitude\n",
            "fewer\n",
            "images\n",
            ".\n",
            "We\n",
            "expect\n",
            "this\n",
            "to\n",
            "open\n",
            "up\n",
            "new\n",
            "application\n",
            "domains\n",
            "for\n",
            "GANs\n",
            ".\n",
            "We\n",
            "also\n",
            "find\n",
            "that\n",
            "the\n",
            "widely\n",
            "used\n",
            "CIFAR-10\n",
            "is\n",
            ",\n",
            "in\n",
            "fact\n",
            ",\n",
            "a\n",
            "limited\n",
            "data\n",
            "benchmark\n",
            ",\n",
            "and\n",
            "improve\n",
            "the\n",
            "record\n",
            "FID\n",
            "from\n",
            "5.59\n",
            "to\n",
            "2.42\n",
            ".\n",
            "Estimating\n",
            "Training\n",
            "Data\n",
            "Influence\n",
            "by\n",
            "Tracing\n",
            "Gradient\n",
            "Descent\n",
            "Part\n",
            "of\n",
            "Advances\n",
            "in\n",
            "Neural\n",
            "Information\n",
            "Processing\n",
            "Systems\n",
            "33\n",
            "(\n",
            "NeurIPS\n",
            "2020\n",
            ")\n",
            "Authors\n",
            "Garima\n",
            "Pruthi\n",
            ",\n",
            "Frederick\n",
            "Liu\n",
            ",\n",
            "Satyen\n",
            "Kale\n",
            ",\n",
            "Mukund\n",
            "Sundararajan\n",
            "Abstract\n",
            "We\n",
            "introduce\n",
            "a\n",
            "method\n",
            "called\n",
            "TracIn\n",
            "that\n",
            "computes\n",
            "the\n",
            "influence\n",
            "of\n",
            "a\n",
            "training\n",
            "example\n",
            "on\n",
            "a\n",
            "prediction\n",
            "made\n",
            "by\n",
            "the\n",
            "model\n",
            ".\n",
            "The\n",
            "idea\n",
            "is\n",
            "to\n",
            "trace\n",
            "how\n",
            "the\n",
            "loss\n",
            "on\n",
            "the\n",
            "test\n",
            "point\n",
            "changes\n",
            "during\n",
            "the\n",
            "training\n",
            "process\n",
            "whenever\n",
            "the\n",
            "training\n",
            "example\n",
            "of\n",
            "interest\n",
            "was\n",
            "utilized\n",
            ".\n",
            "We\n",
            "provide\n",
            "a\n",
            "scalable\n",
            "implementation\n",
            "of\n",
            "TracIn\n",
            "via\n",
            ":\n",
            "(\n",
            "a\n",
            ")\n",
            "a\n",
            "first-order\n",
            "gradient\n",
            "approximation\n",
            "to\n",
            "the\n",
            "exact\n",
            "computation\n",
            ",\n",
            "(\n",
            "b\n",
            ")\n",
            "saved\n",
            "checkpoints\n",
            "of\n",
            "standard\n",
            "training\n",
            "procedures\n",
            ",\n",
            "and\n",
            "(\n",
            "c\n",
            ")\n",
            "cherry-picking\n",
            "layers\n",
            "of\n",
            "a\n",
            "deep\n",
            "neural\n",
            "network\n",
            ".\n",
            "In\n",
            "contrast\n",
            "with\n",
            "previously\n",
            "proposed\n",
            "methods\n",
            ",\n",
            "TracIn\n",
            "is\n",
            "simple\n",
            "to\n",
            "implement\n",
            ";\n",
            "all\n",
            "it\n",
            "needs\n",
            "is\n",
            "the\n",
            "ability\n",
            "to\n",
            "work\n",
            "with\n",
            "gradients\n",
            ",\n",
            "checkpoints\n",
            ",\n",
            "and\n",
            "loss\n",
            "functions\n",
            ".\n",
            "The\n",
            "method\n",
            "is\n",
            "general\n",
            ".\n",
            "It\n",
            "applies\n",
            "to\n",
            "any\n",
            "machine\n",
            "learning\n",
            "model\n",
            "trained\n",
            "using\n",
            "stochastic\n",
            "gradient\n",
            "descent\n",
            "or\n",
            "a\n",
            "variant\n",
            "of\n",
            "it\n",
            ",\n",
            "agnostic\n",
            "of\n",
            "architecture\n",
            ",\n",
            "domain\n",
            "and\n",
            "task\n",
            ".\n",
            "We\n",
            "expect\n",
            "the\n",
            "method\n",
            "to\n",
            "be\n",
            "widely\n",
            "useful\n",
            "within\n",
            "processes\n",
            "that\n",
            "study\n",
            "and\n",
            "improve\n",
            "training\n",
            "data\n",
            ".\n",
            "Deep\n",
            "Evidential\n",
            "Regression\n",
            "Part\n",
            "of\n",
            "Advances\n",
            "in\n",
            "Neural\n",
            "Information\n",
            "Processing\n",
            "Systems\n",
            "33\n",
            "(\n",
            "NeurIPS\n",
            "2020\n",
            ")\n",
            "Authors\n",
            "Alexander\n",
            "Amini\n",
            ",\n",
            "Wilko\n",
            "Schwarting\n",
            ",\n",
            "Ava\n",
            "Soleimany\n",
            ",\n",
            "Daniela\n",
            "Rus\n",
            "Abstract\n",
            "Deterministic\n",
            "neural\n",
            "networks\n",
            "(\n",
            "NNs\n",
            ")\n",
            "are\n",
            "increasingly\n",
            "being\n",
            "deployed\n",
            "in\n",
            "safety\n",
            "critical\n",
            "domains\n",
            ",\n",
            "where\n",
            "calibrated\n",
            ",\n",
            "robust\n",
            ",\n",
            "and\n",
            "efficient\n",
            "measures\n",
            "of\n",
            "uncertainty\n",
            "are\n",
            "crucial\n",
            ".\n",
            "In\n",
            "this\n",
            "paper\n",
            ",\n",
            "we\n",
            "propose\n",
            "a\n",
            "novel\n",
            "method\n",
            "for\n",
            "training\n",
            "non-Bayesian\n",
            "NNs\n",
            "to\n",
            "estimate\n",
            "a\n",
            "continuous\n",
            "target\n",
            "as\n",
            "well\n",
            "as\n",
            "its\n",
            "associated\n",
            "evidence\n",
            "in\n",
            "order\n",
            "to\n",
            "learn\n",
            "both\n",
            "aleatoric\n",
            "and\n",
            "epistemic\n",
            "uncertainty\n",
            ".\n",
            "We\n",
            "accomplish\n",
            "this\n",
            "by\n",
            "placing\n",
            "evidential\n",
            "priors\n",
            "over\n",
            "the\n",
            "original\n",
            "Gaussian\n",
            "likelihood\n",
            "function\n",
            "and\n",
            "training\n",
            "the\n",
            "NN\n",
            "to\n",
            "infer\n",
            "the\n",
            "hyperparameters\n",
            "of\n",
            "the\n",
            "evidential\n",
            "distribution\n",
            ".\n",
            "We\n",
            "additionally\n",
            "impose\n",
            "priors\n",
            "during\n",
            "training\n",
            "such\n",
            "that\n",
            "the\n",
            "model\n",
            "is\n",
            "regularized\n",
            "when\n",
            "its\n",
            "predicted\n",
            "evidence\n",
            "is\n",
            "not\n",
            "aligned\n",
            "with\n",
            "the\n",
            "correct\n",
            "output\n",
            ".\n",
            "Our\n",
            "method\n",
            "does\n",
            "not\n",
            "rely\n",
            "on\n",
            "sampling\n",
            "during\n",
            "inference\n",
            "or\n",
            "on\n",
            "out-of-distribution\n",
            "(\n",
            "OOD\n",
            ")\n",
            "examples\n",
            "for\n",
            "training\n",
            ",\n",
            "thus\n",
            "enabling\n",
            "efficient\n",
            "and\n",
            "scalable\n",
            "uncertainty\n",
            "learning\n",
            ".\n",
            "We\n",
            "demonstrate\n",
            "learning\n",
            "well-calibrated\n",
            "measures\n",
            "of\n",
            "uncertainty\n",
            "on\n",
            "various\n",
            "benchmarks\n",
            ",\n",
            "scaling\n",
            "to\n",
            "complex\n",
            "computer\n",
            "vision\n",
            "tasks\n",
            ",\n",
            "as\n",
            "well\n",
            "as\n",
            "robustness\n",
            "to\n",
            "adversarial\n",
            "and\n",
            "OOD\n",
            "test\n",
            "samples\n",
            ".\n",
            "Information\n",
            "Theoretic\n",
            "Regret\n",
            "Bounds\n",
            "for\n",
            "Online\n",
            "Nonlinear\n",
            "Control\n",
            "Part\n",
            "of\n",
            "Advances\n",
            "in\n",
            "Neural\n",
            "Information\n",
            "Processing\n",
            "Systems\n",
            "33\n",
            "(\n",
            "NeurIPS\n",
            "2020\n",
            ")\n",
            "Authors\n",
            "Sham\n",
            "Kakade\n",
            ",\n",
            "Akshay\n",
            "Krishnamurthy\n",
            ",\n",
            "Kendall\n",
            "Lowrey\n",
            ",\n",
            "Motoya\n",
            "Ohnishi\n",
            ",\n",
            "Wen\n",
            "Sun\n",
            "Abstract\n",
            "This\n",
            "work\n",
            "studies\n",
            "the\n",
            "problem\n",
            "of\n",
            "sequential\n",
            "control\n",
            "in\n",
            "an\n",
            "unknown\n",
            ",\n",
            "nonlinear\n",
            "dynamical\n",
            "system\n",
            ",\n",
            "where\n",
            "we\n",
            "model\n",
            "the\n",
            "underlying\n",
            "system\n",
            "dynamics\n",
            "as\n",
            "an\n",
            "unknown\n",
            "function\n",
            "in\n",
            "a\n",
            "known\n",
            "Reproducing\n",
            "Kernel\n",
            "Hilbert\n",
            "Space\n",
            ".\n",
            "This\n",
            "framework\n",
            "yields\n",
            "a\n",
            "general\n",
            "setting\n",
            "that\n",
            "permits\n",
            "discrete\n",
            "and\n",
            "continuous\n",
            "control\n",
            "inputs\n",
            "as\n",
            "well\n",
            "as\n",
            "non-smooth\n",
            ",\n",
            "non-differentiable\n",
            "dynamics\n",
            ".\n",
            "Our\n",
            "main\n",
            "result\n",
            ",\n",
            "the\n",
            "Lower\n",
            "Confidence-based\n",
            "Continuous\n",
            "Control\n",
            "(\n",
            "LC3\n",
            ")\n",
            "algorithm\n",
            ",\n",
            "enjoys\n",
            "a\n",
            "near-optimal\n",
            "$\n",
            "O\n",
            "(\n",
            "\\sqrt\n",
            "{\n",
            "T\n",
            "}\n",
            ")\n",
            "$\n",
            "regret\n",
            "bound\n",
            "against\n",
            "the\n",
            "optimal\n",
            "controller\n",
            "in\n",
            "episodic\n",
            "settings\n",
            ",\n",
            "where\n",
            "$\n",
            "T\n",
            "$\n",
            "is\n",
            "the\n",
            "number\n",
            "of\n",
            "episodes\n",
            ".\n",
            "The\n",
            "bound\n",
            "has\n",
            "no\n",
            "explicit\n",
            "dependence\n",
            "on\n",
            "dimension\n",
            "of\n",
            "the\n",
            "system\n",
            "dynamics\n",
            ",\n",
            "which\n",
            "could\n",
            "be\n",
            "infinite\n",
            ",\n",
            "but\n",
            "instead\n",
            "only\n",
            "depends\n",
            "on\n",
            "information\n",
            "theoretic\n",
            "quantities\n",
            ".\n",
            "We\n",
            "empirically\n",
            "show\n",
            "its\n",
            "application\n",
            "to\n",
            "a\n",
            "number\n",
            "of\n",
            "nonlinear\n",
            "control\n",
            "tasks\n",
            "and\n",
            "demonstrate\n",
            "the\n",
            "benefit\n",
            "of\n",
            "exploration\n",
            "for\n",
            "learning\n",
            "model\n",
            "dynamics\n",
            ".\n",
            "Universally\n",
            "Quantized\n",
            "Neural\n",
            "Compression\n",
            "Part\n",
            "of\n",
            "Advances\n",
            "in\n",
            "Neural\n",
            "Information\n",
            "Processing\n",
            "Systems\n",
            "33\n",
            "(\n",
            "NeurIPS\n",
            "2020\n",
            ")\n",
            "Authors\n",
            "Eirikur\n",
            "Agustsson\n",
            ",\n",
            "Lucas\n",
            "Theis\n",
            "Abstract\n",
            "A\n",
            "popular\n",
            "approach\n",
            "to\n",
            "learning\n",
            "encoders\n",
            "for\n",
            "lossy\n",
            "compression\n",
            "is\n",
            "to\n",
            "use\n",
            "additive\n",
            "uniform\n",
            "noise\n",
            "during\n",
            "training\n",
            "as\n",
            "a\n",
            "differentiable\n",
            "approximation\n",
            "to\n",
            "test-time\n",
            "quantization\n",
            ".\n",
            "We\n",
            "demonstrate\n",
            "that\n",
            "a\n",
            "uniform\n",
            "noise\n",
            "channel\n",
            "can\n",
            "also\n",
            "be\n",
            "implemented\n",
            "at\n",
            "test\n",
            "time\n",
            "using\n",
            "universal\n",
            "quantization\n",
            "(\n",
            "Ziv\n",
            ",\n",
            "1985\n",
            ")\n",
            ".\n",
            "This\n",
            "allows\n",
            "us\n",
            "to\n",
            "eliminate\n",
            "the\n",
            "mismatch\n",
            "between\n",
            "training\n",
            "and\n",
            "test\n",
            "phases\n",
            "while\n",
            "maintaining\n",
            "a\n",
            "completely\n",
            "differentiable\n",
            "loss\n",
            "function\n",
            ".\n",
            "Implementing\n",
            "the\n",
            "uniform\n",
            "noise\n",
            "channel\n",
            "is\n",
            "a\n",
            "special\n",
            "case\n",
            "of\n",
            "the\n",
            "more\n",
            "general\n",
            "problem\n",
            "of\n",
            "communicating\n",
            "a\n",
            "sample\n",
            ",\n",
            "which\n",
            "we\n",
            "prove\n",
            "is\n",
            "computationally\n",
            "hard\n",
            "if\n",
            "we\n",
            "do\n",
            "not\n",
            "make\n",
            "assumptions\n",
            "about\n",
            "its\n",
            "distribution\n",
            ".\n",
            "However\n",
            ",\n",
            "the\n",
            "uniform\n",
            "special\n",
            "case\n",
            "is\n",
            "efficient\n",
            "as\n",
            "well\n",
            "as\n",
            "easy\n",
            "to\n",
            "implement\n",
            "and\n",
            "thus\n",
            "of\n",
            "great\n",
            "interest\n",
            "from\n",
            "a\n",
            "practical\n",
            "point\n",
            "of\n",
            "view\n",
            ".\n",
            "Finally\n",
            ",\n",
            "we\n",
            "show\n",
            "that\n",
            "quantization\n",
            "can\n",
            "be\n",
            "obtained\n",
            "as\n",
            "a\n",
            "limiting\n",
            "case\n",
            "of\n",
            "a\n",
            "soft\n",
            "quantizer\n",
            "applied\n",
            "to\n",
            "the\n",
            "uniform\n",
            "noise\n",
            "channel\n",
            ",\n",
            "bridging\n",
            "compression\n",
            "with\n",
            "and\n",
            "without\n",
            "quantization\n",
            ".\n",
            "Book\n",
            "Do\n",
            "not\n",
            "remove\n",
            ":\n",
            "This\n",
            "comment\n",
            "is\n",
            "monitored\n",
            "to\n",
            "verify\n",
            "that\n",
            "the\n",
            "site\n",
            "is\n",
            "working\n",
            "properly\n",
            "Graph\n",
            "Contrastive\n",
            "Learning\n",
            "with\n",
            "Augmentations\n",
            "Part\n",
            "of\n",
            "Advances\n",
            "in\n",
            "Neural\n",
            "Information\n",
            "Processing\n",
            "Systems\n",
            "33\n",
            "(\n",
            "NeurIPS\n",
            "2020\n",
            ")\n",
            "Authors\n",
            "Yuning\n",
            "You\n",
            ",\n",
            "Tianlong\n",
            "Chen\n",
            ",\n",
            "Yongduo\n",
            "Sui\n",
            ",\n",
            "Ting\n",
            "Chen\n",
            ",\n",
            "Zhangyang\n",
            "Wang\n",
            ",\n",
            "Yang\n",
            "Shen\n",
            "Abstract\n",
            "Generalizable\n",
            ",\n",
            "transferrable\n",
            ",\n",
            "and\n",
            "robust\n",
            "representation\n",
            "learning\n",
            "on\n",
            "graph-structured\n",
            "data\n",
            "remains\n",
            "a\n",
            "challenge\n",
            "for\n",
            "current\n",
            "graph\n",
            "neural\n",
            "networks\n",
            "(\n",
            "GNNs\n",
            ")\n",
            ".\n",
            "Unlike\n",
            "what\n",
            "has\n",
            "been\n",
            "developed\n",
            "for\n",
            "convolutional\n",
            "neural\n",
            "networks\n",
            "(\n",
            "CNNs\n",
            ")\n",
            "for\n",
            "image\n",
            "data\n",
            ",\n",
            "self-supervised\n",
            "learning\n",
            "and\n",
            "pre-training\n",
            "are\n",
            "less\n",
            "explored\n",
            "for\n",
            "GNNs\n",
            ".\n",
            "In\n",
            "this\n",
            "paper\n",
            ",\n",
            "we\n",
            "propose\n",
            "a\n",
            "graph\n",
            "contrastive\n",
            "learning\n",
            "(\n",
            "GraphCL\n",
            ")\n",
            "framework\n",
            "for\n",
            "learning\n",
            "unsupervised\n",
            "representations\n",
            "of\n",
            "graph\n",
            "data\n",
            ".\n",
            "We\n",
            "first\n",
            "design\n",
            "four\n",
            "types\n",
            "of\n",
            "graph\n",
            "augmentations\n",
            "to\n",
            "incorporate\n",
            "various\n",
            "priors\n",
            ".\n",
            "We\n",
            "then\n",
            "systematically\n",
            "study\n",
            "the\n",
            "impact\n",
            "of\n",
            "various\n",
            "combinations\n",
            "of\n",
            "graph\n",
            "augmentations\n",
            "on\n",
            "multiple\n",
            "datasets\n",
            ",\n",
            "in\n",
            "four\n",
            "different\n",
            "settings\n",
            ":\n",
            "semi-supervised\n",
            ",\n",
            "unsupervised\n",
            ",\n",
            "and\n",
            "transfer\n",
            "learning\n",
            "as\n",
            "well\n",
            "as\n",
            "adversarial\n",
            "attacks\n",
            ".\n",
            "The\n",
            "results\n",
            "show\n",
            "that\n",
            ",\n",
            "even\n",
            "without\n",
            "tuning\n",
            "augmentation\n",
            "extents\n",
            "nor\n",
            "using\n",
            "sophisticated\n",
            "GNN\n",
            "architectures\n",
            ",\n",
            "our\n",
            "GraphCL\n",
            "framework\n",
            "can\n",
            "produce\n",
            "graph\n",
            "representations\n",
            "of\n",
            "similar\n",
            "or\n",
            "better\n",
            "generalizability\n",
            ",\n",
            "transferrability\n",
            ",\n",
            "and\n",
            "robustness\n",
            "compared\n",
            "to\n",
            "state-of-the-art\n",
            "methods\n",
            ".\n",
            "We\n",
            "also\n",
            "investigate\n",
            "the\n",
            "impact\n",
            "of\n",
            "parameterized\n",
            "graph\n",
            "augmentation\n",
            "extents\n",
            "and\n",
            "patterns\n",
            ",\n",
            "and\n",
            "observe\n",
            "further\n",
            "performance\n",
            "gains\n",
            "in\n",
            "preliminary\n",
            "experiments\n",
            ".\n",
            "Our\n",
            "codes\n",
            "are\n",
            "available\n",
            "at\n",
            "https\n",
            ":\n",
            "//github.com/Shen-Lab/GraphCL\n",
            ".\n",
            "Efficient\n",
            "Exact\n",
            "Verification\n",
            "of\n",
            "Binarized\n",
            "Neural\n",
            "Networks\n",
            "Part\n",
            "of\n",
            "Advances\n",
            "in\n",
            "Neural\n",
            "Information\n",
            "Processing\n",
            "Systems\n",
            "33\n",
            "(\n",
            "NeurIPS\n",
            "2020\n",
            ")\n",
            "Authors\n",
            "Kai\n",
            "Jia\n",
            ",\n",
            "Martin\n",
            "Rinard\n",
            "Abstract\n",
            "Concerned\n",
            "with\n",
            "the\n",
            "reliability\n",
            "of\n",
            "neural\n",
            "networks\n",
            ",\n",
            "researchers\n",
            "have\n",
            "developed\n",
            "verification\n",
            "techniques\n",
            "to\n",
            "prove\n",
            "their\n",
            "robustness\n",
            ".\n",
            "Most\n",
            "verifiers\n",
            "work\n",
            "with\n",
            "real-valued\n",
            "networks\n",
            ".\n",
            "Unfortunately\n",
            ",\n",
            "the\n",
            "exact\n",
            "(\n",
            "complete\n",
            "and\n",
            "sound\n",
            ")\n",
            "verifiers\n",
            "face\n",
            "scalability\n",
            "challenges\n",
            "and\n",
            "provide\n",
            "no\n",
            "correctness\n",
            "guarantees\n",
            "due\n",
            "to\n",
            "floating\n",
            "point\n",
            "errors\n",
            ".\n",
            "We\n",
            "argue\n",
            "that\n",
            "Binarized\n",
            "Neural\n",
            "Networks\n",
            "(\n",
            "BNNs\n",
            ")\n",
            "provide\n",
            "comparable\n",
            "robustness\n",
            "and\n",
            "allow\n",
            "exact\n",
            "and\n",
            "significantly\n",
            "more\n",
            "efficient\n",
            "verification\n",
            ".\n",
            "We\n",
            "present\n",
            "a\n",
            "new\n",
            "system\n",
            ",\n",
            "EEV\n",
            ",\n",
            "for\n",
            "efficient\n",
            "and\n",
            "exact\n",
            "verification\n",
            "of\n",
            "BNNs\n",
            ".\n",
            "EEV\n",
            "consists\n",
            "of\n",
            "two\n",
            "parts\n",
            ":\n",
            "(\n",
            "i\n",
            ")\n",
            "a\n",
            "novel\n",
            "SAT\n",
            "solver\n",
            "that\n",
            "speeds\n",
            "up\n",
            "BNN\n",
            "verification\n",
            "by\n",
            "natively\n",
            "handling\n",
            "the\n",
            "reified\n",
            "cardinality\n",
            "constraints\n",
            "arising\n",
            "in\n",
            "BNN\n",
            "encodings\n",
            ";\n",
            "and\n",
            "(\n",
            "ii\n",
            ")\n",
            "strategies\n",
            "to\n",
            "train\n",
            "solver-friendly\n",
            "robust\n",
            "BNNs\n",
            "by\n",
            "inducing\n",
            "balanced\n",
            "layer-wise\n",
            "sparsity\n",
            "and\n",
            "low\n",
            "cardinality\n",
            "bounds\n",
            ",\n",
            "and\n",
            "adaptively\n",
            "cancelling\n",
            "the\n",
            "gradients\n",
            ".\n",
            "We\n",
            "demonstrate\n",
            "the\n",
            "effectiveness\n",
            "of\n",
            "EEV\n",
            "by\n",
            "presenting\n",
            "the\n",
            "first\n",
            "exact\n",
            "verification\n",
            "results\n",
            "for\n",
            "L-inf-bounded\n",
            "adversarial\n",
            "robustness\n",
            "of\n",
            "nontrivial\n",
            "convolutional\n",
            "BNNs\n",
            "on\n",
            "the\n",
            "MNIST\n",
            "and\n",
            "CIFAR10\n",
            "datasets\n",
            ".\n",
            "Compared\n",
            "to\n",
            "exact\n",
            "verification\n",
            "of\n",
            "real-valued\n",
            "networks\n",
            "of\n",
            "the\n",
            "same\n",
            "architectures\n",
            "on\n",
            "the\n",
            "same\n",
            "tasks\n",
            ",\n",
            "EEV\n",
            "verifies\n",
            "BNNs\n",
            "hundreds\n",
            "to\n",
            "thousands\n",
            "of\n",
            "times\n",
            "faster\n",
            ",\n",
            "while\n",
            "delivering\n",
            "comparable\n",
            "verifiable\n",
            "accuracy\n",
            "in\n",
            "most\n",
            "cases\n",
            ".\n",
            "Path\n",
            "Sample-Analytic\n",
            "Gradient\n",
            "Estimators\n",
            "for\n",
            "Stochastic\n",
            "Binary\n",
            "Networks\n",
            "Part\n",
            "of\n",
            "Advances\n",
            "in\n",
            "Neural\n",
            "Information\n",
            "Processing\n",
            "Systems\n",
            "33\n",
            "(\n",
            "NeurIPS\n",
            "2020\n",
            ")\n",
            "Authors\n",
            "Alexander\n",
            "Shekhovtsov\n",
            ",\n",
            "Viktor\n",
            "Yanush\n",
            ",\n",
            "Boris\n",
            "Flach\n",
            "Abstract\n",
            "In\n",
            "neural\n",
            "networks\n",
            "with\n",
            "binary\n",
            "activations\n",
            "and\n",
            "or\n",
            "binary\n",
            "weights\n",
            "the\n",
            "training\n",
            "by\n",
            "gradient\n",
            "descent\n",
            "is\n",
            "complicated\n",
            "as\n",
            "the\n",
            "model\n",
            "has\n",
            "piecewise\n",
            "constant\n",
            "response\n",
            ".\n",
            "We\n",
            "consider\n",
            "stochastic\n",
            "binary\n",
            "networks\n",
            ",\n",
            "obtained\n",
            "by\n",
            "adding\n",
            "noises\n",
            "in\n",
            "front\n",
            "of\n",
            "activations\n",
            ".\n",
            "The\n",
            "expected\n",
            "model\n",
            "response\n",
            "becomes\n",
            "a\n",
            "smooth\n",
            "function\n",
            "of\n",
            "parameters\n",
            ",\n",
            "its\n",
            "gradient\n",
            "is\n",
            "well\n",
            "defined\n",
            "but\n",
            "it\n",
            "is\n",
            "challenging\n",
            "to\n",
            "estimate\n",
            "it\n",
            "accurately\n",
            ".\n",
            "We\n",
            "propose\n",
            "a\n",
            "new\n",
            "method\n",
            "for\n",
            "this\n",
            "estimation\n",
            "problem\n",
            "combining\n",
            "sampling\n",
            "and\n",
            "analytic\n",
            "approximation\n",
            "steps\n",
            ".\n",
            "The\n",
            "method\n",
            "has\n",
            "a\n",
            "significantly\n",
            "reduced\n",
            "variance\n",
            "at\n",
            "the\n",
            "price\n",
            "of\n",
            "a\n",
            "small\n",
            "bias\n",
            "which\n",
            "gives\n",
            "a\n",
            "very\n",
            "practical\n",
            "tradeoff\n",
            "in\n",
            "comparison\n",
            "with\n",
            "existing\n",
            "unbiased\n",
            "and\n",
            "biased\n",
            "estimators\n",
            ".\n",
            "We\n",
            "further\n",
            "show\n",
            "that\n",
            "one\n",
            "extra\n",
            "linearization\n",
            "step\n",
            "leads\n",
            "to\n",
            "a\n",
            "deep\n",
            "straight-through\n",
            "estimator\n",
            "previously\n",
            "known\n",
            "only\n",
            "as\n",
            "an\n",
            "ad-hoc\n",
            "heuristic\n",
            ".\n",
            "We\n",
            "experimentally\n",
            "show\n",
            "higher\n",
            "accuracy\n",
            "in\n",
            "gradient\n",
            "estimation\n",
            "and\n",
            "demonstrate\n",
            "a\n",
            "more\n",
            "stable\n",
            "and\n",
            "better\n",
            "performing\n",
            "training\n",
            "in\n",
            "deep\n",
            "convolutional\n",
            "models\n",
            "with\n",
            "both\n",
            "proposed\n",
            "methods\n",
            ".\n",
            "Deep\n",
            "Archimedean\n",
            "Copulas\n",
            "Part\n",
            "of\n",
            "Advances\n",
            "in\n",
            "Neural\n",
            "Information\n",
            "Processing\n",
            "Systems\n",
            "33\n",
            "(\n",
            "NeurIPS\n",
            "2020\n",
            ")\n",
            "Authors\n",
            "Chun\n",
            "Kai\n",
            "Ling\n",
            ",\n",
            "Fei\n",
            "Fang\n",
            ",\n",
            "J.\n",
            "Zico\n",
            "Kolter\n",
            "Abstract\n",
            "A\n",
            "central\n",
            "problem\n",
            "in\n",
            "machine\n",
            "learning\n",
            "and\n",
            "statistics\n",
            "is\n",
            "to\n",
            "model\n",
            "joint\n",
            "densities\n",
            "of\n",
            "random\n",
            "variables\n",
            "from\n",
            "data\n",
            ".\n",
            "Copulas\n",
            "are\n",
            "joint\n",
            "cumulative\n",
            "distribution\n",
            "functions\n",
            "with\n",
            "uniform\n",
            "marginal\n",
            "distributions\n",
            "and\n",
            "are\n",
            "used\n",
            "to\n",
            "capture\n",
            "interdependencies\n",
            "in\n",
            "isolation\n",
            "from\n",
            "marginals\n",
            ".\n",
            "Copulas\n",
            "are\n",
            "widely\n",
            "used\n",
            "within\n",
            "statistics\n",
            ",\n",
            "but\n",
            "have\n",
            "not\n",
            "gained\n",
            "traction\n",
            "in\n",
            "the\n",
            "context\n",
            "of\n",
            "modern\n",
            "deep\n",
            "learning\n",
            ".\n",
            "In\n",
            "this\n",
            "paper\n",
            ",\n",
            "we\n",
            "introduce\n",
            "ACNet\n",
            ",\n",
            "a\n",
            "novel\n",
            "differentiable\n",
            "neural\n",
            "network\n",
            "architecture\n",
            "that\n",
            "enforces\n",
            "structural\n",
            "properties\n",
            "and\n",
            "enables\n",
            "one\n",
            "to\n",
            "learn\n",
            "an\n",
            "important\n",
            "class\n",
            "of\n",
            "copulas\n",
            "--\n",
            "Archimedean\n",
            "Copulas\n",
            ".\n",
            "Unlike\n",
            "Generative\n",
            "Adversarial\n",
            "Networks\n",
            ",\n",
            "Variational\n",
            "Autoencoders\n",
            ",\n",
            "or\n",
            "Normalizing\n",
            "Flow\n",
            "methods\n",
            ",\n",
            "which\n",
            "learn\n",
            "either\n",
            "densities\n",
            "or\n",
            "the\n",
            "generative\n",
            "process\n",
            "directly\n",
            ",\n",
            "ACNet\n",
            "learns\n",
            "a\n",
            "generator\n",
            "of\n",
            "the\n",
            "copula\n",
            ",\n",
            "which\n",
            "implicitly\n",
            "defines\n",
            "the\n",
            "cumulative\n",
            "distribution\n",
            "function\n",
            "of\n",
            "a\n",
            "joint\n",
            "distribution\n",
            ".\n",
            "We\n",
            "give\n",
            "a\n",
            "probabilistic\n",
            "interpretation\n",
            "of\n",
            "the\n",
            "network\n",
            "parameters\n",
            "of\n",
            "ACNet\n",
            "and\n",
            "use\n",
            "this\n",
            "to\n",
            "derive\n",
            "a\n",
            "simple\n",
            "but\n",
            "efficient\n",
            "sampling\n",
            "algorithm\n",
            "for\n",
            "the\n",
            "learned\n",
            "copula\n",
            ".\n",
            "Our\n",
            "experiments\n",
            "show\n",
            "that\n",
            "ACNet\n",
            "is\n",
            "able\n",
            "to\n",
            "both\n",
            "approximate\n",
            "common\n",
            "Archimedean\n",
            "Copulas\n",
            "and\n",
            "generate\n",
            "new\n",
            "copulas\n",
            "which\n",
            "may\n",
            "provide\n",
            "better\n",
            "fits\n",
            "to\n",
            "data\n",
            ".\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "df_output       topic                                              title  \\\n",
            "0   neurips  Training Generative Adversarial Networks with ...   \n",
            "1   neurips  Estimating Training Data Influence by Tracing ...   \n",
            "2   neurips                         Deep Evidential Regression   \n",
            "3   neurips  Information Theoretic Regret Bounds for Online...   \n",
            "4   neurips           Universally Quantized Neural Compression   \n",
            "5   neurips  Advances in Neural Information Processing Syst...   \n",
            "6   neurips      Graph Contrastive Learning with Augmentations   \n",
            "7   neurips  Efficient Exact Verification of Binarized Neur...   \n",
            "8   neurips  Path Sample-Analytic Gradient Estimators for S...   \n",
            "9   neurips                           Deep Archimedean Copulas   \n",
            "\n",
            "                                                text  \\\n",
            "0  Training Generative Adversarial Networks with ...   \n",
            "1  Estimating Training Data Influence by Tracing ...   \n",
            "2  Deep Evidential Regression\\n\\nPart of Advances...   \n",
            "3  Information Theoretic Regret Bounds for Online...   \n",
            "4  Universally Quantized Neural Compression\\n\\nPa...   \n",
            "5  Book\\n\\nDo not remove: This comment is monitor...   \n",
            "6  Graph Contrastive Learning with Augmentations\\...   \n",
            "7  Efficient Exact Verification of Binarized Neur...   \n",
            "8  Path Sample-Analytic Gradient Estimators for S...   \n",
            "9  Deep Archimedean Copulas\\n\\nPart of Advances i...   \n",
            "\n",
            "                                                 url  similarity_score  rank  \\\n",
            "0  https://papers.nips.cc/paper/2020/hash/8d30aa9...          0.965153   3.0   \n",
            "1  https://papers.nips.cc/paper/2020/hash/e6385d3...          0.965144   4.0   \n",
            "2  https://papers.nips.cc/paper/2020/hash/aab0854...          0.965102   6.0   \n",
            "3  https://papers.nips.cc/paper/2020/hash/aee5620...          0.965130   5.0   \n",
            "4  https://papers.nips.cc/paper/2020/hash/92049de...          0.965285   2.0   \n",
            "5                  https://papers.nips.cc/paper/2020          0.965377   1.0   \n",
            "6  https://papers.nips.cc/paper/2020/hash/3fe2303...          0.960548  10.0   \n",
            "7  https://papers.nips.cc/paper/2020/hash/1385974...          0.962081   7.0   \n",
            "8  https://papers.nips.cc/paper/2020/hash/96fca94...          0.961407   9.0   \n",
            "9  https://papers.nips.cc/paper/2020/hash/10eb650...          0.961599   8.0   \n",
            "\n",
            "   similarity_score_lda  rank_lda  \n",
            "0              0.976416       8.0  \n",
            "1              0.976422       7.0  \n",
            "2              0.976501       5.0  \n",
            "3              0.976803       3.0  \n",
            "4              0.976386       9.0  \n",
            "5              0.976283      10.0  \n",
            "6              0.977023       1.0  \n",
            "7              0.976987       2.0  \n",
            "8              0.976438       6.0  \n",
            "9              0.976682       4.0  \n",
            "topic:  unsupervised information theoretic perceptual quality metric neurips id_= 1\n",
            "1 . An Unsupervised Information-Theoretic Perceptual Quality Metric https://papers.nips.cc/paper/2020/hash/00482b9bed15a272730fcb590ffebddd-Abstract.html\n",
            "**********************************************\n",
            "2 . An Unsupervised Information-Theoretic ... - Review for NeurIPS paper https://papers.nips.cc/paper/2020/file/00482b9bed15a272730fcb590ffebddd-Review.html\n",
            "**********************************************\n",
            "3 . An Unsupervised Information-Theoretic ... - Review for NeurIPS paper https://papers.nips.cc/paper/2020/file/00482b9bed15a272730fcb590ffebddd-MetaReview.html\n",
            "**********************************************\n",
            "4 . Advances in Neural Information Processing Systems 33 (NeurIPS ... https://papers.nips.cc/paper/2020\n",
            "**********************************************\n",
            "5 . Neural FFTs for Universal Texture Image Synthesis https://papers.nips.cc/paper/2020/file/a23156abfd4a114c35b930b836064e8b-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Synthesizing larger texture images from a smaller exemplar is an important task\n",
            "in graphics and vision. The conventional CNNs, recently adopted for synthesis,\n",
            "require to train and test on the same set of images and fail to generalize to unseen\n",
            "images. This is mainly because those CNNs fully rely on convolutional and\n",
            "upsampling layers that operate locally and not suitable for a task as global as texture\n",
            "synthesis. In this work, inspired by the repetitive nature of texture patterns, we\n",
            "ﬁnd that texture synthesis can be viewed as (local) upsampling in the Fast Fourier\n",
            "Transform (FFT) domain. However, FFT of natural images exhibits high dynamic\n",
            "range and lacks local correlations. Therefore, to train CNNs we design a framework\n",
            "to perform FFT upsampling in feature space using deformable convolutions. Such\n",
            "design allows our framework to generalize to unseen images, and synthesize\n",
            "textures in a single pass. Extensive evaluations conﬁrm that our method achieves\n",
            "state-of-the-art performance both quantitatively and qualitatively.\n",
            "\n",
            "\n",
            "**********************************************\n",
            "6 . Object-Centric Learning with Slot Attention https://papers.nips.cc/paper/2020/file/8511df98c02ab60aea1b2356c013bc0f-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Learning object-centric representations of complex scenes is a promising step\n",
            "towards enabling efﬁcient abstract reasoning from low-level perceptual features.\n",
            "Yet, most deep learning approaches learn distributed representations that do\n",
            "not capture the compositional properties of natural scenes.\n",
            "In this paper, we\n",
            "present the Slot Attention module, an architectural component that interfaces with\n",
            "perceptual representations such as the output of a convolutional neural network\n",
            "and produces a set of task-dependent abstract representations which we call slots.\n",
            "These slots are exchangeable and can bind to any object in the input by specializing\n",
            "through a competitive procedure over multiple rounds of attention. We empirically\n",
            "demonstrate that Slot Attention can extract object-centric representations that\n",
            "enable generalization to unseen compositions when trained on unsupervised object\n",
            "discovery and supervised property prediction tasks.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "7 . Self-supervised learning through the eyes of a child https://papers.nips.cc/paper/2020/file/7183145a2a3e0ce2b68cd3735186b1d5-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Within months of birth, children develop meaningful expectations about the world\n",
            "around them. How much of this early knowledge can be explained through generic\n",
            "learning mechanisms applied to sensory data, and how much of it requires more\n",
            "substantive innate inductive biases? Addressing this fundamental question in its full\n",
            "generality is currently infeasible, but we can hope to make real progress in more\n",
            "narrowly deﬁned domains, such as the development of high-level visual categories,\n",
            "thanks to improvements in data collecting technology and recent progress in deep\n",
            "learning. In this paper, our goal is precisely to achieve such progress by utilizing\n",
            "modern self-supervised deep learning methods and a recent longitudinal, egocentric\n",
            "video dataset recorded from the perspective of three young children (Sullivan et\n",
            "al., 2020). Our results demonstrate the emergence of powerful, high-level visual\n",
            "representations from developmentally realistic natural videos using generic self-\n",
            "supervised learning objectives.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "8 . Robust Compressed Sensing using Generative Models https://papers.nips.cc/paper/2020/file/07cb5f86508f146774a2fac4373a8e50-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "The goal of compressed sensing is to estimate a high dimensional vector from\n",
            "an underdetermined system of noisy linear equations. In analogy to classical\n",
            "compressed sensing, here we assume a generative model as a prior, that is, we\n",
            "assume the vector is represented by a deep generative model G : Rk → Rn.\n",
            "Classical recovery approaches such as empirical risk minimization (ERM) are\n",
            "guaranteed to succeed when the measurement matrix is sub-Gaussian. However,\n",
            "when the measurement matrix and measurements are heavy-tailed or have outliers,\n",
            "recovery may fail dramatically. In this paper we propose an algorithm inspired by\n",
            "the Median-of-Means (MOM). Our algorithm guarantees recovery for heavy-tailed\n",
            "data, even in the presence of outliers. Theoretically, our results show our novel\n",
            "MOM-based algorithm enjoys the same sample complexity guarantees as ERM\n",
            "under sub-Gaussian assumptions. Our experiments validate both aspects of our\n",
            "claims: other algorithms are indeed fragile and fail under heavy-tailed and/or\n",
            "corrupted data, while our approach exhibits the predicted robustness.\n",
            "\n",
            "\n",
            "**********************************************\n",
            "9 . Network-to-Network Translation with Conditional Invertible Neural ... https://papers.nips.cc/paper/2020/file/1cfa81af29c6f2d8cacb44921722e753-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Given the ever-increasing computational costs of modern machine learning mod-\n",
            "els, we need to ﬁnd new ways to reuse such expert models and thus tap into the\n",
            "resources that have been invested in their creation. Recent work suggests that the\n",
            "power of these massive models is captured by the representations they learn. There-\n",
            "fore, we seek a model that can relate between different existing representations and\n",
            "propose to solve this task with a conditionally invertible network. This network\n",
            "demonstrates its capability by (i) providing generic transfer between diverse do-\n",
            "mains, (ii) enabling controlled content synthesis by allowing modiﬁcation in other\n",
            "domains, and (iii) facilitating diagnosis of existing representations by translating\n",
            "them into interpretable domains such as images. Our domain transfer network\n",
            "can translate between ﬁxed representations without having to learn or ﬁnetune\n",
            "them. This allows users to utilize various existing domain-speciﬁc expert models\n",
            "from the literature that had been trained with extensive computational resources.\n",
            "Experiments on diverse conditional image synthesis tasks, competitive image mod-\n",
            "iﬁcation results and experiments on image-to-image and text-to-image generation\n",
            "demonstrate the generic applicability of our approach. For example, we translate\n",
            "between BERT and BigGAN, state-of-the-art text and image models to provide\n",
            "text-to-image generation, which neither of both experts can perform on their own.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "10 . Functional Regularization for Representation Learning: A Unified ... https://papers.nips.cc/paper/2020/file/c793b3be8f18731f2a4c627fb3c6c63d-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Unsupervised and self-supervised learning approaches have become a crucial tool\n",
            "to learn representations for downstream prediction tasks. While these approaches\n",
            "are widely used in practice and achieve impressive empirical gains, their theoret-\n",
            "ical understanding largely lags behind. Towards bridging this gap, we present a\n",
            "unifying perspective where several such approaches can be viewed as imposing\n",
            "a regularization on the representation via a learnable function using unlabeled\n",
            "data. We propose a discriminative theoretical framework for analyzing the sam-\n",
            "ple complexity of these approaches, which generalizes the framework of [3] to\n",
            "allow learnable regularization functions. Our sample complexity bounds show\n",
            "that, with carefully chosen hypothesis classes to exploit the structure in the data,\n",
            "these learnable regularization functions can prune the hypothesis space, and help\n",
            "reduce the amount of labeled data needed. We then provide two concrete examples\n",
            "of functional regularization, one using auto-encoders and the other using masked\n",
            "self-supervision, and apply our framework to quantify the reduction in the sample\n",
            "complexity bound of labeled data. We also provide complementary empirical\n",
            "results to support our analysis.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "data:                                                topic  \\\n",
            "0  unsupervised information theoretic perceptual ...   \n",
            "1  unsupervised information theoretic perceptual ...   \n",
            "2  unsupervised information theoretic perceptual ...   \n",
            "3  unsupervised information theoretic perceptual ...   \n",
            "4  unsupervised information theoretic perceptual ...   \n",
            "5  unsupervised information theoretic perceptual ...   \n",
            "6  unsupervised information theoretic perceptual ...   \n",
            "7  unsupervised information theoretic perceptual ...   \n",
            "8  unsupervised information theoretic perceptual ...   \n",
            "9  unsupervised information theoretic perceptual ...   \n",
            "\n",
            "                                               title  \\\n",
            "0  An Unsupervised Information-Theoretic Perceptu...   \n",
            "1  An Unsupervised Information-Theoretic ... - Re...   \n",
            "2  An Unsupervised Information-Theoretic ... - Re...   \n",
            "3  Advances in Neural Information Processing Syst...   \n",
            "4  Neural FFTs for Universal Texture Image Synthesis   \n",
            "5        Object-Centric Learning with Slot Attention   \n",
            "6  Self-supervised learning through the eyes of a...   \n",
            "7  Robust Compressed Sensing using Generative Models   \n",
            "8  Network-to-Network Translation with Conditiona...   \n",
            "9  Functional Regularization for Representation L...   \n",
            "\n",
            "                                                text  \\\n",
            "0  An Unsupervised Information-Theoretic Perceptu...   \n",
            "1  NeurIPS 2020\\n\\nAn Unsupervised Information-Th...   \n",
            "2  NeurIPS 2020\\n\\nAn Unsupervised Information-Th...   \n",
            "3  Book\\n\\nDo not remove: This comment is monitor...   \n",
            "4  Abstract\\n\\nSynthesizing larger texture images...   \n",
            "5  Abstract\\n\\nLearning object-centric representa...   \n",
            "6  Abstract\\n\\nWithin months of birth, children d...   \n",
            "7  Abstract\\n\\nThe goal of compressed sensing is ...   \n",
            "8  Abstract\\n\\nGiven the ever-increasing computat...   \n",
            "9  Abstract\\n\\nUnsupervised and self-supervised l...   \n",
            "\n",
            "                                                 url  \n",
            "0  https://papers.nips.cc/paper/2020/hash/00482b9...  \n",
            "1  https://papers.nips.cc/paper/2020/file/00482b9...  \n",
            "2  https://papers.nips.cc/paper/2020/file/00482b9...  \n",
            "3                  https://papers.nips.cc/paper/2020  \n",
            "4  https://papers.nips.cc/paper/2020/file/a23156a...  \n",
            "5  https://papers.nips.cc/paper/2020/file/8511df9...  \n",
            "6  https://papers.nips.cc/paper/2020/file/7183145...  \n",
            "7  https://papers.nips.cc/paper/2020/file/07cb5f8...  \n",
            "8  https://papers.nips.cc/paper/2020/file/1cfa81a...  \n",
            "9  https://papers.nips.cc/paper/2020/file/c793b3b...  \n",
            "**********************************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                                               topic  \\\n",
            "0  unsupervised information theoretic perceptual ...   \n",
            "1  unsupervised information theoretic perceptual ...   \n",
            "2  unsupervised information theoretic perceptual ...   \n",
            "3  unsupervised information theoretic perceptual ...   \n",
            "4  unsupervised information theoretic perceptual ...   \n",
            "5  unsupervised information theoretic perceptual ...   \n",
            "6  unsupervised information theoretic perceptual ...   \n",
            "7  unsupervised information theoretic perceptual ...   \n",
            "8  unsupervised information theoretic perceptual ...   \n",
            "9  unsupervised information theoretic perceptual ...   \n",
            "\n",
            "                                               title  \\\n",
            "0  An Unsupervised Information-Theoretic Perceptu...   \n",
            "1  An Unsupervised Information-Theoretic ... - Re...   \n",
            "2  An Unsupervised Information-Theoretic ... - Re...   \n",
            "3  Advances in Neural Information Processing Syst...   \n",
            "4  Neural FFTs for Universal Texture Image Synthesis   \n",
            "5        Object-Centric Learning with Slot Attention   \n",
            "6  Self-supervised learning through the eyes of a...   \n",
            "7  Robust Compressed Sensing using Generative Models   \n",
            "8  Network-to-Network Translation with Conditiona...   \n",
            "9  Functional Regularization for Representation L...   \n",
            "\n",
            "                                                text  \\\n",
            "0  An Unsupervised Information-Theoretic Perceptu...   \n",
            "1  NeurIPS 2020\\n\\nAn Unsupervised Information-Th...   \n",
            "2  NeurIPS 2020\\n\\nAn Unsupervised Information-Th...   \n",
            "3  Book\\n\\nDo not remove: This comment is monitor...   \n",
            "4  Abstract\\n\\nSynthesizing larger texture images...   \n",
            "5  Abstract\\n\\nLearning object-centric representa...   \n",
            "6  Abstract\\n\\nWithin months of birth, children d...   \n",
            "7  Abstract\\n\\nThe goal of compressed sensing is ...   \n",
            "8  Abstract\\n\\nGiven the ever-increasing computat...   \n",
            "9  Abstract\\n\\nUnsupervised and self-supervised l...   \n",
            "\n",
            "                                                 url  similarity_score  \n",
            "0  https://papers.nips.cc/paper/2020/hash/00482b9...          0.960361  \n",
            "1  https://papers.nips.cc/paper/2020/file/00482b9...          0.940551  \n",
            "2  https://papers.nips.cc/paper/2020/file/00482b9...          0.960248  \n",
            "3                  https://papers.nips.cc/paper/2020          0.964870  \n",
            "4  https://papers.nips.cc/paper/2020/file/a23156a...          0.960257  \n",
            "5  https://papers.nips.cc/paper/2020/file/8511df9...          0.959921  \n",
            "6  https://papers.nips.cc/paper/2020/file/7183145...          0.964294  \n",
            "7  https://papers.nips.cc/paper/2020/file/07cb5f8...          0.963900  \n",
            "8  https://papers.nips.cc/paper/2020/file/1cfa81a...          0.963835  \n",
            "9  https://papers.nips.cc/paper/2020/file/c793b3b...          0.961062  \n",
            "df_final after rank=                                                topic  \\\n",
            "0  unsupervised information theoretic perceptual ...   \n",
            "1  unsupervised information theoretic perceptual ...   \n",
            "2  unsupervised information theoretic perceptual ...   \n",
            "3  unsupervised information theoretic perceptual ...   \n",
            "4  unsupervised information theoretic perceptual ...   \n",
            "5  unsupervised information theoretic perceptual ...   \n",
            "6  unsupervised information theoretic perceptual ...   \n",
            "7  unsupervised information theoretic perceptual ...   \n",
            "8  unsupervised information theoretic perceptual ...   \n",
            "9  unsupervised information theoretic perceptual ...   \n",
            "\n",
            "                                               title  \\\n",
            "0  An Unsupervised Information-Theoretic Perceptu...   \n",
            "1  An Unsupervised Information-Theoretic ... - Re...   \n",
            "2  An Unsupervised Information-Theoretic ... - Re...   \n",
            "3  Advances in Neural Information Processing Syst...   \n",
            "4  Neural FFTs for Universal Texture Image Synthesis   \n",
            "5        Object-Centric Learning with Slot Attention   \n",
            "6  Self-supervised learning through the eyes of a...   \n",
            "7  Robust Compressed Sensing using Generative Models   \n",
            "8  Network-to-Network Translation with Conditiona...   \n",
            "9  Functional Regularization for Representation L...   \n",
            "\n",
            "                                                text  \\\n",
            "0  An Unsupervised Information-Theoretic Perceptu...   \n",
            "1  NeurIPS 2020\\n\\nAn Unsupervised Information-Th...   \n",
            "2  NeurIPS 2020\\n\\nAn Unsupervised Information-Th...   \n",
            "3  Book\\n\\nDo not remove: This comment is monitor...   \n",
            "4  Abstract\\n\\nSynthesizing larger texture images...   \n",
            "5  Abstract\\n\\nLearning object-centric representa...   \n",
            "6  Abstract\\n\\nWithin months of birth, children d...   \n",
            "7  Abstract\\n\\nThe goal of compressed sensing is ...   \n",
            "8  Abstract\\n\\nGiven the ever-increasing computat...   \n",
            "9  Abstract\\n\\nUnsupervised and self-supervised l...   \n",
            "\n",
            "                                                 url  similarity_score  rank  \n",
            "0  https://papers.nips.cc/paper/2020/hash/00482b9...          0.960361   6.0  \n",
            "1  https://papers.nips.cc/paper/2020/file/00482b9...          0.940551  10.0  \n",
            "2  https://papers.nips.cc/paper/2020/file/00482b9...          0.960248   8.0  \n",
            "3                  https://papers.nips.cc/paper/2020          0.964870   1.0  \n",
            "4  https://papers.nips.cc/paper/2020/file/a23156a...          0.960257   7.0  \n",
            "5  https://papers.nips.cc/paper/2020/file/8511df9...          0.959921   9.0  \n",
            "6  https://papers.nips.cc/paper/2020/file/7183145...          0.964294   2.0  \n",
            "7  https://papers.nips.cc/paper/2020/file/07cb5f8...          0.963900   3.0  \n",
            "8  https://papers.nips.cc/paper/2020/file/1cfa81a...          0.963835   4.0  \n",
            "9  https://papers.nips.cc/paper/2020/file/c793b3b...          0.961062   5.0  \n",
            "0    An Unsupervised Information-Theoretic Perceptu...\n",
            "1    NeurIPS 2020\\n\\nAn Unsupervised Information-Th...\n",
            "2    NeurIPS 2020\\n\\nAn Unsupervised Information-Th...\n",
            "3    Book\\n\\nDo not remove: This comment is monitor...\n",
            "4    Abstract\\n\\nSynthesizing larger texture images...\n",
            "5    Abstract\\n\\nLearning object-centric representa...\n",
            "6    Abstract\\n\\nWithin months of birth, children d...\n",
            "7    Abstract\\n\\nThe goal of compressed sensing is ...\n",
            "8    Abstract\\n\\nGiven the ever-increasing computat...\n",
            "9    Abstract\\n\\nUnsupervised and self-supervised l...\n",
            "Name: text, dtype: object\n",
            "An\n",
            "Unsupervised\n",
            "Information-Theoretic\n",
            "Perceptual\n",
            "Quality\n",
            "Metric\n",
            "Part\n",
            "of\n",
            "Advances\n",
            "in\n",
            "Neural\n",
            "Information\n",
            "Processing\n",
            "Systems\n",
            "33\n",
            "(\n",
            "NeurIPS\n",
            "2020\n",
            ")\n",
            "Authors\n",
            "Sangnie\n",
            "Bhardwaj\n",
            ",\n",
            "Ian\n",
            "Fischer\n",
            ",\n",
            "Johannes\n",
            "Ballé\n",
            ",\n",
            "Troy\n",
            "Chinen\n",
            "Abstract\n",
            "Tractable\n",
            "models\n",
            "of\n",
            "human\n",
            "perception\n",
            "have\n",
            "proved\n",
            "to\n",
            "be\n",
            "challenging\n",
            "to\n",
            "build\n",
            ".\n",
            "Hand-designed\n",
            "models\n",
            "such\n",
            "as\n",
            "MS-SSIM\n",
            "remain\n",
            "popular\n",
            "predictors\n",
            "of\n",
            "human\n",
            "image\n",
            "quality\n",
            "judgements\n",
            "due\n",
            "to\n",
            "their\n",
            "simplicity\n",
            "and\n",
            "speed\n",
            ".\n",
            "Recent\n",
            "modern\n",
            "deep\n",
            "learning\n",
            "approaches\n",
            "can\n",
            "perform\n",
            "better\n",
            ",\n",
            "but\n",
            "they\n",
            "rely\n",
            "on\n",
            "supervised\n",
            "data\n",
            "which\n",
            "can\n",
            "be\n",
            "costly\n",
            "to\n",
            "gather\n",
            ":\n",
            "large\n",
            "sets\n",
            "of\n",
            "class\n",
            "labels\n",
            "such\n",
            "as\n",
            "ImageNet\n",
            ",\n",
            "image\n",
            "quality\n",
            "ratings\n",
            ",\n",
            "or\n",
            "both\n",
            ".\n",
            "We\n",
            "combine\n",
            "recent\n",
            "advances\n",
            "in\n",
            "information-theoretic\n",
            "objective\n",
            "functions\n",
            "with\n",
            "a\n",
            "computational\n",
            "architecture\n",
            "informed\n",
            "by\n",
            "the\n",
            "physiology\n",
            "of\n",
            "the\n",
            "human\n",
            "visual\n",
            "system\n",
            "and\n",
            "unsupervised\n",
            "training\n",
            "on\n",
            "pairs\n",
            "of\n",
            "video\n",
            "frames\n",
            ",\n",
            "yielding\n",
            "our\n",
            "Perceptual\n",
            "Information\n",
            "Metric\n",
            "(\n",
            "PIM\n",
            ")\n",
            ".\n",
            "We\n",
            "show\n",
            "that\n",
            "PIM\n",
            "is\n",
            "competitive\n",
            "with\n",
            "supervised\n",
            "metrics\n",
            "on\n",
            "the\n",
            "recent\n",
            "and\n",
            "challenging\n",
            "BAPPS\n",
            "image\n",
            "quality\n",
            "assessment\n",
            "dataset\n",
            "and\n",
            "outperforms\n",
            "them\n",
            "in\n",
            "predicting\n",
            "the\n",
            "ranking\n",
            "of\n",
            "image\n",
            "compression\n",
            "methods\n",
            "in\n",
            "CLIC\n",
            "2020\n",
            ".\n",
            "We\n",
            "also\n",
            "perform\n",
            "qualitative\n",
            "experiments\n",
            "using\n",
            "the\n",
            "ImageNet-C\n",
            "dataset\n",
            ",\n",
            "and\n",
            "establish\n",
            "that\n",
            "PIM\n",
            "is\n",
            "robust\n",
            "with\n",
            "respect\n",
            "to\n",
            "architectural\n",
            "details\n",
            ".\n",
            "NeurIPS\n",
            "2020\n",
            "An\n",
            "Unsupervised\n",
            "Information-Theoretic\n",
            "Perceptual\n",
            "Quality\n",
            "Metric\n",
            "Review\n",
            "1\n",
            "Summary\n",
            "and\n",
            "Contributions\n",
            ":\n",
            "The\n",
            "authors\n",
            "propose\n",
            "an\n",
            "advanced\n",
            "perceptual\n",
            "quality\n",
            "metric\n",
            ",\n",
            "which\n",
            "is\n",
            "learned\n",
            "from\n",
            "adjacent\n",
            "video\n",
            "frames\n",
            "in\n",
            "an\n",
            "unsupervised\n",
            "manner\n",
            ".\n",
            "This\n",
            "learning\n",
            "scheme\n",
            "is\n",
            "well\n",
            "motivated\n",
            "by\n",
            "the\n",
            "observation\n",
            "of\n",
            "human\n",
            "visual\n",
            "system\n",
            ".\n",
            "Experiments\n",
            "on\n",
            "BAPPS\n",
            "and\n",
            "ImageNet-C\n",
            "datasets\n",
            "demonstrate\n",
            "the\n",
            "effectiveness\n",
            "of\n",
            "method\n",
            ".\n",
            "Strengths\n",
            ":\n",
            "-\n",
            "The\n",
            "proposed\n",
            "method\n",
            "is\n",
            "well\n",
            "motivated\n",
            "and\n",
            "backed\n",
            "up\n",
            "by\n",
            "solid\n",
            "theories\n",
            ".\n",
            "-\n",
            "Experiments\n",
            "are\n",
            "comprehensive\n",
            "and\n",
            "the\n",
            "overall\n",
            "performance\n",
            "is\n",
            "promising\n",
            ".\n",
            "-\n",
            "Paper\n",
            "is\n",
            "well\n",
            "organized\n",
            "and\n",
            "easy\n",
            "to\n",
            "follow\n",
            ".\n",
            "Weaknesses\n",
            ":\n",
            "A\n",
            "good\n",
            "quality\n",
            "metric\n",
            "should\n",
            "stand\n",
            "the\n",
            "test\n",
            "of\n",
            "time\n",
            ".\n",
            "Yet\n",
            "it\n",
            "seems\n",
            "that\n",
            "the\n",
            "authors\n",
            "have\n",
            "not\n",
            "preparation\n",
            "to\n",
            "make\n",
            "this\n",
            "project\n",
            "publicly\n",
            "available\n",
            ".\n",
            "Therefore\n",
            ",\n",
            "I\n",
            "encourage\n",
            "the\n",
            "authors\n",
            "to\n",
            "provide\n",
            "the\n",
            "code\n",
            "or\n",
            "executable\n",
            "files\n",
            "to\n",
            "ensure\n",
            "the\n",
            "reproducibility\n",
            ".\n",
            "Correctness\n",
            ":\n",
            "Technically\n",
            "sound\n",
            ",\n",
            "but\n",
            "not\n",
            "be\n",
            "carefully\n",
            "checked\n",
            ".\n",
            "Clarity\n",
            ":\n",
            "Yes\n",
            ".\n",
            "Relation\n",
            "to\n",
            "Prior\n",
            "Work\n",
            ":\n",
            "Yes\n",
            ".\n",
            "Reproducibility\n",
            ":\n",
            "No\n",
            "Additional\n",
            "Feedback\n",
            ":\n",
            "Review\n",
            "2\n",
            "Summary\n",
            "and\n",
            "Contributions\n",
            ":\n",
            "An\n",
            "unsupervised\n",
            "Information-Theoretic\n",
            "based\n",
            "image\n",
            "quality\n",
            "metric\n",
            "using\n",
            "deep\n",
            "learning\n",
            "is\n",
            "proposed\n",
            ".\n",
            "Some\n",
            "experiments\n",
            "were\n",
            "conducted\n",
            "and\n",
            "showed\n",
            "the\n",
            "competitive\n",
            "performance\n",
            ".\n",
            "Strengths\n",
            ":\n",
            "NOT\n",
            "CLEAR\n",
            ".\n",
            "Basically\n",
            ",\n",
            "I\n",
            "would\n",
            "not\n",
            "find\n",
            "the\n",
            "strengths\n",
            "of\n",
            "the\n",
            "work\n",
            ".\n",
            "Nothing\n",
            "could\n",
            "be\n",
            "got\n",
            "when\n",
            "reading\n",
            "the\n",
            "abstract\n",
            "several\n",
            "times\n",
            ".\n",
            "How\n",
            "this\n",
            "work\n",
            "is\n",
            "inspired\n",
            "by\n",
            "the\n",
            "physiology\n",
            "of\n",
            "the\n",
            "human\n",
            "visual\n",
            "system\n",
            "is\n",
            "not\n",
            "clear\n",
            "in\n",
            "the\n",
            "abstract\n",
            ".\n",
            "I\n",
            "do\n",
            "not\n",
            "think\n",
            "that\n",
            "using\n",
            "such\n",
            "words\n",
            "``\n",
            "our\n",
            "model\n",
            "is\n",
            "informed\n",
            "by\n",
            "the\n",
            "physiology\n",
            "of\n",
            "the\n",
            "human\n",
            "visual\n",
            "system\n",
            "''\n",
            "in\n",
            "the\n",
            "abstract\n",
            "means\n",
            "this\n",
            "work\n",
            "has\n",
            "new\n",
            "contributions\n",
            ".\n",
            "The\n",
            "key\n",
            "is\n",
            "to\n",
            "how\n",
            "to\n",
            "model\n",
            "the\n",
            "human\n",
            "visual\n",
            "system\n",
            "in\n",
            "your\n",
            "work\n",
            ".\n",
            "Unfortunately\n",
            ",\n",
            "this\n",
            "paper\n",
            "did\n",
            "n't\n",
            "describe\n",
            "it\n",
            "in\n",
            "details\n",
            ".\n",
            "There\n",
            "are\n",
            "too\n",
            "many\n",
            "DL\n",
            "based\n",
            "IQAs\n",
            ".\n",
            "What\n",
            "'s\n",
            "your\n",
            "new\n",
            "contribution\n",
            "?\n",
            "Weaknesses\n",
            ":\n",
            "This\n",
            "paper\n",
            "is\n",
            "not\n",
            "easy\n",
            "to\n",
            "follow\n",
            ".\n",
            "It\n",
            "is\n",
            "difficult\n",
            "to\n",
            "judge\n",
            "the\n",
            "novelty\n",
            ".\n",
            "Author\n",
            "claimed\n",
            "that\n",
            "their\n",
            "model\n",
            "is\n",
            "inspired\n",
            "by\n",
            "visual\n",
            "physiology\n",
            "such\n",
            "as\n",
            "efficient\n",
            "coding\n",
            "and\n",
            "slowness\n",
            ".\n",
            "However\n",
            ",\n",
            "there\n",
            "are\n",
            "no\n",
            "any\n",
            "introductions\n",
            "about\n",
            "them\n",
            "in\n",
            "details\n",
            ".\n",
            "Moreover\n",
            ",\n",
            "I\n",
            "did\n",
            "n't\n",
            "see\n",
            "where\n",
            "two\n",
            "biological\n",
            "mechanisms\n",
            "are\n",
            "imitated\n",
            "in\n",
            "the\n",
            "model\n",
            ".\n",
            "I\n",
            "only\n",
            "see\n",
            "a\n",
            "DL-based\n",
            "IQA\n",
            "method\n",
            "without\n",
            "clear\n",
            "contributions\n",
            ".\n",
            "Finally\n",
            ",\n",
            "there\n",
            "are\n",
            "no\n",
            "scientific\n",
            "contributions\n",
            "in\n",
            "this\n",
            "manuscript\n",
            "such\n",
            "as\n",
            "``\n",
            "perceptual\n",
            "similarity\n",
            "is\n",
            "an\n",
            "emergent\n",
            "property\n",
            "shared\n",
            "across\n",
            "deep\n",
            "visual\n",
            "representations\n",
            "''\n",
            "discovered\n",
            "in\n",
            "[\n",
            "35\n",
            "]\n",
            ".\n",
            "[\n",
            "35\n",
            "]\n",
            "Richard\n",
            "Zhang\n",
            "et\n",
            "al\n",
            ".\n",
            "“\n",
            "The\n",
            "Unreasonable\n",
            "Effectiveness\n",
            "of\n",
            "Deep\n",
            "Features\n",
            "as\n",
            "a\n",
            "Perceptual\n",
            "Metric\n",
            "”\n",
            ".\n",
            "In\n",
            ":\n",
            "(\n",
            "2018\n",
            ")\n",
            ".\n",
            "cite\n",
            "arxiv:1801.03924Comment\n",
            ":\n",
            "Code\n",
            "and\n",
            "data\n",
            "available\n",
            "https\n",
            ":\n",
            "//www.github.com/richzhang/PerceptualSimilarity\n",
            ".\n",
            "URL\n",
            ":\n",
            "http\n",
            ":\n",
            "//arxiv.org/abs/1801.03924\n",
            ".\n",
            "after\n",
            "response\n",
            ":\n",
            "Although\n",
            "some\n",
            "confusion\n",
            "may\n",
            "have\n",
            "been\n",
            "clarified\n",
            ",\n",
            "author\n",
            "did\n",
            "n't\n",
            "positively\n",
            "reply\n",
            "the\n",
            "key\n",
            "comments\n",
            "that\n",
            "their\n",
            "model\n",
            "is\n",
            "inspired\n",
            "by\n",
            "visual\n",
            "physiology\n",
            "such\n",
            "as\n",
            "efficient\n",
            "coding\n",
            "and\n",
            "slowness\n",
            ".\n",
            "However\n",
            ",\n",
            "there\n",
            "are\n",
            "no\n",
            "any\n",
            "introductions\n",
            "about\n",
            "them\n",
            "in\n",
            "details\n",
            ".\n",
            "``\n",
            "Moreover\n",
            ",\n",
            "where\n",
            "two\n",
            "biological\n",
            "mechanisms\n",
            "in\n",
            "details\n",
            "are\n",
            "imitated\n",
            "in\n",
            "the\n",
            "model\n",
            "is\n",
            "not\n",
            "clear\n",
            "''\n",
            ".\n",
            "Furthermore\n",
            ",\n",
            "the\n",
            "paper\n",
            "is\n",
            "lacking\n",
            "of\n",
            "scientific\n",
            "contributions\n",
            "considering\n",
            "that\n",
            "it\n",
            "is\n",
            "only\n",
            "built\n",
            "on\n",
            "previous\n",
            "work\n",
            ".\n",
            "Correctness\n",
            ":\n",
            "No\n",
            "Clarity\n",
            ":\n",
            "This\n",
            "paper\n",
            "is\n",
            "very\n",
            "difficult\n",
            "to\n",
            "follow\n",
            ".\n",
            "Relation\n",
            "to\n",
            "Prior\n",
            "Work\n",
            ":\n",
            "Maybe\n",
            "Reproducibility\n",
            ":\n",
            "No\n",
            "Additional\n",
            "Feedback\n",
            ":\n",
            "1\n",
            ".\n",
            "How\n",
            "this\n",
            "work\n",
            "is\n",
            "inspired\n",
            "by\n",
            "the\n",
            "physiology\n",
            "of\n",
            "the\n",
            "human\n",
            "visual\n",
            "system\n",
            "is\n",
            "not\n",
            "clear\n",
            "in\n",
            "the\n",
            "paper\n",
            ".\n",
            "I\n",
            "do\n",
            "not\n",
            "think\n",
            "that\n",
            "using\n",
            "such\n",
            "words\n",
            "``\n",
            "our\n",
            "model\n",
            "is\n",
            "informed\n",
            "by\n",
            "the\n",
            "physiology\n",
            "of\n",
            "the\n",
            "human\n",
            "visual\n",
            "system\n",
            "''\n",
            "in\n",
            "the\n",
            "abstract\n",
            "means\n",
            "this\n",
            "work\n",
            "has\n",
            "new\n",
            "contributions\n",
            ".\n",
            "The\n",
            "key\n",
            "is\n",
            "to\n",
            "how\n",
            "to\n",
            "model\n",
            "the\n",
            "human\n",
            "visual\n",
            "system\n",
            "in\n",
            "your\n",
            "work\n",
            "in\n",
            "details\n",
            "in\n",
            "order\n",
            "to\n",
            "improve\n",
            "the\n",
            "current\n",
            "IQA\n",
            ".\n",
            "Unfortunately\n",
            ",\n",
            "this\n",
            "paper\n",
            "did\n",
            "n't\n",
            "belong\n",
            "this\n",
            "one\n",
            ".\n",
            "2\n",
            ".\n",
            "Refer\n",
            "to\n",
            "[\n",
            "35\n",
            "]\n",
            "for\n",
            "improvement\n",
            "such\n",
            "as\n",
            "enhancing\n",
            "the\n",
            "scientific\n",
            "contributions\n",
            ".\n",
            "[\n",
            "35\n",
            "]\n",
            "Richard\n",
            "Zhang\n",
            "et\n",
            "al\n",
            ".\n",
            "“\n",
            "The\n",
            "Unreasonable\n",
            "Effectiveness\n",
            "of\n",
            "Deep\n",
            "Features\n",
            "as\n",
            "a\n",
            "Perceptual\n",
            "Metric\n",
            "”\n",
            ".\n",
            "In\n",
            ":\n",
            "(\n",
            "2018\n",
            ")\n",
            ".\n",
            "cite\n",
            "arxiv:1801.03924Comment\n",
            ":\n",
            "Code\n",
            "and\n",
            "data\n",
            "available\n",
            "https\n",
            ":\n",
            "//www.github.com/richzhang/PerceptualSimilarity\n",
            ".\n",
            "URL\n",
            ":\n",
            "http\n",
            ":\n",
            "//arxiv.org/abs/1801.03924\n",
            ".\n",
            "Review\n",
            "3\n",
            "Summary\n",
            "and\n",
            "Contributions\n",
            ":\n",
            "This\n",
            "paper\n",
            "proposed\n",
            "a\n",
            "new\n",
            "unsupervised\n",
            ",\n",
            "information-based\n",
            "perceptual\n",
            "quality\n",
            "metric\n",
            ",\n",
            "i.e\n",
            ".\n",
            "PIM\n",
            ".\n",
            "The\n",
            "method\n",
            "is\n",
            "based\n",
            "on\n",
            "optimization\n",
            "of\n",
            "a\n",
            "lower\n",
            "bound\n",
            "of\n",
            "the\n",
            "multivariate\n",
            "mutual\n",
            "information\n",
            ".\n",
            "This\n",
            "proposal\n",
            "has\n",
            "roots\n",
            "in\n",
            "two\n",
            "prominent\n",
            "ideas\n",
            "in\n",
            "neuroscience\n",
            ",\n",
            "efficient\n",
            "coding\n",
            "and\n",
            "slowness\n",
            ".\n",
            "The\n",
            "authors\n",
            "implemented\n",
            "the\n",
            "proposal\n",
            "in\n",
            "deep\n",
            "neural\n",
            "networks\n",
            ",\n",
            "and\n",
            "test\n",
            "it\n",
            "on\n",
            "BAPPS\n",
            "and\n",
            "ImageNet-C\n",
            ".\n",
            "They\n",
            "reported\n",
            "competitive\n",
            "performance\n",
            "of\n",
            "this\n",
            "method\n",
            "to\n",
            "the\n",
            "supervised\n",
            "methods\n",
            ".\n",
            "Strengths\n",
            ":\n",
            "I\n",
            "very\n",
            "much\n",
            "enjoyed\n",
            "reading\n",
            "this\n",
            "manuscript\n",
            ".\n",
            "The\n",
            "method\n",
            "is\n",
            "to\n",
            "my\n",
            "knowledge\n",
            "novel\n",
            "and\n",
            "principled\n",
            ".\n",
            "It\n",
            "is\n",
            "well\n",
            "founded\n",
            "in\n",
            "Information\n",
            "theory\n",
            ",\n",
            "and\n",
            "broadly\n",
            "inspired\n",
            "by\n",
            "a\n",
            "couple\n",
            "of\n",
            "core\n",
            "principles\n",
            "in\n",
            "neural\n",
            "information\n",
            "processing\n",
            ".\n",
            "The\n",
            "method\n",
            "is\n",
            "purely\n",
            "unsupervised\n",
            ",\n",
            "and\n",
            "does\n",
            "not\n",
            "need\n",
            "human\n",
            "psychophysical\n",
            "judgements\n",
            "to\n",
            "train\n",
            "the\n",
            "model\n",
            ".\n",
            "Yet\n",
            "the\n",
            "method\n",
            "show\n",
            "competitive\n",
            "performance\n",
            "with\n",
            "the\n",
            "fully\n",
            "supervised\n",
            "approach\n",
            "in\n",
            "ref\n",
            "[\n",
            "35\n",
            "]\n",
            ".\n",
            "I\n",
            "found\n",
            "this\n",
            "to\n",
            "be\n",
            "quite\n",
            "remarkable\n",
            "and\n",
            "potentially\n",
            "quite\n",
            "significant\n",
            ".\n",
            "The\n",
            "problem\n",
            "studied\n",
            "in\n",
            "the\n",
            "paper\n",
            "is\n",
            "also\n",
            "high\n",
            "relevant\n",
            "to\n",
            "the\n",
            "NeurIPS\n",
            "community\n",
            ".\n",
            "*\n",
            "*\n",
            "added\n",
            "after\n",
            "rebuttal\n",
            ":\n",
            "After\n",
            "reading\n",
            "through\n",
            "other\n",
            "reviewers\n",
            "'\n",
            "comments\n",
            "and\n",
            "the\n",
            "authors\n",
            "'\n",
            "feedback\n",
            ",\n",
            "I\n",
            "remain\n",
            "very\n",
            "positive\n",
            "of\n",
            "this\n",
            "paper\n",
            ".\n",
            "I\n",
            "think\n",
            "the\n",
            "idea\n",
            "in\n",
            "the\n",
            "paper\n",
            "is\n",
            "novel\n",
            ",\n",
            "the\n",
            "experiments\n",
            "were\n",
            "reasonable\n",
            "and\n",
            "the\n",
            "results\n",
            "are\n",
            "very\n",
            "promising\n",
            ".\n",
            "Weaknesses\n",
            ":\n",
            "My\n",
            "main\n",
            "concern\n",
            "is\n",
            "that\n",
            "the\n",
            "results\n",
            "are\n",
            "a\n",
            "bit\n",
            "preliminary\n",
            "(\n",
            "lacking\n",
            "more\n",
            "comprehensive\n",
            "comparison\n",
            "to\n",
            "some\n",
            "of\n",
            "the\n",
            "previous\n",
            "methods\n",
            ",\n",
            "such\n",
            "as\n",
            "ref\n",
            "[\n",
            "29\n",
            "]\n",
            "as\n",
            "the\n",
            "authors\n",
            "acknowledged\n",
            ")\n",
            ",\n",
            "although\n",
            "the\n",
            "results\n",
            "look\n",
            "very\n",
            "promising\n",
            "for\n",
            "sure\n",
            ".\n",
            "It\n",
            "is\n",
            "also\n",
            "not\n",
            "entirely\n",
            "clear\n",
            "whether\n",
            "the\n",
            "improvement\n",
            "of\n",
            "the\n",
            "performance\n",
            "mainlycomes\n",
            "from\n",
            "the\n",
            "generic\n",
            "advantage\n",
            "of\n",
            "the\n",
            "objective\n",
            "function\n",
            ",\n",
            "or\n",
            "the\n",
            "choice\n",
            "of\n",
            "the\n",
            "hyper-parameters\n",
            "or\n",
            "the\n",
            "model\n",
            "architecture\n",
            ".\n",
            "Correctness\n",
            ":\n",
            "The\n",
            "claims\n",
            "and\n",
            "method\n",
            "are\n",
            "sound\n",
            ".\n",
            "Clarity\n",
            ":\n",
            "The\n",
            "paper\n",
            "is\n",
            "well\n",
            "written\n",
            ".\n",
            "The\n",
            "presentation\n",
            "in\n",
            "Section\n",
            "3.4\n",
            "perhaps\n",
            "could\n",
            "be\n",
            "improved\n",
            ".\n",
            "Right\n",
            "now\n",
            ",\n",
            "it\n",
            "is\n",
            "a\n",
            "bit\n",
            "difficult\n",
            "to\n",
            "get\n",
            "the\n",
            "key\n",
            "message\n",
            ".\n",
            "Relation\n",
            "to\n",
            "Prior\n",
            "Work\n",
            ":\n",
            "The\n",
            "relation\n",
            "to\n",
            "prior\n",
            "work\n",
            "is\n",
            "generally\n",
            "well\n",
            "discussed\n",
            ".\n",
            "Reproducibility\n",
            ":\n",
            "Yes\n",
            "Additional\n",
            "Feedback\n",
            ":\n",
            "Fig\n",
            "2\n",
            "and\n",
            "Fig3\n",
            "could\n",
            "benefit\n",
            "by\n",
            "have\n",
            "a\n",
            "bit\n",
            "more\n",
            "detailed\n",
            "figure\n",
            "legends\n",
            ".\n",
            "Review\n",
            "4\n",
            "Summary\n",
            "and\n",
            "Contributions\n",
            ":\n",
            "The\n",
            "paper\n",
            "proposes\n",
            "PIM\n",
            "(\n",
            "Perceptual\n",
            "Information\n",
            "Metric\n",
            ")\n",
            "which\n",
            "is\n",
            "an\n",
            "image\n",
            "quality\n",
            "metric\n",
            "learned\n",
            "in\n",
            "an\n",
            "unsupervised\n",
            "manner\n",
            "by\n",
            "enforcing\n",
            "two\n",
            "loss\n",
            "functions\n",
            "-\n",
            "1\n",
            ".\n",
            "Compression\n",
            "and\n",
            "2\n",
            ".\n",
            "Consistency\n",
            "across\n",
            "time\n",
            ".\n",
            "The\n",
            "authors\n",
            "compare\n",
            "PIM\n",
            "to\n",
            "other\n",
            "proposed\n",
            "metrics\n",
            "on\n",
            "multiple\n",
            "datasets\n",
            "and\n",
            "show\n",
            "improvements\n",
            ".\n",
            "They\n",
            "also\n",
            "do\n",
            "ablation\n",
            "studies\n",
            "to\n",
            "show\n",
            "how\n",
            "each\n",
            "of\n",
            "the\n",
            "choices\n",
            "made\n",
            "in\n",
            "the\n",
            "paper\n",
            "yield\n",
            "various\n",
            "improvements\n",
            ".\n",
            "Strengths\n",
            ":\n",
            "Competitive\n",
            "results\n",
            "on\n",
            "multiple\n",
            "benchmarks\n",
            ",\n",
            "ablation\n",
            "studies\n",
            ",\n",
            "additional\n",
            "qualitative\n",
            "experiments\n",
            "on\n",
            "ImageNet-C\n",
            "Weaknesses\n",
            ":\n",
            "The\n",
            "paper\n",
            "is\n",
            "built\n",
            "on\n",
            "previous\n",
            "works\n",
            "and\n",
            "one\n",
            "of\n",
            "the\n",
            "main\n",
            "new\n",
            "directions\n",
            "proposed\n",
            "is\n",
            "the\n",
            "notion\n",
            "of\n",
            "consistency\n",
            "(\n",
            "perceptual\n",
            "metric\n",
            "not\n",
            "changing\n",
            "between\n",
            "immediate\n",
            "or\n",
            "nearby\n",
            "frames\n",
            "in\n",
            "a\n",
            "video\n",
            ")\n",
            ".\n",
            "While\n",
            "this\n",
            "intuition\n",
            "seems\n",
            "reasonable\n",
            "I\n",
            "worry\n",
            "that\n",
            "many\n",
            "artifacts\n",
            "like\n",
            "-\n",
            "motion\n",
            "blur\n",
            ",\n",
            "face\n",
            "blur\n",
            ",\n",
            "aliasing\n",
            "etc\n",
            ".\n",
            "are\n",
            "things\n",
            "that\n",
            "could\n",
            "change\n",
            "perceptual\n",
            "metric\n",
            "significantly\n",
            ".\n",
            "It\n",
            "would\n",
            "be\n",
            "great\n",
            "to\n",
            "hear\n",
            "from\n",
            "authors\n",
            "on\n",
            "whether\n",
            "they\n",
            "worked\n",
            "on\n",
            "uncompressed\n",
            "video\n",
            "and\n",
            "if\n",
            "not\n",
            "talk\n",
            "a\n",
            "little\n",
            "more\n",
            "about\n",
            "the\n",
            "importance\n",
            "of\n",
            "using\n",
            "consistency\n",
            "metric\n",
            ".\n",
            "Since\n",
            ",\n",
            "this\n",
            "is\n",
            "one\n",
            "of\n",
            "the\n",
            "main\n",
            "novelty\n",
            "of\n",
            "the\n",
            "paper\n",
            "I\n",
            "would\n",
            "like\n",
            "to\n",
            "make\n",
            "sure\n",
            "this\n",
            "part\n",
            "is\n",
            "well\n",
            "justified\n",
            ".\n",
            "Correctness\n",
            ":\n",
            "Yes\n",
            ",\n",
            "I\n",
            "did\n",
            "not\n",
            "see\n",
            "anything\n",
            "wrong\n",
            "in\n",
            "the\n",
            "setup\n",
            "and\n",
            "the\n",
            "claims\n",
            "made\n",
            "by\n",
            "the\n",
            "authors\n",
            ".\n",
            "Clarity\n",
            ":\n",
            "Yes\n",
            ",\n",
            "for\n",
            "most\n",
            "part\n",
            ".\n",
            "The\n",
            "results\n",
            "section\n",
            "can\n",
            "be\n",
            "improved\n",
            "further\n",
            ",\n",
            "especially\n",
            "maybe\n",
            "contrast\n",
            "where\n",
            "PIM\n",
            "performs\n",
            "better\n",
            "qualitatively\n",
            "and\n",
            "talk\n",
            "about\n",
            "why\n",
            ".\n",
            "Relation\n",
            "to\n",
            "Prior\n",
            "Work\n",
            ":\n",
            "Yes\n",
            ",\n",
            "a\n",
            "latest\n",
            "reference\n",
            "that\n",
            "might\n",
            "be\n",
            "related\n",
            "is\n",
            "shared\n",
            "below\n",
            ":\n",
            "From\n",
            "patches\n",
            "to\n",
            "pictures\n",
            "(\n",
            "PaQ-2-PiQ\n",
            ")\n",
            ":\n",
            "Mapping\n",
            "the\n",
            "perceptual\n",
            "space\n",
            "of\n",
            "picture\n",
            "quality\n",
            "Z\n",
            "Ying\n",
            ",\n",
            "H\n",
            "Niu\n",
            ",\n",
            "P\n",
            "Gupta\n",
            ",\n",
            "D\n",
            "Mahajan\n",
            ",\n",
            "D\n",
            "Ghadiyaram\n",
            ",\n",
            "A\n",
            "Bovik\n",
            "Reproducibility\n",
            ":\n",
            "Yes\n",
            "NeurIPS\n",
            "2020\n",
            "An\n",
            "Unsupervised\n",
            "Information-Theoretic\n",
            "Perceptual\n",
            "Quality\n",
            "Metric\n",
            "Meta\n",
            "Review\n",
            "This\n",
            "paper\n",
            "proposes\n",
            "a\n",
            "novel\n",
            "perceptual\n",
            "image\n",
            "quality\n",
            "evaluation\n",
            "metric\n",
            "based\n",
            "on\n",
            "unsupervised\n",
            "method\n",
            "that\n",
            "aims\n",
            "optimization\n",
            "of\n",
            "a\n",
            "lower\n",
            "bound\n",
            "of\n",
            "the\n",
            "multivariate\n",
            "mutual\n",
            "information\n",
            ".\n",
            "The\n",
            "method\n",
            "is\n",
            "implemented\n",
            "using\n",
            "deep\n",
            "neural\n",
            "networks\n",
            "and\n",
            "tested\n",
            "two\n",
            "datasets\n",
            ",\n",
            "BAPPS\n",
            "and\n",
            "ImageNEt-C\n",
            "and\n",
            "was\n",
            "shown\n",
            "to\n",
            "achieve\n",
            "results\n",
            "comparable\n",
            "with\n",
            "supervised\n",
            "methods\n",
            ".\n",
            "The\n",
            "approach\n",
            "is\n",
            "well-motivated\n",
            "and\n",
            "clearly\n",
            "presented\n",
            ",\n",
            "and\n",
            "tackles\n",
            "an\n",
            "important\n",
            "problem\n",
            "without\n",
            "requiring\n",
            "subjective\n",
            "human\n",
            "judgements\n",
            ".\n",
            "One\n",
            "of\n",
            "the\n",
            "reviewers\n",
            "raise\n",
            "the\n",
            "question\n",
            "of\n",
            "applicability\n",
            "of\n",
            "the\n",
            "approach\n",
            "on\n",
            "compressed\n",
            "images\n",
            ".\n",
            "Others\n",
            "also\n",
            "suggest\n",
            "the\n",
            "experimentation\n",
            "part\n",
            "of\n",
            "the\n",
            "paper\n",
            "is\n",
            "somewhat\n",
            "preliminary\n",
            ".\n",
            "Book\n",
            "Do\n",
            "not\n",
            "remove\n",
            ":\n",
            "This\n",
            "comment\n",
            "is\n",
            "monitored\n",
            "to\n",
            "verify\n",
            "that\n",
            "the\n",
            "site\n",
            "is\n",
            "working\n",
            "properly\n",
            "Abstract\n",
            "Synthesizing\n",
            "larger\n",
            "texture\n",
            "images\n",
            "from\n",
            "a\n",
            "smaller\n",
            "exemplar\n",
            "is\n",
            "an\n",
            "important\n",
            "task\n",
            "in\n",
            "graphics\n",
            "and\n",
            "vision\n",
            ".\n",
            "The\n",
            "conventional\n",
            "CNNs\n",
            ",\n",
            "recently\n",
            "adopted\n",
            "for\n",
            "synthesis\n",
            ",\n",
            "require\n",
            "to\n",
            "train\n",
            "and\n",
            "test\n",
            "on\n",
            "the\n",
            "same\n",
            "set\n",
            "of\n",
            "images\n",
            "and\n",
            "fail\n",
            "to\n",
            "generalize\n",
            "to\n",
            "unseen\n",
            "images\n",
            ".\n",
            "This\n",
            "is\n",
            "mainly\n",
            "because\n",
            "those\n",
            "CNNs\n",
            "fully\n",
            "rely\n",
            "on\n",
            "convolutional\n",
            "and\n",
            "upsampling\n",
            "layers\n",
            "that\n",
            "operate\n",
            "locally\n",
            "and\n",
            "not\n",
            "suitable\n",
            "for\n",
            "a\n",
            "task\n",
            "as\n",
            "global\n",
            "as\n",
            "texture\n",
            "synthesis\n",
            ".\n",
            "In\n",
            "this\n",
            "work\n",
            ",\n",
            "inspired\n",
            "by\n",
            "the\n",
            "repetitive\n",
            "nature\n",
            "of\n",
            "texture\n",
            "patterns\n",
            ",\n",
            "we\n",
            "ﬁnd\n",
            "that\n",
            "texture\n",
            "synthesis\n",
            "can\n",
            "be\n",
            "viewed\n",
            "as\n",
            "(\n",
            "local\n",
            ")\n",
            "upsampling\n",
            "in\n",
            "the\n",
            "Fast\n",
            "Fourier\n",
            "Transform\n",
            "(\n",
            "FFT\n",
            ")\n",
            "domain\n",
            ".\n",
            "However\n",
            ",\n",
            "FFT\n",
            "of\n",
            "natural\n",
            "images\n",
            "exhibits\n",
            "high\n",
            "dynamic\n",
            "range\n",
            "and\n",
            "lacks\n",
            "local\n",
            "correlations\n",
            ".\n",
            "Therefore\n",
            ",\n",
            "to\n",
            "train\n",
            "CNNs\n",
            "we\n",
            "design\n",
            "a\n",
            "framework\n",
            "to\n",
            "perform\n",
            "FFT\n",
            "upsampling\n",
            "in\n",
            "feature\n",
            "space\n",
            "using\n",
            "deformable\n",
            "convolutions\n",
            ".\n",
            "Such\n",
            "design\n",
            "allows\n",
            "our\n",
            "framework\n",
            "to\n",
            "generalize\n",
            "to\n",
            "unseen\n",
            "images\n",
            ",\n",
            "and\n",
            "synthesize\n",
            "textures\n",
            "in\n",
            "a\n",
            "single\n",
            "pass\n",
            ".\n",
            "Extensive\n",
            "evaluations\n",
            "conﬁrm\n",
            "that\n",
            "our\n",
            "method\n",
            "achieves\n",
            "state-of-the-art\n",
            "performance\n",
            "both\n",
            "quantitatively\n",
            "and\n",
            "qualitatively\n",
            ".\n",
            "Abstract\n",
            "Learning\n",
            "object-centric\n",
            "representations\n",
            "of\n",
            "complex\n",
            "scenes\n",
            "is\n",
            "a\n",
            "promising\n",
            "step\n",
            "towards\n",
            "enabling\n",
            "efﬁcient\n",
            "abstract\n",
            "reasoning\n",
            "from\n",
            "low-level\n",
            "perceptual\n",
            "features\n",
            ".\n",
            "Yet\n",
            ",\n",
            "most\n",
            "deep\n",
            "learning\n",
            "approaches\n",
            "learn\n",
            "distributed\n",
            "representations\n",
            "that\n",
            "do\n",
            "not\n",
            "capture\n",
            "the\n",
            "compositional\n",
            "properties\n",
            "of\n",
            "natural\n",
            "scenes\n",
            ".\n",
            "In\n",
            "this\n",
            "paper\n",
            ",\n",
            "we\n",
            "present\n",
            "the\n",
            "Slot\n",
            "Attention\n",
            "module\n",
            ",\n",
            "an\n",
            "architectural\n",
            "component\n",
            "that\n",
            "interfaces\n",
            "with\n",
            "perceptual\n",
            "representations\n",
            "such\n",
            "as\n",
            "the\n",
            "output\n",
            "of\n",
            "a\n",
            "convolutional\n",
            "neural\n",
            "network\n",
            "and\n",
            "produces\n",
            "a\n",
            "set\n",
            "of\n",
            "task-dependent\n",
            "abstract\n",
            "representations\n",
            "which\n",
            "we\n",
            "call\n",
            "slots\n",
            ".\n",
            "These\n",
            "slots\n",
            "are\n",
            "exchangeable\n",
            "and\n",
            "can\n",
            "bind\n",
            "to\n",
            "any\n",
            "object\n",
            "in\n",
            "the\n",
            "input\n",
            "by\n",
            "specializing\n",
            "through\n",
            "a\n",
            "competitive\n",
            "procedure\n",
            "over\n",
            "multiple\n",
            "rounds\n",
            "of\n",
            "attention\n",
            ".\n",
            "We\n",
            "empirically\n",
            "demonstrate\n",
            "that\n",
            "Slot\n",
            "Attention\n",
            "can\n",
            "extract\n",
            "object-centric\n",
            "representations\n",
            "that\n",
            "enable\n",
            "generalization\n",
            "to\n",
            "unseen\n",
            "compositions\n",
            "when\n",
            "trained\n",
            "on\n",
            "unsupervised\n",
            "object\n",
            "discovery\n",
            "and\n",
            "supervised\n",
            "property\n",
            "prediction\n",
            "tasks\n",
            ".\n",
            "1\n",
            "Abstract\n",
            "Within\n",
            "months\n",
            "of\n",
            "birth\n",
            ",\n",
            "children\n",
            "develop\n",
            "meaningful\n",
            "expectations\n",
            "about\n",
            "the\n",
            "world\n",
            "around\n",
            "them\n",
            ".\n",
            "How\n",
            "much\n",
            "of\n",
            "this\n",
            "early\n",
            "knowledge\n",
            "can\n",
            "be\n",
            "explained\n",
            "through\n",
            "generic\n",
            "learning\n",
            "mechanisms\n",
            "applied\n",
            "to\n",
            "sensory\n",
            "data\n",
            ",\n",
            "and\n",
            "how\n",
            "much\n",
            "of\n",
            "it\n",
            "requires\n",
            "more\n",
            "substantive\n",
            "innate\n",
            "inductive\n",
            "biases\n",
            "?\n",
            "Addressing\n",
            "this\n",
            "fundamental\n",
            "question\n",
            "in\n",
            "its\n",
            "full\n",
            "generality\n",
            "is\n",
            "currently\n",
            "infeasible\n",
            ",\n",
            "but\n",
            "we\n",
            "can\n",
            "hope\n",
            "to\n",
            "make\n",
            "real\n",
            "progress\n",
            "in\n",
            "more\n",
            "narrowly\n",
            "deﬁned\n",
            "domains\n",
            ",\n",
            "such\n",
            "as\n",
            "the\n",
            "development\n",
            "of\n",
            "high-level\n",
            "visual\n",
            "categories\n",
            ",\n",
            "thanks\n",
            "to\n",
            "improvements\n",
            "in\n",
            "data\n",
            "collecting\n",
            "technology\n",
            "and\n",
            "recent\n",
            "progress\n",
            "in\n",
            "deep\n",
            "learning\n",
            ".\n",
            "In\n",
            "this\n",
            "paper\n",
            ",\n",
            "our\n",
            "goal\n",
            "is\n",
            "precisely\n",
            "to\n",
            "achieve\n",
            "such\n",
            "progress\n",
            "by\n",
            "utilizing\n",
            "modern\n",
            "self-supervised\n",
            "deep\n",
            "learning\n",
            "methods\n",
            "and\n",
            "a\n",
            "recent\n",
            "longitudinal\n",
            ",\n",
            "egocentric\n",
            "video\n",
            "dataset\n",
            "recorded\n",
            "from\n",
            "the\n",
            "perspective\n",
            "of\n",
            "three\n",
            "young\n",
            "children\n",
            "(\n",
            "Sullivan\n",
            "et\n",
            "al.\n",
            ",\n",
            "2020\n",
            ")\n",
            ".\n",
            "Our\n",
            "results\n",
            "demonstrate\n",
            "the\n",
            "emergence\n",
            "of\n",
            "powerful\n",
            ",\n",
            "high-level\n",
            "visual\n",
            "representations\n",
            "from\n",
            "developmentally\n",
            "realistic\n",
            "natural\n",
            "videos\n",
            "using\n",
            "generic\n",
            "self-\n",
            "supervised\n",
            "learning\n",
            "objectives\n",
            ".\n",
            "1\n",
            "Abstract\n",
            "The\n",
            "goal\n",
            "of\n",
            "compressed\n",
            "sensing\n",
            "is\n",
            "to\n",
            "estimate\n",
            "a\n",
            "high\n",
            "dimensional\n",
            "vector\n",
            "from\n",
            "an\n",
            "underdetermined\n",
            "system\n",
            "of\n",
            "noisy\n",
            "linear\n",
            "equations\n",
            ".\n",
            "In\n",
            "analogy\n",
            "to\n",
            "classical\n",
            "compressed\n",
            "sensing\n",
            ",\n",
            "here\n",
            "we\n",
            "assume\n",
            "a\n",
            "generative\n",
            "model\n",
            "as\n",
            "a\n",
            "prior\n",
            ",\n",
            "that\n",
            "is\n",
            ",\n",
            "we\n",
            "assume\n",
            "the\n",
            "vector\n",
            "is\n",
            "represented\n",
            "by\n",
            "a\n",
            "deep\n",
            "generative\n",
            "model\n",
            "G\n",
            ":\n",
            "Rk\n",
            "→\n",
            "Rn\n",
            ".\n",
            "Classical\n",
            "recovery\n",
            "approaches\n",
            "such\n",
            "as\n",
            "empirical\n",
            "risk\n",
            "minimization\n",
            "(\n",
            "ERM\n",
            ")\n",
            "are\n",
            "guaranteed\n",
            "to\n",
            "succeed\n",
            "when\n",
            "the\n",
            "measurement\n",
            "matrix\n",
            "is\n",
            "sub-Gaussian\n",
            ".\n",
            "However\n",
            ",\n",
            "when\n",
            "the\n",
            "measurement\n",
            "matrix\n",
            "and\n",
            "measurements\n",
            "are\n",
            "heavy-tailed\n",
            "or\n",
            "have\n",
            "outliers\n",
            ",\n",
            "recovery\n",
            "may\n",
            "fail\n",
            "dramatically\n",
            ".\n",
            "In\n",
            "this\n",
            "paper\n",
            "we\n",
            "propose\n",
            "an\n",
            "algorithm\n",
            "inspired\n",
            "by\n",
            "the\n",
            "Median-of-Means\n",
            "(\n",
            "MOM\n",
            ")\n",
            ".\n",
            "Our\n",
            "algorithm\n",
            "guarantees\n",
            "recovery\n",
            "for\n",
            "heavy-tailed\n",
            "data\n",
            ",\n",
            "even\n",
            "in\n",
            "the\n",
            "presence\n",
            "of\n",
            "outliers\n",
            ".\n",
            "Theoretically\n",
            ",\n",
            "our\n",
            "results\n",
            "show\n",
            "our\n",
            "novel\n",
            "MOM-based\n",
            "algorithm\n",
            "enjoys\n",
            "the\n",
            "same\n",
            "sample\n",
            "complexity\n",
            "guarantees\n",
            "as\n",
            "ERM\n",
            "under\n",
            "sub-Gaussian\n",
            "assumptions\n",
            ".\n",
            "Our\n",
            "experiments\n",
            "validate\n",
            "both\n",
            "aspects\n",
            "of\n",
            "our\n",
            "claims\n",
            ":\n",
            "other\n",
            "algorithms\n",
            "are\n",
            "indeed\n",
            "fragile\n",
            "and\n",
            "fail\n",
            "under\n",
            "heavy-tailed\n",
            "and/or\n",
            "corrupted\n",
            "data\n",
            ",\n",
            "while\n",
            "our\n",
            "approach\n",
            "exhibits\n",
            "the\n",
            "predicted\n",
            "robustness\n",
            ".\n",
            "Abstract\n",
            "Given\n",
            "the\n",
            "ever-increasing\n",
            "computational\n",
            "costs\n",
            "of\n",
            "modern\n",
            "machine\n",
            "learning\n",
            "mod-\n",
            "els\n",
            ",\n",
            "we\n",
            "need\n",
            "to\n",
            "ﬁnd\n",
            "new\n",
            "ways\n",
            "to\n",
            "reuse\n",
            "such\n",
            "expert\n",
            "models\n",
            "and\n",
            "thus\n",
            "tap\n",
            "into\n",
            "the\n",
            "resources\n",
            "that\n",
            "have\n",
            "been\n",
            "invested\n",
            "in\n",
            "their\n",
            "creation\n",
            ".\n",
            "Recent\n",
            "work\n",
            "suggests\n",
            "that\n",
            "the\n",
            "power\n",
            "of\n",
            "these\n",
            "massive\n",
            "models\n",
            "is\n",
            "captured\n",
            "by\n",
            "the\n",
            "representations\n",
            "they\n",
            "learn\n",
            ".\n",
            "There-\n",
            "fore\n",
            ",\n",
            "we\n",
            "seek\n",
            "a\n",
            "model\n",
            "that\n",
            "can\n",
            "relate\n",
            "between\n",
            "different\n",
            "existing\n",
            "representations\n",
            "and\n",
            "propose\n",
            "to\n",
            "solve\n",
            "this\n",
            "task\n",
            "with\n",
            "a\n",
            "conditionally\n",
            "invertible\n",
            "network\n",
            ".\n",
            "This\n",
            "network\n",
            "demonstrates\n",
            "its\n",
            "capability\n",
            "by\n",
            "(\n",
            "i\n",
            ")\n",
            "providing\n",
            "generic\n",
            "transfer\n",
            "between\n",
            "diverse\n",
            "do-\n",
            "mains\n",
            ",\n",
            "(\n",
            "ii\n",
            ")\n",
            "enabling\n",
            "controlled\n",
            "content\n",
            "synthesis\n",
            "by\n",
            "allowing\n",
            "modiﬁcation\n",
            "in\n",
            "other\n",
            "domains\n",
            ",\n",
            "and\n",
            "(\n",
            "iii\n",
            ")\n",
            "facilitating\n",
            "diagnosis\n",
            "of\n",
            "existing\n",
            "representations\n",
            "by\n",
            "translating\n",
            "them\n",
            "into\n",
            "interpretable\n",
            "domains\n",
            "such\n",
            "as\n",
            "images\n",
            ".\n",
            "Our\n",
            "domain\n",
            "transfer\n",
            "network\n",
            "can\n",
            "translate\n",
            "between\n",
            "ﬁxed\n",
            "representations\n",
            "without\n",
            "having\n",
            "to\n",
            "learn\n",
            "or\n",
            "ﬁnetune\n",
            "them\n",
            ".\n",
            "This\n",
            "allows\n",
            "users\n",
            "to\n",
            "utilize\n",
            "various\n",
            "existing\n",
            "domain-speciﬁc\n",
            "expert\n",
            "models\n",
            "from\n",
            "the\n",
            "literature\n",
            "that\n",
            "had\n",
            "been\n",
            "trained\n",
            "with\n",
            "extensive\n",
            "computational\n",
            "resources\n",
            ".\n",
            "Experiments\n",
            "on\n",
            "diverse\n",
            "conditional\n",
            "image\n",
            "synthesis\n",
            "tasks\n",
            ",\n",
            "competitive\n",
            "image\n",
            "mod-\n",
            "iﬁcation\n",
            "results\n",
            "and\n",
            "experiments\n",
            "on\n",
            "image-to-image\n",
            "and\n",
            "text-to-image\n",
            "generation\n",
            "demonstrate\n",
            "the\n",
            "generic\n",
            "applicability\n",
            "of\n",
            "our\n",
            "approach\n",
            ".\n",
            "For\n",
            "example\n",
            ",\n",
            "we\n",
            "translate\n",
            "between\n",
            "BERT\n",
            "and\n",
            "BigGAN\n",
            ",\n",
            "state-of-the-art\n",
            "text\n",
            "and\n",
            "image\n",
            "models\n",
            "to\n",
            "provide\n",
            "text-to-image\n",
            "generation\n",
            ",\n",
            "which\n",
            "neither\n",
            "of\n",
            "both\n",
            "experts\n",
            "can\n",
            "perform\n",
            "on\n",
            "their\n",
            "own\n",
            ".\n",
            "1\n",
            "Abstract\n",
            "Unsupervised\n",
            "and\n",
            "self-supervised\n",
            "learning\n",
            "approaches\n",
            "have\n",
            "become\n",
            "a\n",
            "crucial\n",
            "tool\n",
            "to\n",
            "learn\n",
            "representations\n",
            "for\n",
            "downstream\n",
            "prediction\n",
            "tasks\n",
            ".\n",
            "While\n",
            "these\n",
            "approaches\n",
            "are\n",
            "widely\n",
            "used\n",
            "in\n",
            "practice\n",
            "and\n",
            "achieve\n",
            "impressive\n",
            "empirical\n",
            "gains\n",
            ",\n",
            "their\n",
            "theoret-\n",
            "ical\n",
            "understanding\n",
            "largely\n",
            "lags\n",
            "behind\n",
            ".\n",
            "Towards\n",
            "bridging\n",
            "this\n",
            "gap\n",
            ",\n",
            "we\n",
            "present\n",
            "a\n",
            "unifying\n",
            "perspective\n",
            "where\n",
            "several\n",
            "such\n",
            "approaches\n",
            "can\n",
            "be\n",
            "viewed\n",
            "as\n",
            "imposing\n",
            "a\n",
            "regularization\n",
            "on\n",
            "the\n",
            "representation\n",
            "via\n",
            "a\n",
            "learnable\n",
            "function\n",
            "using\n",
            "unlabeled\n",
            "data\n",
            ".\n",
            "We\n",
            "propose\n",
            "a\n",
            "discriminative\n",
            "theoretical\n",
            "framework\n",
            "for\n",
            "analyzing\n",
            "the\n",
            "sam-\n",
            "ple\n",
            "complexity\n",
            "of\n",
            "these\n",
            "approaches\n",
            ",\n",
            "which\n",
            "generalizes\n",
            "the\n",
            "framework\n",
            "of\n",
            "[\n",
            "3\n",
            "]\n",
            "to\n",
            "allow\n",
            "learnable\n",
            "regularization\n",
            "functions\n",
            ".\n",
            "Our\n",
            "sample\n",
            "complexity\n",
            "bounds\n",
            "show\n",
            "that\n",
            ",\n",
            "with\n",
            "carefully\n",
            "chosen\n",
            "hypothesis\n",
            "classes\n",
            "to\n",
            "exploit\n",
            "the\n",
            "structure\n",
            "in\n",
            "the\n",
            "data\n",
            ",\n",
            "these\n",
            "learnable\n",
            "regularization\n",
            "functions\n",
            "can\n",
            "prune\n",
            "the\n",
            "hypothesis\n",
            "space\n",
            ",\n",
            "and\n",
            "help\n",
            "reduce\n",
            "the\n",
            "amount\n",
            "of\n",
            "labeled\n",
            "data\n",
            "needed\n",
            ".\n",
            "We\n",
            "then\n",
            "provide\n",
            "two\n",
            "concrete\n",
            "examples\n",
            "of\n",
            "functional\n",
            "regularization\n",
            ",\n",
            "one\n",
            "using\n",
            "auto-encoders\n",
            "and\n",
            "the\n",
            "other\n",
            "using\n",
            "masked\n",
            "self-supervision\n",
            ",\n",
            "and\n",
            "apply\n",
            "our\n",
            "framework\n",
            "to\n",
            "quantify\n",
            "the\n",
            "reduction\n",
            "in\n",
            "the\n",
            "sample\n",
            "complexity\n",
            "bound\n",
            "of\n",
            "labeled\n",
            "data\n",
            ".\n",
            "We\n",
            "also\n",
            "provide\n",
            "complementary\n",
            "empirical\n",
            "results\n",
            "to\n",
            "support\n",
            "our\n",
            "analysis\n",
            ".\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "df_output                                                topic  \\\n",
            "0                                            neurips   \n",
            "1                                            neurips   \n",
            "2                                            neurips   \n",
            "3                                            neurips   \n",
            "4                                            neurips   \n",
            "5                                            neurips   \n",
            "6                                            neurips   \n",
            "7                                            neurips   \n",
            "8                                            neurips   \n",
            "9                                            neurips   \n",
            "0  unsupervised information theoretic perceptual ...   \n",
            "1  unsupervised information theoretic perceptual ...   \n",
            "2  unsupervised information theoretic perceptual ...   \n",
            "3  unsupervised information theoretic perceptual ...   \n",
            "4  unsupervised information theoretic perceptual ...   \n",
            "5  unsupervised information theoretic perceptual ...   \n",
            "6  unsupervised information theoretic perceptual ...   \n",
            "7  unsupervised information theoretic perceptual ...   \n",
            "8  unsupervised information theoretic perceptual ...   \n",
            "9  unsupervised information theoretic perceptual ...   \n",
            "\n",
            "                                               title  \\\n",
            "0  Training Generative Adversarial Networks with ...   \n",
            "1  Estimating Training Data Influence by Tracing ...   \n",
            "2                         Deep Evidential Regression   \n",
            "3  Information Theoretic Regret Bounds for Online...   \n",
            "4           Universally Quantized Neural Compression   \n",
            "5  Advances in Neural Information Processing Syst...   \n",
            "6      Graph Contrastive Learning with Augmentations   \n",
            "7  Efficient Exact Verification of Binarized Neur...   \n",
            "8  Path Sample-Analytic Gradient Estimators for S...   \n",
            "9                           Deep Archimedean Copulas   \n",
            "0  An Unsupervised Information-Theoretic Perceptu...   \n",
            "1  An Unsupervised Information-Theoretic ... - Re...   \n",
            "2  An Unsupervised Information-Theoretic ... - Re...   \n",
            "3  Advances in Neural Information Processing Syst...   \n",
            "4  Neural FFTs for Universal Texture Image Synthesis   \n",
            "5        Object-Centric Learning with Slot Attention   \n",
            "6  Self-supervised learning through the eyes of a...   \n",
            "7  Robust Compressed Sensing using Generative Models   \n",
            "8  Network-to-Network Translation with Conditiona...   \n",
            "9  Functional Regularization for Representation L...   \n",
            "\n",
            "                                                text  \\\n",
            "0  Training Generative Adversarial Networks with ...   \n",
            "1  Estimating Training Data Influence by Tracing ...   \n",
            "2  Deep Evidential Regression\\n\\nPart of Advances...   \n",
            "3  Information Theoretic Regret Bounds for Online...   \n",
            "4  Universally Quantized Neural Compression\\n\\nPa...   \n",
            "5  Book\\n\\nDo not remove: This comment is monitor...   \n",
            "6  Graph Contrastive Learning with Augmentations\\...   \n",
            "7  Efficient Exact Verification of Binarized Neur...   \n",
            "8  Path Sample-Analytic Gradient Estimators for S...   \n",
            "9  Deep Archimedean Copulas\\n\\nPart of Advances i...   \n",
            "0  An Unsupervised Information-Theoretic Perceptu...   \n",
            "1  NeurIPS 2020\\n\\nAn Unsupervised Information-Th...   \n",
            "2  NeurIPS 2020\\n\\nAn Unsupervised Information-Th...   \n",
            "3  Book\\n\\nDo not remove: This comment is monitor...   \n",
            "4  Abstract\\n\\nSynthesizing larger texture images...   \n",
            "5  Abstract\\n\\nLearning object-centric representa...   \n",
            "6  Abstract\\n\\nWithin months of birth, children d...   \n",
            "7  Abstract\\n\\nThe goal of compressed sensing is ...   \n",
            "8  Abstract\\n\\nGiven the ever-increasing computat...   \n",
            "9  Abstract\\n\\nUnsupervised and self-supervised l...   \n",
            "\n",
            "                                                 url  similarity_score  rank  \\\n",
            "0  https://papers.nips.cc/paper/2020/hash/8d30aa9...          0.965153   3.0   \n",
            "1  https://papers.nips.cc/paper/2020/hash/e6385d3...          0.965144   4.0   \n",
            "2  https://papers.nips.cc/paper/2020/hash/aab0854...          0.965102   6.0   \n",
            "3  https://papers.nips.cc/paper/2020/hash/aee5620...          0.965130   5.0   \n",
            "4  https://papers.nips.cc/paper/2020/hash/92049de...          0.965285   2.0   \n",
            "5                  https://papers.nips.cc/paper/2020          0.965377   1.0   \n",
            "6  https://papers.nips.cc/paper/2020/hash/3fe2303...          0.960548  10.0   \n",
            "7  https://papers.nips.cc/paper/2020/hash/1385974...          0.962081   7.0   \n",
            "8  https://papers.nips.cc/paper/2020/hash/96fca94...          0.961407   9.0   \n",
            "9  https://papers.nips.cc/paper/2020/hash/10eb650...          0.961599   8.0   \n",
            "0  https://papers.nips.cc/paper/2020/hash/00482b9...          0.960361   6.0   \n",
            "1  https://papers.nips.cc/paper/2020/file/00482b9...          0.940551  10.0   \n",
            "2  https://papers.nips.cc/paper/2020/file/00482b9...          0.960248   8.0   \n",
            "3                  https://papers.nips.cc/paper/2020          0.964870   1.0   \n",
            "4  https://papers.nips.cc/paper/2020/file/a23156a...          0.960257   7.0   \n",
            "5  https://papers.nips.cc/paper/2020/file/8511df9...          0.959921   9.0   \n",
            "6  https://papers.nips.cc/paper/2020/file/7183145...          0.964294   2.0   \n",
            "7  https://papers.nips.cc/paper/2020/file/07cb5f8...          0.963900   3.0   \n",
            "8  https://papers.nips.cc/paper/2020/file/1cfa81a...          0.963835   4.0   \n",
            "9  https://papers.nips.cc/paper/2020/file/c793b3b...          0.961062   5.0   \n",
            "\n",
            "   similarity_score_lda  rank_lda  \n",
            "0              0.976416       8.0  \n",
            "1              0.976422       7.0  \n",
            "2              0.976501       5.0  \n",
            "3              0.976803       3.0  \n",
            "4              0.976386       9.0  \n",
            "5              0.976283      10.0  \n",
            "6              0.977023       1.0  \n",
            "7              0.976987       2.0  \n",
            "8              0.976438       6.0  \n",
            "9              0.976682       4.0  \n",
            "0              0.976147       8.0  \n",
            "1              0.975887       9.0  \n",
            "2              0.976883       2.0  \n",
            "3              0.976728       5.0  \n",
            "4              0.975769      10.0  \n",
            "5              0.976862       3.0  \n",
            "6              0.976213       7.0  \n",
            "7              0.977043       1.0  \n",
            "8              0.976403       6.0  \n",
            "9              0.976810       4.0  \n",
            "topic:  self supervised multimodal versatile networks neurips id_= 2\n",
            "1 . Self-Supervised MultiModal Versatile Networks https://papers.nips.cc/paper/2020/hash/0060ef47b12160b9198302ebdb144dcf-Abstract.html\n",
            "**********************************************\n",
            "2 . Advances in Neural Information Processing Systems 33 (NeurIPS ... https://papers.nips.cc/paper/2020\n",
            "**********************************************\n",
            "3 . Large-Scale Adversarial Training for Vision-and-Language ... https://papers.nips.cc/paper/2020/file/49562478de4c54fafd4ec46fdb297de5-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "We present VILLA, the ﬁrst known effort on large-scale adversarial training for\n",
            "vision-and-language (V+L) representation learning. VILLA consists of two training\n",
            "stages: (i) task-agnostic adversarial pre-training; followed by (ii) task-speciﬁc\n",
            "adversarial ﬁnetuning. Instead of adding adversarial perturbations on image pixels\n",
            "and textual tokens, we propose to perform adversarial training in the embedding\n",
            "space of each modality. To enable large-scale training, we adopt the “free” adver-\n",
            "sarial training strategy, and combine it with KL-divergence-based regularization to\n",
            "promote higher invariance in the embedding space. We apply VILLA to current\n",
            "best-performing V+L models, and achieve new state of the art on a wide range\n",
            "of tasks, including Visual Question Answering, Visual Commonsense Reasoning,\n",
            "Image-Text Retrieval, Referring Expression Comprehension, Visual Entailment,\n",
            "and NLVR2.1\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "4 . Training Generative Adversarial Networks with Limited Data https://papers.nips.cc/paper/2020/file/8d30aa96e72440759f74bd2306c1fa3d-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Training generative adversarial networks (GAN) using too little data typically leads\n",
            "to discriminator overﬁtting, causing training to diverge. We propose an adaptive\n",
            "discriminator augmentation mechanism that signiﬁcantly stabilizes training in\n",
            "limited data regimes. The approach does not require changes to loss functions\n",
            "or network architectures, and is applicable both when training from scratch and\n",
            "when ﬁne-tuning an existing GAN on another dataset. We demonstrate, on several\n",
            "datasets, that good results are now possible using only a few thousand training\n",
            "images, often matching StyleGAN2 results with an order of magnitude fewer\n",
            "images. We expect this to open up new application domains for GANs. We also\n",
            "ﬁnd that the widely used CIFAR-10 is, in fact, a limited data benchmark, and\n",
            "improve the record FID from 5.59 to 2.42.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "5 . Bayesian Attention Modules https://papers.nips.cc/paper/2020/file/bcff3f632fd16ff099a49c2f0932b47a-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Attention modules, as simple and effective tools, have not only enabled deep neural\n",
            "networks to achieve state-of-the-art results in many domains, but also enhanced\n",
            "their interpretability. Most current models use deterministic attention modules\n",
            "due to their simplicity and ease of optimization. Stochastic counterparts, on the\n",
            "other hand, are less popular despite their potential beneﬁts. The main reason is\n",
            "that stochastic attention often introduces optimization issues or requires signiﬁcant\n",
            "model changes. In this paper, we propose a scalable stochastic version of attention\n",
            "that is easy to implement and optimize. We construct simplex-constrained attention\n",
            "distributions by normalizing reparameterizable distributions, making the training\n",
            "process differentiable. We learn their parameters in a Bayesian framework where\n",
            "a data-dependent prior is introduced for regularization. We apply the proposed\n",
            "stochastic attention modules to various attention-based models, with applications\n",
            "to graph node classiﬁcation, visual question answering, image captioning, machine\n",
            "translation, and language understanding. Our experiments show the proposed\n",
            "method brings consistent improvements over the corresponding baselines.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "6 . Language-Conditioned Imitation Learning for Robot Manipulation ... https://papers.nips.cc/paper/2020/file/9909794d52985cbc5d95c26e31125d1a-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Imitation learning is a popular approach for teaching motor skills to robots. How-\n",
            "ever, most approaches focus on extracting policy parameters from execution traces\n",
            "alone (i.e., motion trajectories and perceptual data). No adequate communication\n",
            "channel exists between the human expert and the robot to describe critical aspects\n",
            "of the task, such as the properties of the target object or the intended shape of the\n",
            "motion. Motivated by insights into the human teaching process, we introduce a\n",
            "method for incorporating unstructured natural language into imitation learning. At\n",
            "training time, the expert can provide demonstrations along with verbal descriptions\n",
            "in order to describe the underlying intent (e.g., “go to the large green bowl”). The\n",
            "training process then interrelates these two modalities to encode the correlations\n",
            "between language, perception, and motion. The resulting language-conditioned\n",
            "visuomotor policies can be conditioned at runtime on new human commands and\n",
            "instructions, which allows for more ﬁne-grained control over the trained policies\n",
            "while also reducing situational ambiguity. We demonstrate in a set of simulation\n",
            "experiments how our approach can learn language-conditioned manipulation poli-\n",
            "cies for a seven-degree-of-freedom robot arm and compare the results to a variety\n",
            "of alternative methods.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "data:                                                topic  \\\n",
            "0  self supervised multimodal versatile networks ...   \n",
            "1  self supervised multimodal versatile networks ...   \n",
            "2  self supervised multimodal versatile networks ...   \n",
            "3  self supervised multimodal versatile networks ...   \n",
            "4  self supervised multimodal versatile networks ...   \n",
            "5  self supervised multimodal versatile networks ...   \n",
            "\n",
            "                                               title  \\\n",
            "0      Self-Supervised MultiModal Versatile Networks   \n",
            "1  Advances in Neural Information Processing Syst...   \n",
            "2  Large-Scale Adversarial Training for Vision-an...   \n",
            "3  Training Generative Adversarial Networks with ...   \n",
            "4                         Bayesian Attention Modules   \n",
            "5  Language-Conditioned Imitation Learning for Ro...   \n",
            "\n",
            "                                                text  \\\n",
            "0  Self-Supervised MultiModal Versatile Networks\\...   \n",
            "1  Book\\n\\nDo not remove: This comment is monitor...   \n",
            "2  Abstract\\n\\nWe present VILLA, the ﬁrst known e...   \n",
            "3  Abstract\\n\\nTraining generative adversarial ne...   \n",
            "4  Abstract\\n\\nAttention modules, as simple and e...   \n",
            "5  Abstract\\n\\nImitation learning is a popular ap...   \n",
            "\n",
            "                                                 url  \n",
            "0  https://papers.nips.cc/paper/2020/hash/0060ef4...  \n",
            "1                  https://papers.nips.cc/paper/2020  \n",
            "2  https://papers.nips.cc/paper/2020/file/4956247...  \n",
            "3  https://papers.nips.cc/paper/2020/file/8d30aa9...  \n",
            "4  https://papers.nips.cc/paper/2020/file/bcff3f6...  \n",
            "5  https://papers.nips.cc/paper/2020/file/9909794...  \n",
            "**********************************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                                               topic  \\\n",
            "0  self supervised multimodal versatile networks ...   \n",
            "1  self supervised multimodal versatile networks ...   \n",
            "2  self supervised multimodal versatile networks ...   \n",
            "3  self supervised multimodal versatile networks ...   \n",
            "4  self supervised multimodal versatile networks ...   \n",
            "5  self supervised multimodal versatile networks ...   \n",
            "\n",
            "                                               title  \\\n",
            "0      Self-Supervised MultiModal Versatile Networks   \n",
            "1  Advances in Neural Information Processing Syst...   \n",
            "2  Large-Scale Adversarial Training for Vision-an...   \n",
            "3  Training Generative Adversarial Networks with ...   \n",
            "4                         Bayesian Attention Modules   \n",
            "5  Language-Conditioned Imitation Learning for Ro...   \n",
            "\n",
            "                                                text  \\\n",
            "0  Self-Supervised MultiModal Versatile Networks\\...   \n",
            "1  Book\\n\\nDo not remove: This comment is monitor...   \n",
            "2  Abstract\\n\\nWe present VILLA, the ﬁrst known e...   \n",
            "3  Abstract\\n\\nTraining generative adversarial ne...   \n",
            "4  Abstract\\n\\nAttention modules, as simple and e...   \n",
            "5  Abstract\\n\\nImitation learning is a popular ap...   \n",
            "\n",
            "                                                 url  similarity_score  \n",
            "0  https://papers.nips.cc/paper/2020/hash/0060ef4...          0.965593  \n",
            "1                  https://papers.nips.cc/paper/2020          0.966477  \n",
            "2  https://papers.nips.cc/paper/2020/file/4956247...          0.965714  \n",
            "3  https://papers.nips.cc/paper/2020/file/8d30aa9...          0.963016  \n",
            "4  https://papers.nips.cc/paper/2020/file/bcff3f6...          0.962894  \n",
            "5  https://papers.nips.cc/paper/2020/file/9909794...          0.966408  \n",
            "df_final after rank=                                                topic  \\\n",
            "0  self supervised multimodal versatile networks ...   \n",
            "1  self supervised multimodal versatile networks ...   \n",
            "2  self supervised multimodal versatile networks ...   \n",
            "3  self supervised multimodal versatile networks ...   \n",
            "4  self supervised multimodal versatile networks ...   \n",
            "5  self supervised multimodal versatile networks ...   \n",
            "\n",
            "                                               title  \\\n",
            "0      Self-Supervised MultiModal Versatile Networks   \n",
            "1  Advances in Neural Information Processing Syst...   \n",
            "2  Large-Scale Adversarial Training for Vision-an...   \n",
            "3  Training Generative Adversarial Networks with ...   \n",
            "4                         Bayesian Attention Modules   \n",
            "5  Language-Conditioned Imitation Learning for Ro...   \n",
            "\n",
            "                                                text  \\\n",
            "0  Self-Supervised MultiModal Versatile Networks\\...   \n",
            "1  Book\\n\\nDo not remove: This comment is monitor...   \n",
            "2  Abstract\\n\\nWe present VILLA, the ﬁrst known e...   \n",
            "3  Abstract\\n\\nTraining generative adversarial ne...   \n",
            "4  Abstract\\n\\nAttention modules, as simple and e...   \n",
            "5  Abstract\\n\\nImitation learning is a popular ap...   \n",
            "\n",
            "                                                 url  similarity_score  rank  \n",
            "0  https://papers.nips.cc/paper/2020/hash/0060ef4...          0.965593   4.0  \n",
            "1                  https://papers.nips.cc/paper/2020          0.966477   1.0  \n",
            "2  https://papers.nips.cc/paper/2020/file/4956247...          0.965714   3.0  \n",
            "3  https://papers.nips.cc/paper/2020/file/8d30aa9...          0.963016   5.0  \n",
            "4  https://papers.nips.cc/paper/2020/file/bcff3f6...          0.962894   6.0  \n",
            "5  https://papers.nips.cc/paper/2020/file/9909794...          0.966408   2.0  \n",
            "0    Self-Supervised MultiModal Versatile Networks\\...\n",
            "1    Book\\n\\nDo not remove: This comment is monitor...\n",
            "2    Abstract\\n\\nWe present VILLA, the ﬁrst known e...\n",
            "3    Abstract\\n\\nTraining generative adversarial ne...\n",
            "4    Abstract\\n\\nAttention modules, as simple and e...\n",
            "5    Abstract\\n\\nImitation learning is a popular ap...\n",
            "Name: text, dtype: object\n",
            "Self-Supervised\n",
            "MultiModal\n",
            "Versatile\n",
            "Networks\n",
            "Part\n",
            "of\n",
            "Advances\n",
            "in\n",
            "Neural\n",
            "Information\n",
            "Processing\n",
            "Systems\n",
            "33\n",
            "(\n",
            "NeurIPS\n",
            "2020\n",
            ")\n",
            "Authors\n",
            "Jean-Baptiste\n",
            "Alayrac\n",
            ",\n",
            "Adria\n",
            "Recasens\n",
            ",\n",
            "Rosalia\n",
            "Schneider\n",
            ",\n",
            "Relja\n",
            "Arandjelović\n",
            ",\n",
            "Jason\n",
            "Ramapuram\n",
            ",\n",
            "Jeffrey\n",
            "De\n",
            "Fauw\n",
            ",\n",
            "Lucas\n",
            "Smaira\n",
            ",\n",
            "Sander\n",
            "Dieleman\n",
            ",\n",
            "Andrew\n",
            "Zisserman\n",
            "Abstract\n",
            "Videos\n",
            "are\n",
            "a\n",
            "rich\n",
            "source\n",
            "of\n",
            "multi-modal\n",
            "supervision\n",
            ".\n",
            "In\n",
            "this\n",
            "work\n",
            ",\n",
            "we\n",
            "learn\n",
            "representations\n",
            "using\n",
            "self-supervision\n",
            "by\n",
            "leveraging\n",
            "three\n",
            "modalities\n",
            "naturally\n",
            "present\n",
            "in\n",
            "videos\n",
            ":\n",
            "visual\n",
            ",\n",
            "audio\n",
            "and\n",
            "language\n",
            "streams\n",
            ".\n",
            "To\n",
            "this\n",
            "end\n",
            ",\n",
            "we\n",
            "introduce\n",
            "the\n",
            "notion\n",
            "of\n",
            "a\n",
            "multimodal\n",
            "versatile\n",
            "network\n",
            "--\n",
            "a\n",
            "network\n",
            "that\n",
            "can\n",
            "ingest\n",
            "multiple\n",
            "modalities\n",
            "and\n",
            "whose\n",
            "representations\n",
            "enable\n",
            "downstream\n",
            "tasks\n",
            "in\n",
            "multiple\n",
            "modalities\n",
            ".\n",
            "In\n",
            "particular\n",
            ",\n",
            "we\n",
            "explore\n",
            "how\n",
            "best\n",
            "to\n",
            "combine\n",
            "the\n",
            "modalities\n",
            ",\n",
            "such\n",
            "that\n",
            "fine-grained\n",
            "representations\n",
            "of\n",
            "the\n",
            "visual\n",
            "and\n",
            "audio\n",
            "modalities\n",
            "can\n",
            "be\n",
            "maintained\n",
            ",\n",
            "whilst\n",
            "also\n",
            "integrating\n",
            "text\n",
            "into\n",
            "a\n",
            "common\n",
            "embedding\n",
            ".\n",
            "Driven\n",
            "by\n",
            "versatility\n",
            ",\n",
            "we\n",
            "also\n",
            "introduce\n",
            "a\n",
            "novel\n",
            "process\n",
            "of\n",
            "deflation\n",
            ",\n",
            "so\n",
            "that\n",
            "the\n",
            "networks\n",
            "can\n",
            "be\n",
            "effortlessly\n",
            "applied\n",
            "to\n",
            "the\n",
            "visual\n",
            "data\n",
            "in\n",
            "the\n",
            "form\n",
            "of\n",
            "video\n",
            "or\n",
            "a\n",
            "static\n",
            "image\n",
            ".\n",
            "We\n",
            "demonstrate\n",
            "how\n",
            "such\n",
            "networks\n",
            "trained\n",
            "on\n",
            "large\n",
            "collections\n",
            "of\n",
            "unlabelled\n",
            "video\n",
            "data\n",
            "can\n",
            "be\n",
            "applied\n",
            "on\n",
            "video\n",
            ",\n",
            "video-text\n",
            ",\n",
            "image\n",
            "and\n",
            "audio\n",
            "tasks\n",
            ".\n",
            "Equipped\n",
            "with\n",
            "these\n",
            "representations\n",
            ",\n",
            "we\n",
            "obtain\n",
            "state-of-the-art\n",
            "performance\n",
            "on\n",
            "multiple\n",
            "challenging\n",
            "benchmarks\n",
            "including\n",
            "UCF101\n",
            ",\n",
            "HMDB51\n",
            ",\n",
            "Kinetics600\n",
            ",\n",
            "AudioSet\n",
            "and\n",
            "ESC-50\n",
            "when\n",
            "compared\n",
            "to\n",
            "previous\n",
            "self-supervised\n",
            "work\n",
            ".\n",
            "Our\n",
            "models\n",
            "are\n",
            "publicly\n",
            "available\n",
            ".\n",
            "Book\n",
            "Do\n",
            "not\n",
            "remove\n",
            ":\n",
            "This\n",
            "comment\n",
            "is\n",
            "monitored\n",
            "to\n",
            "verify\n",
            "that\n",
            "the\n",
            "site\n",
            "is\n",
            "working\n",
            "properly\n",
            "Abstract\n",
            "We\n",
            "present\n",
            "VILLA\n",
            ",\n",
            "the\n",
            "ﬁrst\n",
            "known\n",
            "effort\n",
            "on\n",
            "large-scale\n",
            "adversarial\n",
            "training\n",
            "for\n",
            "vision-and-language\n",
            "(\n",
            "V+L\n",
            ")\n",
            "representation\n",
            "learning\n",
            ".\n",
            "VILLA\n",
            "consists\n",
            "of\n",
            "two\n",
            "training\n",
            "stages\n",
            ":\n",
            "(\n",
            "i\n",
            ")\n",
            "task-agnostic\n",
            "adversarial\n",
            "pre-training\n",
            ";\n",
            "followed\n",
            "by\n",
            "(\n",
            "ii\n",
            ")\n",
            "task-speciﬁc\n",
            "adversarial\n",
            "ﬁnetuning\n",
            ".\n",
            "Instead\n",
            "of\n",
            "adding\n",
            "adversarial\n",
            "perturbations\n",
            "on\n",
            "image\n",
            "pixels\n",
            "and\n",
            "textual\n",
            "tokens\n",
            ",\n",
            "we\n",
            "propose\n",
            "to\n",
            "perform\n",
            "adversarial\n",
            "training\n",
            "in\n",
            "the\n",
            "embedding\n",
            "space\n",
            "of\n",
            "each\n",
            "modality\n",
            ".\n",
            "To\n",
            "enable\n",
            "large-scale\n",
            "training\n",
            ",\n",
            "we\n",
            "adopt\n",
            "the\n",
            "“\n",
            "free\n",
            "”\n",
            "adver-\n",
            "sarial\n",
            "training\n",
            "strategy\n",
            ",\n",
            "and\n",
            "combine\n",
            "it\n",
            "with\n",
            "KL-divergence-based\n",
            "regularization\n",
            "to\n",
            "promote\n",
            "higher\n",
            "invariance\n",
            "in\n",
            "the\n",
            "embedding\n",
            "space\n",
            ".\n",
            "We\n",
            "apply\n",
            "VILLA\n",
            "to\n",
            "current\n",
            "best-performing\n",
            "V+L\n",
            "models\n",
            ",\n",
            "and\n",
            "achieve\n",
            "new\n",
            "state\n",
            "of\n",
            "the\n",
            "art\n",
            "on\n",
            "a\n",
            "wide\n",
            "range\n",
            "of\n",
            "tasks\n",
            ",\n",
            "including\n",
            "Visual\n",
            "Question\n",
            "Answering\n",
            ",\n",
            "Visual\n",
            "Commonsense\n",
            "Reasoning\n",
            ",\n",
            "Image-Text\n",
            "Retrieval\n",
            ",\n",
            "Referring\n",
            "Expression\n",
            "Comprehension\n",
            ",\n",
            "Visual\n",
            "Entailment\n",
            ",\n",
            "and\n",
            "NLVR2.1\n",
            "1\n",
            "Abstract\n",
            "Training\n",
            "generative\n",
            "adversarial\n",
            "networks\n",
            "(\n",
            "GAN\n",
            ")\n",
            "using\n",
            "too\n",
            "little\n",
            "data\n",
            "typically\n",
            "leads\n",
            "to\n",
            "discriminator\n",
            "overﬁtting\n",
            ",\n",
            "causing\n",
            "training\n",
            "to\n",
            "diverge\n",
            ".\n",
            "We\n",
            "propose\n",
            "an\n",
            "adaptive\n",
            "discriminator\n",
            "augmentation\n",
            "mechanism\n",
            "that\n",
            "signiﬁcantly\n",
            "stabilizes\n",
            "training\n",
            "in\n",
            "limited\n",
            "data\n",
            "regimes\n",
            ".\n",
            "The\n",
            "approach\n",
            "does\n",
            "not\n",
            "require\n",
            "changes\n",
            "to\n",
            "loss\n",
            "functions\n",
            "or\n",
            "network\n",
            "architectures\n",
            ",\n",
            "and\n",
            "is\n",
            "applicable\n",
            "both\n",
            "when\n",
            "training\n",
            "from\n",
            "scratch\n",
            "and\n",
            "when\n",
            "ﬁne-tuning\n",
            "an\n",
            "existing\n",
            "GAN\n",
            "on\n",
            "another\n",
            "dataset\n",
            ".\n",
            "We\n",
            "demonstrate\n",
            ",\n",
            "on\n",
            "several\n",
            "datasets\n",
            ",\n",
            "that\n",
            "good\n",
            "results\n",
            "are\n",
            "now\n",
            "possible\n",
            "using\n",
            "only\n",
            "a\n",
            "few\n",
            "thousand\n",
            "training\n",
            "images\n",
            ",\n",
            "often\n",
            "matching\n",
            "StyleGAN2\n",
            "results\n",
            "with\n",
            "an\n",
            "order\n",
            "of\n",
            "magnitude\n",
            "fewer\n",
            "images\n",
            ".\n",
            "We\n",
            "expect\n",
            "this\n",
            "to\n",
            "open\n",
            "up\n",
            "new\n",
            "application\n",
            "domains\n",
            "for\n",
            "GANs\n",
            ".\n",
            "We\n",
            "also\n",
            "ﬁnd\n",
            "that\n",
            "the\n",
            "widely\n",
            "used\n",
            "CIFAR-10\n",
            "is\n",
            ",\n",
            "in\n",
            "fact\n",
            ",\n",
            "a\n",
            "limited\n",
            "data\n",
            "benchmark\n",
            ",\n",
            "and\n",
            "improve\n",
            "the\n",
            "record\n",
            "FID\n",
            "from\n",
            "5.59\n",
            "to\n",
            "2.42\n",
            ".\n",
            "1\n",
            "Abstract\n",
            "Attention\n",
            "modules\n",
            ",\n",
            "as\n",
            "simple\n",
            "and\n",
            "effective\n",
            "tools\n",
            ",\n",
            "have\n",
            "not\n",
            "only\n",
            "enabled\n",
            "deep\n",
            "neural\n",
            "networks\n",
            "to\n",
            "achieve\n",
            "state-of-the-art\n",
            "results\n",
            "in\n",
            "many\n",
            "domains\n",
            ",\n",
            "but\n",
            "also\n",
            "enhanced\n",
            "their\n",
            "interpretability\n",
            ".\n",
            "Most\n",
            "current\n",
            "models\n",
            "use\n",
            "deterministic\n",
            "attention\n",
            "modules\n",
            "due\n",
            "to\n",
            "their\n",
            "simplicity\n",
            "and\n",
            "ease\n",
            "of\n",
            "optimization\n",
            ".\n",
            "Stochastic\n",
            "counterparts\n",
            ",\n",
            "on\n",
            "the\n",
            "other\n",
            "hand\n",
            ",\n",
            "are\n",
            "less\n",
            "popular\n",
            "despite\n",
            "their\n",
            "potential\n",
            "beneﬁts\n",
            ".\n",
            "The\n",
            "main\n",
            "reason\n",
            "is\n",
            "that\n",
            "stochastic\n",
            "attention\n",
            "often\n",
            "introduces\n",
            "optimization\n",
            "issues\n",
            "or\n",
            "requires\n",
            "signiﬁcant\n",
            "model\n",
            "changes\n",
            ".\n",
            "In\n",
            "this\n",
            "paper\n",
            ",\n",
            "we\n",
            "propose\n",
            "a\n",
            "scalable\n",
            "stochastic\n",
            "version\n",
            "of\n",
            "attention\n",
            "that\n",
            "is\n",
            "easy\n",
            "to\n",
            "implement\n",
            "and\n",
            "optimize\n",
            ".\n",
            "We\n",
            "construct\n",
            "simplex-constrained\n",
            "attention\n",
            "distributions\n",
            "by\n",
            "normalizing\n",
            "reparameterizable\n",
            "distributions\n",
            ",\n",
            "making\n",
            "the\n",
            "training\n",
            "process\n",
            "differentiable\n",
            ".\n",
            "We\n",
            "learn\n",
            "their\n",
            "parameters\n",
            "in\n",
            "a\n",
            "Bayesian\n",
            "framework\n",
            "where\n",
            "a\n",
            "data-dependent\n",
            "prior\n",
            "is\n",
            "introduced\n",
            "for\n",
            "regularization\n",
            ".\n",
            "We\n",
            "apply\n",
            "the\n",
            "proposed\n",
            "stochastic\n",
            "attention\n",
            "modules\n",
            "to\n",
            "various\n",
            "attention-based\n",
            "models\n",
            ",\n",
            "with\n",
            "applications\n",
            "to\n",
            "graph\n",
            "node\n",
            "classiﬁcation\n",
            ",\n",
            "visual\n",
            "question\n",
            "answering\n",
            ",\n",
            "image\n",
            "captioning\n",
            ",\n",
            "machine\n",
            "translation\n",
            ",\n",
            "and\n",
            "language\n",
            "understanding\n",
            ".\n",
            "Our\n",
            "experiments\n",
            "show\n",
            "the\n",
            "proposed\n",
            "method\n",
            "brings\n",
            "consistent\n",
            "improvements\n",
            "over\n",
            "the\n",
            "corresponding\n",
            "baselines\n",
            ".\n",
            "1\n",
            "Abstract\n",
            "Imitation\n",
            "learning\n",
            "is\n",
            "a\n",
            "popular\n",
            "approach\n",
            "for\n",
            "teaching\n",
            "motor\n",
            "skills\n",
            "to\n",
            "robots\n",
            ".\n",
            "How-\n",
            "ever\n",
            ",\n",
            "most\n",
            "approaches\n",
            "focus\n",
            "on\n",
            "extracting\n",
            "policy\n",
            "parameters\n",
            "from\n",
            "execution\n",
            "traces\n",
            "alone\n",
            "(\n",
            "i.e.\n",
            ",\n",
            "motion\n",
            "trajectories\n",
            "and\n",
            "perceptual\n",
            "data\n",
            ")\n",
            ".\n",
            "No\n",
            "adequate\n",
            "communication\n",
            "channel\n",
            "exists\n",
            "between\n",
            "the\n",
            "human\n",
            "expert\n",
            "and\n",
            "the\n",
            "robot\n",
            "to\n",
            "describe\n",
            "critical\n",
            "aspects\n",
            "of\n",
            "the\n",
            "task\n",
            ",\n",
            "such\n",
            "as\n",
            "the\n",
            "properties\n",
            "of\n",
            "the\n",
            "target\n",
            "object\n",
            "or\n",
            "the\n",
            "intended\n",
            "shape\n",
            "of\n",
            "the\n",
            "motion\n",
            ".\n",
            "Motivated\n",
            "by\n",
            "insights\n",
            "into\n",
            "the\n",
            "human\n",
            "teaching\n",
            "process\n",
            ",\n",
            "we\n",
            "introduce\n",
            "a\n",
            "method\n",
            "for\n",
            "incorporating\n",
            "unstructured\n",
            "natural\n",
            "language\n",
            "into\n",
            "imitation\n",
            "learning\n",
            ".\n",
            "At\n",
            "training\n",
            "time\n",
            ",\n",
            "the\n",
            "expert\n",
            "can\n",
            "provide\n",
            "demonstrations\n",
            "along\n",
            "with\n",
            "verbal\n",
            "descriptions\n",
            "in\n",
            "order\n",
            "to\n",
            "describe\n",
            "the\n",
            "underlying\n",
            "intent\n",
            "(\n",
            "e.g.\n",
            ",\n",
            "“\n",
            "go\n",
            "to\n",
            "the\n",
            "large\n",
            "green\n",
            "bowl\n",
            "”\n",
            ")\n",
            ".\n",
            "The\n",
            "training\n",
            "process\n",
            "then\n",
            "interrelates\n",
            "these\n",
            "two\n",
            "modalities\n",
            "to\n",
            "encode\n",
            "the\n",
            "correlations\n",
            "between\n",
            "language\n",
            ",\n",
            "perception\n",
            ",\n",
            "and\n",
            "motion\n",
            ".\n",
            "The\n",
            "resulting\n",
            "language-conditioned\n",
            "visuomotor\n",
            "policies\n",
            "can\n",
            "be\n",
            "conditioned\n",
            "at\n",
            "runtime\n",
            "on\n",
            "new\n",
            "human\n",
            "commands\n",
            "and\n",
            "instructions\n",
            ",\n",
            "which\n",
            "allows\n",
            "for\n",
            "more\n",
            "ﬁne-grained\n",
            "control\n",
            "over\n",
            "the\n",
            "trained\n",
            "policies\n",
            "while\n",
            "also\n",
            "reducing\n",
            "situational\n",
            "ambiguity\n",
            ".\n",
            "We\n",
            "demonstrate\n",
            "in\n",
            "a\n",
            "set\n",
            "of\n",
            "simulation\n",
            "experiments\n",
            "how\n",
            "our\n",
            "approach\n",
            "can\n",
            "learn\n",
            "language-conditioned\n",
            "manipulation\n",
            "poli-\n",
            "cies\n",
            "for\n",
            "a\n",
            "seven-degree-of-freedom\n",
            "robot\n",
            "arm\n",
            "and\n",
            "compare\n",
            "the\n",
            "results\n",
            "to\n",
            "a\n",
            "variety\n",
            "of\n",
            "alternative\n",
            "methods\n",
            ".\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "df_output                                                topic  \\\n",
            "0                                            neurips   \n",
            "1                                            neurips   \n",
            "2                                            neurips   \n",
            "3                                            neurips   \n",
            "4                                            neurips   \n",
            "5                                            neurips   \n",
            "6                                            neurips   \n",
            "7                                            neurips   \n",
            "8                                            neurips   \n",
            "9                                            neurips   \n",
            "0  unsupervised information theoretic perceptual ...   \n",
            "1  unsupervised information theoretic perceptual ...   \n",
            "2  unsupervised information theoretic perceptual ...   \n",
            "3  unsupervised information theoretic perceptual ...   \n",
            "4  unsupervised information theoretic perceptual ...   \n",
            "5  unsupervised information theoretic perceptual ...   \n",
            "6  unsupervised information theoretic perceptual ...   \n",
            "7  unsupervised information theoretic perceptual ...   \n",
            "8  unsupervised information theoretic perceptual ...   \n",
            "9  unsupervised information theoretic perceptual ...   \n",
            "0  self supervised multimodal versatile networks ...   \n",
            "1  self supervised multimodal versatile networks ...   \n",
            "2  self supervised multimodal versatile networks ...   \n",
            "3  self supervised multimodal versatile networks ...   \n",
            "4  self supervised multimodal versatile networks ...   \n",
            "5  self supervised multimodal versatile networks ...   \n",
            "\n",
            "                                               title  \\\n",
            "0  Training Generative Adversarial Networks with ...   \n",
            "1  Estimating Training Data Influence by Tracing ...   \n",
            "2                         Deep Evidential Regression   \n",
            "3  Information Theoretic Regret Bounds for Online...   \n",
            "4           Universally Quantized Neural Compression   \n",
            "5  Advances in Neural Information Processing Syst...   \n",
            "6      Graph Contrastive Learning with Augmentations   \n",
            "7  Efficient Exact Verification of Binarized Neur...   \n",
            "8  Path Sample-Analytic Gradient Estimators for S...   \n",
            "9                           Deep Archimedean Copulas   \n",
            "0  An Unsupervised Information-Theoretic Perceptu...   \n",
            "1  An Unsupervised Information-Theoretic ... - Re...   \n",
            "2  An Unsupervised Information-Theoretic ... - Re...   \n",
            "3  Advances in Neural Information Processing Syst...   \n",
            "4  Neural FFTs for Universal Texture Image Synthesis   \n",
            "5        Object-Centric Learning with Slot Attention   \n",
            "6  Self-supervised learning through the eyes of a...   \n",
            "7  Robust Compressed Sensing using Generative Models   \n",
            "8  Network-to-Network Translation with Conditiona...   \n",
            "9  Functional Regularization for Representation L...   \n",
            "0      Self-Supervised MultiModal Versatile Networks   \n",
            "1  Advances in Neural Information Processing Syst...   \n",
            "2  Large-Scale Adversarial Training for Vision-an...   \n",
            "3  Training Generative Adversarial Networks with ...   \n",
            "4                         Bayesian Attention Modules   \n",
            "5  Language-Conditioned Imitation Learning for Ro...   \n",
            "\n",
            "                                                text  \\\n",
            "0  Training Generative Adversarial Networks with ...   \n",
            "1  Estimating Training Data Influence by Tracing ...   \n",
            "2  Deep Evidential Regression\\n\\nPart of Advances...   \n",
            "3  Information Theoretic Regret Bounds for Online...   \n",
            "4  Universally Quantized Neural Compression\\n\\nPa...   \n",
            "5  Book\\n\\nDo not remove: This comment is monitor...   \n",
            "6  Graph Contrastive Learning with Augmentations\\...   \n",
            "7  Efficient Exact Verification of Binarized Neur...   \n",
            "8  Path Sample-Analytic Gradient Estimators for S...   \n",
            "9  Deep Archimedean Copulas\\n\\nPart of Advances i...   \n",
            "0  An Unsupervised Information-Theoretic Perceptu...   \n",
            "1  NeurIPS 2020\\n\\nAn Unsupervised Information-Th...   \n",
            "2  NeurIPS 2020\\n\\nAn Unsupervised Information-Th...   \n",
            "3  Book\\n\\nDo not remove: This comment is monitor...   \n",
            "4  Abstract\\n\\nSynthesizing larger texture images...   \n",
            "5  Abstract\\n\\nLearning object-centric representa...   \n",
            "6  Abstract\\n\\nWithin months of birth, children d...   \n",
            "7  Abstract\\n\\nThe goal of compressed sensing is ...   \n",
            "8  Abstract\\n\\nGiven the ever-increasing computat...   \n",
            "9  Abstract\\n\\nUnsupervised and self-supervised l...   \n",
            "0  Self-Supervised MultiModal Versatile Networks\\...   \n",
            "1  Book\\n\\nDo not remove: This comment is monitor...   \n",
            "2  Abstract\\n\\nWe present VILLA, the ﬁrst known e...   \n",
            "3  Abstract\\n\\nTraining generative adversarial ne...   \n",
            "4  Abstract\\n\\nAttention modules, as simple and e...   \n",
            "5  Abstract\\n\\nImitation learning is a popular ap...   \n",
            "\n",
            "                                                 url  similarity_score  rank  \\\n",
            "0  https://papers.nips.cc/paper/2020/hash/8d30aa9...          0.965153   3.0   \n",
            "1  https://papers.nips.cc/paper/2020/hash/e6385d3...          0.965144   4.0   \n",
            "2  https://papers.nips.cc/paper/2020/hash/aab0854...          0.965102   6.0   \n",
            "3  https://papers.nips.cc/paper/2020/hash/aee5620...          0.965130   5.0   \n",
            "4  https://papers.nips.cc/paper/2020/hash/92049de...          0.965285   2.0   \n",
            "5                  https://papers.nips.cc/paper/2020          0.965377   1.0   \n",
            "6  https://papers.nips.cc/paper/2020/hash/3fe2303...          0.960548  10.0   \n",
            "7  https://papers.nips.cc/paper/2020/hash/1385974...          0.962081   7.0   \n",
            "8  https://papers.nips.cc/paper/2020/hash/96fca94...          0.961407   9.0   \n",
            "9  https://papers.nips.cc/paper/2020/hash/10eb650...          0.961599   8.0   \n",
            "0  https://papers.nips.cc/paper/2020/hash/00482b9...          0.960361   6.0   \n",
            "1  https://papers.nips.cc/paper/2020/file/00482b9...          0.940551  10.0   \n",
            "2  https://papers.nips.cc/paper/2020/file/00482b9...          0.960248   8.0   \n",
            "3                  https://papers.nips.cc/paper/2020          0.964870   1.0   \n",
            "4  https://papers.nips.cc/paper/2020/file/a23156a...          0.960257   7.0   \n",
            "5  https://papers.nips.cc/paper/2020/file/8511df9...          0.959921   9.0   \n",
            "6  https://papers.nips.cc/paper/2020/file/7183145...          0.964294   2.0   \n",
            "7  https://papers.nips.cc/paper/2020/file/07cb5f8...          0.963900   3.0   \n",
            "8  https://papers.nips.cc/paper/2020/file/1cfa81a...          0.963835   4.0   \n",
            "9  https://papers.nips.cc/paper/2020/file/c793b3b...          0.961062   5.0   \n",
            "0  https://papers.nips.cc/paper/2020/hash/0060ef4...          0.965593   4.0   \n",
            "1                  https://papers.nips.cc/paper/2020          0.966477   1.0   \n",
            "2  https://papers.nips.cc/paper/2020/file/4956247...          0.965714   3.0   \n",
            "3  https://papers.nips.cc/paper/2020/file/8d30aa9...          0.963016   5.0   \n",
            "4  https://papers.nips.cc/paper/2020/file/bcff3f6...          0.962894   6.0   \n",
            "5  https://papers.nips.cc/paper/2020/file/9909794...          0.966408   2.0   \n",
            "\n",
            "   similarity_score_lda  rank_lda  \n",
            "0              0.976416       8.0  \n",
            "1              0.976422       7.0  \n",
            "2              0.976501       5.0  \n",
            "3              0.976803       3.0  \n",
            "4              0.976386       9.0  \n",
            "5              0.976283      10.0  \n",
            "6              0.977023       1.0  \n",
            "7              0.976987       2.0  \n",
            "8              0.976438       6.0  \n",
            "9              0.976682       4.0  \n",
            "0              0.976147       8.0  \n",
            "1              0.975887       9.0  \n",
            "2              0.976883       2.0  \n",
            "3              0.976728       5.0  \n",
            "4              0.975769      10.0  \n",
            "5              0.976862       3.0  \n",
            "6              0.976213       7.0  \n",
            "7              0.977043       1.0  \n",
            "8              0.976403       6.0  \n",
            "9              0.976810       4.0  \n",
            "0              0.977262       6.0  \n",
            "1              0.978460       1.0  \n",
            "2              0.978236       4.0  \n",
            "3              0.977762       5.0  \n",
            "4              0.978310       2.0  \n",
            "5              0.978285       3.0  \n",
            "topic:  benchmarking deep inverse models time neural adjoint method neurips id_= 3\n",
            "1 . Benchmarking Deep Inverse Models over time, and the Neural ... https://papers.nips.cc/paper/2020/hash/007ff380ee5ac49ffc34442f5c2a2b86-Abstract.html\n",
            "**********************************************\n",
            "2 . Benchmarking Deep Inverse Models ... - Review for NeurIPS paper https://papers.nips.cc/paper/2020/file/007ff380ee5ac49ffc34442f5c2a2b86-Review.html\n",
            "**********************************************\n",
            "3 . Benchmarking Deep Inverse Models ... - Review for NeurIPS paper https://papers.nips.cc/paper/2020/file/007ff380ee5ac49ffc34442f5c2a2b86-MetaReview.html\n",
            "**********************************************\n",
            "4 . Supplementary material: Benchmarking Deep Inverse Models over ... https://papers.nips.cc/paper/2020/file/007ff380ee5ac49ffc34442f5c2a2b86-Supplemental.pdf\n",
            "example.pdf\n",
            "No Text\n",
            "4 . Advances in Neural Information Processing Systems 33 (NeurIPS ... https://papers.nips.cc/paper/2020\n",
            "**********************************************\n",
            "5 . Author Response for Paper 6449 We thank the reviewers for their ... https://papers.nips.cc/paper/2020/file/007ff380ee5ac49ffc34442f5c2a2b86-AuthorFeedback.pdf\n",
            "example.pdf\n",
            "No Text\n",
            "5 . On Second Order Behaviour in Augmented Neural ODEs https://papers.nips.cc/paper/2020/file/418db2ea5d227a9ea8db8e5357ca2084-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Neural Ordinary Differential Equations (NODEs) are a new class of models that\n",
            "transform data continuously through inﬁnite-depth architectures. The continuous\n",
            "nature of NODEs has made them particularly suitable for learning the dynamics\n",
            "of complex physical systems. While previous work has mostly been focused on\n",
            "ﬁrst order ODEs, the dynamics of many systems, especially in classical physics,\n",
            "are governed by second order laws. In this work, we consider Second Order\n",
            "Neural ODEs (SONODEs). We show how the adjoint sensitivity method can be\n",
            "extended to SONODEs and prove that the optimisation of a ﬁrst order coupled\n",
            "ODE is equivalent and computationally more efﬁcient. Furthermore, we extend the\n",
            "theoretical understanding of the broader class of Augmented NODEs (ANODEs)\n",
            "by showing they can also learn higher order dynamics with a minimal number\n",
            "of augmented dimensions, but at the cost of interpretability. This indicates that\n",
            "the advantages of ANODEs go beyond the extra space offered by the augmented\n",
            "dimensions, as originally thought. Finally, we compare SONODEs and ANODEs\n",
            "on synthetic and real dynamical systems and demonstrate that the inductive biases\n",
            "of the former generally result in faster training and better performance.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "6 . Supplemental https://papers.nips.cc/paper/2020/file/766d856ef1a6b02f93d894415e6bfa0e-Supplemental.pdf\n",
            "example.pdf\n",
            "No Text\n",
            "6 . A Flexible Framework for Designing Trainable Priors with Adaptive ... https://papers.nips.cc/paper/2020/file/b4edda67f0f57e218a8e766927e3e5c5-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "We introduce a general framework for designing and training neural network\n",
            "layers whose forward passes can be interpreted as solving non-smooth convex\n",
            "optimization problems, and whose architectures are derived from an optimization\n",
            "algorithm. We focus on convex games, solved by local agents represented by the\n",
            "nodes of a graph and interacting through regularization functions. This approach\n",
            "is appealing for solving imaging problems, as it allows the use of classical image\n",
            "priors within deep models that are trainable end to end. The priors used in this\n",
            "presentation include variants of total variation, Laplacian regularization, bilateral\n",
            "ﬁltering, sparse coding on learned dictionaries, and non-local self similarities.\n",
            "Our models are fully interpretable as well as parameter and data efﬁcient. Our\n",
            "experiments demonstrate their effectiveness on a large diversity of tasks ranging\n",
            "from image denoising and compressed sensing for fMRI to dense stereo matching.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "7 . JAX, M.D. https://papers.nips.cc/paper/2020/file/83d3d4b6c9579515e1679aca8cbc8033-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "We introduce JAX MD, a software package for performing differentiable physics\n",
            "simulations with a focus on molecular dynamics. JAX MD includes a number\n",
            "of physics simulation environments, as well as interaction potentials and neural\n",
            "networks that can be integrated into these environments without writing any addi-\n",
            "tional code. Since the simulations themselves are differentiable functions, entire\n",
            "trajectories can be differentiated to perform meta-optimization. These features are\n",
            "built on primitive operations, such as spatial partitioning, that allow simulations to\n",
            "scale to hundreds-of-thousands of particles on a single GPU. These primitives are\n",
            "ﬂexible enough that they can be used to scale up workloads outside of molecular\n",
            "dynamics. We present several examples that highlight the features of JAX MD\n",
            "including: integration of graph neural networks into traditional simulations, meta-\n",
            "optimization through minimization of particle packings, and a multi-agent ﬂocking\n",
            "simulation. JAX MD is available at www.github.com/google/jax-md.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "data:                                                topic  \\\n",
            "0  benchmarking deep inverse models time neural a...   \n",
            "1  benchmarking deep inverse models time neural a...   \n",
            "2  benchmarking deep inverse models time neural a...   \n",
            "3  benchmarking deep inverse models time neural a...   \n",
            "4  benchmarking deep inverse models time neural a...   \n",
            "5  benchmarking deep inverse models time neural a...   \n",
            "6  benchmarking deep inverse models time neural a...   \n",
            "\n",
            "                                               title  \\\n",
            "0  Benchmarking Deep Inverse Models over time, an...   \n",
            "1  Benchmarking Deep Inverse Models ... - Review ...   \n",
            "2  Benchmarking Deep Inverse Models ... - Review ...   \n",
            "3  Advances in Neural Information Processing Syst...   \n",
            "4  On Second Order Behaviour in Augmented Neural ...   \n",
            "5  A Flexible Framework for Designing Trainable P...   \n",
            "6                                          JAX, M.D.   \n",
            "\n",
            "                                                text  \\\n",
            "0  Benchmarking Deep Inverse Models over time, an...   \n",
            "1  NeurIPS 2020\\n\\nBenchmarking Deep Inverse Mode...   \n",
            "2  NeurIPS 2020\\n\\nBenchmarking Deep Inverse Mode...   \n",
            "3  Book\\n\\nDo not remove: This comment is monitor...   \n",
            "4  Abstract\\n\\nNeural Ordinary Differential Equat...   \n",
            "5  Abstract\\n\\nWe introduce a general framework f...   \n",
            "6  Abstract\\n\\nWe introduce JAX MD, a software pa...   \n",
            "\n",
            "                                                 url  \n",
            "0  https://papers.nips.cc/paper/2020/hash/007ff38...  \n",
            "1  https://papers.nips.cc/paper/2020/file/007ff38...  \n",
            "2  https://papers.nips.cc/paper/2020/file/007ff38...  \n",
            "3                  https://papers.nips.cc/paper/2020  \n",
            "4  https://papers.nips.cc/paper/2020/file/418db2e...  \n",
            "5  https://papers.nips.cc/paper/2020/file/b4edda6...  \n",
            "6  https://papers.nips.cc/paper/2020/file/83d3d4b...  \n",
            "**********************************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                                               topic  \\\n",
            "0  benchmarking deep inverse models time neural a...   \n",
            "1  benchmarking deep inverse models time neural a...   \n",
            "2  benchmarking deep inverse models time neural a...   \n",
            "3  benchmarking deep inverse models time neural a...   \n",
            "4  benchmarking deep inverse models time neural a...   \n",
            "5  benchmarking deep inverse models time neural a...   \n",
            "6  benchmarking deep inverse models time neural a...   \n",
            "\n",
            "                                               title  \\\n",
            "0  Benchmarking Deep Inverse Models over time, an...   \n",
            "1  Benchmarking Deep Inverse Models ... - Review ...   \n",
            "2  Benchmarking Deep Inverse Models ... - Review ...   \n",
            "3  Advances in Neural Information Processing Syst...   \n",
            "4  On Second Order Behaviour in Augmented Neural ...   \n",
            "5  A Flexible Framework for Designing Trainable P...   \n",
            "6                                          JAX, M.D.   \n",
            "\n",
            "                                                text  \\\n",
            "0  Benchmarking Deep Inverse Models over time, an...   \n",
            "1  NeurIPS 2020\\n\\nBenchmarking Deep Inverse Mode...   \n",
            "2  NeurIPS 2020\\n\\nBenchmarking Deep Inverse Mode...   \n",
            "3  Book\\n\\nDo not remove: This comment is monitor...   \n",
            "4  Abstract\\n\\nNeural Ordinary Differential Equat...   \n",
            "5  Abstract\\n\\nWe introduce a general framework f...   \n",
            "6  Abstract\\n\\nWe introduce JAX MD, a software pa...   \n",
            "\n",
            "                                                 url  similarity_score  \n",
            "0  https://papers.nips.cc/paper/2020/hash/007ff38...          0.961588  \n",
            "1  https://papers.nips.cc/paper/2020/file/007ff38...          0.966438  \n",
            "2  https://papers.nips.cc/paper/2020/file/007ff38...          0.966165  \n",
            "3                  https://papers.nips.cc/paper/2020          0.965975  \n",
            "4  https://papers.nips.cc/paper/2020/file/418db2e...          0.961224  \n",
            "5  https://papers.nips.cc/paper/2020/file/b4edda6...          0.962293  \n",
            "6  https://papers.nips.cc/paper/2020/file/83d3d4b...          0.966740  \n",
            "df_final after rank=                                                topic  \\\n",
            "0  benchmarking deep inverse models time neural a...   \n",
            "1  benchmarking deep inverse models time neural a...   \n",
            "2  benchmarking deep inverse models time neural a...   \n",
            "3  benchmarking deep inverse models time neural a...   \n",
            "4  benchmarking deep inverse models time neural a...   \n",
            "5  benchmarking deep inverse models time neural a...   \n",
            "6  benchmarking deep inverse models time neural a...   \n",
            "\n",
            "                                               title  \\\n",
            "0  Benchmarking Deep Inverse Models over time, an...   \n",
            "1  Benchmarking Deep Inverse Models ... - Review ...   \n",
            "2  Benchmarking Deep Inverse Models ... - Review ...   \n",
            "3  Advances in Neural Information Processing Syst...   \n",
            "4  On Second Order Behaviour in Augmented Neural ...   \n",
            "5  A Flexible Framework for Designing Trainable P...   \n",
            "6                                          JAX, M.D.   \n",
            "\n",
            "                                                text  \\\n",
            "0  Benchmarking Deep Inverse Models over time, an...   \n",
            "1  NeurIPS 2020\\n\\nBenchmarking Deep Inverse Mode...   \n",
            "2  NeurIPS 2020\\n\\nBenchmarking Deep Inverse Mode...   \n",
            "3  Book\\n\\nDo not remove: This comment is monitor...   \n",
            "4  Abstract\\n\\nNeural Ordinary Differential Equat...   \n",
            "5  Abstract\\n\\nWe introduce a general framework f...   \n",
            "6  Abstract\\n\\nWe introduce JAX MD, a software pa...   \n",
            "\n",
            "                                                 url  similarity_score  rank  \n",
            "0  https://papers.nips.cc/paper/2020/hash/007ff38...          0.961588   6.0  \n",
            "1  https://papers.nips.cc/paper/2020/file/007ff38...          0.966438   2.0  \n",
            "2  https://papers.nips.cc/paper/2020/file/007ff38...          0.966165   3.0  \n",
            "3                  https://papers.nips.cc/paper/2020          0.965975   4.0  \n",
            "4  https://papers.nips.cc/paper/2020/file/418db2e...          0.961224   7.0  \n",
            "5  https://papers.nips.cc/paper/2020/file/b4edda6...          0.962293   5.0  \n",
            "6  https://papers.nips.cc/paper/2020/file/83d3d4b...          0.966740   1.0  \n",
            "0    Benchmarking Deep Inverse Models over time, an...\n",
            "1    NeurIPS 2020\\n\\nBenchmarking Deep Inverse Mode...\n",
            "2    NeurIPS 2020\\n\\nBenchmarking Deep Inverse Mode...\n",
            "3    Book\\n\\nDo not remove: This comment is monitor...\n",
            "4    Abstract\\n\\nNeural Ordinary Differential Equat...\n",
            "5    Abstract\\n\\nWe introduce a general framework f...\n",
            "6    Abstract\\n\\nWe introduce JAX MD, a software pa...\n",
            "Name: text, dtype: object\n",
            "Benchmarking\n",
            "Deep\n",
            "Inverse\n",
            "Models\n",
            "over\n",
            "time\n",
            ",\n",
            "and\n",
            "the\n",
            "Neural-Adjoint\n",
            "method\n",
            "Part\n",
            "of\n",
            "Advances\n",
            "in\n",
            "Neural\n",
            "Information\n",
            "Processing\n",
            "Systems\n",
            "33\n",
            "(\n",
            "NeurIPS\n",
            "2020\n",
            ")\n",
            "Authors\n",
            "Simiao\n",
            "Ren\n",
            ",\n",
            "Willie\n",
            "Padilla\n",
            ",\n",
            "Jordan\n",
            "Malof\n",
            "Abstract\n",
            "We\n",
            "consider\n",
            "the\n",
            "task\n",
            "of\n",
            "solving\n",
            "generic\n",
            "inverse\n",
            "problems\n",
            ",\n",
            "where\n",
            "one\n",
            "wishes\n",
            "to\n",
            "determine\n",
            "the\n",
            "hidden\n",
            "parameters\n",
            "of\n",
            "a\n",
            "natural\n",
            "system\n",
            "that\n",
            "will\n",
            "give\n",
            "rise\n",
            "to\n",
            "a\n",
            "particular\n",
            "set\n",
            "of\n",
            "measurements\n",
            ".\n",
            "Recently\n",
            "many\n",
            "new\n",
            "approaches\n",
            "based\n",
            "upon\n",
            "deep\n",
            "learning\n",
            "have\n",
            "arisen\n",
            ",\n",
            "generating\n",
            "promising\n",
            "results\n",
            ".\n",
            "We\n",
            "conceptualize\n",
            "these\n",
            "models\n",
            "as\n",
            "different\n",
            "schemes\n",
            "for\n",
            "efficiently\n",
            ",\n",
            "but\n",
            "randomly\n",
            ",\n",
            "exploring\n",
            "the\n",
            "space\n",
            "of\n",
            "possible\n",
            "inverse\n",
            "solutions\n",
            ".\n",
            "As\n",
            "a\n",
            "result\n",
            ",\n",
            "the\n",
            "accuracy\n",
            "of\n",
            "each\n",
            "approach\n",
            "should\n",
            "be\n",
            "evaluated\n",
            "as\n",
            "a\n",
            "function\n",
            "of\n",
            "time\n",
            "rather\n",
            "than\n",
            "a\n",
            "single\n",
            "estimated\n",
            "solution\n",
            ",\n",
            "as\n",
            "is\n",
            "often\n",
            "done\n",
            "now\n",
            ".\n",
            "Using\n",
            "this\n",
            "metric\n",
            ",\n",
            "we\n",
            "compare\n",
            "several\n",
            "state-of-the-art\n",
            "inverse\n",
            "modeling\n",
            "approaches\n",
            "on\n",
            "four\n",
            "benchmark\n",
            "tasks\n",
            ":\n",
            "two\n",
            "existing\n",
            "tasks\n",
            ",\n",
            "a\n",
            "new\n",
            "2-dimensional\n",
            "sinusoid\n",
            "task\n",
            ",\n",
            "and\n",
            "a\n",
            "challenging\n",
            "modern\n",
            "task\n",
            "of\n",
            "meta-material\n",
            "design\n",
            ".\n",
            "Finally\n",
            ",\n",
            "inspired\n",
            "by\n",
            "our\n",
            "conception\n",
            "of\n",
            "the\n",
            "inverse\n",
            "problem\n",
            ",\n",
            "we\n",
            "explore\n",
            "a\n",
            "simple\n",
            "solution\n",
            "that\n",
            "uses\n",
            "a\n",
            "deep\n",
            "neural\n",
            "network\n",
            "as\n",
            "a\n",
            "surrogate\n",
            "(\n",
            "i.e.\n",
            ",\n",
            "approximation\n",
            ")\n",
            "for\n",
            "the\n",
            "forward\n",
            "model\n",
            ",\n",
            "and\n",
            "then\n",
            "uses\n",
            "backpropagation\n",
            "with\n",
            "respect\n",
            "to\n",
            "the\n",
            "model\n",
            "input\n",
            "to\n",
            "search\n",
            "for\n",
            "good\n",
            "inverse\n",
            "solutions\n",
            ".\n",
            "Variations\n",
            "of\n",
            "this\n",
            "approach\n",
            "-\n",
            "which\n",
            "we\n",
            "term\n",
            "the\n",
            "neural\n",
            "adjoint\n",
            "(\n",
            "NA\n",
            ")\n",
            "-\n",
            "have\n",
            "been\n",
            "explored\n",
            "recently\n",
            "on\n",
            "specific\n",
            "problems\n",
            ",\n",
            "and\n",
            "here\n",
            "we\n",
            "evaluate\n",
            "it\n",
            "comprehensively\n",
            "on\n",
            "our\n",
            "benchmark\n",
            ".\n",
            "We\n",
            "find\n",
            "that\n",
            "the\n",
            "addition\n",
            "of\n",
            "a\n",
            "simple\n",
            "novel\n",
            "loss\n",
            "term\n",
            "-\n",
            "which\n",
            "we\n",
            "term\n",
            "the\n",
            "boundary\n",
            "loss\n",
            "-\n",
            "dramatically\n",
            "improves\n",
            "the\n",
            "NA\n",
            "’\n",
            "s\n",
            "performance\n",
            ",\n",
            "and\n",
            "it\n",
            "consequentially\n",
            "achieves\n",
            "the\n",
            "best\n",
            "(\n",
            "or\n",
            "nearly\n",
            "best\n",
            ")\n",
            "performance\n",
            "in\n",
            "all\n",
            "of\n",
            "our\n",
            "benchmark\n",
            "scenarios\n",
            ".\n",
            "NeurIPS\n",
            "2020\n",
            "Benchmarking\n",
            "Deep\n",
            "Inverse\n",
            "Models\n",
            "over\n",
            "time\n",
            ",\n",
            "and\n",
            "the\n",
            "Neural-Adjoint\n",
            "method\n",
            "Review\n",
            "1\n",
            "Summary\n",
            "and\n",
            "Contributions\n",
            ":\n",
            "The\n",
            "paper\n",
            "considers\n",
            "deep\n",
            "learning\n",
            "for\n",
            "solving\n",
            "inverse\n",
            "problems\n",
            ".\n",
            "It\n",
            "compares\n",
            "existing\n",
            "approaches\n",
            "on\n",
            "several\n",
            "benchmark\n",
            "tasks\n",
            ",\n",
            "including\n",
            "one\n",
            "for\n",
            "metamaterial\n",
            "design\n",
            ".\n",
            "The\n",
            "paper\n",
            "proposes\n",
            "a\n",
            "``\n",
            "neural-adjoint\n",
            "''\n",
            "method\n",
            "which\n",
            "``\n",
            "uses\n",
            "a\n",
            "deep\n",
            "learning\n",
            "model\n",
            "to\n",
            "approximate\n",
            "the\n",
            "forward\n",
            "model\n",
            ",\n",
            "then\n",
            "uses\n",
            "backpropogation\n",
            "to\n",
            "search\n",
            "for\n",
            "good\n",
            "inverse\n",
            "solutions\n",
            "''\n",
            ".\n",
            "This\n",
            "method\n",
            "is\n",
            "demonstrated\n",
            "to\n",
            "have\n",
            "best\n",
            "or\n",
            "best-equal\n",
            "performance\n",
            "on\n",
            "most\n",
            "tasks\n",
            "as\n",
            "a\n",
            "function\n",
            "of\n",
            "number\n",
            "of\n",
            "inferences\n",
            ",\n",
            "at\n",
            "the\n",
            "cost\n",
            "of\n",
            "increased\n",
            "time\n",
            "per\n",
            "inference\n",
            ".\n",
            "Strengths\n",
            ":\n",
            "Comparing\n",
            "of\n",
            "a\n",
            "number\n",
            "of\n",
            "deep\n",
            "inverse\n",
            "models\n",
            "on\n",
            "a\n",
            "number\n",
            "of\n",
            "benchmarks\n",
            ",\n",
            "as\n",
            "a\n",
            "function\n",
            "of\n",
            "the\n",
            "number\n",
            "of\n",
            "proposed\n",
            "solutions\n",
            ",\n",
            "is\n",
            "great\n",
            "idea\n",
            ".\n",
            "The\n",
            "proposed\n",
            "``\n",
            "neural\n",
            "adjoint\n",
            "method\n",
            "''\n",
            "is\n",
            "a\n",
            "smart\n",
            "approach\n",
            "for\n",
            "inverse\n",
            "problems\n",
            "and\n",
            "the\n",
            "experimental\n",
            "evidence\n",
            "convincingly\n",
            "supports\n",
            "the\n",
            "superior\n",
            "performance\n",
            "of\n",
            "this\n",
            "to\n",
            "the\n",
            "other\n",
            "inverse\n",
            "problem\n",
            "models\n",
            "considered\n",
            ".\n",
            "Weaknesses\n",
            ":\n",
            "Given\n",
            "many\n",
            "of\n",
            "the\n",
            "benchmarks\n",
            "presented\n",
            "here\n",
            "were\n",
            "also\n",
            "presented\n",
            "in\n",
            "``\n",
            "Benchmarking\n",
            "invertible\n",
            "architectures\n",
            "on\n",
            "inverse\n",
            "problems\n",
            "''\n",
            ",\n",
            "the\n",
            "value\n",
            "of\n",
            "the\n",
            "benchmarks\n",
            "presented\n",
            "seems\n",
            "somewhat\n",
            "marginal\n",
            ".\n",
            "I\n",
            "have\n",
            "a\n",
            "concern\n",
            "about\n",
            "the\n",
            "paper\n",
            "'s\n",
            "presentation\n",
            "of\n",
            "the\n",
            "proposed\n",
            "``\n",
            "neural\n",
            "adjoint\n",
            "method\n",
            "''\n",
            ",\n",
            "which\n",
            "seems\n",
            "to\n",
            "me\n",
            "to\n",
            "be\n",
            "a\n",
            "straightforward\n",
            "application\n",
            "of\n",
            "techniques\n",
            "from\n",
            "NN\n",
            "surrogate-based\n",
            "/\n",
            "model-based\n",
            "optimization\n",
            "to\n",
            "inverse\n",
            "modeling\n",
            ".\n",
            "I\n",
            "discuss\n",
            "this\n",
            "concern\n",
            "in\n",
            "``\n",
            "relation\n",
            "to\n",
            "prior\n",
            "work\n",
            "''\n",
            "below\n",
            ".\n",
            "The\n",
            "metamaterial\n",
            "task\n",
            "is\n",
            "very\n",
            "interesting\n",
            ",\n",
            "and\n",
            "seems\n",
            "like\n",
            "a\n",
            "good\n",
            "benchmark\n",
            ":\n",
            "however\n",
            "this\n",
            "was\n",
            "proposed\n",
            "in\n",
            "a\n",
            "``\n",
            "Deep\n",
            "learning\n",
            "for\n",
            "accelerated\n",
            "all-dielectric\n",
            "metasurface\n",
            "design\n",
            "''\n",
            "and\n",
            "so\n",
            "can\n",
            "not\n",
            "be\n",
            "claimed\n",
            "as\n",
            "a\n",
            "contribution\n",
            "by\n",
            "the\n",
            "current\n",
            "paper\n",
            ".\n",
            "To\n",
            "the\n",
            "authors\n",
            ":\n",
            "does\n",
            "the\n",
            "current\n",
            "paper\n",
            "make\n",
            "a\n",
            "substantial\n",
            "novel\n",
            "contribution\n",
            ",\n",
            "beyond\n",
            "this\n",
            "prior\n",
            "work\n",
            ",\n",
            "to\n",
            "this\n",
            "task\n",
            "as\n",
            "a\n",
            "benchmark\n",
            "?\n",
            "Correctness\n",
            ":\n",
            "I\n",
            "believe\n",
            "the\n",
            "claims\n",
            "to\n",
            "be\n",
            "correct\n",
            ".\n",
            "I\n",
            "have\n",
            "not\n",
            "checked\n",
            "the\n",
            "code\n",
            "but\n",
            "the\n",
            "experimental\n",
            "design\n",
            "looks\n",
            "thorough\n",
            "and\n",
            "the\n",
            "experimental\n",
            "results\n",
            "look\n",
            "plausible\n",
            ".\n",
            "Clarity\n",
            ":\n",
            "The\n",
            "paper\n",
            "is\n",
            "well\n",
            "written\n",
            "and\n",
            "easy\n",
            "to\n",
            "read\n",
            ".\n",
            "Relation\n",
            "to\n",
            "Prior\n",
            "Work\n",
            ":\n",
            "``\n",
            "Inverse\n",
            "problems\n",
            "''\n",
            "can\n",
            "be\n",
            "framed\n",
            "as\n",
            "optimization\n",
            ",\n",
            "minimizing\n",
            "the\n",
            "loss\n",
            "L\n",
            "(\n",
            "x\n",
            ")\n",
            "where\n",
            "this\n",
            "loss\n",
            "is\n",
            "a\n",
            "distance\n",
            "between\n",
            "yhat\n",
            "=\n",
            "f\n",
            "(\n",
            "x\n",
            ")\n",
            "and\n",
            "the\n",
            "observations\n",
            "y\n",
            ".\n",
            "Thus\n",
            "I\n",
            "have\n",
            "a\n",
            "potential\n",
            "case\n",
            "with\n",
            "the\n",
            "paper\n",
            "'s\n",
            "presentation\n",
            "of\n",
            "the\n",
            "``\n",
            "neural\n",
            "adjoint\n",
            "''\n",
            "method\n",
            "as\n",
            "related\n",
            "to\n",
            "previous\n",
            "work\n",
            "There\n",
            "is\n",
            "lots\n",
            "of\n",
            "work\n",
            "on\n",
            "using\n",
            "NNs\n",
            "for\n",
            "model-based\n",
            "or\n",
            "surrogate-based\n",
            "optimization\n",
            ".\n",
            "Sometimes\n",
            "people\n",
            "model\n",
            "an\n",
            "objective\n",
            "function\n",
            "Jhat\n",
            "=\n",
            "ftheta\n",
            "(\n",
            "x\n",
            ")\n",
            ",\n",
            "and\n",
            "search\n",
            "(\n",
            "i.e\n",
            ".\n",
            "via\n",
            "gradient\n",
            "descent\n",
            ")\n",
            "for\n",
            "x\n",
            "*\n",
            "which\n",
            "minimizes\n",
            "Jhat\n",
            ":\n",
            "this\n",
            "is\n",
            "most\n",
            "common\n",
            "in\n",
            "Bayesian\n",
            "optimization\n",
            "(\n",
            "e.g\n",
            ".\n",
            "see\n",
            "``\n",
            "Scalable\n",
            "Bayesian\n",
            "optimization\n",
            "with\n",
            "neural\n",
            "networks\n",
            "''\n",
            ")\n",
            ".\n",
            "Sometimes\n",
            "people\n",
            "model\n",
            "an\n",
            "output\n",
            "yhat\n",
            "=\n",
            "ftheta\n",
            "(\n",
            "x\n",
            ")\n",
            ",\n",
            "and\n",
            "search\n",
            "(\n",
            "i.e\n",
            ".\n",
            "via\n",
            "gradient\n",
            "descent\n",
            ")\n",
            "for\n",
            "x\n",
            "*\n",
            "which\n",
            "minimizes\n",
            "J\n",
            "(\n",
            "yhat\n",
            ")\n",
            "where\n",
            "J\n",
            "is\n",
            "a\n",
            "known\n",
            "function\n",
            ":\n",
            "this\n",
            "is\n",
            "most\n",
            "common\n",
            "in\n",
            "surrogate-based\n",
            "optimization\n",
            ".\n",
            "The\n",
            "neural-adjoint\n",
            "method\n",
            "is\n",
            "clearly\n",
            "a\n",
            "special\n",
            "case\n",
            "of\n",
            "this\n",
            "latter\n",
            "scenario\n",
            ".\n",
            "See\n",
            ":\n",
            "-\n",
            "``\n",
            "Automatic\n",
            "Chemical\n",
            "Design\n",
            "Using\n",
            "a\n",
            "Data-Driven\n",
            "Continuous\n",
            "Representation\n",
            "of\n",
            "Molecules\n",
            "''\n",
            ",\n",
            "-\n",
            "``\n",
            "Multiscale\n",
            "topology\n",
            "optimization\n",
            "using\n",
            "neural\n",
            "network\n",
            "surrogate\n",
            "models\n",
            "''\n",
            ",\n",
            "-\n",
            "``\n",
            "Amortized\n",
            "Finite\n",
            "Element\n",
            "Analysis\n",
            "for\n",
            "Fast\n",
            "PDE-Constrained\n",
            "Optimization\n",
            "''\n",
            ",\n",
            "-\n",
            "``\n",
            "Conditioning\n",
            "by\n",
            "adaptive\n",
            "sampling\n",
            "for\n",
            "robust\n",
            "design\n",
            "''\n",
            ",\n",
            "-\n",
            "the\n",
            "surrogate-based\n",
            "optimization\n",
            "portions\n",
            "of\n",
            "``\n",
            "Algorithms\n",
            "for\n",
            "Optimization\n",
            "''\n",
            ".\n",
            "I\n",
            "think\n",
            "the\n",
            "framing\n",
            "of\n",
            "this\n",
            "method\n",
            "as\n",
            "novel\n",
            "and\n",
            "the\n",
            "introduction\n",
            "of\n",
            "a\n",
            "name\n",
            "for\n",
            "the\n",
            "method\n",
            "is\n",
            "inappropriate\n",
            "without\n",
            "significant\n",
            "methodological\n",
            "differences\n",
            "from\n",
            "prior\n",
            "work\n",
            ".\n",
            "I\n",
            "am\n",
            "far\n",
            "from\n",
            "an\n",
            "expert\n",
            "in\n",
            "these\n",
            "areas\n",
            "so\n",
            "may\n",
            "not\n",
            "have\n",
            "picked\n",
            "the\n",
            "best\n",
            "references\n",
            ".\n",
            "I\n",
            "do\n",
            "like\n",
            "the\n",
            "method\n",
            "itself\n",
            "of\n",
            "training\n",
            "a\n",
            "NN\n",
            "surrogate\n",
            "and\n",
            "finding\n",
            "the\n",
            "points\n",
            "which\n",
            "optimize\n",
            "the\n",
            "loss\n",
            "according\n",
            "to\n",
            "the\n",
            "surrogate\n",
            "(\n",
            "which\n",
            "has\n",
            "been\n",
            "demonstrated\n",
            "to\n",
            "be\n",
            "effective\n",
            "in\n",
            "these\n",
            "other\n",
            "problems\n",
            ")\n",
            ".\n",
            "The\n",
            "paper\n",
            "should\n",
            "clearly\n",
            "discuss\n",
            "the\n",
            "relation\n",
            "of\n",
            "the\n",
            "proposed\n",
            "method\n",
            "to\n",
            "other\n",
            "work\n",
            "in\n",
            "model-based\n",
            "optimization\n",
            "(\n",
            "making\n",
            "it\n",
            "clear\n",
            "that\n",
            "this\n",
            "is\n",
            "a\n",
            "direct\n",
            "application\n",
            "of\n",
            "NN\n",
            "surrogate\n",
            "modeling\n",
            "to\n",
            "the\n",
            "inverse\n",
            "modeling\n",
            "problem\n",
            ")\n",
            ".\n",
            "Possibly\n",
            "it\n",
            "should\n",
            "remove\n",
            "the\n",
            "``\n",
            "neural-adjoint\n",
            "''\n",
            "method\n",
            "branding\n",
            "as\n",
            "this\n",
            "branding\n",
            "is\n",
            "misleading\n",
            "in\n",
            "making\n",
            "the\n",
            "proposed\n",
            "method\n",
            "seem\n",
            "like\n",
            "a\n",
            "newly\n",
            "derived\n",
            "thing\n",
            ".\n",
            "The\n",
            "paper\n",
            "should\n",
            "also\n",
            "relate\n",
            "the\n",
            "techniques\n",
            "in\n",
            "section\n",
            "3.1\n",
            "to\n",
            "closely\n",
            "related\n",
            "techniques\n",
            "in\n",
            "safe\n",
            "exploration\n",
            "/\n",
            "safe\n",
            "Bayesian\n",
            "optimization\n",
            "(\n",
            "staying\n",
            "on\n",
            "the\n",
            "manifold\n",
            "of\n",
            "designs\n",
            ")\n",
            ".\n",
            "Reproducibility\n",
            ":\n",
            "Yes\n",
            "Additional\n",
            "Feedback\n",
            ":\n",
            "--\n",
            "-\n",
            "Update\n",
            "after\n",
            "rebuttal\n",
            ":\n",
            "Thanks\n",
            "for\n",
            "the\n",
            "effort\n",
            "you\n",
            "put\n",
            "into\n",
            "the\n",
            "response\n",
            ".\n",
            "I\n",
            "think\n",
            "if\n",
            "the\n",
            "boundary\n",
            "loss\n",
            "is\n",
            "a\n",
            "main\n",
            "contribution\n",
            "of\n",
            "the\n",
            "paper\n",
            ",\n",
            "there\n",
            "needs\n",
            "to\n",
            "be\n",
            "more\n",
            "insight\n",
            "into\n",
            "its\n",
            "design\n",
            ".\n",
            "Currently\n",
            "it\n",
            "looks\n",
            "quite\n",
            "ad-hoc\n",
            "(\n",
            "just\n",
            "a\n",
            "loss\n",
            "to\n",
            "force\n",
            "the\n",
            "x\n",
            "to\n",
            "be\n",
            "within\n",
            "2\n",
            "sigma\n",
            "of\n",
            "the\n",
            "mean\n",
            ")\n",
            "and\n",
            "it\n",
            "would\n",
            "be\n",
            "good\n",
            "to\n",
            "understand\n",
            "the\n",
            "effect\n",
            "of\n",
            "this\n",
            "on\n",
            "different\n",
            "datasets\n",
            ",\n",
            "how\n",
            "it\n",
            "varies\n",
            "with\n",
            "the\n",
            "number\n",
            "of\n",
            "sigma\n",
            "from\n",
            "the\n",
            "mean\n",
            ",\n",
            "hard/soft\n",
            "threshold\n",
            "etc\n",
            ".\n",
            "It\n",
            "'s\n",
            "worth\n",
            "noting\n",
            "that\n",
            "there\n",
            "is\n",
            "somewhat\n",
            "similar\n",
            "work\n",
            "on\n",
            "avoiding\n",
            "unrealistic\n",
            "x\n",
            "in\n",
            "surrogate-based\n",
            "optimization\n",
            ",\n",
            "albeit\n",
            "mostly\n",
            "in\n",
            "model-based\n",
            "RL\n",
            ":\n",
            "see\n",
            "model-ensemble\n",
            "TRPO\n",
            ",\n",
            "or\n",
            "model-predictive\n",
            "policy\n",
            "learning\n",
            "with\n",
            "uncertainty\n",
            "regularization\n",
            ".\n",
            "These\n",
            "seem\n",
            "to\n",
            "me\n",
            "to\n",
            "be\n",
            "more\n",
            "principled\n",
            ",\n",
            "in\n",
            "a\n",
            "sense\n",
            ",\n",
            "than\n",
            "using\n",
            "the\n",
            "mean\n",
            "and\n",
            "standard\n",
            "deviation\n",
            "of\n",
            "the\n",
            "training\n",
            "data\n",
            ".\n",
            "I\n",
            "appreciate\n",
            "the\n",
            "work\n",
            "and\n",
            "effort\n",
            "you\n",
            "put\n",
            "into\n",
            "benchmarking\n",
            "on\n",
            "a\n",
            "number\n",
            "of\n",
            "problems\n",
            "and\n",
            "I\n",
            "think\n",
            "this\n",
            "is\n",
            "of\n",
            "great\n",
            "value\n",
            ".\n",
            "I\n",
            "maintain\n",
            "my\n",
            "score\n",
            ",\n",
            "but\n",
            "I\n",
            "hope\n",
            "that\n",
            "if\n",
            "this\n",
            "is\n",
            "not\n",
            "accepted\n",
            "you\n",
            "will\n",
            "resubmit\n",
            "(\n",
            "e.g\n",
            ".\n",
            "to\n",
            "ICLR\n",
            ")\n",
            ",\n",
            "with\n",
            "a\n",
            "rewrite\n",
            "to\n",
            "adjust\n",
            "or\n",
            "remove\n",
            "the\n",
            "``\n",
            "neural\n",
            "adjoint\n",
            "''\n",
            "branding\n",
            "and\n",
            "position\n",
            "your\n",
            "work\n",
            "more\n",
            "clearly\n",
            "w.r.t\n",
            ".\n",
            "model-based\n",
            "optimization\n",
            ",\n",
            "and\n",
            "with\n",
            "more\n",
            "insight\n",
            "into\n",
            "the\n",
            "boundary\n",
            "loss\n",
            ",\n",
            "and\n",
            "understanding\n",
            "of\n",
            "this\n",
            "boundary\n",
            "loss\n",
            "vs\n",
            "other\n",
            "techniques\n",
            "in\n",
            "uncertainty-aware\n",
            "/\n",
            "safe\n",
            "/\n",
            "robust\n",
            "optimization\n",
            ".\n",
            "--\n",
            "-\n",
            "Review\n",
            "2\n",
            "Summary\n",
            "and\n",
            "Contributions\n",
            ":\n",
            "This\n",
            "paper\n",
            "proposes\n",
            "a\n",
            "new\n",
            "method\n",
            ",\n",
            "a\n",
            "new\n",
            "performance\n",
            "metric\n",
            ",\n",
            "and\n",
            "presents\n",
            "a\n",
            "benchmark\n",
            "evaluation\n",
            "on\n",
            "four\n",
            "tasks\n",
            "of\n",
            "inverse\n",
            "problems\n",
            ",\n",
            "where\n",
            "one\n",
            "of\n",
            "them\n",
            "is\n",
            "newly\n",
            "constructed\n",
            "in\n",
            "this\n",
            "paper\n",
            ".\n",
            "The\n",
            "contributions\n",
            "of\n",
            "this\n",
            "paper\n",
            "are\n",
            "three\n",
            "folds\n",
            ".\n",
            "-\n",
            "A\n",
            "simple\n",
            "yet\n",
            "strong\n",
            "method\n",
            "to\n",
            "inverse\n",
            "problems\n",
            ".\n",
            "-\n",
            "A\n",
            "new\n",
            "metric\n",
            "that\n",
            "characterizes\n",
            "the\n",
            "performance\n",
            "trade-off\n",
            "in\n",
            "terms\n",
            "of\n",
            "inference\n",
            "efficiency\n",
            ".\n",
            "-\n",
            "A\n",
            "new\n",
            "benchmark\n",
            "dataset\n",
            "constructed\n",
            "from\n",
            "training\n",
            "a\n",
            "network\n",
            "ensemble\n",
            "on\n",
            "40k\n",
            "examples\n",
            "to\n",
            "fit\n",
            "the\n",
            "simulator\n",
            "of\n",
            "meta-material\n",
            "design\n",
            ".\n",
            "Strengths\n",
            ":\n",
            "-\n",
            "The\n",
            "proposed\n",
            "inverse\n",
            "solver\n",
            "is\n",
            "simple\n",
            "yet\n",
            "accurate\n",
            ",\n",
            "which\n",
            "serves\n",
            "as\n",
            "a\n",
            "strong\n",
            "baseline\n",
            "method\n",
            "for\n",
            "future\n",
            "research\n",
            ".\n",
            "-\n",
            "The\n",
            "proposed\n",
            "evaluation\n",
            "metric\n",
            "looks\n",
            "reasonable\n",
            ".\n",
            "-\n",
            "The\n",
            "proposed\n",
            "benchmark\n",
            "evaluation\n",
            "looks\n",
            "fair\n",
            "and\n",
            "thorough\n",
            ",\n",
            "which\n",
            "builds\n",
            "a\n",
            "foundation\n",
            "for\n",
            "future\n",
            "research\n",
            ".\n",
            "Weaknesses\n",
            ":\n",
            "This\n",
            "paper\n",
            "focuses\n",
            "only\n",
            "on\n",
            "measuring\n",
            "the\n",
            "error\n",
            "of\n",
            "point\n",
            "estimates\n",
            "while\n",
            "lacking\n",
            "the\n",
            "error\n",
            "of\n",
            "the\n",
            "estimated\n",
            "“\n",
            "posterior\n",
            "probability\n",
            "distributions\n",
            ",\n",
            "”\n",
            "which\n",
            "has\n",
            "been\n",
            "done\n",
            "in\n",
            "[\n",
            "1,2\n",
            "]\n",
            ".\n",
            "Specifically\n",
            ",\n",
            "[\n",
            "1\n",
            "]\n",
            "used\n",
            "calibration\n",
            "error\n",
            ",\n",
            "and\n",
            "[\n",
            "2\n",
            "]\n",
            "used\n",
            "MMD\n",
            "as\n",
            "the\n",
            "distribution-based\n",
            "metric\n",
            ".\n",
            "In\n",
            "this\n",
            "paper\n",
            ",\n",
            "the\n",
            "“\n",
            "Inverse\n",
            "model\n",
            "performance\n",
            "metrics\n",
            "”\n",
            "subsection\n",
            "in\n",
            "Related\n",
            "Work\n",
            "(\n",
            "line\n",
            "102-106\n",
            ")\n",
            "only\n",
            "mentioned\n",
            "MSE\n",
            "of\n",
            "point\n",
            "estimates\n",
            ".\n",
            "Throughout\n",
            "the\n",
            "paper\n",
            ",\n",
            "the\n",
            "keyword\n",
            "“\n",
            "posterior\n",
            "”\n",
            "only\n",
            "appears\n",
            "once\n",
            "in\n",
            "Related\n",
            "Work\n",
            ".\n",
            "Since\n",
            "one\n",
            "of\n",
            "the\n",
            "focus\n",
            "of\n",
            "this\n",
            "paper\n",
            "is\n",
            "the\n",
            "evaluation\n",
            "metric\n",
            ",\n",
            "the\n",
            "lack\n",
            "of\n",
            "discussion\n",
            ",\n",
            "comparison\n",
            ",\n",
            "and\n",
            "experiments\n",
            "on\n",
            "distribution-based\n",
            "metrics\n",
            "pose\n",
            "a\n",
            "weakness\n",
            "in\n",
            "this\n",
            "paper\n",
            ".\n",
            "Section\n",
            "4\n",
            "can\n",
            "be\n",
            "improved\n",
            "in\n",
            "terms\n",
            "of\n",
            "technical\n",
            "writing\n",
            ".\n",
            "Specifically\n",
            ",\n",
            "I\n",
            "can\n",
            "not\n",
            "understand\n",
            "the\n",
            "four\n",
            "methods\n",
            "without\n",
            "reading\n",
            "their\n",
            "original\n",
            "papers\n",
            "since\n",
            "the\n",
            "technical\n",
            "description\n",
            "is\n",
            "not\n",
            "precise\n",
            "and\n",
            "clear\n",
            "enough\n",
            ".\n",
            "The\n",
            "main\n",
            "reason\n",
            "that\n",
            "I\n",
            "can\n",
            "not\n",
            "understand\n",
            "clearly\n",
            "is\n",
            "due\n",
            "to\n",
            "the\n",
            "somewhat\n",
            "simplified\n",
            "equations\n",
            "(\n",
            "Eq\n",
            ".\n",
            "6\n",
            ",\n",
            "7\n",
            ",\n",
            "8\n",
            ",\n",
            "and\n",
            "9\n",
            ")\n",
            ".\n",
            "For\n",
            "example\n",
            ",\n",
            "all\n",
            "the\n",
            "four\n",
            "equations\n",
            "start\n",
            "with\n",
            "“\n",
            "Loss\n",
            "”\n",
            "as\n",
            "their\n",
            "left-hand\n",
            "side\n",
            ",\n",
            "which\n",
            "is\n",
            "too\n",
            "simplified\n",
            "since\n",
            "there\n",
            "should\n",
            "have\n",
            "the\n",
            "model\n",
            "parameters\n",
            "to\n",
            "be\n",
            "learned\n",
            ".\n",
            "Furthermore\n",
            ",\n",
            "the\n",
            "actual\n",
            "expression\n",
            "of\n",
            "\\hat\n",
            "{\n",
            "x\n",
            "}\n",
            "or\n",
            "\\hat\n",
            "{\n",
            "y\n",
            "}\n",
            "in\n",
            "each\n",
            "method\n",
            "is\n",
            "not\n",
            "revealed\n",
            ".\n",
            "For\n",
            "readers\n",
            "not\n",
            "familiar\n",
            "with\n",
            "the\n",
            "area\n",
            ",\n",
            "such\n",
            "simplification\n",
            "may\n",
            "make\n",
            "the\n",
            "reading\n",
            "harder\n",
            ".\n",
            "In\n",
            "line\n",
            "94-96\n",
            ":\n",
            "“\n",
            "Earlier\n",
            "work\n",
            "on\n",
            "Mixture\n",
            "density\n",
            "networks\n",
            "[\n",
            "14\n",
            "]\n",
            "model\n",
            "the\n",
            "direct\n",
            "conditional\n",
            "distribution\n",
            "using\n",
            "gaussians\n",
            ".\n",
            "However\n",
            "due\n",
            "to\n",
            "low\n",
            "accuracy\n",
            "reported\n",
            "by\n",
            "[\n",
            "2\n",
            "]\n",
            ",\n",
            "we\n",
            "do\n",
            "not\n",
            "include\n",
            "comparison\n",
            "to\n",
            "this\n",
            "work.\n",
            "”\n",
            "I\n",
            "am\n",
            "not\n",
            "sure\n",
            "whether\n",
            "it\n",
            "is\n",
            "an\n",
            "adequate\n",
            "statement\n",
            ".\n",
            "In\n",
            "[\n",
            "2\n",
            "]\n",
            "’\n",
            "s\n",
            "Figure\n",
            "4\n",
            "and\n",
            "5\n",
            ",\n",
            "Mixture\n",
            "density\n",
            "networks\n",
            "(\n",
            "MDN\n",
            ")\n",
            "[\n",
            "14\n",
            "]\n",
            "performs\n",
            "quite\n",
            "competitively\n",
            ".\n",
            "I\n",
            "would\n",
            "like\n",
            "to\n",
            "know\n",
            "why\n",
            "this\n",
            "paper\n",
            "ignores\n",
            "the\n",
            "comparison\n",
            "with\n",
            "[\n",
            "14\n",
            "]\n",
            ".\n",
            "Correctness\n",
            ":\n",
            "Most\n",
            "of\n",
            "the\n",
            "claims\n",
            "and\n",
            "method\n",
            "in\n",
            "the\n",
            "paper\n",
            "looks\n",
            "correct\n",
            ".\n",
            "The\n",
            "empirical\n",
            "methodology\n",
            "looks\n",
            "correct\n",
            ",\n",
            "too\n",
            ".\n",
            "Clarity\n",
            ":\n",
            "The\n",
            "clarity\n",
            "of\n",
            "Section\n",
            "4\n",
            "has\n",
            "room\n",
            "for\n",
            "improvement\n",
            ".\n",
            "The\n",
            "overall\n",
            "clarity\n",
            "is\n",
            "only\n",
            "borderline\n",
            "to\n",
            "me\n",
            ".\n",
            "I\n",
            "can\n",
            "not\n",
            "have\n",
            "a\n",
            "clear\n",
            "picture\n",
            "after\n",
            "the\n",
            "first-round\n",
            "reading\n",
            ",\n",
            "though\n",
            "I\n",
            "finally\n",
            "understand\n",
            "most\n",
            "of\n",
            "the\n",
            "paper\n",
            "after\n",
            "the\n",
            "third-round\n",
            "reading\n",
            ".\n",
            "Relation\n",
            "to\n",
            "Prior\n",
            "Work\n",
            ":\n",
            "From\n",
            "my\n",
            "perspective\n",
            ",\n",
            "this\n",
            "paper\n",
            "looks\n",
            "closely\n",
            "related\n",
            "to\n",
            "[\n",
            "1\n",
            "]\n",
            "and\n",
            "[\n",
            "2\n",
            "]\n",
            ":\n",
            "[\n",
            "1\n",
            "]\n",
            "Analyzing\n",
            "inverse\n",
            "problems\n",
            "with\n",
            "invertible\n",
            "neural\n",
            "networks\n",
            ",\n",
            "ICLR19\n",
            ".\n",
            "[\n",
            "2\n",
            "]\n",
            "Benchmarking\n",
            "invertible\n",
            "architectures\n",
            "on\n",
            "inverse\n",
            "problems\n",
            ",\n",
            "ICML19\n",
            "workshop\n",
            ".\n",
            "The\n",
            "difference\n",
            "between\n",
            "this\n",
            "work\n",
            "and\n",
            "[\n",
            "1,2\n",
            "]\n",
            "can\n",
            "be\n",
            "seen\n",
            "from\n",
            "the\n",
            "contribution\n",
            "summary\n",
            "(\n",
            "line\n",
            "68-80\n",
            ")\n",
            "and\n",
            "the\n",
            "related\n",
            "work\n",
            "(\n",
            "line\n",
            "97-101\n",
            ")\n",
            ".\n",
            "Therefore\n",
            ",\n",
            "the\n",
            "relation\n",
            "to\n",
            "prior\n",
            "work\n",
            "is\n",
            "clear\n",
            "enough\n",
            "to\n",
            "me\n",
            ".\n",
            "Reproducibility\n",
            ":\n",
            "Yes\n",
            "Additional\n",
            "Feedback\n",
            ":\n",
            "The\n",
            "“\n",
            "Tandem\n",
            "model\n",
            "”\n",
            "subsection\n",
            "(\n",
            "start\n",
            "from\n",
            "line\n",
            "164\n",
            ")\n",
            "is\n",
            "hard\n",
            "to\n",
            "understand\n",
            ".\n",
            "Comparing\n",
            "with\n",
            "the\n",
            "supplementary\n",
            "material\n",
            ",\n",
            "are\n",
            "the\n",
            "role\n",
            "of\n",
            "“\n",
            "encoder\n",
            "”\n",
            "and\n",
            "“\n",
            "decoder\n",
            "”\n",
            "reversed\n",
            "in\n",
            "line\n",
            "164-166\n",
            "in\n",
            "the\n",
            "main\n",
            "paper\n",
            "?\n",
            "It\n",
            "would\n",
            "be\n",
            "better\n",
            "to\n",
            "explain\n",
            "in\n",
            "the\n",
            "caption\n",
            "of\n",
            "Figure\n",
            "3\n",
            "about\n",
            "why\n",
            "Figure\n",
            "3\n",
            "(\n",
            "d\n",
            ")\n",
            "has\n",
            "no\n",
            "yellow\n",
            "line\n",
            "(\n",
            "INN\n",
            ")\n",
            ".\n",
            "I\n",
            "know\n",
            "that\n",
            "the\n",
            "supplementary\n",
            "material\n",
            "(\n",
            "line\n",
            "151\n",
            ")\n",
            "has\n",
            "mentioned\n",
            "that\n",
            ".\n",
            "It\n",
            "is\n",
            "better\n",
            "to\n",
            "cite\n",
            "[\n",
            "1\n",
            "]\n",
            "as\n",
            "an\n",
            "ICLR19\n",
            "paper\n",
            ",\n",
            "not\n",
            "arXiv\n",
            ".\n",
            "Similarly\n",
            ",\n",
            "[\n",
            "2\n",
            "]\n",
            "should\n",
            "be\n",
            "cited\n",
            "as\n",
            "an\n",
            "ICML19\n",
            "workshop\n",
            "paper\n",
            ".\n",
            "Current\n",
            "citation\n",
            "makes\n",
            "it\n",
            "look\n",
            "like\n",
            "a\n",
            "conference\n",
            "paper\n",
            ".\n",
            "In\n",
            "the\n",
            "supplementary\n",
            "material\n",
            ",\n",
            "“\n",
            "Parameters\n",
            "”\n",
            "in\n",
            "Table\n",
            "2\n",
            "should\n",
            "be\n",
            "called\n",
            "“\n",
            "Hyperparameters.\n",
            "”\n",
            "In\n",
            "the\n",
            "supplementary\n",
            "material\n",
            ",\n",
            "I\n",
            "can\n",
            "not\n",
            "understand\n",
            "how\n",
            "to\n",
            "define\n",
            "the\n",
            "performance\n",
            "when\n",
            "T=0\n",
            "(\n",
            "subsection\n",
            "6.1\n",
            ")\n",
            ".\n",
            "It\n",
            "would\n",
            "be\n",
            "better\n",
            "to\n",
            "explain\n",
            "clearly\n",
            "how\n",
            "each\n",
            "method\n",
            "is\n",
            "applied\n",
            "with\n",
            "T=0\n",
            ".\n",
            "In\n",
            "the\n",
            "supplementary\n",
            "material\n",
            ",\n",
            "Figure\n",
            "3\n",
            "is\n",
            "hard\n",
            "to\n",
            "understand\n",
            ".\n",
            "Why\n",
            "the\n",
            "upper-left\n",
            "of\n",
            "the\n",
            "left\n",
            "subfigure\n",
            "is\n",
            "white\n",
            "?\n",
            "Why\n",
            "the\n",
            "right\n",
            "of\n",
            "the\n",
            "middle\n",
            "subfigure\n",
            "represent\n",
            "x\n",
            ",\n",
            "not\n",
            "\\hat\n",
            "{\n",
            "x\n",
            "}\n",
            "?\n",
            "Why\n",
            "the\n",
            "upper-left\n",
            "of\n",
            "the\n",
            "middle\n",
            "subfigure\n",
            "is\n",
            "y\n",
            ",\n",
            "not\n",
            "y_\n",
            "{\n",
            "gt\n",
            "}\n",
            "?\n",
            "Typos\n",
            ":\n",
            "Main\n",
            "paper\n",
            "line\n",
            "128\n",
            ":\n",
            "“\n",
            "be\n",
            "a\n",
            "our\n",
            "”\n",
            "Main\n",
            "paper\n",
            "line\n",
            "167-168\n",
            ":\n",
            "“\n",
            "but\n",
            "we\n",
            "found\n",
            "that\n",
            "adding\n",
            "in\n",
            "our\n",
            "boundary\n",
            "loss\n",
            "(\n",
            "see\n",
            "3.1\n",
            ")\n",
            ",\n",
            "”\n",
            "Main\n",
            "paper\n",
            "line\n",
            "246\n",
            ":\n",
            "“\n",
            "found\n",
            "found\n",
            "”\n",
            "Supplementary\n",
            "material\n",
            "line\n",
            "95\n",
            ":\n",
            "“\n",
            "from\n",
            "from\n",
            "”\n",
            "========\n",
            "post\n",
            "rebuttal\n",
            "========\n",
            "Thanks\n",
            "for\n",
            "the\n",
            "rebuttal\n",
            ".\n",
            "Table\n",
            "1\n",
            "in\n",
            "the\n",
            "rebuttal\n",
            "well\n",
            "addressed\n",
            "my\n",
            "first\n",
            "concern\n",
            "in\n",
            "my\n",
            "Weaknesses\n",
            "session\n",
            ".\n",
            "My\n",
            "2nd\n",
            "concern\n",
            "(\n",
            "about\n",
            "writing\n",
            ")\n",
            "is\n",
            "not\n",
            "mentioned\n",
            "in\n",
            "rebuttal\n",
            ",\n",
            "which\n",
            "I\n",
            "can\n",
            "understand\n",
            "it\n",
            "is\n",
            "due\n",
            "to\n",
            "space\n",
            "limit\n",
            ".\n",
            "My\n",
            "3rd\n",
            "concern\n",
            "is\n",
            "addressed\n",
            "and\n",
            "I\n",
            "can\n",
            "understand\n",
            "your\n",
            "situation\n",
            ".\n",
            "I\n",
            "really\n",
            "appreciate\n",
            "the\n",
            "author\n",
            "response\n",
            ",\n",
            "especially\n",
            "Table\n",
            "1\n",
            ".\n",
            "However\n",
            ",\n",
            "after\n",
            "reading\n",
            "all\n",
            "the\n",
            "reviews\n",
            "and\n",
            "the\n",
            "rebuttal\n",
            ",\n",
            "I\n",
            "am\n",
            "afraid\n",
            "that\n",
            "I\n",
            "can\n",
            "not\n",
            "give\n",
            "an\n",
            "overall\n",
            "score\n",
            "of\n",
            "7\n",
            "(\n",
            "a\n",
            "good\n",
            "submission\n",
            ",\n",
            "accept\n",
            ")\n",
            "because\n",
            "(\n",
            "1\n",
            ")\n",
            "The\n",
            "writing\n",
            "of\n",
            "the\n",
            "technical\n",
            "methods\n",
            "(\n",
            "as\n",
            "my\n",
            "second\n",
            "concern\n",
            ")\n",
            "is\n",
            "not\n",
            "ready\n",
            "to\n",
            "me\n",
            ".\n",
            "(\n",
            "2\n",
            ")\n",
            "As\n",
            "mentioned\n",
            "by\n",
            "R1\n",
            ",\n",
            "it\n",
            "seems\n",
            "that\n",
            "this\n",
            "work\n",
            "is\n",
            "somewhat\n",
            "similar\n",
            "to\n",
            "some\n",
            "particular\n",
            "works\n",
            ",\n",
            "and\n",
            "a\n",
            "major\n",
            "revision\n",
            "of\n",
            "the\n",
            "introduction\n",
            "and\n",
            "related\n",
            "work\n",
            "seems\n",
            "to\n",
            "be\n",
            "required\n",
            "for\n",
            "clarifying\n",
            "and\n",
            "positioning\n",
            "this\n",
            "work\n",
            ".\n",
            "Overall\n",
            ",\n",
            "the\n",
            "main\n",
            "reason\n",
            "this\n",
            "paper\n",
            "is\n",
            "not\n",
            "ready\n",
            "to\n",
            "me\n",
            "is\n",
            "mostly\n",
            "about\n",
            "writing\n",
            ".\n",
            "Review\n",
            "3\n",
            "Summary\n",
            "and\n",
            "Contributions\n",
            ":\n",
            "This\n",
            "paper\n",
            "proposes\n",
            "a\n",
            "neural\n",
            "inverse\n",
            "method\n",
            "that\n",
            "first\n",
            "learns\n",
            "a\n",
            "forward\n",
            "model\n",
            "and\n",
            "then\n",
            "uses\n",
            "SGD\n",
            "with\n",
            "random\n",
            "initializations\n",
            "to\n",
            "find\n",
            "the\n",
            "inverse\n",
            ".\n",
            "A\n",
            "boundary\n",
            "loss\n",
            "keeps\n",
            "the\n",
            "inverse\n",
            "solutions\n",
            "close\n",
            "to\n",
            "the\n",
            "training\n",
            "data\n",
            ".\n",
            "The\n",
            "authors\n",
            "propose\n",
            "an\n",
            "evaluation\n",
            "based\n",
            "on\n",
            "the\n",
            "number\n",
            "of\n",
            "samples\n",
            "taken\n",
            "and\n",
            "propose\n",
            "two\n",
            "new\n",
            "benchmark\n",
            "tasks\n",
            ".\n",
            "Strengths\n",
            ":\n",
            "This\n",
            "method\n",
            "can\n",
            "be\n",
            "effective\n",
            "at\n",
            "solving\n",
            "one-to-many\n",
            "inverse\n",
            "problems\n",
            "when\n",
            "the\n",
            "forward\n",
            "model\n",
            "can\n",
            "be\n",
            "well\n",
            "approximated\n",
            "by\n",
            "a\n",
            "neural\n",
            "net\n",
            ".\n",
            "This\n",
            "sidesteps\n",
            "the\n",
            "challenge\n",
            "of\n",
            "learning\n",
            "one-to-many\n",
            "inverse\n",
            "functions\n",
            ".\n",
            "Moreover\n",
            ",\n",
            "the\n",
            "inverse\n",
            "function\n",
            "doesn\n",
            "’\n",
            "t\n",
            "need\n",
            "to\n",
            "keep\n",
            "all\n",
            "its\n",
            "information\n",
            "in\n",
            "the\n",
            "weights\n",
            ",\n",
            "instead\n",
            "the\n",
            "method\n",
            "just\n",
            "requires\n",
            "a\n",
            "good\n",
            "approximation\n",
            "of\n",
            "the\n",
            "forward\n",
            "model\n",
            "and\n",
            "the\n",
            "remaining\n",
            "optimization\n",
            "can\n",
            "be\n",
            "done\n",
            "using\n",
            "SGD\n",
            ".\n",
            "Weaknesses\n",
            ":\n",
            "The\n",
            "boundary\n",
            "loss\n",
            "imposes\n",
            "a\n",
            "specific\n",
            "prior\n",
            "on\n",
            "the\n",
            "inverse\n",
            "solutions\n",
            "and\n",
            "assumes\n",
            "a\n",
            "specific\n",
            "data\n",
            "distribution\n",
            "—\n",
            "that\n",
            "the\n",
            "dimensions\n",
            "of\n",
            "x\n",
            "are\n",
            "independent\n",
            "and\n",
            "concentrated\n",
            "within\n",
            "2\n",
            "standard\n",
            "deviations\n",
            "of\n",
            "the\n",
            "mean\n",
            ".\n",
            "It\n",
            "would\n",
            "be\n",
            "hard\n",
            "to\n",
            "imagine\n",
            "this\n",
            "boundary\n",
            "loss\n",
            "working\n",
            "effectively\n",
            "in\n",
            "more\n",
            "complex\n",
            "data\n",
            "regimes\n",
            ".\n",
            "Moreover\n",
            ",\n",
            "this\n",
            "paper\n",
            "is\n",
            "primarily\n",
            "concerned\n",
            "with\n",
            "evaluating\n",
            "the\n",
            "re-simulation\n",
            "error\n",
            "with\n",
            "no\n",
            "evaluation\n",
            "of\n",
            "the\n",
            "actual\n",
            "inverses\n",
            ",\n",
            "$\n",
            "x\n",
            "$\n",
            ",\n",
            "such\n",
            "as\n",
            "whether\n",
            "the\n",
            "posterior\n",
            "$\n",
            "p\n",
            "(\n",
            "x|y\n",
            ")\n",
            "$\n",
            "can\n",
            "resemble\n",
            "that\n",
            "of\n",
            "the\n",
            "training\n",
            "distribution\n",
            ".\n",
            "Correctness\n",
            ":\n",
            "If\n",
            "re-simulation\n",
            "error\n",
            "is\n",
            "the\n",
            "only\n",
            "metric\n",
            "that\n",
            "you\n",
            "care\n",
            "about\n",
            ",\n",
            "then\n",
            "this\n",
            "method\n",
            "is\n",
            "generally\n",
            "correct\n",
            ".\n",
            "Approximating\n",
            "the\n",
            "forward\n",
            "model\n",
            "with\n",
            "a\n",
            "neural\n",
            "net\n",
            "and\n",
            "using\n",
            "SGD\n",
            "with\n",
            "random\n",
            "initializations\n",
            "can\n",
            "be\n",
            "a\n",
            "reasonable\n",
            "solution\n",
            ".\n",
            "The\n",
            "only\n",
            "concern\n",
            "is\n",
            "whether\n",
            "the\n",
            "boundary\n",
            "loss\n",
            "could\n",
            "result\n",
            "in\n",
            "a\n",
            "poor\n",
            "solution\n",
            ",\n",
            "i.e\n",
            ".\n",
            "you\n",
            "can\n",
            "imagine\n",
            "a\n",
            "$\n",
            "y\n",
            "$\n",
            "which\n",
            "requires\n",
            "some\n",
            "$\n",
            "x\n",
            "$\n",
            "outside\n",
            "of\n",
            "the\n",
            "$\n",
            "2\\sigma\n",
            "$\n",
            "range\n",
            "but\n",
            "boundary\n",
            "loss\n",
            "outweighs\n",
            "the\n",
            "L2\n",
            "loss\n",
            ".\n",
            "Clarity\n",
            ":\n",
            "The\n",
            "paper\n",
            "is\n",
            "generally\n",
            "well\n",
            "written\n",
            ".\n",
            "Some\n",
            "descriptions\n",
            "of\n",
            "the\n",
            "comparison\n",
            "models\n",
            "in\n",
            "section\n",
            "4\n",
            "have\n",
            "simplified\n",
            "losses\n",
            "and\n",
            "it\n",
            "’\n",
            "s\n",
            "not\n",
            "clear\n",
            "what\n",
            "the\n",
            "general\n",
            "loss\n",
            "is\n",
            "and\n",
            "what\n",
            "the\n",
            "learned\n",
            "parameters\n",
            "are\n",
            ".\n",
            "Relation\n",
            "to\n",
            "Prior\n",
            "Work\n",
            ":\n",
            "The\n",
            "paper\n",
            "offers\n",
            "a\n",
            "reasonable\n",
            "discussion\n",
            "of\n",
            "prior\n",
            "work\n",
            ".\n",
            "Reproducibility\n",
            ":\n",
            "Yes\n",
            "Additional\n",
            "Feedback\n",
            ":\n",
            "Update\n",
            "after\n",
            "author\n",
            "response\n",
            ":\n",
            "Generally\n",
            "I\n",
            "agree\n",
            "with\n",
            "the\n",
            "points\n",
            "made\n",
            "by\n",
            "reviewer\n",
            "1\n",
            "--\n",
            "in\n",
            "the\n",
            "context\n",
            "of\n",
            "the\n",
            "prior\n",
            "work\n",
            ",\n",
            "the\n",
            "boundary\n",
            "loss\n",
            "and\n",
            "evaluation\n",
            "are\n",
            "somewhat\n",
            "incremental\n",
            "contributions\n",
            ".\n",
            "I\n",
            "would\n",
            "have\n",
            "liked\n",
            "to\n",
            "see\n",
            "a\n",
            "more\n",
            "generalizable\n",
            "boundary\n",
            "loss/prior\n",
            "and\n",
            "more\n",
            "detailed\n",
            "evaluation\n",
            "that\n",
            "prior\n",
            "work\n",
            "has\n",
            "done\n",
            ".\n",
            "Review\n",
            "4\n",
            "Summary\n",
            "and\n",
            "Contributions\n",
            ":\n",
            "The\n",
            "paper\n",
            "has\n",
            "following\n",
            "contributions\n",
            ":\n",
            "1\n",
            ".\n",
            "A\n",
            "neural\n",
            "adjoint\n",
            "method\n",
            "for\n",
            "inverse\n",
            "problems\n",
            "which\n",
            "outperforms\n",
            "other\n",
            "strong\n",
            "baselines\n",
            "of\n",
            "[\n",
            "4,5\n",
            "]\n",
            ",\n",
            "cVAE\n",
            ",\n",
            "INN\n",
            "methods\n",
            ".\n",
            "Briefly\n",
            ",\n",
            "this\n",
            "method\n",
            "entails\n",
            "training\n",
            "a\n",
            "forward\n",
            "approximator\n",
            "``\n",
            "f\n",
            "''\n",
            "on\n",
            "data\n",
            "(\n",
            "x\n",
            ",\n",
            "y\n",
            ")\n",
            ",\n",
            "and\n",
            "then\n",
            "use\n",
            "of\n",
            "gradients\n",
            "for\n",
            "different\n",
            "initializations\n",
            "(\n",
            "x_0\n",
            ")\n",
            "to\n",
            "obtain\n",
            "the\n",
            "input\n",
            "x\n",
            "for\n",
            "given\n",
            "y\n",
            ".\n",
            "2\n",
            ".\n",
            "It\n",
            "proposes\n",
            "a\n",
            "benchmark\n",
            "with\n",
            "many\n",
            "old/new\n",
            "inverse\n",
            "problems\n",
            "and\n",
            "compares\n",
            "the\n",
            "proposed\n",
            "adjoint\n",
            "method\n",
            "to\n",
            "the\n",
            "baselines\n",
            ".\n",
            "They\n",
            "perform\n",
            "comparisons\n",
            "of\n",
            "inverse\n",
            "model\n",
            "with\n",
            "multiple\n",
            "samples\n",
            "(\n",
            "or\n",
            "over\n",
            "inference\n",
            "time\n",
            ")\n",
            ".\n",
            "with\n",
            "the\n",
            "``\n",
            "r_t\n",
            "''\n",
            "metric\n",
            ".\n",
            "Strengths\n",
            ":\n",
            "+\n",
            "Experimental\n",
            "evaluation\n",
            "is\n",
            "a\n",
            "strength\n",
            "of\n",
            "this\n",
            "work\n",
            ".\n",
            "The\n",
            "proposed\n",
            "method\n",
            "is\n",
            "compared\n",
            "to\n",
            "many\n",
            "relevant\n",
            "baselines\n",
            "in\n",
            "the\n",
            "literature\n",
            ".\n",
            "All\n",
            "the\n",
            "methods\n",
            "are\n",
            "evaluated\n",
            "on\n",
            "different\n",
            "inverse\n",
            "problems\n",
            "and\n",
            "their\n",
            "runtime\n",
            "and\n",
            "accuracy\n",
            "are\n",
            "measured\n",
            ".\n",
            "+\n",
            "The\n",
            "proposed\n",
            "neural\n",
            "adjoint\n",
            "method\n",
            "with\n",
            "enough\n",
            "inference\n",
            "budget\n",
            "obtains\n",
            "the\n",
            "best\n",
            "accuracy\n",
            "on\n",
            "the\n",
            "benchmark\n",
            ".\n",
            "Weaknesses\n",
            ":\n",
            "-\n",
            "Unlike\n",
            "Tandem\n",
            "Model\n",
            "[\n",
            "4,5\n",
            "]\n",
            "and\n",
            "cVAE\n",
            "based\n",
            "methods\n",
            "the\n",
            "proposed\n",
            "method\n",
            "uses\n",
            "gradient\n",
            "updates\n",
            "and\n",
            "therefore\n",
            "is\n",
            "slow\n",
            ".\n",
            "The\n",
            "authors\n",
            "acknowledge\n",
            "this\n",
            "in\n",
            "the\n",
            "manuscript\n",
            "and\n",
            "demonstrate\n",
            "study\n",
            "the\n",
            "method\n",
            "as\n",
            "a\n",
            "function\n",
            "of\n",
            "inference\n",
            "budget\n",
            ".\n",
            "-\n",
            "The\n",
            "sampling\n",
            "performed\n",
            "to\n",
            "obtain\n",
            "different\n",
            "initializations\n",
            "x_0\n",
            "seems\n",
            "important\n",
            "for\n",
            "the\n",
            "convergence\n",
            "to\n",
            "optimum\n",
            ".\n",
            "This\n",
            "is\n",
            "not\n",
            "experimentally\n",
            "evaluated\n",
            "carefully\n",
            "on\n",
            "the\n",
            "proposed\n",
            "benchmarks\n",
            ",\n",
            "except\n",
            "for\n",
            "Tab\n",
            ".\n",
            "1\n",
            "in\n",
            "supplementary\n",
            "where\n",
            "it\n",
            "is\n",
            "compared\n",
            "to\n",
            "sampling\n",
            "from\n",
            "uniform\n",
            "distribution\n",
            ".\n",
            "Correctness\n",
            ":\n",
            "The\n",
            "contributions\n",
            "of\n",
            "the\n",
            "method\n",
            "in\n",
            "the\n",
            "form\n",
            "of\n",
            "a\n",
            "benchmark\n",
            "for\n",
            "inverse\n",
            "problems\n",
            "and\n",
            "the\n",
            "experimental\n",
            "evaluation\n",
            "of\n",
            "proposed\n",
            "NA\n",
            "method\n",
            "and\n",
            "other\n",
            "baselines\n",
            "cVAE\n",
            ",\n",
            "INN\n",
            ",\n",
            "[\n",
            "4,5\n",
            "]\n",
            "is\n",
            "technically\n",
            "correct\n",
            "and\n",
            "sound\n",
            ".\n",
            "Clarity\n",
            ":\n",
            "The\n",
            "paper\n",
            "is\n",
            "well\n",
            "written\n",
            "and\n",
            "easy\n",
            "to\n",
            "follow\n",
            ".\n",
            "Some\n",
            "important\n",
            "ablation\n",
            "results\n",
            "(\n",
            "Tab\n",
            ".\n",
            "1\n",
            ")\n",
            "are\n",
            "in\n",
            "supplementary\n",
            "and\n",
            "can\n",
            "be\n",
            "moved\n",
            "to\n",
            "the\n",
            "main\n",
            "paper\n",
            ".\n",
            "Relation\n",
            "to\n",
            "Prior\n",
            "Work\n",
            ":\n",
            "Prior\n",
            "work\n",
            "on\n",
            "inverse\n",
            "problems\n",
            "is\n",
            "discussed\n",
            "and\n",
            "included\n",
            "in\n",
            "the\n",
            "benchmark\n",
            "of\n",
            "the\n",
            "paper\n",
            ".\n",
            "Reproducibility\n",
            ":\n",
            "Yes\n",
            "NeurIPS\n",
            "2020\n",
            "Benchmarking\n",
            "Deep\n",
            "Inverse\n",
            "Models\n",
            "over\n",
            "time\n",
            ",\n",
            "and\n",
            "the\n",
            "Neural-Adjoint\n",
            "method\n",
            "Meta\n",
            "Review\n",
            "The\n",
            "reviewers\n",
            "all\n",
            "liked\n",
            "some\n",
            "aspects\n",
            "of\n",
            "the\n",
            "paper\n",
            ",\n",
            "agreed\n",
            "that\n",
            "the\n",
            "presentation\n",
            "of\n",
            "the\n",
            "technical\n",
            "part\n",
            "can\n",
            "be\n",
            "improved\n",
            "(\n",
            "e.g\n",
            "just\n",
            "spotted\n",
            "a\n",
            "missing\n",
            "^2\n",
            "in\n",
            "eq\n",
            "7\n",
            ")\n",
            "and\n",
            "that\n",
            "the\n",
            "main\n",
            "contributions\n",
            "are\n",
            "1\n",
            ")\n",
            "a\n",
            "heuristic\n",
            "(\n",
            "eq\n",
            "5\n",
            ")\n",
            "to\n",
            "regularise\n",
            "the\n",
            "inverse\n",
            "solutions\n",
            "to\n",
            "be\n",
            "close\n",
            "to\n",
            "the\n",
            "input\n",
            "data\n",
            "and\n",
            "2\n",
            ")\n",
            "the\n",
            "empirical\n",
            "evaluation\n",
            "suite\n",
            ".\n",
            "The\n",
            "presentation\n",
            "can\n",
            "(\n",
            "and\n",
            "should\n",
            ")\n",
            "of\n",
            "course\n",
            "be\n",
            "improved\n",
            "but\n",
            "it\n",
            "is\n",
            "not\n",
            "likely\n",
            "that\n",
            "the\n",
            "method\n",
            "will\n",
            "change\n",
            "if\n",
            "the\n",
            "paper\n",
            "is\n",
            "rejected\n",
            "now\n",
            "and\n",
            "resubmitted\n",
            "to\n",
            "another\n",
            "conference\n",
            ".\n",
            "Therefore\n",
            "acceptance\n",
            "is\n",
            "recommended\n",
            "together\n",
            "with\n",
            "a\n",
            "strong\n",
            "encouragement\n",
            "to\n",
            "rework\n",
            "the\n",
            "presentation\n",
            "for\n",
            "the\n",
            "final\n",
            "version\n",
            ".\n",
            "Book\n",
            "Do\n",
            "not\n",
            "remove\n",
            ":\n",
            "This\n",
            "comment\n",
            "is\n",
            "monitored\n",
            "to\n",
            "verify\n",
            "that\n",
            "the\n",
            "site\n",
            "is\n",
            "working\n",
            "properly\n",
            "Abstract\n",
            "Neural\n",
            "Ordinary\n",
            "Differential\n",
            "Equations\n",
            "(\n",
            "NODEs\n",
            ")\n",
            "are\n",
            "a\n",
            "new\n",
            "class\n",
            "of\n",
            "models\n",
            "that\n",
            "transform\n",
            "data\n",
            "continuously\n",
            "through\n",
            "inﬁnite-depth\n",
            "architectures\n",
            ".\n",
            "The\n",
            "continuous\n",
            "nature\n",
            "of\n",
            "NODEs\n",
            "has\n",
            "made\n",
            "them\n",
            "particularly\n",
            "suitable\n",
            "for\n",
            "learning\n",
            "the\n",
            "dynamics\n",
            "of\n",
            "complex\n",
            "physical\n",
            "systems\n",
            ".\n",
            "While\n",
            "previous\n",
            "work\n",
            "has\n",
            "mostly\n",
            "been\n",
            "focused\n",
            "on\n",
            "ﬁrst\n",
            "order\n",
            "ODEs\n",
            ",\n",
            "the\n",
            "dynamics\n",
            "of\n",
            "many\n",
            "systems\n",
            ",\n",
            "especially\n",
            "in\n",
            "classical\n",
            "physics\n",
            ",\n",
            "are\n",
            "governed\n",
            "by\n",
            "second\n",
            "order\n",
            "laws\n",
            ".\n",
            "In\n",
            "this\n",
            "work\n",
            ",\n",
            "we\n",
            "consider\n",
            "Second\n",
            "Order\n",
            "Neural\n",
            "ODEs\n",
            "(\n",
            "SONODEs\n",
            ")\n",
            ".\n",
            "We\n",
            "show\n",
            "how\n",
            "the\n",
            "adjoint\n",
            "sensitivity\n",
            "method\n",
            "can\n",
            "be\n",
            "extended\n",
            "to\n",
            "SONODEs\n",
            "and\n",
            "prove\n",
            "that\n",
            "the\n",
            "optimisation\n",
            "of\n",
            "a\n",
            "ﬁrst\n",
            "order\n",
            "coupled\n",
            "ODE\n",
            "is\n",
            "equivalent\n",
            "and\n",
            "computationally\n",
            "more\n",
            "efﬁcient\n",
            ".\n",
            "Furthermore\n",
            ",\n",
            "we\n",
            "extend\n",
            "the\n",
            "theoretical\n",
            "understanding\n",
            "of\n",
            "the\n",
            "broader\n",
            "class\n",
            "of\n",
            "Augmented\n",
            "NODEs\n",
            "(\n",
            "ANODEs\n",
            ")\n",
            "by\n",
            "showing\n",
            "they\n",
            "can\n",
            "also\n",
            "learn\n",
            "higher\n",
            "order\n",
            "dynamics\n",
            "with\n",
            "a\n",
            "minimal\n",
            "number\n",
            "of\n",
            "augmented\n",
            "dimensions\n",
            ",\n",
            "but\n",
            "at\n",
            "the\n",
            "cost\n",
            "of\n",
            "interpretability\n",
            ".\n",
            "This\n",
            "indicates\n",
            "that\n",
            "the\n",
            "advantages\n",
            "of\n",
            "ANODEs\n",
            "go\n",
            "beyond\n",
            "the\n",
            "extra\n",
            "space\n",
            "offered\n",
            "by\n",
            "the\n",
            "augmented\n",
            "dimensions\n",
            ",\n",
            "as\n",
            "originally\n",
            "thought\n",
            ".\n",
            "Finally\n",
            ",\n",
            "we\n",
            "compare\n",
            "SONODEs\n",
            "and\n",
            "ANODEs\n",
            "on\n",
            "synthetic\n",
            "and\n",
            "real\n",
            "dynamical\n",
            "systems\n",
            "and\n",
            "demonstrate\n",
            "that\n",
            "the\n",
            "inductive\n",
            "biases\n",
            "of\n",
            "the\n",
            "former\n",
            "generally\n",
            "result\n",
            "in\n",
            "faster\n",
            "training\n",
            "and\n",
            "better\n",
            "performance\n",
            ".\n",
            "1\n",
            "Abstract\n",
            "We\n",
            "introduce\n",
            "a\n",
            "general\n",
            "framework\n",
            "for\n",
            "designing\n",
            "and\n",
            "training\n",
            "neural\n",
            "network\n",
            "layers\n",
            "whose\n",
            "forward\n",
            "passes\n",
            "can\n",
            "be\n",
            "interpreted\n",
            "as\n",
            "solving\n",
            "non-smooth\n",
            "convex\n",
            "optimization\n",
            "problems\n",
            ",\n",
            "and\n",
            "whose\n",
            "architectures\n",
            "are\n",
            "derived\n",
            "from\n",
            "an\n",
            "optimization\n",
            "algorithm\n",
            ".\n",
            "We\n",
            "focus\n",
            "on\n",
            "convex\n",
            "games\n",
            ",\n",
            "solved\n",
            "by\n",
            "local\n",
            "agents\n",
            "represented\n",
            "by\n",
            "the\n",
            "nodes\n",
            "of\n",
            "a\n",
            "graph\n",
            "and\n",
            "interacting\n",
            "through\n",
            "regularization\n",
            "functions\n",
            ".\n",
            "This\n",
            "approach\n",
            "is\n",
            "appealing\n",
            "for\n",
            "solving\n",
            "imaging\n",
            "problems\n",
            ",\n",
            "as\n",
            "it\n",
            "allows\n",
            "the\n",
            "use\n",
            "of\n",
            "classical\n",
            "image\n",
            "priors\n",
            "within\n",
            "deep\n",
            "models\n",
            "that\n",
            "are\n",
            "trainable\n",
            "end\n",
            "to\n",
            "end\n",
            ".\n",
            "The\n",
            "priors\n",
            "used\n",
            "in\n",
            "this\n",
            "presentation\n",
            "include\n",
            "variants\n",
            "of\n",
            "total\n",
            "variation\n",
            ",\n",
            "Laplacian\n",
            "regularization\n",
            ",\n",
            "bilateral\n",
            "ﬁltering\n",
            ",\n",
            "sparse\n",
            "coding\n",
            "on\n",
            "learned\n",
            "dictionaries\n",
            ",\n",
            "and\n",
            "non-local\n",
            "self\n",
            "similarities\n",
            ".\n",
            "Our\n",
            "models\n",
            "are\n",
            "fully\n",
            "interpretable\n",
            "as\n",
            "well\n",
            "as\n",
            "parameter\n",
            "and\n",
            "data\n",
            "efﬁcient\n",
            ".\n",
            "Our\n",
            "experiments\n",
            "demonstrate\n",
            "their\n",
            "effectiveness\n",
            "on\n",
            "a\n",
            "large\n",
            "diversity\n",
            "of\n",
            "tasks\n",
            "ranging\n",
            "from\n",
            "image\n",
            "denoising\n",
            "and\n",
            "compressed\n",
            "sensing\n",
            "for\n",
            "fMRI\n",
            "to\n",
            "dense\n",
            "stereo\n",
            "matching\n",
            ".\n",
            "1\n",
            "Abstract\n",
            "We\n",
            "introduce\n",
            "JAX\n",
            "MD\n",
            ",\n",
            "a\n",
            "software\n",
            "package\n",
            "for\n",
            "performing\n",
            "differentiable\n",
            "physics\n",
            "simulations\n",
            "with\n",
            "a\n",
            "focus\n",
            "on\n",
            "molecular\n",
            "dynamics\n",
            ".\n",
            "JAX\n",
            "MD\n",
            "includes\n",
            "a\n",
            "number\n",
            "of\n",
            "physics\n",
            "simulation\n",
            "environments\n",
            ",\n",
            "as\n",
            "well\n",
            "as\n",
            "interaction\n",
            "potentials\n",
            "and\n",
            "neural\n",
            "networks\n",
            "that\n",
            "can\n",
            "be\n",
            "integrated\n",
            "into\n",
            "these\n",
            "environments\n",
            "without\n",
            "writing\n",
            "any\n",
            "addi-\n",
            "tional\n",
            "code\n",
            ".\n",
            "Since\n",
            "the\n",
            "simulations\n",
            "themselves\n",
            "are\n",
            "differentiable\n",
            "functions\n",
            ",\n",
            "entire\n",
            "trajectories\n",
            "can\n",
            "be\n",
            "differentiated\n",
            "to\n",
            "perform\n",
            "meta-optimization\n",
            ".\n",
            "These\n",
            "features\n",
            "are\n",
            "built\n",
            "on\n",
            "primitive\n",
            "operations\n",
            ",\n",
            "such\n",
            "as\n",
            "spatial\n",
            "partitioning\n",
            ",\n",
            "that\n",
            "allow\n",
            "simulations\n",
            "to\n",
            "scale\n",
            "to\n",
            "hundreds-of-thousands\n",
            "of\n",
            "particles\n",
            "on\n",
            "a\n",
            "single\n",
            "GPU\n",
            ".\n",
            "These\n",
            "primitives\n",
            "are\n",
            "ﬂexible\n",
            "enough\n",
            "that\n",
            "they\n",
            "can\n",
            "be\n",
            "used\n",
            "to\n",
            "scale\n",
            "up\n",
            "workloads\n",
            "outside\n",
            "of\n",
            "molecular\n",
            "dynamics\n",
            ".\n",
            "We\n",
            "present\n",
            "several\n",
            "examples\n",
            "that\n",
            "highlight\n",
            "the\n",
            "features\n",
            "of\n",
            "JAX\n",
            "MD\n",
            "including\n",
            ":\n",
            "integration\n",
            "of\n",
            "graph\n",
            "neural\n",
            "networks\n",
            "into\n",
            "traditional\n",
            "simulations\n",
            ",\n",
            "meta-\n",
            "optimization\n",
            "through\n",
            "minimization\n",
            "of\n",
            "particle\n",
            "packings\n",
            ",\n",
            "and\n",
            "a\n",
            "multi-agent\n",
            "ﬂocking\n",
            "simulation\n",
            ".\n",
            "JAX\n",
            "MD\n",
            "is\n",
            "available\n",
            "at\n",
            "www.github.com/google/jax-md\n",
            ".\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "df_output                                                topic  \\\n",
            "0                                            neurips   \n",
            "1                                            neurips   \n",
            "2                                            neurips   \n",
            "3                                            neurips   \n",
            "4                                            neurips   \n",
            "5                                            neurips   \n",
            "6                                            neurips   \n",
            "7                                            neurips   \n",
            "8                                            neurips   \n",
            "9                                            neurips   \n",
            "0  unsupervised information theoretic perceptual ...   \n",
            "1  unsupervised information theoretic perceptual ...   \n",
            "2  unsupervised information theoretic perceptual ...   \n",
            "3  unsupervised information theoretic perceptual ...   \n",
            "4  unsupervised information theoretic perceptual ...   \n",
            "5  unsupervised information theoretic perceptual ...   \n",
            "6  unsupervised information theoretic perceptual ...   \n",
            "7  unsupervised information theoretic perceptual ...   \n",
            "8  unsupervised information theoretic perceptual ...   \n",
            "9  unsupervised information theoretic perceptual ...   \n",
            "0  self supervised multimodal versatile networks ...   \n",
            "1  self supervised multimodal versatile networks ...   \n",
            "2  self supervised multimodal versatile networks ...   \n",
            "3  self supervised multimodal versatile networks ...   \n",
            "4  self supervised multimodal versatile networks ...   \n",
            "5  self supervised multimodal versatile networks ...   \n",
            "0  benchmarking deep inverse models time neural a...   \n",
            "1  benchmarking deep inverse models time neural a...   \n",
            "2  benchmarking deep inverse models time neural a...   \n",
            "3  benchmarking deep inverse models time neural a...   \n",
            "4  benchmarking deep inverse models time neural a...   \n",
            "5  benchmarking deep inverse models time neural a...   \n",
            "6  benchmarking deep inverse models time neural a...   \n",
            "\n",
            "                                               title  \\\n",
            "0  Training Generative Adversarial Networks with ...   \n",
            "1  Estimating Training Data Influence by Tracing ...   \n",
            "2                         Deep Evidential Regression   \n",
            "3  Information Theoretic Regret Bounds for Online...   \n",
            "4           Universally Quantized Neural Compression   \n",
            "5  Advances in Neural Information Processing Syst...   \n",
            "6      Graph Contrastive Learning with Augmentations   \n",
            "7  Efficient Exact Verification of Binarized Neur...   \n",
            "8  Path Sample-Analytic Gradient Estimators for S...   \n",
            "9                           Deep Archimedean Copulas   \n",
            "0  An Unsupervised Information-Theoretic Perceptu...   \n",
            "1  An Unsupervised Information-Theoretic ... - Re...   \n",
            "2  An Unsupervised Information-Theoretic ... - Re...   \n",
            "3  Advances in Neural Information Processing Syst...   \n",
            "4  Neural FFTs for Universal Texture Image Synthesis   \n",
            "5        Object-Centric Learning with Slot Attention   \n",
            "6  Self-supervised learning through the eyes of a...   \n",
            "7  Robust Compressed Sensing using Generative Models   \n",
            "8  Network-to-Network Translation with Conditiona...   \n",
            "9  Functional Regularization for Representation L...   \n",
            "0      Self-Supervised MultiModal Versatile Networks   \n",
            "1  Advances in Neural Information Processing Syst...   \n",
            "2  Large-Scale Adversarial Training for Vision-an...   \n",
            "3  Training Generative Adversarial Networks with ...   \n",
            "4                         Bayesian Attention Modules   \n",
            "5  Language-Conditioned Imitation Learning for Ro...   \n",
            "0  Benchmarking Deep Inverse Models over time, an...   \n",
            "1  Benchmarking Deep Inverse Models ... - Review ...   \n",
            "2  Benchmarking Deep Inverse Models ... - Review ...   \n",
            "3  Advances in Neural Information Processing Syst...   \n",
            "4  On Second Order Behaviour in Augmented Neural ...   \n",
            "5  A Flexible Framework for Designing Trainable P...   \n",
            "6                                          JAX, M.D.   \n",
            "\n",
            "                                                text  \\\n",
            "0  Training Generative Adversarial Networks with ...   \n",
            "1  Estimating Training Data Influence by Tracing ...   \n",
            "2  Deep Evidential Regression\\n\\nPart of Advances...   \n",
            "3  Information Theoretic Regret Bounds for Online...   \n",
            "4  Universally Quantized Neural Compression\\n\\nPa...   \n",
            "5  Book\\n\\nDo not remove: This comment is monitor...   \n",
            "6  Graph Contrastive Learning with Augmentations\\...   \n",
            "7  Efficient Exact Verification of Binarized Neur...   \n",
            "8  Path Sample-Analytic Gradient Estimators for S...   \n",
            "9  Deep Archimedean Copulas\\n\\nPart of Advances i...   \n",
            "0  An Unsupervised Information-Theoretic Perceptu...   \n",
            "1  NeurIPS 2020\\n\\nAn Unsupervised Information-Th...   \n",
            "2  NeurIPS 2020\\n\\nAn Unsupervised Information-Th...   \n",
            "3  Book\\n\\nDo not remove: This comment is monitor...   \n",
            "4  Abstract\\n\\nSynthesizing larger texture images...   \n",
            "5  Abstract\\n\\nLearning object-centric representa...   \n",
            "6  Abstract\\n\\nWithin months of birth, children d...   \n",
            "7  Abstract\\n\\nThe goal of compressed sensing is ...   \n",
            "8  Abstract\\n\\nGiven the ever-increasing computat...   \n",
            "9  Abstract\\n\\nUnsupervised and self-supervised l...   \n",
            "0  Self-Supervised MultiModal Versatile Networks\\...   \n",
            "1  Book\\n\\nDo not remove: This comment is monitor...   \n",
            "2  Abstract\\n\\nWe present VILLA, the ﬁrst known e...   \n",
            "3  Abstract\\n\\nTraining generative adversarial ne...   \n",
            "4  Abstract\\n\\nAttention modules, as simple and e...   \n",
            "5  Abstract\\n\\nImitation learning is a popular ap...   \n",
            "0  Benchmarking Deep Inverse Models over time, an...   \n",
            "1  NeurIPS 2020\\n\\nBenchmarking Deep Inverse Mode...   \n",
            "2  NeurIPS 2020\\n\\nBenchmarking Deep Inverse Mode...   \n",
            "3  Book\\n\\nDo not remove: This comment is monitor...   \n",
            "4  Abstract\\n\\nNeural Ordinary Differential Equat...   \n",
            "5  Abstract\\n\\nWe introduce a general framework f...   \n",
            "6  Abstract\\n\\nWe introduce JAX MD, a software pa...   \n",
            "\n",
            "                                                 url  similarity_score  rank  \\\n",
            "0  https://papers.nips.cc/paper/2020/hash/8d30aa9...          0.965153   3.0   \n",
            "1  https://papers.nips.cc/paper/2020/hash/e6385d3...          0.965144   4.0   \n",
            "2  https://papers.nips.cc/paper/2020/hash/aab0854...          0.965102   6.0   \n",
            "3  https://papers.nips.cc/paper/2020/hash/aee5620...          0.965130   5.0   \n",
            "4  https://papers.nips.cc/paper/2020/hash/92049de...          0.965285   2.0   \n",
            "5                  https://papers.nips.cc/paper/2020          0.965377   1.0   \n",
            "6  https://papers.nips.cc/paper/2020/hash/3fe2303...          0.960548  10.0   \n",
            "7  https://papers.nips.cc/paper/2020/hash/1385974...          0.962081   7.0   \n",
            "8  https://papers.nips.cc/paper/2020/hash/96fca94...          0.961407   9.0   \n",
            "9  https://papers.nips.cc/paper/2020/hash/10eb650...          0.961599   8.0   \n",
            "0  https://papers.nips.cc/paper/2020/hash/00482b9...          0.960361   6.0   \n",
            "1  https://papers.nips.cc/paper/2020/file/00482b9...          0.940551  10.0   \n",
            "2  https://papers.nips.cc/paper/2020/file/00482b9...          0.960248   8.0   \n",
            "3                  https://papers.nips.cc/paper/2020          0.964870   1.0   \n",
            "4  https://papers.nips.cc/paper/2020/file/a23156a...          0.960257   7.0   \n",
            "5  https://papers.nips.cc/paper/2020/file/8511df9...          0.959921   9.0   \n",
            "6  https://papers.nips.cc/paper/2020/file/7183145...          0.964294   2.0   \n",
            "7  https://papers.nips.cc/paper/2020/file/07cb5f8...          0.963900   3.0   \n",
            "8  https://papers.nips.cc/paper/2020/file/1cfa81a...          0.963835   4.0   \n",
            "9  https://papers.nips.cc/paper/2020/file/c793b3b...          0.961062   5.0   \n",
            "0  https://papers.nips.cc/paper/2020/hash/0060ef4...          0.965593   4.0   \n",
            "1                  https://papers.nips.cc/paper/2020          0.966477   1.0   \n",
            "2  https://papers.nips.cc/paper/2020/file/4956247...          0.965714   3.0   \n",
            "3  https://papers.nips.cc/paper/2020/file/8d30aa9...          0.963016   5.0   \n",
            "4  https://papers.nips.cc/paper/2020/file/bcff3f6...          0.962894   6.0   \n",
            "5  https://papers.nips.cc/paper/2020/file/9909794...          0.966408   2.0   \n",
            "0  https://papers.nips.cc/paper/2020/hash/007ff38...          0.961588   6.0   \n",
            "1  https://papers.nips.cc/paper/2020/file/007ff38...          0.966438   2.0   \n",
            "2  https://papers.nips.cc/paper/2020/file/007ff38...          0.966165   3.0   \n",
            "3                  https://papers.nips.cc/paper/2020          0.965975   4.0   \n",
            "4  https://papers.nips.cc/paper/2020/file/418db2e...          0.961224   7.0   \n",
            "5  https://papers.nips.cc/paper/2020/file/b4edda6...          0.962293   5.0   \n",
            "6  https://papers.nips.cc/paper/2020/file/83d3d4b...          0.966740   1.0   \n",
            "\n",
            "   similarity_score_lda  rank_lda  \n",
            "0              0.976416       8.0  \n",
            "1              0.976422       7.0  \n",
            "2              0.976501       5.0  \n",
            "3              0.976803       3.0  \n",
            "4              0.976386       9.0  \n",
            "5              0.976283      10.0  \n",
            "6              0.977023       1.0  \n",
            "7              0.976987       2.0  \n",
            "8              0.976438       6.0  \n",
            "9              0.976682       4.0  \n",
            "0              0.976147       8.0  \n",
            "1              0.975887       9.0  \n",
            "2              0.976883       2.0  \n",
            "3              0.976728       5.0  \n",
            "4              0.975769      10.0  \n",
            "5              0.976862       3.0  \n",
            "6              0.976213       7.0  \n",
            "7              0.977043       1.0  \n",
            "8              0.976403       6.0  \n",
            "9              0.976810       4.0  \n",
            "0              0.977262       6.0  \n",
            "1              0.978460       1.0  \n",
            "2              0.978236       4.0  \n",
            "3              0.977762       5.0  \n",
            "4              0.978310       2.0  \n",
            "5              0.978285       3.0  \n",
            "0              0.976925       4.0  \n",
            "1              0.976647       7.0  \n",
            "2              0.977214       1.0  \n",
            "3              0.976798       6.0  \n",
            "4              0.977014       2.0  \n",
            "5              0.976808       5.0  \n",
            "6              0.976971       3.0  \n",
            "topic:  off policy evaluation learning external validity covariate shift neurips id_= 4\n",
            "1 . Off-Policy Evaluation and Learning for External Validity under a ... https://papers.nips.cc/paper/2020/file/0084ae4bc24c0795d1e6a4f58444d39b-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "We consider evaluating and training a new policy for the evaluation data by using\n",
            "the historical data obtained from a different policy. The goal of off-policy evalua-\n",
            "tion (OPE) is to estimate the expected reward of a new policy over the evaluation\n",
            "data, and that of off-policy learning (OPL) is to ﬁnd a new policy that maximizes\n",
            "the expected reward over the evaluation data. Although the standard OPE and\n",
            "OPL methods assume the same distribution of covariate between the historical\n",
            "and evaluation data, a covariate shift often exists in real-world applications, i.e.,\n",
            "the distribution of the covariate of the historical data is different from that of the\n",
            "evaluation data. In this paper, we derive the efﬁciency bound of an OPE estimator\n",
            "under a covariate shift. Then, we propose doubly robust and efﬁcient estimators\n",
            "for OPE and OPL under a covariate shift by using a nonparametric estimator of\n",
            "the density ratio between the historical and evaluation data distributions. We also\n",
            "discuss other possible estimators and compare their theoretical properties. Finally,\n",
            "we conduct experiments to conﬁrm the effectiveness of the proposed estimators.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "2 . Advances in Neural Information Processing Systems 33 (NeurIPS ... https://papers.nips.cc/paper/2020\n",
            "**********************************************\n",
            "3 . Fourier Sparse Leverage Scores and Approximate Kernel Learning https://papers.nips.cc/paper/2020/file/012d9fe15b2493f21902cd55603382ec-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "s-sparse functions of the form f (x) = (cid:80)s\n",
            "\n",
            "We prove new explicit upper bounds on the leverage scores of Fourier sparse\n",
            "functions under both the Gaussian and Laplace measures. In particular, we study\n",
            "j=1 ajeiλj x for coefﬁcients aj ∈ C\n",
            "and frequencies λj ∈ R. Bounding Fourier sparse leverage scores under various\n",
            "measures is of pure mathematical interest in approximation theory, and our work\n",
            "extends existing results for the uniform measure [Erd17, CP19a]. Practically, our\n",
            "bounds are motivated by two important applications in machine learning:\n",
            "1. Kernel Approximation. They yield a new random Fourier features algorithm\n",
            "for approximating Gaussian and Cauchy (rational quadratic) kernel matrices. For\n",
            "low-dimensional data, our method uses a near optimal number of features, and its\n",
            "runtime is polynomial in the statistical dimension of the approximated kernel matrix.\n",
            "It is the ﬁrst “oblivious sketching method” with this property for any kernel besides\n",
            "the polynomial kernel, resolving an open question of [AKM+17, AKK+20b].\n",
            "2. Active Learning. They can be used as non-uniform sampling distributions\n",
            "for robust active learning when data follows a Gaussian or Laplace distribution.\n",
            "Using the framework of [AKM+19], we provide essentially optimal results for\n",
            "bandlimited and multiband interpolation, and Gaussian process regression. These\n",
            "results generalize existing work that only applies to uniformly distributed data.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "4 . Fourier Sparse Leverage Scores and Approximate Kernel Learning https://papers.nips.cc/paper/2020/file/012d9fe15b2493f21902cd55603382ec-Supplemental.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "s-sparse functions of the form f (x) = (cid:80)s\n",
            "\n",
            "We prove new explicit upper bounds on the leverage scores of Fourier sparse\n",
            "functions under both the Gaussian and Laplace measures. In particular, we study\n",
            "j=1 ajeiλj x for coefﬁcients aj ∈ C\n",
            "and frequencies λj ∈ R. Bounding Fourier sparse leverage scores under various\n",
            "measures is of pure mathematical interest in approximation theory, and our work\n",
            "extends existing results for the uniform measure [Erd17, CP19a]. Practically, our\n",
            "bounds are motivated by two important applications in machine learning:\n",
            "1. Kernel Approximation. They yield a new random Fourier features algorithm\n",
            "for approximating Gaussian and Cauchy (rational quadratic) kernel matrices. For\n",
            "low-dimensional data, our method uses a near optimal number of features, and its\n",
            "runtime is polynomial in the statistical dimension of the approximated kernel matrix.\n",
            "It is the ﬁrst “oblivious sketching method” with this property for any kernel besides\n",
            "the polynomial kernel, resolving an open question of [AKM+17, AKK+20b].\n",
            "2. Active Learning. They can be used as non-uniform sampling distributions\n",
            "for robust active learning when data follows a Gaussian or Laplace distribution.\n",
            "Using the framework of [AKM+19], we provide essentially optimal results for\n",
            "bandlimited and multiband interpolation, and Gaussian process regression. These\n",
            "results generalize existing work that only applies to uniformly distributed data.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "5 . Recurrent Switching Dynamical Systems Models for Multiple ... https://papers.nips.cc/paper/2020/file/aa1f5f73327ba40d47ebce155e785aaf-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Modern recording techniques can generate large-scale measurements of multiple\n",
            "neural populations over extended time periods. However, it remains a challenge to\n",
            "model non-stationary interactions between high-dimensional populations of neu-\n",
            "rons. To tackle this challenge, we develop recurrent switching linear dynamical\n",
            "systems models for multiple populations. Here, each high-dimensional neural\n",
            "population is represented by a unique set of latent variables, which evolve dynam-\n",
            "ically in time. Populations interact with each other through this low-dimensional\n",
            "space. We allow the nature of these interactions to change over time by using a\n",
            "discrete set of dynamical states. Additionally, we parameterize these discrete state\n",
            "transition rules to capture which neural populations are responsible for switch-\n",
            "ing between interaction states. To ﬁt the model, we use variational expectation-\n",
            "maximization with a structured mean-ﬁeld approximation. After validating the\n",
            "model on simulations, we apply it to two different neural datasets: spiking activity\n",
            "from motor areas in a non-human primate, and calcium imaging from neurons in\n",
            "the nematode C. elegans. In both datasets, the model reveals behaviorally-relevant\n",
            "discrete states with unique inter-population interactions and different populations\n",
            "that predict transitioning between these states.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "data:                                                topic  \\\n",
            "0  off policy evaluation learning external validi...   \n",
            "1  off policy evaluation learning external validi...   \n",
            "2  off policy evaluation learning external validi...   \n",
            "3  off policy evaluation learning external validi...   \n",
            "4  off policy evaluation learning external validi...   \n",
            "\n",
            "                                               title  \\\n",
            "0  Off-Policy Evaluation and Learning for Externa...   \n",
            "1  Advances in Neural Information Processing Syst...   \n",
            "2  Fourier Sparse Leverage Scores and Approximate...   \n",
            "3  Fourier Sparse Leverage Scores and Approximate...   \n",
            "4  Recurrent Switching Dynamical Systems Models f...   \n",
            "\n",
            "                                                text  \\\n",
            "0  Abstract\\n\\nWe consider evaluating and trainin...   \n",
            "1  Book\\n\\nDo not remove: This comment is monitor...   \n",
            "2  Abstract\\n\\ns-sparse functions of the form f (...   \n",
            "3  Abstract\\n\\ns-sparse functions of the form f (...   \n",
            "4  Abstract\\n\\nModern recording techniques can ge...   \n",
            "\n",
            "                                                 url  \n",
            "0  https://papers.nips.cc/paper/2020/file/0084ae4...  \n",
            "1                  https://papers.nips.cc/paper/2020  \n",
            "2  https://papers.nips.cc/paper/2020/file/012d9fe...  \n",
            "3  https://papers.nips.cc/paper/2020/file/012d9fe...  \n",
            "4  https://papers.nips.cc/paper/2020/file/aa1f5f7...  \n",
            "**********************************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                                               topic  \\\n",
            "0  off policy evaluation learning external validi...   \n",
            "1  off policy evaluation learning external validi...   \n",
            "2  off policy evaluation learning external validi...   \n",
            "3  off policy evaluation learning external validi...   \n",
            "4  off policy evaluation learning external validi...   \n",
            "\n",
            "                                               title  \\\n",
            "0  Off-Policy Evaluation and Learning for Externa...   \n",
            "1  Advances in Neural Information Processing Syst...   \n",
            "2  Fourier Sparse Leverage Scores and Approximate...   \n",
            "3  Fourier Sparse Leverage Scores and Approximate...   \n",
            "4  Recurrent Switching Dynamical Systems Models f...   \n",
            "\n",
            "                                                text  \\\n",
            "0  Abstract\\n\\nWe consider evaluating and trainin...   \n",
            "1  Book\\n\\nDo not remove: This comment is monitor...   \n",
            "2  Abstract\\n\\ns-sparse functions of the form f (...   \n",
            "3  Abstract\\n\\ns-sparse functions of the form f (...   \n",
            "4  Abstract\\n\\nModern recording techniques can ge...   \n",
            "\n",
            "                                                 url  similarity_score  \n",
            "0  https://papers.nips.cc/paper/2020/file/0084ae4...          0.961221  \n",
            "1                  https://papers.nips.cc/paper/2020          0.965306  \n",
            "2  https://papers.nips.cc/paper/2020/file/012d9fe...          0.961443  \n",
            "3  https://papers.nips.cc/paper/2020/file/012d9fe...          0.961443  \n",
            "4  https://papers.nips.cc/paper/2020/file/aa1f5f7...          0.965760  \n",
            "df_final after rank=                                                topic  \\\n",
            "0  off policy evaluation learning external validi...   \n",
            "1  off policy evaluation learning external validi...   \n",
            "2  off policy evaluation learning external validi...   \n",
            "3  off policy evaluation learning external validi...   \n",
            "4  off policy evaluation learning external validi...   \n",
            "\n",
            "                                               title  \\\n",
            "0  Off-Policy Evaluation and Learning for Externa...   \n",
            "1  Advances in Neural Information Processing Syst...   \n",
            "2  Fourier Sparse Leverage Scores and Approximate...   \n",
            "3  Fourier Sparse Leverage Scores and Approximate...   \n",
            "4  Recurrent Switching Dynamical Systems Models f...   \n",
            "\n",
            "                                                text  \\\n",
            "0  Abstract\\n\\nWe consider evaluating and trainin...   \n",
            "1  Book\\n\\nDo not remove: This comment is monitor...   \n",
            "2  Abstract\\n\\ns-sparse functions of the form f (...   \n",
            "3  Abstract\\n\\ns-sparse functions of the form f (...   \n",
            "4  Abstract\\n\\nModern recording techniques can ge...   \n",
            "\n",
            "                                                 url  similarity_score  rank  \n",
            "0  https://papers.nips.cc/paper/2020/file/0084ae4...          0.961221   5.0  \n",
            "1                  https://papers.nips.cc/paper/2020          0.965306   2.0  \n",
            "2  https://papers.nips.cc/paper/2020/file/012d9fe...          0.961443   4.0  \n",
            "3  https://papers.nips.cc/paper/2020/file/012d9fe...          0.961443   4.0  \n",
            "4  https://papers.nips.cc/paper/2020/file/aa1f5f7...          0.965760   1.0  \n",
            "0    Abstract\\n\\nWe consider evaluating and trainin...\n",
            "1    Book\\n\\nDo not remove: This comment is monitor...\n",
            "2    Abstract\\n\\ns-sparse functions of the form f (...\n",
            "3    Abstract\\n\\ns-sparse functions of the form f (...\n",
            "4    Abstract\\n\\nModern recording techniques can ge...\n",
            "Name: text, dtype: object\n",
            "Abstract\n",
            "We\n",
            "consider\n",
            "evaluating\n",
            "and\n",
            "training\n",
            "a\n",
            "new\n",
            "policy\n",
            "for\n",
            "the\n",
            "evaluation\n",
            "data\n",
            "by\n",
            "using\n",
            "the\n",
            "historical\n",
            "data\n",
            "obtained\n",
            "from\n",
            "a\n",
            "different\n",
            "policy\n",
            ".\n",
            "The\n",
            "goal\n",
            "of\n",
            "off-policy\n",
            "evalua-\n",
            "tion\n",
            "(\n",
            "OPE\n",
            ")\n",
            "is\n",
            "to\n",
            "estimate\n",
            "the\n",
            "expected\n",
            "reward\n",
            "of\n",
            "a\n",
            "new\n",
            "policy\n",
            "over\n",
            "the\n",
            "evaluation\n",
            "data\n",
            ",\n",
            "and\n",
            "that\n",
            "of\n",
            "off-policy\n",
            "learning\n",
            "(\n",
            "OPL\n",
            ")\n",
            "is\n",
            "to\n",
            "ﬁnd\n",
            "a\n",
            "new\n",
            "policy\n",
            "that\n",
            "maximizes\n",
            "the\n",
            "expected\n",
            "reward\n",
            "over\n",
            "the\n",
            "evaluation\n",
            "data\n",
            ".\n",
            "Although\n",
            "the\n",
            "standard\n",
            "OPE\n",
            "and\n",
            "OPL\n",
            "methods\n",
            "assume\n",
            "the\n",
            "same\n",
            "distribution\n",
            "of\n",
            "covariate\n",
            "between\n",
            "the\n",
            "historical\n",
            "and\n",
            "evaluation\n",
            "data\n",
            ",\n",
            "a\n",
            "covariate\n",
            "shift\n",
            "often\n",
            "exists\n",
            "in\n",
            "real-world\n",
            "applications\n",
            ",\n",
            "i.e.\n",
            ",\n",
            "the\n",
            "distribution\n",
            "of\n",
            "the\n",
            "covariate\n",
            "of\n",
            "the\n",
            "historical\n",
            "data\n",
            "is\n",
            "different\n",
            "from\n",
            "that\n",
            "of\n",
            "the\n",
            "evaluation\n",
            "data\n",
            ".\n",
            "In\n",
            "this\n",
            "paper\n",
            ",\n",
            "we\n",
            "derive\n",
            "the\n",
            "efﬁciency\n",
            "bound\n",
            "of\n",
            "an\n",
            "OPE\n",
            "estimator\n",
            "under\n",
            "a\n",
            "covariate\n",
            "shift\n",
            ".\n",
            "Then\n",
            ",\n",
            "we\n",
            "propose\n",
            "doubly\n",
            "robust\n",
            "and\n",
            "efﬁcient\n",
            "estimators\n",
            "for\n",
            "OPE\n",
            "and\n",
            "OPL\n",
            "under\n",
            "a\n",
            "covariate\n",
            "shift\n",
            "by\n",
            "using\n",
            "a\n",
            "nonparametric\n",
            "estimator\n",
            "of\n",
            "the\n",
            "density\n",
            "ratio\n",
            "between\n",
            "the\n",
            "historical\n",
            "and\n",
            "evaluation\n",
            "data\n",
            "distributions\n",
            ".\n",
            "We\n",
            "also\n",
            "discuss\n",
            "other\n",
            "possible\n",
            "estimators\n",
            "and\n",
            "compare\n",
            "their\n",
            "theoretical\n",
            "properties\n",
            ".\n",
            "Finally\n",
            ",\n",
            "we\n",
            "conduct\n",
            "experiments\n",
            "to\n",
            "conﬁrm\n",
            "the\n",
            "effectiveness\n",
            "of\n",
            "the\n",
            "proposed\n",
            "estimators\n",
            ".\n",
            "1\n",
            "Book\n",
            "Do\n",
            "not\n",
            "remove\n",
            ":\n",
            "This\n",
            "comment\n",
            "is\n",
            "monitored\n",
            "to\n",
            "verify\n",
            "that\n",
            "the\n",
            "site\n",
            "is\n",
            "working\n",
            "properly\n",
            "Abstract\n",
            "s-sparse\n",
            "functions\n",
            "of\n",
            "the\n",
            "form\n",
            "f\n",
            "(\n",
            "x\n",
            ")\n",
            "=\n",
            "(\n",
            "cid:80\n",
            ")\n",
            "s\n",
            "We\n",
            "prove\n",
            "new\n",
            "explicit\n",
            "upper\n",
            "bounds\n",
            "on\n",
            "the\n",
            "leverage\n",
            "scores\n",
            "of\n",
            "Fourier\n",
            "sparse\n",
            "functions\n",
            "under\n",
            "both\n",
            "the\n",
            "Gaussian\n",
            "and\n",
            "Laplace\n",
            "measures\n",
            ".\n",
            "In\n",
            "particular\n",
            ",\n",
            "we\n",
            "study\n",
            "j=1\n",
            "ajeiλj\n",
            "x\n",
            "for\n",
            "coefﬁcients\n",
            "aj\n",
            "∈\n",
            "C\n",
            "and\n",
            "frequencies\n",
            "λj\n",
            "∈\n",
            "R.\n",
            "Bounding\n",
            "Fourier\n",
            "sparse\n",
            "leverage\n",
            "scores\n",
            "under\n",
            "various\n",
            "measures\n",
            "is\n",
            "of\n",
            "pure\n",
            "mathematical\n",
            "interest\n",
            "in\n",
            "approximation\n",
            "theory\n",
            ",\n",
            "and\n",
            "our\n",
            "work\n",
            "extends\n",
            "existing\n",
            "results\n",
            "for\n",
            "the\n",
            "uniform\n",
            "measure\n",
            "[\n",
            "Erd17\n",
            ",\n",
            "CP19a\n",
            "]\n",
            ".\n",
            "Practically\n",
            ",\n",
            "our\n",
            "bounds\n",
            "are\n",
            "motivated\n",
            "by\n",
            "two\n",
            "important\n",
            "applications\n",
            "in\n",
            "machine\n",
            "learning\n",
            ":\n",
            "1\n",
            ".\n",
            "Kernel\n",
            "Approximation\n",
            ".\n",
            "They\n",
            "yield\n",
            "a\n",
            "new\n",
            "random\n",
            "Fourier\n",
            "features\n",
            "algorithm\n",
            "for\n",
            "approximating\n",
            "Gaussian\n",
            "and\n",
            "Cauchy\n",
            "(\n",
            "rational\n",
            "quadratic\n",
            ")\n",
            "kernel\n",
            "matrices\n",
            ".\n",
            "For\n",
            "low-dimensional\n",
            "data\n",
            ",\n",
            "our\n",
            "method\n",
            "uses\n",
            "a\n",
            "near\n",
            "optimal\n",
            "number\n",
            "of\n",
            "features\n",
            ",\n",
            "and\n",
            "its\n",
            "runtime\n",
            "is\n",
            "polynomial\n",
            "in\n",
            "the\n",
            "statistical\n",
            "dimension\n",
            "of\n",
            "the\n",
            "approximated\n",
            "kernel\n",
            "matrix\n",
            ".\n",
            "It\n",
            "is\n",
            "the\n",
            "ﬁrst\n",
            "“\n",
            "oblivious\n",
            "sketching\n",
            "method\n",
            "”\n",
            "with\n",
            "this\n",
            "property\n",
            "for\n",
            "any\n",
            "kernel\n",
            "besides\n",
            "the\n",
            "polynomial\n",
            "kernel\n",
            ",\n",
            "resolving\n",
            "an\n",
            "open\n",
            "question\n",
            "of\n",
            "[\n",
            "AKM+17\n",
            ",\n",
            "AKK+20b\n",
            "]\n",
            ".\n",
            "2\n",
            ".\n",
            "Active\n",
            "Learning\n",
            ".\n",
            "They\n",
            "can\n",
            "be\n",
            "used\n",
            "as\n",
            "non-uniform\n",
            "sampling\n",
            "distributions\n",
            "for\n",
            "robust\n",
            "active\n",
            "learning\n",
            "when\n",
            "data\n",
            "follows\n",
            "a\n",
            "Gaussian\n",
            "or\n",
            "Laplace\n",
            "distribution\n",
            ".\n",
            "Using\n",
            "the\n",
            "framework\n",
            "of\n",
            "[\n",
            "AKM+19\n",
            "]\n",
            ",\n",
            "we\n",
            "provide\n",
            "essentially\n",
            "optimal\n",
            "results\n",
            "for\n",
            "bandlimited\n",
            "and\n",
            "multiband\n",
            "interpolation\n",
            ",\n",
            "and\n",
            "Gaussian\n",
            "process\n",
            "regression\n",
            ".\n",
            "These\n",
            "results\n",
            "generalize\n",
            "existing\n",
            "work\n",
            "that\n",
            "only\n",
            "applies\n",
            "to\n",
            "uniformly\n",
            "distributed\n",
            "data\n",
            ".\n",
            "1\n",
            "Abstract\n",
            "s-sparse\n",
            "functions\n",
            "of\n",
            "the\n",
            "form\n",
            "f\n",
            "(\n",
            "x\n",
            ")\n",
            "=\n",
            "(\n",
            "cid:80\n",
            ")\n",
            "s\n",
            "We\n",
            "prove\n",
            "new\n",
            "explicit\n",
            "upper\n",
            "bounds\n",
            "on\n",
            "the\n",
            "leverage\n",
            "scores\n",
            "of\n",
            "Fourier\n",
            "sparse\n",
            "functions\n",
            "under\n",
            "both\n",
            "the\n",
            "Gaussian\n",
            "and\n",
            "Laplace\n",
            "measures\n",
            ".\n",
            "In\n",
            "particular\n",
            ",\n",
            "we\n",
            "study\n",
            "j=1\n",
            "ajeiλj\n",
            "x\n",
            "for\n",
            "coefﬁcients\n",
            "aj\n",
            "∈\n",
            "C\n",
            "and\n",
            "frequencies\n",
            "λj\n",
            "∈\n",
            "R.\n",
            "Bounding\n",
            "Fourier\n",
            "sparse\n",
            "leverage\n",
            "scores\n",
            "under\n",
            "various\n",
            "measures\n",
            "is\n",
            "of\n",
            "pure\n",
            "mathematical\n",
            "interest\n",
            "in\n",
            "approximation\n",
            "theory\n",
            ",\n",
            "and\n",
            "our\n",
            "work\n",
            "extends\n",
            "existing\n",
            "results\n",
            "for\n",
            "the\n",
            "uniform\n",
            "measure\n",
            "[\n",
            "Erd17\n",
            ",\n",
            "CP19a\n",
            "]\n",
            ".\n",
            "Practically\n",
            ",\n",
            "our\n",
            "bounds\n",
            "are\n",
            "motivated\n",
            "by\n",
            "two\n",
            "important\n",
            "applications\n",
            "in\n",
            "machine\n",
            "learning\n",
            ":\n",
            "1\n",
            ".\n",
            "Kernel\n",
            "Approximation\n",
            ".\n",
            "They\n",
            "yield\n",
            "a\n",
            "new\n",
            "random\n",
            "Fourier\n",
            "features\n",
            "algorithm\n",
            "for\n",
            "approximating\n",
            "Gaussian\n",
            "and\n",
            "Cauchy\n",
            "(\n",
            "rational\n",
            "quadratic\n",
            ")\n",
            "kernel\n",
            "matrices\n",
            ".\n",
            "For\n",
            "low-dimensional\n",
            "data\n",
            ",\n",
            "our\n",
            "method\n",
            "uses\n",
            "a\n",
            "near\n",
            "optimal\n",
            "number\n",
            "of\n",
            "features\n",
            ",\n",
            "and\n",
            "its\n",
            "runtime\n",
            "is\n",
            "polynomial\n",
            "in\n",
            "the\n",
            "statistical\n",
            "dimension\n",
            "of\n",
            "the\n",
            "approximated\n",
            "kernel\n",
            "matrix\n",
            ".\n",
            "It\n",
            "is\n",
            "the\n",
            "ﬁrst\n",
            "“\n",
            "oblivious\n",
            "sketching\n",
            "method\n",
            "”\n",
            "with\n",
            "this\n",
            "property\n",
            "for\n",
            "any\n",
            "kernel\n",
            "besides\n",
            "the\n",
            "polynomial\n",
            "kernel\n",
            ",\n",
            "resolving\n",
            "an\n",
            "open\n",
            "question\n",
            "of\n",
            "[\n",
            "AKM+17\n",
            ",\n",
            "AKK+20b\n",
            "]\n",
            ".\n",
            "2\n",
            ".\n",
            "Active\n",
            "Learning\n",
            ".\n",
            "They\n",
            "can\n",
            "be\n",
            "used\n",
            "as\n",
            "non-uniform\n",
            "sampling\n",
            "distributions\n",
            "for\n",
            "robust\n",
            "active\n",
            "learning\n",
            "when\n",
            "data\n",
            "follows\n",
            "a\n",
            "Gaussian\n",
            "or\n",
            "Laplace\n",
            "distribution\n",
            ".\n",
            "Using\n",
            "the\n",
            "framework\n",
            "of\n",
            "[\n",
            "AKM+19\n",
            "]\n",
            ",\n",
            "we\n",
            "provide\n",
            "essentially\n",
            "optimal\n",
            "results\n",
            "for\n",
            "bandlimited\n",
            "and\n",
            "multiband\n",
            "interpolation\n",
            ",\n",
            "and\n",
            "Gaussian\n",
            "process\n",
            "regression\n",
            ".\n",
            "These\n",
            "results\n",
            "generalize\n",
            "existing\n",
            "work\n",
            "that\n",
            "only\n",
            "applies\n",
            "to\n",
            "uniformly\n",
            "distributed\n",
            "data\n",
            ".\n",
            "1\n",
            "Abstract\n",
            "Modern\n",
            "recording\n",
            "techniques\n",
            "can\n",
            "generate\n",
            "large-scale\n",
            "measurements\n",
            "of\n",
            "multiple\n",
            "neural\n",
            "populations\n",
            "over\n",
            "extended\n",
            "time\n",
            "periods\n",
            ".\n",
            "However\n",
            ",\n",
            "it\n",
            "remains\n",
            "a\n",
            "challenge\n",
            "to\n",
            "model\n",
            "non-stationary\n",
            "interactions\n",
            "between\n",
            "high-dimensional\n",
            "populations\n",
            "of\n",
            "neu-\n",
            "rons\n",
            ".\n",
            "To\n",
            "tackle\n",
            "this\n",
            "challenge\n",
            ",\n",
            "we\n",
            "develop\n",
            "recurrent\n",
            "switching\n",
            "linear\n",
            "dynamical\n",
            "systems\n",
            "models\n",
            "for\n",
            "multiple\n",
            "populations\n",
            ".\n",
            "Here\n",
            ",\n",
            "each\n",
            "high-dimensional\n",
            "neural\n",
            "population\n",
            "is\n",
            "represented\n",
            "by\n",
            "a\n",
            "unique\n",
            "set\n",
            "of\n",
            "latent\n",
            "variables\n",
            ",\n",
            "which\n",
            "evolve\n",
            "dynam-\n",
            "ically\n",
            "in\n",
            "time\n",
            ".\n",
            "Populations\n",
            "interact\n",
            "with\n",
            "each\n",
            "other\n",
            "through\n",
            "this\n",
            "low-dimensional\n",
            "space\n",
            ".\n",
            "We\n",
            "allow\n",
            "the\n",
            "nature\n",
            "of\n",
            "these\n",
            "interactions\n",
            "to\n",
            "change\n",
            "over\n",
            "time\n",
            "by\n",
            "using\n",
            "a\n",
            "discrete\n",
            "set\n",
            "of\n",
            "dynamical\n",
            "states\n",
            ".\n",
            "Additionally\n",
            ",\n",
            "we\n",
            "parameterize\n",
            "these\n",
            "discrete\n",
            "state\n",
            "transition\n",
            "rules\n",
            "to\n",
            "capture\n",
            "which\n",
            "neural\n",
            "populations\n",
            "are\n",
            "responsible\n",
            "for\n",
            "switch-\n",
            "ing\n",
            "between\n",
            "interaction\n",
            "states\n",
            ".\n",
            "To\n",
            "ﬁt\n",
            "the\n",
            "model\n",
            ",\n",
            "we\n",
            "use\n",
            "variational\n",
            "expectation-\n",
            "maximization\n",
            "with\n",
            "a\n",
            "structured\n",
            "mean-ﬁeld\n",
            "approximation\n",
            ".\n",
            "After\n",
            "validating\n",
            "the\n",
            "model\n",
            "on\n",
            "simulations\n",
            ",\n",
            "we\n",
            "apply\n",
            "it\n",
            "to\n",
            "two\n",
            "different\n",
            "neural\n",
            "datasets\n",
            ":\n",
            "spiking\n",
            "activity\n",
            "from\n",
            "motor\n",
            "areas\n",
            "in\n",
            "a\n",
            "non-human\n",
            "primate\n",
            ",\n",
            "and\n",
            "calcium\n",
            "imaging\n",
            "from\n",
            "neurons\n",
            "in\n",
            "the\n",
            "nematode\n",
            "C.\n",
            "elegans\n",
            ".\n",
            "In\n",
            "both\n",
            "datasets\n",
            ",\n",
            "the\n",
            "model\n",
            "reveals\n",
            "behaviorally-relevant\n",
            "discrete\n",
            "states\n",
            "with\n",
            "unique\n",
            "inter-population\n",
            "interactions\n",
            "and\n",
            "different\n",
            "populations\n",
            "that\n",
            "predict\n",
            "transitioning\n",
            "between\n",
            "these\n",
            "states\n",
            ".\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "df_output                                                topic  \\\n",
            "0                                            neurips   \n",
            "1                                            neurips   \n",
            "2                                            neurips   \n",
            "3                                            neurips   \n",
            "4                                            neurips   \n",
            "5                                            neurips   \n",
            "6                                            neurips   \n",
            "7                                            neurips   \n",
            "8                                            neurips   \n",
            "9                                            neurips   \n",
            "0  unsupervised information theoretic perceptual ...   \n",
            "1  unsupervised information theoretic perceptual ...   \n",
            "2  unsupervised information theoretic perceptual ...   \n",
            "3  unsupervised information theoretic perceptual ...   \n",
            "4  unsupervised information theoretic perceptual ...   \n",
            "5  unsupervised information theoretic perceptual ...   \n",
            "6  unsupervised information theoretic perceptual ...   \n",
            "7  unsupervised information theoretic perceptual ...   \n",
            "8  unsupervised information theoretic perceptual ...   \n",
            "9  unsupervised information theoretic perceptual ...   \n",
            "0  self supervised multimodal versatile networks ...   \n",
            "1  self supervised multimodal versatile networks ...   \n",
            "2  self supervised multimodal versatile networks ...   \n",
            "3  self supervised multimodal versatile networks ...   \n",
            "4  self supervised multimodal versatile networks ...   \n",
            "5  self supervised multimodal versatile networks ...   \n",
            "0  benchmarking deep inverse models time neural a...   \n",
            "1  benchmarking deep inverse models time neural a...   \n",
            "2  benchmarking deep inverse models time neural a...   \n",
            "3  benchmarking deep inverse models time neural a...   \n",
            "4  benchmarking deep inverse models time neural a...   \n",
            "5  benchmarking deep inverse models time neural a...   \n",
            "6  benchmarking deep inverse models time neural a...   \n",
            "0  off policy evaluation learning external validi...   \n",
            "1  off policy evaluation learning external validi...   \n",
            "2  off policy evaluation learning external validi...   \n",
            "3  off policy evaluation learning external validi...   \n",
            "4  off policy evaluation learning external validi...   \n",
            "\n",
            "                                               title  \\\n",
            "0  Training Generative Adversarial Networks with ...   \n",
            "1  Estimating Training Data Influence by Tracing ...   \n",
            "2                         Deep Evidential Regression   \n",
            "3  Information Theoretic Regret Bounds for Online...   \n",
            "4           Universally Quantized Neural Compression   \n",
            "5  Advances in Neural Information Processing Syst...   \n",
            "6      Graph Contrastive Learning with Augmentations   \n",
            "7  Efficient Exact Verification of Binarized Neur...   \n",
            "8  Path Sample-Analytic Gradient Estimators for S...   \n",
            "9                           Deep Archimedean Copulas   \n",
            "0  An Unsupervised Information-Theoretic Perceptu...   \n",
            "1  An Unsupervised Information-Theoretic ... - Re...   \n",
            "2  An Unsupervised Information-Theoretic ... - Re...   \n",
            "3  Advances in Neural Information Processing Syst...   \n",
            "4  Neural FFTs for Universal Texture Image Synthesis   \n",
            "5        Object-Centric Learning with Slot Attention   \n",
            "6  Self-supervised learning through the eyes of a...   \n",
            "7  Robust Compressed Sensing using Generative Models   \n",
            "8  Network-to-Network Translation with Conditiona...   \n",
            "9  Functional Regularization for Representation L...   \n",
            "0      Self-Supervised MultiModal Versatile Networks   \n",
            "1  Advances in Neural Information Processing Syst...   \n",
            "2  Large-Scale Adversarial Training for Vision-an...   \n",
            "3  Training Generative Adversarial Networks with ...   \n",
            "4                         Bayesian Attention Modules   \n",
            "5  Language-Conditioned Imitation Learning for Ro...   \n",
            "0  Benchmarking Deep Inverse Models over time, an...   \n",
            "1  Benchmarking Deep Inverse Models ... - Review ...   \n",
            "2  Benchmarking Deep Inverse Models ... - Review ...   \n",
            "3  Advances in Neural Information Processing Syst...   \n",
            "4  On Second Order Behaviour in Augmented Neural ...   \n",
            "5  A Flexible Framework for Designing Trainable P...   \n",
            "6                                          JAX, M.D.   \n",
            "0  Off-Policy Evaluation and Learning for Externa...   \n",
            "1  Advances in Neural Information Processing Syst...   \n",
            "2  Fourier Sparse Leverage Scores and Approximate...   \n",
            "3  Fourier Sparse Leverage Scores and Approximate...   \n",
            "4  Recurrent Switching Dynamical Systems Models f...   \n",
            "\n",
            "                                                text  \\\n",
            "0  Training Generative Adversarial Networks with ...   \n",
            "1  Estimating Training Data Influence by Tracing ...   \n",
            "2  Deep Evidential Regression\\n\\nPart of Advances...   \n",
            "3  Information Theoretic Regret Bounds for Online...   \n",
            "4  Universally Quantized Neural Compression\\n\\nPa...   \n",
            "5  Book\\n\\nDo not remove: This comment is monitor...   \n",
            "6  Graph Contrastive Learning with Augmentations\\...   \n",
            "7  Efficient Exact Verification of Binarized Neur...   \n",
            "8  Path Sample-Analytic Gradient Estimators for S...   \n",
            "9  Deep Archimedean Copulas\\n\\nPart of Advances i...   \n",
            "0  An Unsupervised Information-Theoretic Perceptu...   \n",
            "1  NeurIPS 2020\\n\\nAn Unsupervised Information-Th...   \n",
            "2  NeurIPS 2020\\n\\nAn Unsupervised Information-Th...   \n",
            "3  Book\\n\\nDo not remove: This comment is monitor...   \n",
            "4  Abstract\\n\\nSynthesizing larger texture images...   \n",
            "5  Abstract\\n\\nLearning object-centric representa...   \n",
            "6  Abstract\\n\\nWithin months of birth, children d...   \n",
            "7  Abstract\\n\\nThe goal of compressed sensing is ...   \n",
            "8  Abstract\\n\\nGiven the ever-increasing computat...   \n",
            "9  Abstract\\n\\nUnsupervised and self-supervised l...   \n",
            "0  Self-Supervised MultiModal Versatile Networks\\...   \n",
            "1  Book\\n\\nDo not remove: This comment is monitor...   \n",
            "2  Abstract\\n\\nWe present VILLA, the ﬁrst known e...   \n",
            "3  Abstract\\n\\nTraining generative adversarial ne...   \n",
            "4  Abstract\\n\\nAttention modules, as simple and e...   \n",
            "5  Abstract\\n\\nImitation learning is a popular ap...   \n",
            "0  Benchmarking Deep Inverse Models over time, an...   \n",
            "1  NeurIPS 2020\\n\\nBenchmarking Deep Inverse Mode...   \n",
            "2  NeurIPS 2020\\n\\nBenchmarking Deep Inverse Mode...   \n",
            "3  Book\\n\\nDo not remove: This comment is monitor...   \n",
            "4  Abstract\\n\\nNeural Ordinary Differential Equat...   \n",
            "5  Abstract\\n\\nWe introduce a general framework f...   \n",
            "6  Abstract\\n\\nWe introduce JAX MD, a software pa...   \n",
            "0  Abstract\\n\\nWe consider evaluating and trainin...   \n",
            "1  Book\\n\\nDo not remove: This comment is monitor...   \n",
            "2  Abstract\\n\\ns-sparse functions of the form f (...   \n",
            "3  Abstract\\n\\ns-sparse functions of the form f (...   \n",
            "4  Abstract\\n\\nModern recording techniques can ge...   \n",
            "\n",
            "                                                 url  similarity_score  rank  \\\n",
            "0  https://papers.nips.cc/paper/2020/hash/8d30aa9...          0.965153   3.0   \n",
            "1  https://papers.nips.cc/paper/2020/hash/e6385d3...          0.965144   4.0   \n",
            "2  https://papers.nips.cc/paper/2020/hash/aab0854...          0.965102   6.0   \n",
            "3  https://papers.nips.cc/paper/2020/hash/aee5620...          0.965130   5.0   \n",
            "4  https://papers.nips.cc/paper/2020/hash/92049de...          0.965285   2.0   \n",
            "5                  https://papers.nips.cc/paper/2020          0.965377   1.0   \n",
            "6  https://papers.nips.cc/paper/2020/hash/3fe2303...          0.960548  10.0   \n",
            "7  https://papers.nips.cc/paper/2020/hash/1385974...          0.962081   7.0   \n",
            "8  https://papers.nips.cc/paper/2020/hash/96fca94...          0.961407   9.0   \n",
            "9  https://papers.nips.cc/paper/2020/hash/10eb650...          0.961599   8.0   \n",
            "0  https://papers.nips.cc/paper/2020/hash/00482b9...          0.960361   6.0   \n",
            "1  https://papers.nips.cc/paper/2020/file/00482b9...          0.940551  10.0   \n",
            "2  https://papers.nips.cc/paper/2020/file/00482b9...          0.960248   8.0   \n",
            "3                  https://papers.nips.cc/paper/2020          0.964870   1.0   \n",
            "4  https://papers.nips.cc/paper/2020/file/a23156a...          0.960257   7.0   \n",
            "5  https://papers.nips.cc/paper/2020/file/8511df9...          0.959921   9.0   \n",
            "6  https://papers.nips.cc/paper/2020/file/7183145...          0.964294   2.0   \n",
            "7  https://papers.nips.cc/paper/2020/file/07cb5f8...          0.963900   3.0   \n",
            "8  https://papers.nips.cc/paper/2020/file/1cfa81a...          0.963835   4.0   \n",
            "9  https://papers.nips.cc/paper/2020/file/c793b3b...          0.961062   5.0   \n",
            "0  https://papers.nips.cc/paper/2020/hash/0060ef4...          0.965593   4.0   \n",
            "1                  https://papers.nips.cc/paper/2020          0.966477   1.0   \n",
            "2  https://papers.nips.cc/paper/2020/file/4956247...          0.965714   3.0   \n",
            "3  https://papers.nips.cc/paper/2020/file/8d30aa9...          0.963016   5.0   \n",
            "4  https://papers.nips.cc/paper/2020/file/bcff3f6...          0.962894   6.0   \n",
            "5  https://papers.nips.cc/paper/2020/file/9909794...          0.966408   2.0   \n",
            "0  https://papers.nips.cc/paper/2020/hash/007ff38...          0.961588   6.0   \n",
            "1  https://papers.nips.cc/paper/2020/file/007ff38...          0.966438   2.0   \n",
            "2  https://papers.nips.cc/paper/2020/file/007ff38...          0.966165   3.0   \n",
            "3                  https://papers.nips.cc/paper/2020          0.965975   4.0   \n",
            "4  https://papers.nips.cc/paper/2020/file/418db2e...          0.961224   7.0   \n",
            "5  https://papers.nips.cc/paper/2020/file/b4edda6...          0.962293   5.0   \n",
            "6  https://papers.nips.cc/paper/2020/file/83d3d4b...          0.966740   1.0   \n",
            "0  https://papers.nips.cc/paper/2020/file/0084ae4...          0.961221   5.0   \n",
            "1                  https://papers.nips.cc/paper/2020          0.965306   2.0   \n",
            "2  https://papers.nips.cc/paper/2020/file/012d9fe...          0.961443   4.0   \n",
            "3  https://papers.nips.cc/paper/2020/file/012d9fe...          0.961443   4.0   \n",
            "4  https://papers.nips.cc/paper/2020/file/aa1f5f7...          0.965760   1.0   \n",
            "\n",
            "   similarity_score_lda  rank_lda  \n",
            "0              0.976416       8.0  \n",
            "1              0.976422       7.0  \n",
            "2              0.976501       5.0  \n",
            "3              0.976803       3.0  \n",
            "4              0.976386       9.0  \n",
            "5              0.976283      10.0  \n",
            "6              0.977023       1.0  \n",
            "7              0.976987       2.0  \n",
            "8              0.976438       6.0  \n",
            "9              0.976682       4.0  \n",
            "0              0.976147       8.0  \n",
            "1              0.975887       9.0  \n",
            "2              0.976883       2.0  \n",
            "3              0.976728       5.0  \n",
            "4              0.975769      10.0  \n",
            "5              0.976862       3.0  \n",
            "6              0.976213       7.0  \n",
            "7              0.977043       1.0  \n",
            "8              0.976403       6.0  \n",
            "9              0.976810       4.0  \n",
            "0              0.977262       6.0  \n",
            "1              0.978460       1.0  \n",
            "2              0.978236       4.0  \n",
            "3              0.977762       5.0  \n",
            "4              0.978310       2.0  \n",
            "5              0.978285       3.0  \n",
            "0              0.976925       4.0  \n",
            "1              0.976647       7.0  \n",
            "2              0.977214       1.0  \n",
            "3              0.976798       6.0  \n",
            "4              0.977014       2.0  \n",
            "5              0.976808       5.0  \n",
            "6              0.976971       3.0  \n",
            "0              0.975795       3.0  \n",
            "1              0.975710       4.0  \n",
            "2              0.975524       5.0  \n",
            "3              0.976571       1.0  \n",
            "4              0.976526       2.0  \n",
            "topic:  neural methods point wise dependency estimation neurips id_= 5\n",
            "1 . Neural Methods for Point-wise Dependency Estimation https://papers.nips.cc/paper/2020/hash/00a03ec6533ca7f5c644d198d815329c-Abstract.html\n",
            "**********************************************\n",
            "2 . Neural Methods for Point-wise Dependency Estimation https://papers.nips.cc/paper/2020/file/00a03ec6533ca7f5c644d198d815329c-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Since its inception, the neural estimation of mutual information (MI) has demon-\n",
            "strated the empirical success of modeling expected dependency between high-\n",
            "dimensional random variables. However, MI is an aggregate statistic and cannot\n",
            "be used to measure point-wise dependency between different events. In this work,\n",
            "instead of estimating the expected dependency, we focus on estimating point-wise\n",
            "dependency (PD), which quantitatively measures how likely two outcomes co-\n",
            "occur. We show that we can naturally obtain PD when we are optimizing MI neural\n",
            "variational bounds. However, optimizing these bounds is challenging due to its\n",
            "large variance in practice. To address this issue, we develop two methods (free\n",
            "of optimizing MI variational bounds): Probabilistic Classiﬁer and Density-Ratio\n",
            "Fitting.We demonstrate the effectiveness of our approaches in 1) MI estimation, 2)\n",
            "self-supervised representation learning, and 3) cross-modal retrieval task.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "3 . Neural Methods for Point-wise ... - Review for NeurIPS paper https://papers.nips.cc/paper/2020/file/00a03ec6533ca7f5c644d198d815329c-Review.html\n",
            "**********************************************\n",
            "4 . Neural Methods for Point-wise ... - Review for NeurIPS paper https://papers.nips.cc/paper/2020/file/00a03ec6533ca7f5c644d198d815329c-MetaReview.html\n",
            "**********************************************\n",
            "5 . Advances in Neural Information Processing Systems 33 (NeurIPS ... https://papers.nips.cc/paper/2020\n",
            "**********************************************\n",
            "6 . Exchangeable Neural ODE for Set Modeling https://papers.nips.cc/paper/2020/file/4db73860ecb5533b5a6c710341d5bbec-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Reasoning over an instance composed of a set of vectors, like a point cloud, requires\n",
            "that one accounts for intra-set dependent features among elements. However, since\n",
            "such instances are unordered, the elements’ features should remain unchanged\n",
            "when the input’s order is permuted. This property, permutation equivariance, is\n",
            "a challenging constraint for most neural architectures. While recent work has\n",
            "proposed global pooling and attention-based solutions, these may be limited in the\n",
            "way that intradependencies are captured in practice. In this work we propose a\n",
            "more general formulation to achieve permutation equivariance through ordinary\n",
            "differential equations (ODE). Our proposed module, Exchangeable Neural ODE\n",
            "(ExNODE), can be seamlessly applied for both discriminative and generative tasks.\n",
            "We also extend set modeling in the temporal dimension and propose a VAE based\n",
            "model for temporal set modeling. Extensive experiments demonstrate the efﬁcacy\n",
            "of our method over strong baselines.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "7 . Matrix Inference and Estimation in Multi-Layer Models https://papers.nips.cc/paper/2020/file/fe2b421b8b5f0e7c355ace66a9fe0206-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "We consider the problem of estimating the input and hidden variables of a stochastic\n",
            "multi-layer neural network from an observation of the output. The hidden variables\n",
            "in each layer are represented as matrices with statistical interactions along both\n",
            "rows as well as columns. This problem applies to matrix imputation, signal recovery\n",
            "via deep generative prior models, multi-task and mixed regression, and learning\n",
            "certain classes of two-layer neural networks. We extend a recently-developed\n",
            "algorithm – Multi-Layer Vector Approximate Message Passing (ML-VAMP), for\n",
            "this matrix-valued inference problem. It is shown that the performance of the\n",
            "proposed Multi-Layer Matrix VAMP (ML-Mat-VAMP) algorithm can be exactly\n",
            "predicted in a certain random large-system limit, where the dimensions N ×d of the\n",
            "unknown quantities grow as N → ∞ with d ﬁxed. In the two-layer neural-network\n",
            "learning problem, this scaling corresponds to the case where the number of input\n",
            "features as well as training samples grow to inﬁnity but the number of hidden nodes\n",
            "stays ﬁxed. The analysis enables a precise prediction of the parameter and test\n",
            "error of the learning.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "8 . User-dependent neural sequence models for continuous-time event ... https://papers.nips.cc/paper/2020/file/f56de5ef149cf0aedcc8f4797031e229-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Continuous-time event data are common in applications such as individual behavior\n",
            "data, ﬁnancial transactions, and medical health records. Modeling such data can be\n",
            "very challenging, in particular for applications with many different types of events,\n",
            "since it requires a model to predict the event types as well as the time of occurrence.\n",
            "Recurrent neural networks that parameterize time-varying intensity functions are\n",
            "the current state-of-the-art for predictive modeling with such data. These models\n",
            "typically assume that all event sequences come from the same data distribution.\n",
            "However, in many applications event sequences are generated by different sources,\n",
            "or users, and their characteristics can be very different. In this paper, we extend the\n",
            "broad class of neural marked point process models to mixtures of latent embeddings,\n",
            "where each mixture component models the characteristic traits of a given user. Our\n",
            "approach relies on augmenting these models with a latent variable that encodes\n",
            "user characteristics, represented by a mixture model over user behavior that is\n",
            "trained via amortized variational inference. We evaluate our methods on four large\n",
            "real-world datasets and demonstrate systematic improvements from our approach\n",
            "over existing work for a variety of predictive metrics such as log-likelihood, next\n",
            "event ranking, and source-of-sequence identiﬁcation.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "9 . Fast and Flexible Temporal Point Processes with Triangular Maps https://papers.nips.cc/paper/2020/file/00ac8ed3b4327bdd4ebbebcb2ba10a00-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Temporal point process (TPP) models combined with recurrent neural networks\n",
            "provide a powerful framework for modeling continuous-time event data. While\n",
            "such models are ﬂexible, they are inherently sequential and therefore cannot beneﬁt\n",
            "from the parallelism of modern hardware. By exploiting the recent developments\n",
            "in the ﬁeld of normalizing ﬂows, we design TriTPP— a new class of non-recurrent\n",
            "TPP models, where both sampling and likelihood computation can be done in\n",
            "parallel. TriTPP matches the ﬂexibility of RNN-based methods but permits orders\n",
            "of magnitude faster sampling. This enables us to use the new model for variational\n",
            "inference in continuous-time discrete-state systems. We demonstrate the advantages\n",
            "of the proposed framework on synthetic and real-world datasets.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "10 . Telescoping Density-Ratio Estimation https://papers.nips.cc/paper/2020/file/33d3b157ddc0896addfb22fa2a519097-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Density-ratio estimation via classiﬁcation is a cornerstone of unsupervised learning.\n",
            "It has provided the foundation for state-of-the-art methods in representation learning\n",
            "and generative modelling, with the number of use-cases continuing to proliferate.\n",
            "However, it suffers from a critical limitation: it fails to accurately estimate ratios\n",
            "p/q for which the two densities differ signiﬁcantly. Empirically, we ﬁnd this\n",
            "occurs whenever the KL divergence between p and q exceeds tens of nats. To\n",
            "resolve this limitation, we introduce a new framework, telescoping density-ratio\n",
            "estimation (TRE), that enables the estimation of ratios between highly dissimilar\n",
            "densities in high-dimensional spaces. Our experiments demonstrate that TRE\n",
            "can yield substantial improvements over existing single-ratio methods for mutual\n",
            "information estimation, representation learning and energy-based modelling.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "data:                                                topic  \\\n",
            "0  neural methods point wise dependency estimatio...   \n",
            "1  neural methods point wise dependency estimatio...   \n",
            "2  neural methods point wise dependency estimatio...   \n",
            "3  neural methods point wise dependency estimatio...   \n",
            "4  neural methods point wise dependency estimatio...   \n",
            "5  neural methods point wise dependency estimatio...   \n",
            "6  neural methods point wise dependency estimatio...   \n",
            "7  neural methods point wise dependency estimatio...   \n",
            "8  neural methods point wise dependency estimatio...   \n",
            "9  neural methods point wise dependency estimatio...   \n",
            "\n",
            "                                               title  \\\n",
            "0  Neural Methods for Point-wise Dependency Estim...   \n",
            "1  Neural Methods for Point-wise Dependency Estim...   \n",
            "2  Neural Methods for Point-wise ... - Review for...   \n",
            "3  Neural Methods for Point-wise ... - Review for...   \n",
            "4  Advances in Neural Information Processing Syst...   \n",
            "5           Exchangeable Neural ODE for Set Modeling   \n",
            "6  Matrix Inference and Estimation in Multi-Layer...   \n",
            "7  User-dependent neural sequence models for cont...   \n",
            "8  Fast and Flexible Temporal Point Processes wit...   \n",
            "9               Telescoping Density-Ratio Estimation   \n",
            "\n",
            "                                                text  \\\n",
            "0  Neural Methods for Point-wise Dependency Estim...   \n",
            "1  Abstract\\n\\nSince its inception, the neural es...   \n",
            "2  NeurIPS 2020\\n\\nNeural Methods for Point-wise ...   \n",
            "3  NeurIPS 2020\\n\\nNeural Methods for Point-wise ...   \n",
            "4  Book\\n\\nDo not remove: This comment is monitor...   \n",
            "5  Abstract\\n\\nReasoning over an instance compose...   \n",
            "6  Abstract\\n\\nWe consider the problem of estimat...   \n",
            "7  Abstract\\n\\nContinuous-time event data are com...   \n",
            "8  Abstract\\n\\nTemporal point process (TPP) model...   \n",
            "9  Abstract\\n\\nDensity-ratio estimation via class...   \n",
            "\n",
            "                                                 url  \n",
            "0  https://papers.nips.cc/paper/2020/hash/00a03ec...  \n",
            "1  https://papers.nips.cc/paper/2020/file/00a03ec...  \n",
            "2  https://papers.nips.cc/paper/2020/file/00a03ec...  \n",
            "3  https://papers.nips.cc/paper/2020/file/00a03ec...  \n",
            "4                  https://papers.nips.cc/paper/2020  \n",
            "5  https://papers.nips.cc/paper/2020/file/4db7386...  \n",
            "6  https://papers.nips.cc/paper/2020/file/fe2b421...  \n",
            "7  https://papers.nips.cc/paper/2020/file/f56de5e...  \n",
            "8  https://papers.nips.cc/paper/2020/file/00ac8ed...  \n",
            "9  https://papers.nips.cc/paper/2020/file/33d3b15...  \n",
            "**********************************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                                               topic  \\\n",
            "0  neural methods point wise dependency estimatio...   \n",
            "1  neural methods point wise dependency estimatio...   \n",
            "2  neural methods point wise dependency estimatio...   \n",
            "3  neural methods point wise dependency estimatio...   \n",
            "4  neural methods point wise dependency estimatio...   \n",
            "5  neural methods point wise dependency estimatio...   \n",
            "6  neural methods point wise dependency estimatio...   \n",
            "7  neural methods point wise dependency estimatio...   \n",
            "8  neural methods point wise dependency estimatio...   \n",
            "9  neural methods point wise dependency estimatio...   \n",
            "\n",
            "                                               title  \\\n",
            "0  Neural Methods for Point-wise Dependency Estim...   \n",
            "1  Neural Methods for Point-wise Dependency Estim...   \n",
            "2  Neural Methods for Point-wise ... - Review for...   \n",
            "3  Neural Methods for Point-wise ... - Review for...   \n",
            "4  Advances in Neural Information Processing Syst...   \n",
            "5           Exchangeable Neural ODE for Set Modeling   \n",
            "6  Matrix Inference and Estimation in Multi-Layer...   \n",
            "7  User-dependent neural sequence models for cont...   \n",
            "8  Fast and Flexible Temporal Point Processes wit...   \n",
            "9               Telescoping Density-Ratio Estimation   \n",
            "\n",
            "                                                text  \\\n",
            "0  Neural Methods for Point-wise Dependency Estim...   \n",
            "1  Abstract\\n\\nSince its inception, the neural es...   \n",
            "2  NeurIPS 2020\\n\\nNeural Methods for Point-wise ...   \n",
            "3  NeurIPS 2020\\n\\nNeural Methods for Point-wise ...   \n",
            "4  Book\\n\\nDo not remove: This comment is monitor...   \n",
            "5  Abstract\\n\\nReasoning over an instance compose...   \n",
            "6  Abstract\\n\\nWe consider the problem of estimat...   \n",
            "7  Abstract\\n\\nContinuous-time event data are com...   \n",
            "8  Abstract\\n\\nTemporal point process (TPP) model...   \n",
            "9  Abstract\\n\\nDensity-ratio estimation via class...   \n",
            "\n",
            "                                                 url  similarity_score  \n",
            "0  https://papers.nips.cc/paper/2020/hash/00a03ec...          0.960263  \n",
            "1  https://papers.nips.cc/paper/2020/file/00a03ec...          0.965585  \n",
            "2  https://papers.nips.cc/paper/2020/file/00a03ec...          0.965460  \n",
            "3  https://papers.nips.cc/paper/2020/file/00a03ec...          0.966722  \n",
            "4                  https://papers.nips.cc/paper/2020          0.965418  \n",
            "5  https://papers.nips.cc/paper/2020/file/4db7386...          0.960426  \n",
            "6  https://papers.nips.cc/paper/2020/file/fe2b421...          0.967176  \n",
            "7  https://papers.nips.cc/paper/2020/file/f56de5e...          0.961511  \n",
            "8  https://papers.nips.cc/paper/2020/file/00ac8ed...          0.965781  \n",
            "9  https://papers.nips.cc/paper/2020/file/33d3b15...          0.961219  \n",
            "df_final after rank=                                                topic  \\\n",
            "0  neural methods point wise dependency estimatio...   \n",
            "1  neural methods point wise dependency estimatio...   \n",
            "2  neural methods point wise dependency estimatio...   \n",
            "3  neural methods point wise dependency estimatio...   \n",
            "4  neural methods point wise dependency estimatio...   \n",
            "5  neural methods point wise dependency estimatio...   \n",
            "6  neural methods point wise dependency estimatio...   \n",
            "7  neural methods point wise dependency estimatio...   \n",
            "8  neural methods point wise dependency estimatio...   \n",
            "9  neural methods point wise dependency estimatio...   \n",
            "\n",
            "                                               title  \\\n",
            "0  Neural Methods for Point-wise Dependency Estim...   \n",
            "1  Neural Methods for Point-wise Dependency Estim...   \n",
            "2  Neural Methods for Point-wise ... - Review for...   \n",
            "3  Neural Methods for Point-wise ... - Review for...   \n",
            "4  Advances in Neural Information Processing Syst...   \n",
            "5           Exchangeable Neural ODE for Set Modeling   \n",
            "6  Matrix Inference and Estimation in Multi-Layer...   \n",
            "7  User-dependent neural sequence models for cont...   \n",
            "8  Fast and Flexible Temporal Point Processes wit...   \n",
            "9               Telescoping Density-Ratio Estimation   \n",
            "\n",
            "                                                text  \\\n",
            "0  Neural Methods for Point-wise Dependency Estim...   \n",
            "1  Abstract\\n\\nSince its inception, the neural es...   \n",
            "2  NeurIPS 2020\\n\\nNeural Methods for Point-wise ...   \n",
            "3  NeurIPS 2020\\n\\nNeural Methods for Point-wise ...   \n",
            "4  Book\\n\\nDo not remove: This comment is monitor...   \n",
            "5  Abstract\\n\\nReasoning over an instance compose...   \n",
            "6  Abstract\\n\\nWe consider the problem of estimat...   \n",
            "7  Abstract\\n\\nContinuous-time event data are com...   \n",
            "8  Abstract\\n\\nTemporal point process (TPP) model...   \n",
            "9  Abstract\\n\\nDensity-ratio estimation via class...   \n",
            "\n",
            "                                                 url  similarity_score  rank  \n",
            "0  https://papers.nips.cc/paper/2020/hash/00a03ec...          0.960263  10.0  \n",
            "1  https://papers.nips.cc/paper/2020/file/00a03ec...          0.965585   4.0  \n",
            "2  https://papers.nips.cc/paper/2020/file/00a03ec...          0.965460   5.0  \n",
            "3  https://papers.nips.cc/paper/2020/file/00a03ec...          0.966722   2.0  \n",
            "4                  https://papers.nips.cc/paper/2020          0.965418   6.0  \n",
            "5  https://papers.nips.cc/paper/2020/file/4db7386...          0.960426   9.0  \n",
            "6  https://papers.nips.cc/paper/2020/file/fe2b421...          0.967176   1.0  \n",
            "7  https://papers.nips.cc/paper/2020/file/f56de5e...          0.961511   7.0  \n",
            "8  https://papers.nips.cc/paper/2020/file/00ac8ed...          0.965781   3.0  \n",
            "9  https://papers.nips.cc/paper/2020/file/33d3b15...          0.961219   8.0  \n",
            "0    Neural Methods for Point-wise Dependency Estim...\n",
            "1    Abstract\\n\\nSince its inception, the neural es...\n",
            "2    NeurIPS 2020\\n\\nNeural Methods for Point-wise ...\n",
            "3    NeurIPS 2020\\n\\nNeural Methods for Point-wise ...\n",
            "4    Book\\n\\nDo not remove: This comment is monitor...\n",
            "5    Abstract\\n\\nReasoning over an instance compose...\n",
            "6    Abstract\\n\\nWe consider the problem of estimat...\n",
            "7    Abstract\\n\\nContinuous-time event data are com...\n",
            "8    Abstract\\n\\nTemporal point process (TPP) model...\n",
            "9    Abstract\\n\\nDensity-ratio estimation via class...\n",
            "Name: text, dtype: object\n",
            "Neural\n",
            "Methods\n",
            "for\n",
            "Point-wise\n",
            "Dependency\n",
            "Estimation\n",
            "Part\n",
            "of\n",
            "Advances\n",
            "in\n",
            "Neural\n",
            "Information\n",
            "Processing\n",
            "Systems\n",
            "33\n",
            "(\n",
            "NeurIPS\n",
            "2020\n",
            ")\n",
            "Authors\n",
            "Yao-Hung\n",
            "Hubert\n",
            "Tsai\n",
            ",\n",
            "Han\n",
            "Zhao\n",
            ",\n",
            "Makoto\n",
            "Yamada\n",
            ",\n",
            "Louis-Philippe\n",
            "Morency\n",
            ",\n",
            "Russ\n",
            "R.\n",
            "Salakhutdinov\n",
            "Abstract\n",
            "Since\n",
            "its\n",
            "inception\n",
            ",\n",
            "the\n",
            "neural\n",
            "estimation\n",
            "of\n",
            "mutual\n",
            "information\n",
            "(\n",
            "MI\n",
            ")\n",
            "has\n",
            "demonstrated\n",
            "the\n",
            "empirical\n",
            "success\n",
            "of\n",
            "modeling\n",
            "expected\n",
            "dependency\n",
            "between\n",
            "high-dimensional\n",
            "random\n",
            "variables\n",
            ".\n",
            "However\n",
            ",\n",
            "MI\n",
            "is\n",
            "an\n",
            "aggregate\n",
            "statistic\n",
            "and\n",
            "can\n",
            "not\n",
            "be\n",
            "used\n",
            "to\n",
            "measure\n",
            "point-wise\n",
            "dependency\n",
            "between\n",
            "different\n",
            "events\n",
            ".\n",
            "In\n",
            "this\n",
            "work\n",
            ",\n",
            "instead\n",
            "of\n",
            "estimating\n",
            "the\n",
            "expected\n",
            "dependency\n",
            ",\n",
            "we\n",
            "focus\n",
            "on\n",
            "estimating\n",
            "point-wise\n",
            "dependency\n",
            "(\n",
            "PD\n",
            ")\n",
            ",\n",
            "which\n",
            "quantitatively\n",
            "measures\n",
            "how\n",
            "likely\n",
            "two\n",
            "outcomes\n",
            "co-occur\n",
            ".\n",
            "We\n",
            "show\n",
            "that\n",
            "we\n",
            "can\n",
            "naturally\n",
            "obtain\n",
            "PD\n",
            "when\n",
            "we\n",
            "are\n",
            "optimizing\n",
            "MI\n",
            "neural\n",
            "variational\n",
            "bounds\n",
            ".\n",
            "However\n",
            ",\n",
            "optimizing\n",
            "these\n",
            "bounds\n",
            "is\n",
            "challenging\n",
            "due\n",
            "to\n",
            "its\n",
            "large\n",
            "variance\n",
            "in\n",
            "practice\n",
            ".\n",
            "To\n",
            "address\n",
            "this\n",
            "issue\n",
            ",\n",
            "we\n",
            "develop\n",
            "two\n",
            "methods\n",
            "(\n",
            "free\n",
            "of\n",
            "optimizing\n",
            "MI\n",
            "variational\n",
            "bounds\n",
            ")\n",
            ":\n",
            "Probabilistic\n",
            "Classifier\n",
            "and\n",
            "Density-Ratio\n",
            "Fitting\n",
            ".\n",
            "We\n",
            "demonstrate\n",
            "the\n",
            "effectiveness\n",
            "of\n",
            "our\n",
            "approaches\n",
            "in\n",
            "1\n",
            ")\n",
            "MI\n",
            "estimation\n",
            ",\n",
            "2\n",
            ")\n",
            "self-supervised\n",
            "representation\n",
            "learning\n",
            ",\n",
            "and\n",
            "3\n",
            ")\n",
            "cross-modal\n",
            "retrieval\n",
            "task\n",
            ".\n",
            "Abstract\n",
            "Since\n",
            "its\n",
            "inception\n",
            ",\n",
            "the\n",
            "neural\n",
            "estimation\n",
            "of\n",
            "mutual\n",
            "information\n",
            "(\n",
            "MI\n",
            ")\n",
            "has\n",
            "demon-\n",
            "strated\n",
            "the\n",
            "empirical\n",
            "success\n",
            "of\n",
            "modeling\n",
            "expected\n",
            "dependency\n",
            "between\n",
            "high-\n",
            "dimensional\n",
            "random\n",
            "variables\n",
            ".\n",
            "However\n",
            ",\n",
            "MI\n",
            "is\n",
            "an\n",
            "aggregate\n",
            "statistic\n",
            "and\n",
            "can\n",
            "not\n",
            "be\n",
            "used\n",
            "to\n",
            "measure\n",
            "point-wise\n",
            "dependency\n",
            "between\n",
            "different\n",
            "events\n",
            ".\n",
            "In\n",
            "this\n",
            "work\n",
            ",\n",
            "instead\n",
            "of\n",
            "estimating\n",
            "the\n",
            "expected\n",
            "dependency\n",
            ",\n",
            "we\n",
            "focus\n",
            "on\n",
            "estimating\n",
            "point-wise\n",
            "dependency\n",
            "(\n",
            "PD\n",
            ")\n",
            ",\n",
            "which\n",
            "quantitatively\n",
            "measures\n",
            "how\n",
            "likely\n",
            "two\n",
            "outcomes\n",
            "co-\n",
            "occur\n",
            ".\n",
            "We\n",
            "show\n",
            "that\n",
            "we\n",
            "can\n",
            "naturally\n",
            "obtain\n",
            "PD\n",
            "when\n",
            "we\n",
            "are\n",
            "optimizing\n",
            "MI\n",
            "neural\n",
            "variational\n",
            "bounds\n",
            ".\n",
            "However\n",
            ",\n",
            "optimizing\n",
            "these\n",
            "bounds\n",
            "is\n",
            "challenging\n",
            "due\n",
            "to\n",
            "its\n",
            "large\n",
            "variance\n",
            "in\n",
            "practice\n",
            ".\n",
            "To\n",
            "address\n",
            "this\n",
            "issue\n",
            ",\n",
            "we\n",
            "develop\n",
            "two\n",
            "methods\n",
            "(\n",
            "free\n",
            "of\n",
            "optimizing\n",
            "MI\n",
            "variational\n",
            "bounds\n",
            ")\n",
            ":\n",
            "Probabilistic\n",
            "Classiﬁer\n",
            "and\n",
            "Density-Ratio\n",
            "Fitting.We\n",
            "demonstrate\n",
            "the\n",
            "effectiveness\n",
            "of\n",
            "our\n",
            "approaches\n",
            "in\n",
            "1\n",
            ")\n",
            "MI\n",
            "estimation\n",
            ",\n",
            "2\n",
            ")\n",
            "self-supervised\n",
            "representation\n",
            "learning\n",
            ",\n",
            "and\n",
            "3\n",
            ")\n",
            "cross-modal\n",
            "retrieval\n",
            "task\n",
            ".\n",
            "1\n",
            "NeurIPS\n",
            "2020\n",
            "Neural\n",
            "Methods\n",
            "for\n",
            "Point-wise\n",
            "Dependency\n",
            "Estimation\n",
            "Review\n",
            "1\n",
            "Summary\n",
            "and\n",
            "Contributions\n",
            ":\n",
            "The\n",
            "paper\n",
            "focuses\n",
            "on\n",
            "developing\n",
            "methods\n",
            "for\n",
            "estimating\n",
            "point-wise\n",
            "dependency\n",
            ".\n",
            "Strengths\n",
            ":\n",
            "The\n",
            "paper\n",
            "is\n",
            "well\n",
            "written\n",
            ",\n",
            "introducing\n",
            "all\n",
            "the\n",
            "required\n",
            "details\n",
            "and\n",
            "motivating\n",
            "the\n",
            "need\n",
            "to\n",
            "study\n",
            "point-wise\n",
            "dependency\n",
            ".\n",
            "The\n",
            "strength\n",
            "of\n",
            "the\n",
            "paper\n",
            "is\n",
            "in\n",
            "the\n",
            "experiments\n",
            ".\n",
            "1\n",
            ".\n",
            "There\n",
            "are\n",
            "multiple\n",
            "different\n",
            "application\n",
            "scenarios\n",
            "studied\n",
            ",\n",
            "that\n",
            "are\n",
            "broad\n",
            "and\n",
            "representative\n",
            ".\n",
            "2\n",
            ".\n",
            "The\n",
            "comparisons\n",
            "are\n",
            "extensive\n",
            "though\n",
            "they\n",
            "can\n",
            "be\n",
            "represented\n",
            "more\n",
            "convincingly\n",
            "(\n",
            "see\n",
            "below\n",
            ")\n",
            ".\n",
            "3\n",
            ".\n",
            "Self-supervised\n",
            "representation\n",
            "learning\n",
            "is\n",
            "a\n",
            "good\n",
            "useful\n",
            "application\n",
            ".\n",
            "Weaknesses\n",
            ":\n",
            "The\n",
            "connection\n",
            "between\n",
            "Section\n",
            "3.1\n",
            "and\n",
            "Section\n",
            "3.2\n",
            "is\n",
            "hard\n",
            "to\n",
            "follow\n",
            "and\n",
            "can\n",
            "be\n",
            "written\n",
            "better\n",
            ".\n",
            "The\n",
            "paper\n",
            "discusses\n",
            "how\n",
            "PD\n",
            "can\n",
            "be\n",
            "naturally\n",
            "obtained\n",
            "when\n",
            "optimizing\n",
            "fro\n",
            "MI\n",
            "neural\n",
            "variational\n",
            "bounds\n",
            "but\n",
            "the\n",
            "part\n",
            "on\n",
            "these\n",
            "methods\n",
            "having\n",
            "large\n",
            "variance\n",
            "and\n",
            "hence\n",
            "the\n",
            "need\n",
            "for\n",
            "other\n",
            "methods\n",
            "for\n",
            "PD\n",
            "estimation\n",
            "could\n",
            "be\n",
            "motivated\n",
            "better\n",
            ".\n",
            "The\n",
            "proposed\n",
            "methods\n",
            "address\n",
            "an\n",
            "interesting\n",
            "problem\n",
            "but\n",
            "they\n",
            "follow\n",
            "from\n",
            "the\n",
            "density\n",
            "ratio\n",
            "method\n",
            "for\n",
            "PMI\n",
            ".\n",
            "More\n",
            "details\n",
            "on\n",
            "the\n",
            "novelty\n",
            "of\n",
            "the\n",
            "proposed\n",
            "approach\n",
            "can\n",
            "be\n",
            "helpful\n",
            "to\n",
            "the\n",
            "reviewer\n",
            "and\n",
            "some\n",
            "details\n",
            "in\n",
            "Section\n",
            "3.1\n",
            "can\n",
            "be\n",
            "abstracted\n",
            "and\n",
            "absorbed\n",
            "into\n",
            "related\n",
            "work\n",
            "as\n",
            "this\n",
            "is\n",
            "not\n",
            "really\n",
            "the\n",
            "paper\n",
            "'s\n",
            "contribution\n",
            ".\n",
            "The\n",
            "results\n",
            "also\n",
            "can\n",
            "be\n",
            "represented\n",
            "and\n",
            "explained\n",
            "better\n",
            ".\n",
            "Especially\n",
            "connecting\n",
            "the\n",
            "high\n",
            "variance\n",
            "of\n",
            "the\n",
            "existing\n",
            "approaches\n",
            "and\n",
            "how\n",
            "the\n",
            "proposed\n",
            "approaches\n",
            "are\n",
            "better\n",
            ".\n",
            "For\n",
            "example\n",
            ",\n",
            "It\n",
            "is\n",
            "hard\n",
            "to\n",
            "understand\n",
            "how\n",
            "the\n",
            "results\n",
            "are\n",
            "better\n",
            "than\n",
            "SMILE\n",
            "in\n",
            "Figure\n",
            "1\n",
            ".\n",
            "Given\n",
            "that\n",
            "the\n",
            "experiments\n",
            "are\n",
            "the\n",
            "major\n",
            "strength\n",
            "of\n",
            "the\n",
            "paper\n",
            ",\n",
            "this\n",
            "can\n",
            "be\n",
            "expressed\n",
            "more\n",
            "convincingly\n",
            ".\n",
            "Correctness\n",
            ":\n",
            "The\n",
            "claims\n",
            "and\n",
            "methodology\n",
            "is\n",
            "interesting\n",
            "and\n",
            "correct\n",
            ".\n",
            "Clarity\n",
            ":\n",
            "The\n",
            "paper\n",
            "is\n",
            "well-written\n",
            "and\n",
            "easy\n",
            "to\n",
            "read\n",
            ".\n",
            "Relation\n",
            "to\n",
            "Prior\n",
            "Work\n",
            ":\n",
            "The\n",
            "paper\n",
            "clearly\n",
            "articulates\n",
            "its\n",
            "position\n",
            "with\n",
            "respect\n",
            "to\n",
            "the\n",
            "prior\n",
            "literature\n",
            ".\n",
            "Reproducibility\n",
            ":\n",
            "Yes\n",
            "Additional\n",
            "Feedback\n",
            ":\n",
            "Review\n",
            "2\n",
            "Summary\n",
            "and\n",
            "Contributions\n",
            ":\n",
            "This\n",
            "paper\n",
            "focuses\n",
            "on\n",
            "estimating\n",
            "the\n",
            "point-wise\n",
            "dependency\n",
            "(\n",
            "PD\n",
            ")\n",
            "that\n",
            "measures\n",
            "the\n",
            "instance-level\n",
            "dependency\n",
            "between\n",
            "events\n",
            "taken\n",
            "by\n",
            "two\n",
            "random\n",
            "variables\n",
            ".\n",
            "The\n",
            "authors\n",
            "show\n",
            "that\n",
            "although\n",
            "PD\n",
            "can\n",
            "be\n",
            "obtained\n",
            "via\n",
            "optimizing\n",
            "mutual\n",
            "information\n",
            "(\n",
            "MI\n",
            ")\n",
            "neural\n",
            "variational\n",
            "bounds\n",
            ",\n",
            "it\n",
            "leads\n",
            "to\n",
            "large\n",
            "variance\n",
            ".\n",
            "The\n",
            "authors\n",
            "further\n",
            "propose\n",
            "two\n",
            "data-driven\n",
            "approaches\n",
            "to\n",
            "estimate\n",
            "PD\n",
            ":\n",
            "(\n",
            "1\n",
            ")\n",
            "Probabilistic\n",
            "Classifier\n",
            "and\n",
            "(\n",
            "2\n",
            ")\n",
            "Density-Ratio\n",
            "Fitting\n",
            ".\n",
            "The\n",
            "first\n",
            "one\n",
            "casts\n",
            "the\n",
            "problem\n",
            "into\n",
            "a\n",
            "binary\n",
            "classification\n",
            "by\n",
            "sampling\n",
            "data\n",
            "pairs\n",
            "from\n",
            "joint\n",
            "density\n",
            "as\n",
            "positive\n",
            "labels\n",
            "and\n",
            "from\n",
            "the\n",
            "product\n",
            "of\n",
            "marginals\n",
            "as\n",
            "negative\n",
            "labels\n",
            ".\n",
            "The\n",
            "second\n",
            "approach\n",
            "directly\n",
            "minimizes\n",
            "the\n",
            "expected\n",
            "square\n",
            "distance\n",
            "between\n",
            "the\n",
            "true\n",
            "and\n",
            "estimated\n",
            "PD\n",
            ".\n",
            "The\n",
            "authors\n",
            "applied\n",
            "their\n",
            "PD\n",
            "estimation\n",
            "method\n",
            "in\n",
            "several\n",
            "applications\n",
            ",\n",
            "including\n",
            "MI\n",
            "estimation\n",
            "(\n",
            "by\n",
            "plugging-in\n",
            "the\n",
            "point-wise\n",
            "MI\n",
            "obtained\n",
            "by\n",
            "taking\n",
            "the\n",
            "log\n",
            "of\n",
            "PD\n",
            ")\n",
            ",\n",
            "self-supervised\n",
            "representation\n",
            "learning\n",
            "(\n",
            "by\n",
            "using\n",
            "the\n",
            "constructive\n",
            "learning\n",
            "approach\n",
            ",\n",
            "i.e.\n",
            ",\n",
            "similar\n",
            "pairs\n",
            "having\n",
            "higher\n",
            "PD\n",
            ")\n",
            "and\n",
            "cross-model\n",
            "retrieval\n",
            "(\n",
            "using\n",
            "audio\n",
            "and\n",
            "text\n",
            "data\n",
            ")\n",
            ".\n",
            "The\n",
            "proposed\n",
            "method\n",
            "was\n",
            "shown\n",
            "empirically\n",
            "comparable\n",
            "to\n",
            "the\n",
            "baselines\n",
            ".\n",
            "Strengths\n",
            ":\n",
            "Point-wise\n",
            "dependency\n",
            "estimation\n",
            "is\n",
            "an\n",
            "interesting\n",
            "yet\n",
            "understudied\n",
            "research\n",
            "issue\n",
            ".\n",
            "I\n",
            "am\n",
            "glad\n",
            "to\n",
            "see\n",
            "efforts\n",
            "beyond\n",
            "just\n",
            "estimating\n",
            "the\n",
            "aggregated\n",
            "MI\n",
            ".\n",
            "The\n",
            "problem\n",
            "studied\n",
            "and\n",
            "the\n",
            "approaches\n",
            "taken\n",
            "seem\n",
            "pretty\n",
            "novel\n",
            "to\n",
            "me\n",
            "and\n",
            "are\n",
            "technically\n",
            "sound\n",
            ".\n",
            "The\n",
            "paper\n",
            "is\n",
            "well-written\n",
            "and\n",
            "organized\n",
            ".\n",
            "Intuitions\n",
            "are\n",
            "given\n",
            "as\n",
            "well\n",
            "as\n",
            "rigorous\n",
            "mathematical\n",
            "descriptions\n",
            ",\n",
            "which\n",
            "makes\n",
            "it\n",
            "very\n",
            "easy\n",
            "to\n",
            "follow\n",
            ",\n",
            "and\n",
            "I\n",
            "find\n",
            "it\n",
            "enjoyable\n",
            "to\n",
            "read\n",
            ".\n",
            "Besides\n",
            ",\n",
            "the\n",
            "evaluations\n",
            ",\n",
            "theoretical\n",
            "analysis\n",
            "and\n",
            "relevant\n",
            "discussion\n",
            "are\n",
            "also\n",
            "done\n",
            "with\n",
            "high\n",
            "standards\n",
            ".\n",
            "Weaknesses\n",
            ":\n",
            "1\n",
            ".\n",
            "In\n",
            "Fig.1\n",
            ",\n",
            "it\n",
            "seems\n",
            "that\n",
            "the\n",
            "probabilistic\n",
            "classifier\n",
            "approach\n",
            "is\n",
            "better\n",
            "than\n",
            "the\n",
            "density-ratio\n",
            "fitting\n",
            "approach\n",
            ",\n",
            "as\n",
            "it\n",
            "has\n",
            "both\n",
            "smaller\n",
            "bias\n",
            "and\n",
            "variance\n",
            ".\n",
            "However\n",
            ",\n",
            "in\n",
            "Fig\n",
            ".\n",
            "2\n",
            "for\n",
            "another\n",
            "task\n",
            ",\n",
            "the\n",
            "density-ratio\n",
            "fitting\n",
            "is\n",
            "consistently\n",
            "better\n",
            "than\n",
            "all\n",
            "other\n",
            "approaches\n",
            ".\n",
            "I\n",
            "am\n",
            "wondering\n",
            "if\n",
            "authors\n",
            "have\n",
            "any\n",
            "insights\n",
            "to\n",
            "the\n",
            "differences\n",
            "between\n",
            "their\n",
            "performance\n",
            "in\n",
            "different\n",
            "tasks\n",
            ".\n",
            "2\n",
            ".\n",
            "In\n",
            "the\n",
            "cross-modal\n",
            "learning\n",
            "section\n",
            ",\n",
            "no\n",
            "baselines\n",
            "were\n",
            "compared\n",
            ",\n",
            "and\n",
            "the\n",
            "density-ratio\n",
            "fitting\n",
            "was\n",
            "neither\n",
            "compared\n",
            ".\n",
            "While\n",
            "I\n",
            "understand\n",
            "that\n",
            "the\n",
            "main\n",
            "purpose\n",
            "is\n",
            "to\n",
            "showcase\n",
            "the\n",
            "usage\n",
            "of\n",
            "PD\n",
            ",\n",
            "cross-modality\n",
            "learning\n",
            "is\n",
            "potentially\n",
            "an\n",
            "important\n",
            "application\n",
            "of\n",
            "PD\n",
            "estimation\n",
            ",\n",
            "so\n",
            "I\n",
            "would\n",
            "suggest\n",
            "authors\n",
            "to\n",
            "compare\n",
            "against\n",
            "some\n",
            "SOTA\n",
            "baselines\n",
            "in\n",
            "this\n",
            "topic\n",
            ".\n",
            "Correctness\n",
            ":\n",
            "The\n",
            "approaches\n",
            "developed\n",
            "are\n",
            "technically\n",
            "sound\n",
            ".\n",
            "Both\n",
            "theoretical\n",
            "analysis\n",
            "and\n",
            "empirical\n",
            "evaluations\n",
            "are\n",
            "present\n",
            "and\n",
            "solid\n",
            ".\n",
            "Clarity\n",
            ":\n",
            "The\n",
            "paper\n",
            "is\n",
            "well-written\n",
            ",\n",
            "organized\n",
            "and\n",
            "extremely\n",
            "easy\n",
            "to\n",
            "follow\n",
            ".\n",
            "Relation\n",
            "to\n",
            "Prior\n",
            "Work\n",
            ":\n",
            "Relevant\n",
            "prior\n",
            "works\n",
            "are\n",
            "properly\n",
            "cited\n",
            ",\n",
            "discussed\n",
            "and\n",
            "compared\n",
            ".\n",
            "Reproducibility\n",
            ":\n",
            "Yes\n",
            "Additional\n",
            "Feedback\n",
            ":\n",
            "Please\n",
            "kindly\n",
            "see\n",
            "the\n",
            "Weaknesses\n",
            "section\n",
            ".\n",
            "Review\n",
            "3\n",
            "Summary\n",
            "and\n",
            "Contributions\n",
            ":\n",
            "This\n",
            "paper\n",
            "studies\n",
            "estimating\n",
            "point-wise\n",
            "dependency\n",
            "of\n",
            "data\n",
            "instance\n",
            ".\n",
            "For\n",
            "this\n",
            "purpose\n",
            ",\n",
            "two\n",
            "methods\n",
            "are\n",
            "proposed\n",
            ".\n",
            "Experiments\n",
            "on\n",
            "three\n",
            "tasks\n",
            "demonstrate\n",
            "the\n",
            "effectiveness\n",
            "of\n",
            "the\n",
            "proposed\n",
            "methods\n",
            ".\n",
            "Strengths\n",
            ":\n",
            "1\n",
            ".\n",
            "The\n",
            "problem\n",
            "is\n",
            "important\n",
            "to\n",
            "the\n",
            "NeurIPS\n",
            "community\n",
            ".\n",
            "2\n",
            ".\n",
            "The\n",
            "method\n",
            "is\n",
            "theoretically\n",
            "sound\n",
            ".\n",
            "3\n",
            ".\n",
            "The\n",
            "empirical\n",
            "evaluation\n",
            "is\n",
            "extensive\n",
            ".\n",
            "Weaknesses\n",
            ":\n",
            "1\n",
            ".\n",
            "The\n",
            "contribution\n",
            "is\n",
            "not\n",
            "significant\n",
            ",\n",
            "given\n",
            "existing\n",
            "neural\n",
            "method\n",
            "for\n",
            "density\n",
            "ratio\n",
            "estimation\n",
            "and\n",
            "point-wise\n",
            "mutual\n",
            "information\n",
            "estimation\n",
            ".\n",
            "2\n",
            ".\n",
            "The\n",
            "experiment\n",
            "is\n",
            "mainly\n",
            "conducted\n",
            "on\n",
            "toy\n",
            "data\n",
            ".\n",
            "Correctness\n",
            ":\n",
            "They\n",
            "are\n",
            "correct\n",
            ".\n",
            "Clarity\n",
            ":\n",
            "The\n",
            "paper\n",
            "is\n",
            "well\n",
            "written\n",
            ".\n",
            "Relation\n",
            "to\n",
            "Prior\n",
            "Work\n",
            ":\n",
            "The\n",
            "discussion\n",
            "is\n",
            "clear\n",
            ".\n",
            "Reproducibility\n",
            ":\n",
            "Yes\n",
            "Additional\n",
            "Feedback\n",
            ":\n",
            "This\n",
            "paper\n",
            "studies\n",
            "estimating\n",
            "point-wise\n",
            "dependency\n",
            "of\n",
            "data\n",
            "instance\n",
            ".\n",
            "For\n",
            "this\n",
            "purpose\n",
            ",\n",
            "two\n",
            "methods\n",
            "are\n",
            "proposed\n",
            ".\n",
            "Experiments\n",
            "on\n",
            "three\n",
            "tasks\n",
            "demonstrate\n",
            "the\n",
            "effectiveness\n",
            "of\n",
            "the\n",
            "proposed\n",
            "methods\n",
            ".\n",
            "The\n",
            "paper\n",
            "also\n",
            "has\n",
            "several\n",
            "weaknesses\n",
            ":\n",
            "1\n",
            ".\n",
            "The\n",
            "contribution\n",
            "is\n",
            "not\n",
            "so\n",
            "significant\n",
            ".\n",
            "1\n",
            ")\n",
            "This\n",
            "paper\n",
            "focuses\n",
            "on\n",
            "estimating\n",
            "point-wise\n",
            "dependency\n",
            "of\n",
            "data\n",
            "instance\n",
            ",\n",
            "and\n",
            "the\n",
            "proposed\n",
            "methods\n",
            "are\n",
            "principled\n",
            "and\n",
            "theoretically\n",
            "sound\n",
            ".\n",
            "Despite\n",
            "the\n",
            "merit\n",
            ",\n",
            "similar\n",
            "problems\n",
            "have\n",
            "been\n",
            "extensively\n",
            "studied\n",
            "in\n",
            "the\n",
            "machine\n",
            "learning\n",
            "literature\n",
            ".\n",
            "For\n",
            "example\n",
            ",\n",
            "many\n",
            "prior\n",
            "works\n",
            "estimate\n",
            "the\n",
            "density\n",
            "ratio\n",
            "of\n",
            "two\n",
            "distributions\n",
            "by\n",
            "using\n",
            "the\n",
            "conjugate\n",
            "form\n",
            "of\n",
            "f-divergence\n",
            ",\n",
            "and\n",
            "these\n",
            "methods\n",
            "can\n",
            "be\n",
            "used\n",
            "to\n",
            "estimate\n",
            "the\n",
            "point-wise\n",
            "dependency\n",
            ".\n",
            "Also\n",
            ",\n",
            "some\n",
            "other\n",
            "works\n",
            "try\n",
            "to\n",
            "use\n",
            "neural\n",
            "method\n",
            "to\n",
            "estimate\n",
            "point-wise\n",
            "mutual\n",
            "information\n",
            ",\n",
            "which\n",
            "are\n",
            "also\n",
            "able\n",
            "to\n",
            "estimate\n",
            "the\n",
            "point-wise\n",
            "dependency\n",
            ".\n",
            "Given\n",
            "these\n",
            "existing\n",
            "studies\n",
            ",\n",
            "the\n",
            "idea\n",
            "of\n",
            "the\n",
            "paper\n",
            "seems\n",
            "quite\n",
            "straightforward\n",
            ".\n",
            "2\n",
            ")\n",
            "For\n",
            "point-wise\n",
            "dependency\n",
            "estimation\n",
            ",\n",
            "two\n",
            "methods\n",
            "are\n",
            "proposed\n",
            ".\n",
            "The\n",
            "first\n",
            "Probabilistic\n",
            "Classifier\n",
            "method\n",
            "optimizes\n",
            "a\n",
            "classifier\n",
            ",\n",
            "which\n",
            "is\n",
            "then\n",
            "used\n",
            "to\n",
            "estimate\n",
            "the\n",
            "point-wise\n",
            "dependency\n",
            ".\n",
            "However\n",
            ",\n",
            "I\n",
            "feel\n",
            "like\n",
            "this\n",
            "method\n",
            "is\n",
            "a\n",
            "direct\n",
            "extension\n",
            "of\n",
            "GAN\n",
            "and\n",
            "f-divergence\n",
            "for\n",
            "density\n",
            "ratio\n",
            "estimation\n",
            ".\n",
            "For\n",
            "the\n",
            "second\n",
            "Density-Ratio\n",
            "Fitting\n",
            "method\n",
            ",\n",
            "it\n",
            "is\n",
            "also\n",
            "inspired\n",
            "by\n",
            "a\n",
            "prior\n",
            "work\n",
            ".\n",
            "In\n",
            "this\n",
            "sense\n",
            ",\n",
            "this\n",
            "paper\n",
            "does\n",
            "not\n",
            "propose\n",
            "much\n",
            "new\n",
            "insight\n",
            "on\n",
            "methodology\n",
            ".\n",
            "3\n",
            ")\n",
            "The\n",
            "paper\n",
            "also\n",
            "points\n",
            "out\n",
            "that\n",
            "the\n",
            "problem\n",
            "of\n",
            "point-wise\n",
            "dependency\n",
            "estimation\n",
            "can\n",
            "be\n",
            "solved\n",
            "by\n",
            "existing\n",
            "neural\n",
            "estimator\n",
            "of\n",
            "mutual\n",
            "information\n",
            ".\n",
            "From\n",
            "my\n",
            "understanding\n",
            ",\n",
            "the\n",
            "proposed\n",
            "methods\n",
            "share\n",
            "very\n",
            "similar\n",
            "methodology\n",
            "to\n",
            "these\n",
            "methods\n",
            ".\n",
            "I\n",
            "wonder\n",
            "what\n",
            "is\n",
            "the\n",
            "advantage\n",
            "of\n",
            "the\n",
            "proposed\n",
            "methods\n",
            "for\n",
            "estimating\n",
            "point-wise\n",
            "dependency\n",
            "over\n",
            "these\n",
            "related\n",
            "methods\n",
            "?\n",
            "2\n",
            ".\n",
            "The\n",
            "experiment\n",
            "is\n",
            "only\n",
            "conducted\n",
            "on\n",
            "toy\n",
            "dataset\n",
            ".\n",
            "Although\n",
            "the\n",
            "experiment\n",
            "in\n",
            "the\n",
            "paper\n",
            "is\n",
            "extensive\n",
            ",\n",
            "where\n",
            "three\n",
            "tasks\n",
            "are\n",
            "considered\n",
            ",\n",
            "the\n",
            "experiment\n",
            "is\n",
            "only\n",
            "conducted\n",
            "on\n",
            "toy\n",
            "datasets\n",
            ".\n",
            "For\n",
            "example\n",
            ",\n",
            "in\n",
            "application\n",
            "1\n",
            ",\n",
            "different\n",
            "methods\n",
            "are\n",
            "evaluated\n",
            "with\n",
            "correlated\n",
            "Gaussian\n",
            "distributions\n",
            ";\n",
            "in\n",
            "application\n",
            "2\n",
            ",\n",
            "two\n",
            "small\n",
            "datasets\n",
            "MNIST\n",
            "and\n",
            "CIFAR\n",
            "are\n",
            "used\n",
            ".\n",
            "For\n",
            "application\n",
            "1\n",
            ",\n",
            "it\n",
            "is\n",
            "possible\n",
            "to\n",
            "evaluate\n",
            "with\n",
            "some\n",
            "other\n",
            "distributions\n",
            "?\n",
            "For\n",
            "application\n",
            "2\n",
            ",\n",
            "is\n",
            "it\n",
            "possible\n",
            "to\n",
            "evaluate\n",
            "on\n",
            "ImageNet\n",
            "?\n",
            "For\n",
            "application\n",
            "3\n",
            ",\n",
            "is\n",
            "there\n",
            "any\n",
            "baseline\n",
            "method\n",
            "to\n",
            "compare\n",
            "against\n",
            "?\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "--\n",
            "-\n",
            "Thanks\n",
            "the\n",
            "authors\n",
            "for\n",
            "the\n",
            "clarity\n",
            "on\n",
            "the\n",
            "contribution\n",
            "and\n",
            "the\n",
            "additional\n",
            "experimental\n",
            "results\n",
            "!\n",
            "Overall\n",
            ",\n",
            "this\n",
            "is\n",
            "a\n",
            "solid\n",
            "work\n",
            "and\n",
            "I\n",
            "lean\n",
            "towards\n",
            "an\n",
            "accept\n",
            ".\n",
            "Review\n",
            "4\n",
            "Summary\n",
            "and\n",
            "Contributions\n",
            ":\n",
            "In\n",
            "this\n",
            "paper\n",
            ",\n",
            "the\n",
            "authors\n",
            "study\n",
            "how\n",
            "to\n",
            "efficiently\n",
            "and\n",
            "effectively\n",
            "perform\n",
            "point-wise\n",
            "dependency\n",
            "estimation\n",
            "by\n",
            "neural\n",
            "methods\n",
            ".\n",
            "The\n",
            "main\n",
            "contribution\n",
            "could\n",
            "be\n",
            "summarized\n",
            "as\n",
            "follows\n",
            ".\n",
            "C1\n",
            ".\n",
            "An\n",
            "interesting\n",
            "angle\n",
            "to\n",
            "address\n",
            "mutual\n",
            "information\n",
            "estimation\n",
            "is\n",
            "discussed\n",
            ".\n",
            "C2\n",
            ".\n",
            "Probabilistic\n",
            "classifier\n",
            "and\n",
            "density-ratio\n",
            "fitting\n",
            "are\n",
            "proposed\n",
            "to\n",
            "enable\n",
            "effective\n",
            "point-wise\n",
            "dependency\n",
            "estimation\n",
            ".\n",
            "C3\n",
            ".\n",
            "The\n",
            "value\n",
            "of\n",
            "point-wise\n",
            "dependency\n",
            "estimation\n",
            "is\n",
            "highlighted\n",
            "from\n",
            "empirical\n",
            "study\n",
            ".\n",
            "Strengths\n",
            ":\n",
            "S1\n",
            ".\n",
            "The\n",
            "authors\n",
            "suggest\n",
            "interesting\n",
            "perspectives\n",
            "to\n",
            "approach\n",
            "point-wise\n",
            "dependency\n",
            "estimation\n",
            ".\n",
            "S2\n",
            ".\n",
            "Theoretical\n",
            "evidences\n",
            "are\n",
            "provided\n",
            "to\n",
            "enrich\n",
            "the\n",
            "discussion\n",
            "on\n",
            "mutual\n",
            "information\n",
            "estimation\n",
            ".\n",
            "S3\n",
            ".\n",
            "The\n",
            "author\n",
            "explore\n",
            "multiple\n",
            "applications\n",
            "to\n",
            "demonstrate\n",
            "the\n",
            "value\n",
            "in\n",
            "point-wise\n",
            "dependency\n",
            "estimation\n",
            ".\n",
            "Weaknesses\n",
            ":\n",
            "W1\n",
            ".\n",
            "It\n",
            "is\n",
            "difficult\n",
            "to\n",
            "clearly\n",
            "see\n",
            "the\n",
            "concrete\n",
            "difference/impact\n",
            "brought\n",
            "by\n",
            "either\n",
            "probabilistic\n",
            "classifier\n",
            "or\n",
            "density-ratio\n",
            "fitting\n",
            ".\n",
            "It\n",
            "could\n",
            "be\n",
            "the\n",
            "presentation\n",
            "in\n",
            "Figure\n",
            "1\n",
            ".\n",
            "Instead\n",
            "of\n",
            "being\n",
            "qualitative\n",
            ",\n",
            "the\n",
            "authors\n",
            "may\n",
            "make\n",
            "this\n",
            "comparison\n",
            "more\n",
            "quantitative\n",
            ".\n",
            "W2\n",
            ".\n",
            "The\n",
            "value\n",
            "of\n",
            "point-wise\n",
            "dependency\n",
            "estimation\n",
            "in\n",
            "cross-modal\n",
            "learning\n",
            "is\n",
            "a\n",
            "bit\n",
            "weak\n",
            ".\n",
            "The\n",
            "task\n",
            "discussed\n",
            "in\n",
            "Section\n",
            "6\n",
            "seems\n",
            "to\n",
            "be\n",
            "a\n",
            "typical\n",
            "classification\n",
            "or\n",
            "ranking\n",
            "problem\n",
            ".\n",
            "To\n",
            "this\n",
            "end\n",
            ",\n",
            "to\n",
            "better\n",
            "show\n",
            "the\n",
            "value\n",
            "of\n",
            "point-wise\n",
            "estimation\n",
            ",\n",
            "it\n",
            "is\n",
            "important\n",
            "to\n",
            "make\n",
            "comparison\n",
            "with\n",
            "state-of-the-art\n",
            "baselines\n",
            ".\n",
            "Otherwise\n",
            ",\n",
            "only\n",
            "feasibility\n",
            "could\n",
            "be\n",
            "claimed\n",
            ",\n",
            "leaving\n",
            "limited\n",
            "impact\n",
            ".\n",
            "Correctness\n",
            ":\n",
            "In\n",
            "general\n",
            ",\n",
            "yes\n",
            ",\n",
            "but\n",
            "the\n",
            "empirical\n",
            "results\n",
            "presentation\n",
            "may\n",
            "need\n",
            "improvement\n",
            ".\n",
            "Clarity\n",
            ":\n",
            "Yes\n",
            "Relation\n",
            "to\n",
            "Prior\n",
            "Work\n",
            ":\n",
            "Yes\n",
            "Reproducibility\n",
            ":\n",
            "Yes\n",
            "NeurIPS\n",
            "2020\n",
            "Neural\n",
            "Methods\n",
            "for\n",
            "Point-wise\n",
            "Dependency\n",
            "Estimation\n",
            "Meta\n",
            "Review\n",
            "The\n",
            "paper\n",
            "present\n",
            "some\n",
            "clear\n",
            "novelty\n",
            "in\n",
            "the\n",
            "under-studied\n",
            "domain\n",
            "of\n",
            "point-wise\n",
            "dependency\n",
            "estimation\n",
            ",\n",
            "with\n",
            "clear\n",
            "supporting\n",
            "evidence\n",
            "though\n",
            "various\n",
            "experiments\n",
            ".\n",
            "The\n",
            "reviewer\n",
            "concerns\n",
            "were\n",
            "clarified\n",
            "in\n",
            "the\n",
            "rebuttal\n",
            ",\n",
            "but\n",
            "we\n",
            "expect\n",
            "the\n",
            "authors\n",
            "to\n",
            "work\n",
            "significantly\n",
            "by\n",
            "including\n",
            "the\n",
            "changes\n",
            "they\n",
            "mention\n",
            "in\n",
            "their\n",
            "rebuttal\n",
            ",\n",
            "e.g\n",
            ":\n",
            "-\n",
            "shorten\n",
            "Section\n",
            "3.1\n",
            "and\n",
            "include\n",
            "more\n",
            "motivations\n",
            "for\n",
            "our\n",
            "presented\n",
            "approaches\n",
            "in\n",
            "Section\n",
            "3.2\n",
            ".\n",
            "-\n",
            "include\n",
            "the\n",
            "MI\n",
            "discussion\n",
            ",\n",
            "-\n",
            "include\n",
            "ImageNet\n",
            "results\n",
            "in\n",
            "Experiment\n",
            "2\n",
            "Book\n",
            "Do\n",
            "not\n",
            "remove\n",
            ":\n",
            "This\n",
            "comment\n",
            "is\n",
            "monitored\n",
            "to\n",
            "verify\n",
            "that\n",
            "the\n",
            "site\n",
            "is\n",
            "working\n",
            "properly\n",
            "Abstract\n",
            "Reasoning\n",
            "over\n",
            "an\n",
            "instance\n",
            "composed\n",
            "of\n",
            "a\n",
            "set\n",
            "of\n",
            "vectors\n",
            ",\n",
            "like\n",
            "a\n",
            "point\n",
            "cloud\n",
            ",\n",
            "requires\n",
            "that\n",
            "one\n",
            "accounts\n",
            "for\n",
            "intra-set\n",
            "dependent\n",
            "features\n",
            "among\n",
            "elements\n",
            ".\n",
            "However\n",
            ",\n",
            "since\n",
            "such\n",
            "instances\n",
            "are\n",
            "unordered\n",
            ",\n",
            "the\n",
            "elements\n",
            "’\n",
            "features\n",
            "should\n",
            "remain\n",
            "unchanged\n",
            "when\n",
            "the\n",
            "input\n",
            "’\n",
            "s\n",
            "order\n",
            "is\n",
            "permuted\n",
            ".\n",
            "This\n",
            "property\n",
            ",\n",
            "permutation\n",
            "equivariance\n",
            ",\n",
            "is\n",
            "a\n",
            "challenging\n",
            "constraint\n",
            "for\n",
            "most\n",
            "neural\n",
            "architectures\n",
            ".\n",
            "While\n",
            "recent\n",
            "work\n",
            "has\n",
            "proposed\n",
            "global\n",
            "pooling\n",
            "and\n",
            "attention-based\n",
            "solutions\n",
            ",\n",
            "these\n",
            "may\n",
            "be\n",
            "limited\n",
            "in\n",
            "the\n",
            "way\n",
            "that\n",
            "intradependencies\n",
            "are\n",
            "captured\n",
            "in\n",
            "practice\n",
            ".\n",
            "In\n",
            "this\n",
            "work\n",
            "we\n",
            "propose\n",
            "a\n",
            "more\n",
            "general\n",
            "formulation\n",
            "to\n",
            "achieve\n",
            "permutation\n",
            "equivariance\n",
            "through\n",
            "ordinary\n",
            "differential\n",
            "equations\n",
            "(\n",
            "ODE\n",
            ")\n",
            ".\n",
            "Our\n",
            "proposed\n",
            "module\n",
            ",\n",
            "Exchangeable\n",
            "Neural\n",
            "ODE\n",
            "(\n",
            "ExNODE\n",
            ")\n",
            ",\n",
            "can\n",
            "be\n",
            "seamlessly\n",
            "applied\n",
            "for\n",
            "both\n",
            "discriminative\n",
            "and\n",
            "generative\n",
            "tasks\n",
            ".\n",
            "We\n",
            "also\n",
            "extend\n",
            "set\n",
            "modeling\n",
            "in\n",
            "the\n",
            "temporal\n",
            "dimension\n",
            "and\n",
            "propose\n",
            "a\n",
            "VAE\n",
            "based\n",
            "model\n",
            "for\n",
            "temporal\n",
            "set\n",
            "modeling\n",
            ".\n",
            "Extensive\n",
            "experiments\n",
            "demonstrate\n",
            "the\n",
            "efﬁcacy\n",
            "of\n",
            "our\n",
            "method\n",
            "over\n",
            "strong\n",
            "baselines\n",
            ".\n",
            "1\n",
            "Abstract\n",
            "We\n",
            "consider\n",
            "the\n",
            "problem\n",
            "of\n",
            "estimating\n",
            "the\n",
            "input\n",
            "and\n",
            "hidden\n",
            "variables\n",
            "of\n",
            "a\n",
            "stochastic\n",
            "multi-layer\n",
            "neural\n",
            "network\n",
            "from\n",
            "an\n",
            "observation\n",
            "of\n",
            "the\n",
            "output\n",
            ".\n",
            "The\n",
            "hidden\n",
            "variables\n",
            "in\n",
            "each\n",
            "layer\n",
            "are\n",
            "represented\n",
            "as\n",
            "matrices\n",
            "with\n",
            "statistical\n",
            "interactions\n",
            "along\n",
            "both\n",
            "rows\n",
            "as\n",
            "well\n",
            "as\n",
            "columns\n",
            ".\n",
            "This\n",
            "problem\n",
            "applies\n",
            "to\n",
            "matrix\n",
            "imputation\n",
            ",\n",
            "signal\n",
            "recovery\n",
            "via\n",
            "deep\n",
            "generative\n",
            "prior\n",
            "models\n",
            ",\n",
            "multi-task\n",
            "and\n",
            "mixed\n",
            "regression\n",
            ",\n",
            "and\n",
            "learning\n",
            "certain\n",
            "classes\n",
            "of\n",
            "two-layer\n",
            "neural\n",
            "networks\n",
            ".\n",
            "We\n",
            "extend\n",
            "a\n",
            "recently-developed\n",
            "algorithm\n",
            "–\n",
            "Multi-Layer\n",
            "Vector\n",
            "Approximate\n",
            "Message\n",
            "Passing\n",
            "(\n",
            "ML-VAMP\n",
            ")\n",
            ",\n",
            "for\n",
            "this\n",
            "matrix-valued\n",
            "inference\n",
            "problem\n",
            ".\n",
            "It\n",
            "is\n",
            "shown\n",
            "that\n",
            "the\n",
            "performance\n",
            "of\n",
            "the\n",
            "proposed\n",
            "Multi-Layer\n",
            "Matrix\n",
            "VAMP\n",
            "(\n",
            "ML-Mat-VAMP\n",
            ")\n",
            "algorithm\n",
            "can\n",
            "be\n",
            "exactly\n",
            "predicted\n",
            "in\n",
            "a\n",
            "certain\n",
            "random\n",
            "large-system\n",
            "limit\n",
            ",\n",
            "where\n",
            "the\n",
            "dimensions\n",
            "N\n",
            "×d\n",
            "of\n",
            "the\n",
            "unknown\n",
            "quantities\n",
            "grow\n",
            "as\n",
            "N\n",
            "→\n",
            "∞\n",
            "with\n",
            "d\n",
            "ﬁxed\n",
            ".\n",
            "In\n",
            "the\n",
            "two-layer\n",
            "neural-network\n",
            "learning\n",
            "problem\n",
            ",\n",
            "this\n",
            "scaling\n",
            "corresponds\n",
            "to\n",
            "the\n",
            "case\n",
            "where\n",
            "the\n",
            "number\n",
            "of\n",
            "input\n",
            "features\n",
            "as\n",
            "well\n",
            "as\n",
            "training\n",
            "samples\n",
            "grow\n",
            "to\n",
            "inﬁnity\n",
            "but\n",
            "the\n",
            "number\n",
            "of\n",
            "hidden\n",
            "nodes\n",
            "stays\n",
            "ﬁxed\n",
            ".\n",
            "The\n",
            "analysis\n",
            "enables\n",
            "a\n",
            "precise\n",
            "prediction\n",
            "of\n",
            "the\n",
            "parameter\n",
            "and\n",
            "test\n",
            "error\n",
            "of\n",
            "the\n",
            "learning\n",
            ".\n",
            "1\n",
            "Abstract\n",
            "Continuous-time\n",
            "event\n",
            "data\n",
            "are\n",
            "common\n",
            "in\n",
            "applications\n",
            "such\n",
            "as\n",
            "individual\n",
            "behavior\n",
            "data\n",
            ",\n",
            "ﬁnancial\n",
            "transactions\n",
            ",\n",
            "and\n",
            "medical\n",
            "health\n",
            "records\n",
            ".\n",
            "Modeling\n",
            "such\n",
            "data\n",
            "can\n",
            "be\n",
            "very\n",
            "challenging\n",
            ",\n",
            "in\n",
            "particular\n",
            "for\n",
            "applications\n",
            "with\n",
            "many\n",
            "different\n",
            "types\n",
            "of\n",
            "events\n",
            ",\n",
            "since\n",
            "it\n",
            "requires\n",
            "a\n",
            "model\n",
            "to\n",
            "predict\n",
            "the\n",
            "event\n",
            "types\n",
            "as\n",
            "well\n",
            "as\n",
            "the\n",
            "time\n",
            "of\n",
            "occurrence\n",
            ".\n",
            "Recurrent\n",
            "neural\n",
            "networks\n",
            "that\n",
            "parameterize\n",
            "time-varying\n",
            "intensity\n",
            "functions\n",
            "are\n",
            "the\n",
            "current\n",
            "state-of-the-art\n",
            "for\n",
            "predictive\n",
            "modeling\n",
            "with\n",
            "such\n",
            "data\n",
            ".\n",
            "These\n",
            "models\n",
            "typically\n",
            "assume\n",
            "that\n",
            "all\n",
            "event\n",
            "sequences\n",
            "come\n",
            "from\n",
            "the\n",
            "same\n",
            "data\n",
            "distribution\n",
            ".\n",
            "However\n",
            ",\n",
            "in\n",
            "many\n",
            "applications\n",
            "event\n",
            "sequences\n",
            "are\n",
            "generated\n",
            "by\n",
            "different\n",
            "sources\n",
            ",\n",
            "or\n",
            "users\n",
            ",\n",
            "and\n",
            "their\n",
            "characteristics\n",
            "can\n",
            "be\n",
            "very\n",
            "different\n",
            ".\n",
            "In\n",
            "this\n",
            "paper\n",
            ",\n",
            "we\n",
            "extend\n",
            "the\n",
            "broad\n",
            "class\n",
            "of\n",
            "neural\n",
            "marked\n",
            "point\n",
            "process\n",
            "models\n",
            "to\n",
            "mixtures\n",
            "of\n",
            "latent\n",
            "embeddings\n",
            ",\n",
            "where\n",
            "each\n",
            "mixture\n",
            "component\n",
            "models\n",
            "the\n",
            "characteristic\n",
            "traits\n",
            "of\n",
            "a\n",
            "given\n",
            "user\n",
            ".\n",
            "Our\n",
            "approach\n",
            "relies\n",
            "on\n",
            "augmenting\n",
            "these\n",
            "models\n",
            "with\n",
            "a\n",
            "latent\n",
            "variable\n",
            "that\n",
            "encodes\n",
            "user\n",
            "characteristics\n",
            ",\n",
            "represented\n",
            "by\n",
            "a\n",
            "mixture\n",
            "model\n",
            "over\n",
            "user\n",
            "behavior\n",
            "that\n",
            "is\n",
            "trained\n",
            "via\n",
            "amortized\n",
            "variational\n",
            "inference\n",
            ".\n",
            "We\n",
            "evaluate\n",
            "our\n",
            "methods\n",
            "on\n",
            "four\n",
            "large\n",
            "real-world\n",
            "datasets\n",
            "and\n",
            "demonstrate\n",
            "systematic\n",
            "improvements\n",
            "from\n",
            "our\n",
            "approach\n",
            "over\n",
            "existing\n",
            "work\n",
            "for\n",
            "a\n",
            "variety\n",
            "of\n",
            "predictive\n",
            "metrics\n",
            "such\n",
            "as\n",
            "log-likelihood\n",
            ",\n",
            "next\n",
            "event\n",
            "ranking\n",
            ",\n",
            "and\n",
            "source-of-sequence\n",
            "identiﬁcation\n",
            ".\n",
            "1\n",
            "Abstract\n",
            "Temporal\n",
            "point\n",
            "process\n",
            "(\n",
            "TPP\n",
            ")\n",
            "models\n",
            "combined\n",
            "with\n",
            "recurrent\n",
            "neural\n",
            "networks\n",
            "provide\n",
            "a\n",
            "powerful\n",
            "framework\n",
            "for\n",
            "modeling\n",
            "continuous-time\n",
            "event\n",
            "data\n",
            ".\n",
            "While\n",
            "such\n",
            "models\n",
            "are\n",
            "ﬂexible\n",
            ",\n",
            "they\n",
            "are\n",
            "inherently\n",
            "sequential\n",
            "and\n",
            "therefore\n",
            "can\n",
            "not\n",
            "beneﬁt\n",
            "from\n",
            "the\n",
            "parallelism\n",
            "of\n",
            "modern\n",
            "hardware\n",
            ".\n",
            "By\n",
            "exploiting\n",
            "the\n",
            "recent\n",
            "developments\n",
            "in\n",
            "the\n",
            "ﬁeld\n",
            "of\n",
            "normalizing\n",
            "ﬂows\n",
            ",\n",
            "we\n",
            "design\n",
            "TriTPP—\n",
            "a\n",
            "new\n",
            "class\n",
            "of\n",
            "non-recurrent\n",
            "TPP\n",
            "models\n",
            ",\n",
            "where\n",
            "both\n",
            "sampling\n",
            "and\n",
            "likelihood\n",
            "computation\n",
            "can\n",
            "be\n",
            "done\n",
            "in\n",
            "parallel\n",
            ".\n",
            "TriTPP\n",
            "matches\n",
            "the\n",
            "ﬂexibility\n",
            "of\n",
            "RNN-based\n",
            "methods\n",
            "but\n",
            "permits\n",
            "orders\n",
            "of\n",
            "magnitude\n",
            "faster\n",
            "sampling\n",
            ".\n",
            "This\n",
            "enables\n",
            "us\n",
            "to\n",
            "use\n",
            "the\n",
            "new\n",
            "model\n",
            "for\n",
            "variational\n",
            "inference\n",
            "in\n",
            "continuous-time\n",
            "discrete-state\n",
            "systems\n",
            ".\n",
            "We\n",
            "demonstrate\n",
            "the\n",
            "advantages\n",
            "of\n",
            "the\n",
            "proposed\n",
            "framework\n",
            "on\n",
            "synthetic\n",
            "and\n",
            "real-world\n",
            "datasets\n",
            ".\n",
            "1\n",
            "Abstract\n",
            "Density-ratio\n",
            "estimation\n",
            "via\n",
            "classiﬁcation\n",
            "is\n",
            "a\n",
            "cornerstone\n",
            "of\n",
            "unsupervised\n",
            "learning\n",
            ".\n",
            "It\n",
            "has\n",
            "provided\n",
            "the\n",
            "foundation\n",
            "for\n",
            "state-of-the-art\n",
            "methods\n",
            "in\n",
            "representation\n",
            "learning\n",
            "and\n",
            "generative\n",
            "modelling\n",
            ",\n",
            "with\n",
            "the\n",
            "number\n",
            "of\n",
            "use-cases\n",
            "continuing\n",
            "to\n",
            "proliferate\n",
            ".\n",
            "However\n",
            ",\n",
            "it\n",
            "suffers\n",
            "from\n",
            "a\n",
            "critical\n",
            "limitation\n",
            ":\n",
            "it\n",
            "fails\n",
            "to\n",
            "accurately\n",
            "estimate\n",
            "ratios\n",
            "p/q\n",
            "for\n",
            "which\n",
            "the\n",
            "two\n",
            "densities\n",
            "differ\n",
            "signiﬁcantly\n",
            ".\n",
            "Empirically\n",
            ",\n",
            "we\n",
            "ﬁnd\n",
            "this\n",
            "occurs\n",
            "whenever\n",
            "the\n",
            "KL\n",
            "divergence\n",
            "between\n",
            "p\n",
            "and\n",
            "q\n",
            "exceeds\n",
            "tens\n",
            "of\n",
            "nats\n",
            ".\n",
            "To\n",
            "resolve\n",
            "this\n",
            "limitation\n",
            ",\n",
            "we\n",
            "introduce\n",
            "a\n",
            "new\n",
            "framework\n",
            ",\n",
            "telescoping\n",
            "density-ratio\n",
            "estimation\n",
            "(\n",
            "TRE\n",
            ")\n",
            ",\n",
            "that\n",
            "enables\n",
            "the\n",
            "estimation\n",
            "of\n",
            "ratios\n",
            "between\n",
            "highly\n",
            "dissimilar\n",
            "densities\n",
            "in\n",
            "high-dimensional\n",
            "spaces\n",
            ".\n",
            "Our\n",
            "experiments\n",
            "demonstrate\n",
            "that\n",
            "TRE\n",
            "can\n",
            "yield\n",
            "substantial\n",
            "improvements\n",
            "over\n",
            "existing\n",
            "single-ratio\n",
            "methods\n",
            "for\n",
            "mutual\n",
            "information\n",
            "estimation\n",
            ",\n",
            "representation\n",
            "learning\n",
            "and\n",
            "energy-based\n",
            "modelling\n",
            ".\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "df_output                                                topic  \\\n",
            "0                                            neurips   \n",
            "1                                            neurips   \n",
            "2                                            neurips   \n",
            "3                                            neurips   \n",
            "4                                            neurips   \n",
            "5                                            neurips   \n",
            "6                                            neurips   \n",
            "7                                            neurips   \n",
            "8                                            neurips   \n",
            "9                                            neurips   \n",
            "0  unsupervised information theoretic perceptual ...   \n",
            "1  unsupervised information theoretic perceptual ...   \n",
            "2  unsupervised information theoretic perceptual ...   \n",
            "3  unsupervised information theoretic perceptual ...   \n",
            "4  unsupervised information theoretic perceptual ...   \n",
            "5  unsupervised information theoretic perceptual ...   \n",
            "6  unsupervised information theoretic perceptual ...   \n",
            "7  unsupervised information theoretic perceptual ...   \n",
            "8  unsupervised information theoretic perceptual ...   \n",
            "9  unsupervised information theoretic perceptual ...   \n",
            "0  self supervised multimodal versatile networks ...   \n",
            "1  self supervised multimodal versatile networks ...   \n",
            "2  self supervised multimodal versatile networks ...   \n",
            "3  self supervised multimodal versatile networks ...   \n",
            "4  self supervised multimodal versatile networks ...   \n",
            "5  self supervised multimodal versatile networks ...   \n",
            "0  benchmarking deep inverse models time neural a...   \n",
            "1  benchmarking deep inverse models time neural a...   \n",
            "2  benchmarking deep inverse models time neural a...   \n",
            "3  benchmarking deep inverse models time neural a...   \n",
            "4  benchmarking deep inverse models time neural a...   \n",
            "5  benchmarking deep inverse models time neural a...   \n",
            "6  benchmarking deep inverse models time neural a...   \n",
            "0  off policy evaluation learning external validi...   \n",
            "1  off policy evaluation learning external validi...   \n",
            "2  off policy evaluation learning external validi...   \n",
            "3  off policy evaluation learning external validi...   \n",
            "4  off policy evaluation learning external validi...   \n",
            "0  neural methods point wise dependency estimatio...   \n",
            "1  neural methods point wise dependency estimatio...   \n",
            "2  neural methods point wise dependency estimatio...   \n",
            "3  neural methods point wise dependency estimatio...   \n",
            "4  neural methods point wise dependency estimatio...   \n",
            "5  neural methods point wise dependency estimatio...   \n",
            "6  neural methods point wise dependency estimatio...   \n",
            "7  neural methods point wise dependency estimatio...   \n",
            "8  neural methods point wise dependency estimatio...   \n",
            "9  neural methods point wise dependency estimatio...   \n",
            "\n",
            "                                               title  \\\n",
            "0  Training Generative Adversarial Networks with ...   \n",
            "1  Estimating Training Data Influence by Tracing ...   \n",
            "2                         Deep Evidential Regression   \n",
            "3  Information Theoretic Regret Bounds for Online...   \n",
            "4           Universally Quantized Neural Compression   \n",
            "5  Advances in Neural Information Processing Syst...   \n",
            "6      Graph Contrastive Learning with Augmentations   \n",
            "7  Efficient Exact Verification of Binarized Neur...   \n",
            "8  Path Sample-Analytic Gradient Estimators for S...   \n",
            "9                           Deep Archimedean Copulas   \n",
            "0  An Unsupervised Information-Theoretic Perceptu...   \n",
            "1  An Unsupervised Information-Theoretic ... - Re...   \n",
            "2  An Unsupervised Information-Theoretic ... - Re...   \n",
            "3  Advances in Neural Information Processing Syst...   \n",
            "4  Neural FFTs for Universal Texture Image Synthesis   \n",
            "5        Object-Centric Learning with Slot Attention   \n",
            "6  Self-supervised learning through the eyes of a...   \n",
            "7  Robust Compressed Sensing using Generative Models   \n",
            "8  Network-to-Network Translation with Conditiona...   \n",
            "9  Functional Regularization for Representation L...   \n",
            "0      Self-Supervised MultiModal Versatile Networks   \n",
            "1  Advances in Neural Information Processing Syst...   \n",
            "2  Large-Scale Adversarial Training for Vision-an...   \n",
            "3  Training Generative Adversarial Networks with ...   \n",
            "4                         Bayesian Attention Modules   \n",
            "5  Language-Conditioned Imitation Learning for Ro...   \n",
            "0  Benchmarking Deep Inverse Models over time, an...   \n",
            "1  Benchmarking Deep Inverse Models ... - Review ...   \n",
            "2  Benchmarking Deep Inverse Models ... - Review ...   \n",
            "3  Advances in Neural Information Processing Syst...   \n",
            "4  On Second Order Behaviour in Augmented Neural ...   \n",
            "5  A Flexible Framework for Designing Trainable P...   \n",
            "6                                          JAX, M.D.   \n",
            "0  Off-Policy Evaluation and Learning for Externa...   \n",
            "1  Advances in Neural Information Processing Syst...   \n",
            "2  Fourier Sparse Leverage Scores and Approximate...   \n",
            "3  Fourier Sparse Leverage Scores and Approximate...   \n",
            "4  Recurrent Switching Dynamical Systems Models f...   \n",
            "0  Neural Methods for Point-wise Dependency Estim...   \n",
            "1  Neural Methods for Point-wise Dependency Estim...   \n",
            "2  Neural Methods for Point-wise ... - Review for...   \n",
            "3  Neural Methods for Point-wise ... - Review for...   \n",
            "4  Advances in Neural Information Processing Syst...   \n",
            "5           Exchangeable Neural ODE for Set Modeling   \n",
            "6  Matrix Inference and Estimation in Multi-Layer...   \n",
            "7  User-dependent neural sequence models for cont...   \n",
            "8  Fast and Flexible Temporal Point Processes wit...   \n",
            "9               Telescoping Density-Ratio Estimation   \n",
            "\n",
            "                                                text  \\\n",
            "0  Training Generative Adversarial Networks with ...   \n",
            "1  Estimating Training Data Influence by Tracing ...   \n",
            "2  Deep Evidential Regression\\n\\nPart of Advances...   \n",
            "3  Information Theoretic Regret Bounds for Online...   \n",
            "4  Universally Quantized Neural Compression\\n\\nPa...   \n",
            "5  Book\\n\\nDo not remove: This comment is monitor...   \n",
            "6  Graph Contrastive Learning with Augmentations\\...   \n",
            "7  Efficient Exact Verification of Binarized Neur...   \n",
            "8  Path Sample-Analytic Gradient Estimators for S...   \n",
            "9  Deep Archimedean Copulas\\n\\nPart of Advances i...   \n",
            "0  An Unsupervised Information-Theoretic Perceptu...   \n",
            "1  NeurIPS 2020\\n\\nAn Unsupervised Information-Th...   \n",
            "2  NeurIPS 2020\\n\\nAn Unsupervised Information-Th...   \n",
            "3  Book\\n\\nDo not remove: This comment is monitor...   \n",
            "4  Abstract\\n\\nSynthesizing larger texture images...   \n",
            "5  Abstract\\n\\nLearning object-centric representa...   \n",
            "6  Abstract\\n\\nWithin months of birth, children d...   \n",
            "7  Abstract\\n\\nThe goal of compressed sensing is ...   \n",
            "8  Abstract\\n\\nGiven the ever-increasing computat...   \n",
            "9  Abstract\\n\\nUnsupervised and self-supervised l...   \n",
            "0  Self-Supervised MultiModal Versatile Networks\\...   \n",
            "1  Book\\n\\nDo not remove: This comment is monitor...   \n",
            "2  Abstract\\n\\nWe present VILLA, the ﬁrst known e...   \n",
            "3  Abstract\\n\\nTraining generative adversarial ne...   \n",
            "4  Abstract\\n\\nAttention modules, as simple and e...   \n",
            "5  Abstract\\n\\nImitation learning is a popular ap...   \n",
            "0  Benchmarking Deep Inverse Models over time, an...   \n",
            "1  NeurIPS 2020\\n\\nBenchmarking Deep Inverse Mode...   \n",
            "2  NeurIPS 2020\\n\\nBenchmarking Deep Inverse Mode...   \n",
            "3  Book\\n\\nDo not remove: This comment is monitor...   \n",
            "4  Abstract\\n\\nNeural Ordinary Differential Equat...   \n",
            "5  Abstract\\n\\nWe introduce a general framework f...   \n",
            "6  Abstract\\n\\nWe introduce JAX MD, a software pa...   \n",
            "0  Abstract\\n\\nWe consider evaluating and trainin...   \n",
            "1  Book\\n\\nDo not remove: This comment is monitor...   \n",
            "2  Abstract\\n\\ns-sparse functions of the form f (...   \n",
            "3  Abstract\\n\\ns-sparse functions of the form f (...   \n",
            "4  Abstract\\n\\nModern recording techniques can ge...   \n",
            "0  Neural Methods for Point-wise Dependency Estim...   \n",
            "1  Abstract\\n\\nSince its inception, the neural es...   \n",
            "2  NeurIPS 2020\\n\\nNeural Methods for Point-wise ...   \n",
            "3  NeurIPS 2020\\n\\nNeural Methods for Point-wise ...   \n",
            "4  Book\\n\\nDo not remove: This comment is monitor...   \n",
            "5  Abstract\\n\\nReasoning over an instance compose...   \n",
            "6  Abstract\\n\\nWe consider the problem of estimat...   \n",
            "7  Abstract\\n\\nContinuous-time event data are com...   \n",
            "8  Abstract\\n\\nTemporal point process (TPP) model...   \n",
            "9  Abstract\\n\\nDensity-ratio estimation via class...   \n",
            "\n",
            "                                                 url  similarity_score  rank  \\\n",
            "0  https://papers.nips.cc/paper/2020/hash/8d30aa9...          0.965153   3.0   \n",
            "1  https://papers.nips.cc/paper/2020/hash/e6385d3...          0.965144   4.0   \n",
            "2  https://papers.nips.cc/paper/2020/hash/aab0854...          0.965102   6.0   \n",
            "3  https://papers.nips.cc/paper/2020/hash/aee5620...          0.965130   5.0   \n",
            "4  https://papers.nips.cc/paper/2020/hash/92049de...          0.965285   2.0   \n",
            "5                  https://papers.nips.cc/paper/2020          0.965377   1.0   \n",
            "6  https://papers.nips.cc/paper/2020/hash/3fe2303...          0.960548  10.0   \n",
            "7  https://papers.nips.cc/paper/2020/hash/1385974...          0.962081   7.0   \n",
            "8  https://papers.nips.cc/paper/2020/hash/96fca94...          0.961407   9.0   \n",
            "9  https://papers.nips.cc/paper/2020/hash/10eb650...          0.961599   8.0   \n",
            "0  https://papers.nips.cc/paper/2020/hash/00482b9...          0.960361   6.0   \n",
            "1  https://papers.nips.cc/paper/2020/file/00482b9...          0.940551  10.0   \n",
            "2  https://papers.nips.cc/paper/2020/file/00482b9...          0.960248   8.0   \n",
            "3                  https://papers.nips.cc/paper/2020          0.964870   1.0   \n",
            "4  https://papers.nips.cc/paper/2020/file/a23156a...          0.960257   7.0   \n",
            "5  https://papers.nips.cc/paper/2020/file/8511df9...          0.959921   9.0   \n",
            "6  https://papers.nips.cc/paper/2020/file/7183145...          0.964294   2.0   \n",
            "7  https://papers.nips.cc/paper/2020/file/07cb5f8...          0.963900   3.0   \n",
            "8  https://papers.nips.cc/paper/2020/file/1cfa81a...          0.963835   4.0   \n",
            "9  https://papers.nips.cc/paper/2020/file/c793b3b...          0.961062   5.0   \n",
            "0  https://papers.nips.cc/paper/2020/hash/0060ef4...          0.965593   4.0   \n",
            "1                  https://papers.nips.cc/paper/2020          0.966477   1.0   \n",
            "2  https://papers.nips.cc/paper/2020/file/4956247...          0.965714   3.0   \n",
            "3  https://papers.nips.cc/paper/2020/file/8d30aa9...          0.963016   5.0   \n",
            "4  https://papers.nips.cc/paper/2020/file/bcff3f6...          0.962894   6.0   \n",
            "5  https://papers.nips.cc/paper/2020/file/9909794...          0.966408   2.0   \n",
            "0  https://papers.nips.cc/paper/2020/hash/007ff38...          0.961588   6.0   \n",
            "1  https://papers.nips.cc/paper/2020/file/007ff38...          0.966438   2.0   \n",
            "2  https://papers.nips.cc/paper/2020/file/007ff38...          0.966165   3.0   \n",
            "3                  https://papers.nips.cc/paper/2020          0.965975   4.0   \n",
            "4  https://papers.nips.cc/paper/2020/file/418db2e...          0.961224   7.0   \n",
            "5  https://papers.nips.cc/paper/2020/file/b4edda6...          0.962293   5.0   \n",
            "6  https://papers.nips.cc/paper/2020/file/83d3d4b...          0.966740   1.0   \n",
            "0  https://papers.nips.cc/paper/2020/file/0084ae4...          0.961221   5.0   \n",
            "1                  https://papers.nips.cc/paper/2020          0.965306   2.0   \n",
            "2  https://papers.nips.cc/paper/2020/file/012d9fe...          0.961443   4.0   \n",
            "3  https://papers.nips.cc/paper/2020/file/012d9fe...          0.961443   4.0   \n",
            "4  https://papers.nips.cc/paper/2020/file/aa1f5f7...          0.965760   1.0   \n",
            "0  https://papers.nips.cc/paper/2020/hash/00a03ec...          0.960263  10.0   \n",
            "1  https://papers.nips.cc/paper/2020/file/00a03ec...          0.965585   4.0   \n",
            "2  https://papers.nips.cc/paper/2020/file/00a03ec...          0.965460   5.0   \n",
            "3  https://papers.nips.cc/paper/2020/file/00a03ec...          0.966722   2.0   \n",
            "4                  https://papers.nips.cc/paper/2020          0.965418   6.0   \n",
            "5  https://papers.nips.cc/paper/2020/file/4db7386...          0.960426   9.0   \n",
            "6  https://papers.nips.cc/paper/2020/file/fe2b421...          0.967176   1.0   \n",
            "7  https://papers.nips.cc/paper/2020/file/f56de5e...          0.961511   7.0   \n",
            "8  https://papers.nips.cc/paper/2020/file/00ac8ed...          0.965781   3.0   \n",
            "9  https://papers.nips.cc/paper/2020/file/33d3b15...          0.961219   8.0   \n",
            "\n",
            "   similarity_score_lda  rank_lda  \n",
            "0              0.976416       8.0  \n",
            "1              0.976422       7.0  \n",
            "2              0.976501       5.0  \n",
            "3              0.976803       3.0  \n",
            "4              0.976386       9.0  \n",
            "5              0.976283      10.0  \n",
            "6              0.977023       1.0  \n",
            "7              0.976987       2.0  \n",
            "8              0.976438       6.0  \n",
            "9              0.976682       4.0  \n",
            "0              0.976147       8.0  \n",
            "1              0.975887       9.0  \n",
            "2              0.976883       2.0  \n",
            "3              0.976728       5.0  \n",
            "4              0.975769      10.0  \n",
            "5              0.976862       3.0  \n",
            "6              0.976213       7.0  \n",
            "7              0.977043       1.0  \n",
            "8              0.976403       6.0  \n",
            "9              0.976810       4.0  \n",
            "0              0.977262       6.0  \n",
            "1              0.978460       1.0  \n",
            "2              0.978236       4.0  \n",
            "3              0.977762       5.0  \n",
            "4              0.978310       2.0  \n",
            "5              0.978285       3.0  \n",
            "0              0.976925       4.0  \n",
            "1              0.976647       7.0  \n",
            "2              0.977214       1.0  \n",
            "3              0.976798       6.0  \n",
            "4              0.977014       2.0  \n",
            "5              0.976808       5.0  \n",
            "6              0.976971       3.0  \n",
            "0              0.975795       3.0  \n",
            "1              0.975710       4.0  \n",
            "2              0.975524       5.0  \n",
            "3              0.976571       1.0  \n",
            "4              0.976526       2.0  \n",
            "0              0.977240       3.0  \n",
            "1              0.977083       4.0  \n",
            "2              0.976879       7.0  \n",
            "3              0.977366       2.0  \n",
            "4              0.976997       6.0  \n",
            "5              0.976789       9.0  \n",
            "6              0.976850       8.0  \n",
            "7              0.977056       5.0  \n",
            "8              0.977438       1.0  \n",
            "9              0.976064      10.0  \n",
            "topic:  fast flexible temporal point processes triangular maps neurips id_= 6\n",
            "1 . Fast and Flexible Temporal Point Processes with Triangular Maps https://papers.nips.cc/paper/2020/hash/00ac8ed3b4327bdd4ebbebcb2ba10a00-Abstract.html\n",
            "**********************************************\n",
            "2 . Fast and Flexible Temporal Point Processes with Triangular Maps https://papers.nips.cc/paper/2020/file/00ac8ed3b4327bdd4ebbebcb2ba10a00-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Density-ratio estimation via classiﬁcation is a cornerstone of unsupervised learning.\n",
            "It has provided the foundation for state-of-the-art methods in representation learning\n",
            "and generative modelling, with the number of use-cases continuing to proliferate.\n",
            "However, it suffers from a critical limitation: it fails to accurately estimate ratios\n",
            "p/q for which the two densities differ signiﬁcantly. Empirically, we ﬁnd this\n",
            "occurs whenever the KL divergence between p and q exceeds tens of nats. To\n",
            "resolve this limitation, we introduce a new framework, telescoping density-ratio\n",
            "estimation (TRE), that enables the estimation of ratios between highly dissimilar\n",
            "densities in high-dimensional spaces. Our experiments demonstrate that TRE\n",
            "can yield substantial improvements over existing single-ratio methods for mutual\n",
            "information estimation, representation learning and energy-based modelling.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "3 . Advances in Neural Information Processing Systems 33 (NeurIPS ... https://papers.nips.cc/paper/2020\n",
            "**********************************************\n",
            "4 . Exchangeable Neural ODE for Set Modeling https://papers.nips.cc/paper/2020/file/4db73860ecb5533b5a6c710341d5bbec-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Density-ratio estimation via classiﬁcation is a cornerstone of unsupervised learning.\n",
            "It has provided the foundation for state-of-the-art methods in representation learning\n",
            "and generative modelling, with the number of use-cases continuing to proliferate.\n",
            "However, it suffers from a critical limitation: it fails to accurately estimate ratios\n",
            "p/q for which the two densities differ signiﬁcantly. Empirically, we ﬁnd this\n",
            "occurs whenever the KL divergence between p and q exceeds tens of nats. To\n",
            "resolve this limitation, we introduce a new framework, telescoping density-ratio\n",
            "estimation (TRE), that enables the estimation of ratios between highly dissimilar\n",
            "densities in high-dimensional spaces. Our experiments demonstrate that TRE\n",
            "can yield substantial improvements over existing single-ratio methods for mutual\n",
            "information estimation, representation learning and energy-based modelling.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "5 . Finite-Sample Analysis of Contractive Stochastic Approximation ... https://papers.nips.cc/paper/2020/file/5d44ee6f2c3f71b73125876103c8f6c4-Supplemental.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Stochastic Approximation (SA) is a popular approach for solving ﬁxed-point\n",
            "equations where the information is corrupted by noise. In this paper, we consider\n",
            "an SA involving a contraction mapping with respect to an arbitrary norm, and\n",
            "show its ﬁnite-sample error bounds while using different stepsizes. The idea is\n",
            "to construct a smooth Lyapunov function using the generalized Moreau envelope,\n",
            "and show that the iterates of SA have negative drift with respect to that Lyapunov\n",
            "function. Our result is applicable in Reinforcement Learning (RL). In particular,\n",
            "we use it to establish the ﬁrst-known convergence rate of the V-trace algorithm\n",
            "for off-policy TD-learning [18]. Importantly, our construction results in only a\n",
            "logarithmic dependence of the convergence bound on the size of the state-space.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "6 . Sparse Graphical Memory for Robust Planning https://papers.nips.cc/paper/2020/file/385822e359afa26d52b5b286226f2cea-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "To operate effectively in the real world, agents should be able to act from high-\n",
            "dimensional raw sensory input such as images and achieve diverse goals across long\n",
            "time-horizons. Current deep reinforcement and imitation learning methods can\n",
            "learn directly from high-dimensional inputs but do not scale well to long-horizon\n",
            "tasks. In contrast, classical graphical methods like A* search are able to solve\n",
            "long-horizon tasks, but assume that the state space is abstracted away from raw\n",
            "sensory input. Recent works have attempted to combine the strengths of deep\n",
            "learning and classical planning; however, dominant methods in this domain are\n",
            "still quite brittle and scale poorly with the size of the environment. We introduce\n",
            "Sparse Graphical Memory (SGM), a new data structure that stores states and\n",
            "feasible transitions in a sparse memory. SGM aggregates states according to a\n",
            "novel two-way consistency objective, adapting classic state aggregation criteria\n",
            "to goal-conditioned RL: two states are redundant when they are interchangeable\n",
            "both as goals and as starting states. Theoretically, we prove that merging nodes\n",
            "according to two-way consistency leads to an increase in shortest path lengths that\n",
            "scales only linearly with the merging threshold. Experimentally, we show that SGM\n",
            "signiﬁcantly outperforms current state of the art methods on long horizon, sparse-\n",
            "reward visual navigation tasks. Project video and code are available at https:\n",
            "//mishalaskin.github.io/sgm/.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "7 . Neural Dynamic Policies for End-to-End Sensorimotor Learning https://papers.nips.cc/paper/2020/file/354ac345fd8c6d7ef634d9a8e3d47b83-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "The current dominant paradigm in sensorimotor control, whether imitation or\n",
            "reinforcement learning, is to train policies directly in raw action spaces such\n",
            "as torque, joint angle, or end-effector position. This forces the agent to make\n",
            "decision at each point in training, and hence, limit the scalability to continuous,\n",
            "high-dimensional, and long-horizon tasks. In contrast, research in classical robotics\n",
            "has, for a long time, exploited dynamical systems as a policy representation to\n",
            "learn robot behaviors via demonstrations. These techniques, however, lack the\n",
            "ﬂexibility and generalizability provided by deep learning or deep reinforcement\n",
            "learning and have remained under-explored in such settings. In this work, we begin\n",
            "to close this gap and embed dynamics structure into deep neural network-based\n",
            "policies by reparameterizing action spaces with differential equations. We propose\n",
            "Neural Dynamic Policies (NDPs) that make predictions in trajectory distribution\n",
            "space as opposed to prior policy learning methods where action represents the\n",
            "raw control space. The embedded structure allow us to perform end-to-end policy\n",
            "learning under both reinforcement and imitation learning setups. We show that\n",
            "NDPs achieve better or comparable performance to state-of-the-art approaches on\n",
            "many robotic control tasks using both reward-based training and demonstrations.\n",
            "Project video and code are available at: https://shikharbahl.github.io/\n",
            "neural-dynamic-policies/.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "**********************************************\n",
            "8 . Memory Based Trajectory-conditioned Policies for Learning from ... https://papers.nips.cc/paper/2020/file/2df45244f09369e16ea3f9117ca45157-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Reinforcement learning with sparse rewards is challenging because an agent can\n",
            "rarely obtain non-zero rewards and hence, gradient-based optimization of param-\n",
            "eterized policies can be incremental and slow. Recent work demonstrated that\n",
            "using a memory buffer of previous successful trajectories can result in more ef-\n",
            "fective policies. However, existing methods may overly exploit past successful\n",
            "experiences, which can encourage the agent to adopt sub-optimal and myopic\n",
            "behaviors. In this work, instead of focusing on good experiences with limited\n",
            "diversity, we propose to learn a trajectory-conditioned policy to follow and expand\n",
            "diverse past trajectories from a memory buffer. Our method allows the agent to\n",
            "reach diverse regions in the state space and improve upon the past trajectories to\n",
            "reach new states. We empirically show that our approach signiﬁcantly outperforms\n",
            "count-based exploration methods (parametric approach) and self-imitation learning\n",
            "(parametric approach with non-parametric memory) on various complex tasks with\n",
            "local optima. In particular, without using expert demonstrations or resetting to\n",
            "arbitrary states, we achieve the state-of-the-art scores under ﬁve billion number of\n",
            "frames, on challenging Atari games such as Montezuma’s Revenge and Pitfall.\n",
            "\n",
            "\n",
            "**********************************************\n",
            "9 . Learning Physical Graph Representations from Visual Scenes https://papers.nips.cc/paper/2020/file/4324e8d0d37b110ee1a4f1633ac52df5-Paper.pdf\n",
            "example.pdf\n",
            "Abstract\n",
            "\n",
            "Convolutional Neural Networks (CNNs) have proved exceptional at learning repre-\n",
            "sentations for visual object categorization. However, CNNs do not explicitly encode\n",
            "objects, parts, and their physical properties, which has limited CNNs’ success on\n",
            "tasks that require structured understanding of visual scenes. To overcome these lim-\n",
            "itations, we introduce the idea of “Physical Scene Graphs” (PSGs), which represent\n",
            "scenes as hierarchical graphs, with nodes in the hierarchy corresponding intuitively\n",
            "to object parts at different scales, and edges to physical connections between parts.\n",
            "Bound to each node is a vector of latent attributes that intuitively represent ob-\n",
            "ject properties such as surface shape and texture. We also describe PSGNet, a\n",
            "network architecture that learns to extract PSGs by reconstructing scenes through\n",
            "a PSG-structured bottleneck. PSGNet augments standard CNNs by including:\n",
            "recurrent feedback connections to combine low and high-level image information;\n",
            "graph pooling and vectorization operations that convert spatially-uniform feature\n",
            "maps into object-centric graph structures; and perceptual grouping principles to\n",
            "encourage the identiﬁcation of meaningful scene elements. We show that PSGNet\n",
            "outperforms alternative self-supervised scene representation algorithms at scene\n",
            "segmentation tasks, especially on complex real-world images, and generalizes well\n",
            "to unseen object types and scene arrangements. PSGNet is also able learn from\n",
            "physical motion, enhancing scene estimates even for static images. We present a\n",
            "series of ablation studies illustrating the importance of each component of the PS-\n",
            "GNet architecture, analyses showing that learned latent attributes capture intuitive\n",
            "scene properties, and illustrate the use of PSGs for compositional scene inference.\n",
            "\n",
            "\n",
            "**********************************************\n",
            "data:                                                topic  \\\n",
            "0  fast flexible temporal point processes triangu...   \n",
            "1  fast flexible temporal point processes triangu...   \n",
            "2  fast flexible temporal point processes triangu...   \n",
            "3  fast flexible temporal point processes triangu...   \n",
            "4  fast flexible temporal point processes triangu...   \n",
            "5  fast flexible temporal point processes triangu...   \n",
            "6  fast flexible temporal point processes triangu...   \n",
            "7  fast flexible temporal point processes triangu...   \n",
            "8  fast flexible temporal point processes triangu...   \n",
            "\n",
            "                                               title  \\\n",
            "0  Fast and Flexible Temporal Point Processes wit...   \n",
            "1  Fast and Flexible Temporal Point Processes wit...   \n",
            "2  Advances in Neural Information Processing Syst...   \n",
            "3           Exchangeable Neural ODE for Set Modeling   \n",
            "4  Finite-Sample Analysis of Contractive Stochast...   \n",
            "5        Sparse Graphical Memory for Robust Planning   \n",
            "6  Neural Dynamic Policies for End-to-End Sensori...   \n",
            "7  Memory Based Trajectory-conditioned Policies f...   \n",
            "8  Learning Physical Graph Representations from V...   \n",
            "\n",
            "                                                text  \\\n",
            "0  Fast and Flexible Temporal Point Processes wit...   \n",
            "1  Abstract\\n\\nDensity-ratio estimation via class...   \n",
            "2  Book\\n\\nDo not remove: This comment is monitor...   \n",
            "3  Abstract\\n\\nDensity-ratio estimation via class...   \n",
            "4  Abstract\\n\\nStochastic Approximation (SA) is a...   \n",
            "5  Abstract\\n\\nTo operate effectively in the real...   \n",
            "6  Abstract\\n\\nThe current dominant paradigm in s...   \n",
            "7  Abstract\\n\\nReinforcement learning with sparse...   \n",
            "8  Abstract\\n\\nConvolutional Neural Networks (CNN...   \n",
            "\n",
            "                                                 url  \n",
            "0  https://papers.nips.cc/paper/2020/hash/00ac8ed...  \n",
            "1  https://papers.nips.cc/paper/2020/file/00ac8ed...  \n",
            "2                  https://papers.nips.cc/paper/2020  \n",
            "3  https://papers.nips.cc/paper/2020/file/4db7386...  \n",
            "4  https://papers.nips.cc/paper/2020/file/5d44ee6...  \n",
            "5  https://papers.nips.cc/paper/2020/file/385822e...  \n",
            "6  https://papers.nips.cc/paper/2020/file/354ac34...  \n",
            "7  https://papers.nips.cc/paper/2020/file/2df4524...  \n",
            "8  https://papers.nips.cc/paper/2020/file/4324e8d...  \n",
            "**********************************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                                               topic  \\\n",
            "0  fast flexible temporal point processes triangu...   \n",
            "1  fast flexible temporal point processes triangu...   \n",
            "2  fast flexible temporal point processes triangu...   \n",
            "3  fast flexible temporal point processes triangu...   \n",
            "4  fast flexible temporal point processes triangu...   \n",
            "5  fast flexible temporal point processes triangu...   \n",
            "6  fast flexible temporal point processes triangu...   \n",
            "7  fast flexible temporal point processes triangu...   \n",
            "8  fast flexible temporal point processes triangu...   \n",
            "\n",
            "                                               title  \\\n",
            "0  Fast and Flexible Temporal Point Processes wit...   \n",
            "1  Fast and Flexible Temporal Point Processes wit...   \n",
            "2  Advances in Neural Information Processing Syst...   \n",
            "3           Exchangeable Neural ODE for Set Modeling   \n",
            "4  Finite-Sample Analysis of Contractive Stochast...   \n",
            "5        Sparse Graphical Memory for Robust Planning   \n",
            "6  Neural Dynamic Policies for End-to-End Sensori...   \n",
            "7  Memory Based Trajectory-conditioned Policies f...   \n",
            "8  Learning Physical Graph Representations from V...   \n",
            "\n",
            "                                                text  \\\n",
            "0  Fast and Flexible Temporal Point Processes wit...   \n",
            "1  Abstract\\n\\nDensity-ratio estimation via class...   \n",
            "2  Book\\n\\nDo not remove: This comment is monitor...   \n",
            "3  Abstract\\n\\nDensity-ratio estimation via class...   \n",
            "4  Abstract\\n\\nStochastic Approximation (SA) is a...   \n",
            "5  Abstract\\n\\nTo operate effectively in the real...   \n",
            "6  Abstract\\n\\nThe current dominant paradigm in s...   \n",
            "7  Abstract\\n\\nReinforcement learning with sparse...   \n",
            "8  Abstract\\n\\nConvolutional Neural Networks (CNN...   \n",
            "\n",
            "                                                 url  similarity_score  \n",
            "0  https://papers.nips.cc/paper/2020/hash/00ac8ed...          0.966598  \n",
            "1  https://papers.nips.cc/paper/2020/file/00ac8ed...          0.962411  \n",
            "2                  https://papers.nips.cc/paper/2020          0.966444  \n",
            "3  https://papers.nips.cc/paper/2020/file/4db7386...          0.962411  \n",
            "4  https://papers.nips.cc/paper/2020/file/5d44ee6...          0.965445  \n",
            "5  https://papers.nips.cc/paper/2020/file/385822e...          0.961598  \n",
            "6  https://papers.nips.cc/paper/2020/file/354ac34...          0.966305  \n",
            "7  https://papers.nips.cc/paper/2020/file/2df4524...          0.962180  \n",
            "8  https://papers.nips.cc/paper/2020/file/4324e8d...          0.962566  \n",
            "df_final after rank=                                                topic  \\\n",
            "0  fast flexible temporal point processes triangu...   \n",
            "1  fast flexible temporal point processes triangu...   \n",
            "2  fast flexible temporal point processes triangu...   \n",
            "3  fast flexible temporal point processes triangu...   \n",
            "4  fast flexible temporal point processes triangu...   \n",
            "5  fast flexible temporal point processes triangu...   \n",
            "6  fast flexible temporal point processes triangu...   \n",
            "7  fast flexible temporal point processes triangu...   \n",
            "8  fast flexible temporal point processes triangu...   \n",
            "\n",
            "                                               title  \\\n",
            "0  Fast and Flexible Temporal Point Processes wit...   \n",
            "1  Fast and Flexible Temporal Point Processes wit...   \n",
            "2  Advances in Neural Information Processing Syst...   \n",
            "3           Exchangeable Neural ODE for Set Modeling   \n",
            "4  Finite-Sample Analysis of Contractive Stochast...   \n",
            "5        Sparse Graphical Memory for Robust Planning   \n",
            "6  Neural Dynamic Policies for End-to-End Sensori...   \n",
            "7  Memory Based Trajectory-conditioned Policies f...   \n",
            "8  Learning Physical Graph Representations from V...   \n",
            "\n",
            "                                                text  \\\n",
            "0  Fast and Flexible Temporal Point Processes wit...   \n",
            "1  Abstract\\n\\nDensity-ratio estimation via class...   \n",
            "2  Book\\n\\nDo not remove: This comment is monitor...   \n",
            "3  Abstract\\n\\nDensity-ratio estimation via class...   \n",
            "4  Abstract\\n\\nStochastic Approximation (SA) is a...   \n",
            "5  Abstract\\n\\nTo operate effectively in the real...   \n",
            "6  Abstract\\n\\nThe current dominant paradigm in s...   \n",
            "7  Abstract\\n\\nReinforcement learning with sparse...   \n",
            "8  Abstract\\n\\nConvolutional Neural Networks (CNN...   \n",
            "\n",
            "                                                 url  similarity_score  rank  \n",
            "0  https://papers.nips.cc/paper/2020/hash/00ac8ed...          0.966598   1.0  \n",
            "1  https://papers.nips.cc/paper/2020/file/00ac8ed...          0.962411   7.0  \n",
            "2                  https://papers.nips.cc/paper/2020          0.966444   2.0  \n",
            "3  https://papers.nips.cc/paper/2020/file/4db7386...          0.962411   7.0  \n",
            "4  https://papers.nips.cc/paper/2020/file/5d44ee6...          0.965445   4.0  \n",
            "5  https://papers.nips.cc/paper/2020/file/385822e...          0.961598   9.0  \n",
            "6  https://papers.nips.cc/paper/2020/file/354ac34...          0.966305   3.0  \n",
            "7  https://papers.nips.cc/paper/2020/file/2df4524...          0.962180   8.0  \n",
            "8  https://papers.nips.cc/paper/2020/file/4324e8d...          0.962566   5.0  \n",
            "0    Fast and Flexible Temporal Point Processes wit...\n",
            "1    Abstract\\n\\nDensity-ratio estimation via class...\n",
            "2    Book\\n\\nDo not remove: This comment is monitor...\n",
            "3    Abstract\\n\\nDensity-ratio estimation via class...\n",
            "4    Abstract\\n\\nStochastic Approximation (SA) is a...\n",
            "5    Abstract\\n\\nTo operate effectively in the real...\n",
            "6    Abstract\\n\\nThe current dominant paradigm in s...\n",
            "7    Abstract\\n\\nReinforcement learning with sparse...\n",
            "8    Abstract\\n\\nConvolutional Neural Networks (CNN...\n",
            "Name: text, dtype: object\n",
            "Fast\n",
            "and\n",
            "Flexible\n",
            "Temporal\n",
            "Point\n",
            "Processes\n",
            "with\n",
            "Triangular\n",
            "Maps\n",
            "Part\n",
            "of\n",
            "Advances\n",
            "in\n",
            "Neural\n",
            "Information\n",
            "Processing\n",
            "Systems\n",
            "33\n",
            "(\n",
            "NeurIPS\n",
            "2020\n",
            ")\n",
            "Authors\n",
            "Oleksandr\n",
            "Shchur\n",
            ",\n",
            "Nicholas\n",
            "Gao\n",
            ",\n",
            "Marin\n",
            "Biloš\n",
            ",\n",
            "Stephan\n",
            "Günnemann\n",
            "Abstract\n",
            "Temporal\n",
            "point\n",
            "process\n",
            "(\n",
            "TPP\n",
            ")\n",
            "models\n",
            "combined\n",
            "with\n",
            "recurrent\n",
            "neural\n",
            "networks\n",
            "provide\n",
            "a\n",
            "powerful\n",
            "framework\n",
            "for\n",
            "modeling\n",
            "continuous-time\n",
            "event\n",
            "data\n",
            ".\n",
            "While\n",
            "such\n",
            "models\n",
            "are\n",
            "flexible\n",
            ",\n",
            "they\n",
            "are\n",
            "inherently\n",
            "sequential\n",
            "and\n",
            "therefore\n",
            "can\n",
            "not\n",
            "benefit\n",
            "from\n",
            "the\n",
            "parallelism\n",
            "of\n",
            "modern\n",
            "hardware\n",
            ".\n",
            "By\n",
            "exploiting\n",
            "the\n",
            "recent\n",
            "developments\n",
            "in\n",
            "the\n",
            "field\n",
            "of\n",
            "normalizing\n",
            "flows\n",
            ",\n",
            "we\n",
            "design\n",
            "TriTPP\n",
            "-\n",
            "a\n",
            "new\n",
            "class\n",
            "of\n",
            "non-recurrent\n",
            "TPP\n",
            "models\n",
            ",\n",
            "where\n",
            "both\n",
            "sampling\n",
            "and\n",
            "likelihood\n",
            "computation\n",
            "can\n",
            "be\n",
            "done\n",
            "in\n",
            "parallel\n",
            ".\n",
            "TriTPP\n",
            "matches\n",
            "the\n",
            "flexibility\n",
            "of\n",
            "RNN-based\n",
            "methods\n",
            "but\n",
            "permits\n",
            "several\n",
            "orders\n",
            "of\n",
            "magnitude\n",
            "faster\n",
            "sampling\n",
            ".\n",
            "This\n",
            "enables\n",
            "us\n",
            "to\n",
            "use\n",
            "the\n",
            "new\n",
            "model\n",
            "for\n",
            "variational\n",
            "inference\n",
            "in\n",
            "continuous-time\n",
            "discrete-state\n",
            "systems\n",
            ".\n",
            "We\n",
            "demonstrate\n",
            "the\n",
            "advantages\n",
            "of\n",
            "the\n",
            "proposed\n",
            "framework\n",
            "on\n",
            "synthetic\n",
            "and\n",
            "real-world\n",
            "datasets\n",
            ".\n",
            "Abstract\n",
            "Density-ratio\n",
            "estimation\n",
            "via\n",
            "classiﬁcation\n",
            "is\n",
            "a\n",
            "cornerstone\n",
            "of\n",
            "unsupervised\n",
            "learning\n",
            ".\n",
            "It\n",
            "has\n",
            "provided\n",
            "the\n",
            "foundation\n",
            "for\n",
            "state-of-the-art\n",
            "methods\n",
            "in\n",
            "representation\n",
            "learning\n",
            "and\n",
            "generative\n",
            "modelling\n",
            ",\n",
            "with\n",
            "the\n",
            "number\n",
            "of\n",
            "use-cases\n",
            "continuing\n",
            "to\n",
            "proliferate\n",
            ".\n",
            "However\n",
            ",\n",
            "it\n",
            "suffers\n",
            "from\n",
            "a\n",
            "critical\n",
            "limitation\n",
            ":\n",
            "it\n",
            "fails\n",
            "to\n",
            "accurately\n",
            "estimate\n",
            "ratios\n",
            "p/q\n",
            "for\n",
            "which\n",
            "the\n",
            "two\n",
            "densities\n",
            "differ\n",
            "signiﬁcantly\n",
            ".\n",
            "Empirically\n",
            ",\n",
            "we\n",
            "ﬁnd\n",
            "this\n",
            "occurs\n",
            "whenever\n",
            "the\n",
            "KL\n",
            "divergence\n",
            "between\n",
            "p\n",
            "and\n",
            "q\n",
            "exceeds\n",
            "tens\n",
            "of\n",
            "nats\n",
            ".\n",
            "To\n",
            "resolve\n",
            "this\n",
            "limitation\n",
            ",\n",
            "we\n",
            "introduce\n",
            "a\n",
            "new\n",
            "framework\n",
            ",\n",
            "telescoping\n",
            "density-ratio\n",
            "estimation\n",
            "(\n",
            "TRE\n",
            ")\n",
            ",\n",
            "that\n",
            "enables\n",
            "the\n",
            "estimation\n",
            "of\n",
            "ratios\n",
            "between\n",
            "highly\n",
            "dissimilar\n",
            "densities\n",
            "in\n",
            "high-dimensional\n",
            "spaces\n",
            ".\n",
            "Our\n",
            "experiments\n",
            "demonstrate\n",
            "that\n",
            "TRE\n",
            "can\n",
            "yield\n",
            "substantial\n",
            "improvements\n",
            "over\n",
            "existing\n",
            "single-ratio\n",
            "methods\n",
            "for\n",
            "mutual\n",
            "information\n",
            "estimation\n",
            ",\n",
            "representation\n",
            "learning\n",
            "and\n",
            "energy-based\n",
            "modelling\n",
            ".\n",
            "1\n",
            "Book\n",
            "Do\n",
            "not\n",
            "remove\n",
            ":\n",
            "This\n",
            "comment\n",
            "is\n",
            "monitored\n",
            "to\n",
            "verify\n",
            "that\n",
            "the\n",
            "site\n",
            "is\n",
            "working\n",
            "properly\n",
            "Abstract\n",
            "Density-ratio\n",
            "estimation\n",
            "via\n",
            "classiﬁcation\n",
            "is\n",
            "a\n",
            "cornerstone\n",
            "of\n",
            "unsupervised\n",
            "learning\n",
            ".\n",
            "It\n",
            "has\n",
            "provided\n",
            "the\n",
            "foundation\n",
            "for\n",
            "state-of-the-art\n",
            "methods\n",
            "in\n",
            "representation\n",
            "learning\n",
            "and\n",
            "generative\n",
            "modelling\n",
            ",\n",
            "with\n",
            "the\n",
            "number\n",
            "of\n",
            "use-cases\n",
            "continuing\n",
            "to\n",
            "proliferate\n",
            ".\n",
            "However\n",
            ",\n",
            "it\n",
            "suffers\n",
            "from\n",
            "a\n",
            "critical\n",
            "limitation\n",
            ":\n",
            "it\n",
            "fails\n",
            "to\n",
            "accurately\n",
            "estimate\n",
            "ratios\n",
            "p/q\n",
            "for\n",
            "which\n",
            "the\n",
            "two\n",
            "densities\n",
            "differ\n",
            "signiﬁcantly\n",
            ".\n",
            "Empirically\n",
            ",\n",
            "we\n",
            "ﬁnd\n",
            "this\n",
            "occurs\n",
            "whenever\n",
            "the\n",
            "KL\n",
            "divergence\n",
            "between\n",
            "p\n",
            "and\n",
            "q\n",
            "exceeds\n",
            "tens\n",
            "of\n",
            "nats\n",
            ".\n",
            "To\n",
            "resolve\n",
            "this\n",
            "limitation\n",
            ",\n",
            "we\n",
            "introduce\n",
            "a\n",
            "new\n",
            "framework\n",
            ",\n",
            "telescoping\n",
            "density-ratio\n",
            "estimation\n",
            "(\n",
            "TRE\n",
            ")\n",
            ",\n",
            "that\n",
            "enables\n",
            "the\n",
            "estimation\n",
            "of\n",
            "ratios\n",
            "between\n",
            "highly\n",
            "dissimilar\n",
            "densities\n",
            "in\n",
            "high-dimensional\n",
            "spaces\n",
            ".\n",
            "Our\n",
            "experiments\n",
            "demonstrate\n",
            "that\n",
            "TRE\n",
            "can\n",
            "yield\n",
            "substantial\n",
            "improvements\n",
            "over\n",
            "existing\n",
            "single-ratio\n",
            "methods\n",
            "for\n",
            "mutual\n",
            "information\n",
            "estimation\n",
            ",\n",
            "representation\n",
            "learning\n",
            "and\n",
            "energy-based\n",
            "modelling\n",
            ".\n",
            "1\n",
            "Abstract\n",
            "Stochastic\n",
            "Approximation\n",
            "(\n",
            "SA\n",
            ")\n",
            "is\n",
            "a\n",
            "popular\n",
            "approach\n",
            "for\n",
            "solving\n",
            "ﬁxed-point\n",
            "equations\n",
            "where\n",
            "the\n",
            "information\n",
            "is\n",
            "corrupted\n",
            "by\n",
            "noise\n",
            ".\n",
            "In\n",
            "this\n",
            "paper\n",
            ",\n",
            "we\n",
            "consider\n",
            "an\n",
            "SA\n",
            "involving\n",
            "a\n",
            "contraction\n",
            "mapping\n",
            "with\n",
            "respect\n",
            "to\n",
            "an\n",
            "arbitrary\n",
            "norm\n",
            ",\n",
            "and\n",
            "show\n",
            "its\n",
            "ﬁnite-sample\n",
            "error\n",
            "bounds\n",
            "while\n",
            "using\n",
            "different\n",
            "stepsizes\n",
            ".\n",
            "The\n",
            "idea\n",
            "is\n",
            "to\n",
            "construct\n",
            "a\n",
            "smooth\n",
            "Lyapunov\n",
            "function\n",
            "using\n",
            "the\n",
            "generalized\n",
            "Moreau\n",
            "envelope\n",
            ",\n",
            "and\n",
            "show\n",
            "that\n",
            "the\n",
            "iterates\n",
            "of\n",
            "SA\n",
            "have\n",
            "negative\n",
            "drift\n",
            "with\n",
            "respect\n",
            "to\n",
            "that\n",
            "Lyapunov\n",
            "function\n",
            ".\n",
            "Our\n",
            "result\n",
            "is\n",
            "applicable\n",
            "in\n",
            "Reinforcement\n",
            "Learning\n",
            "(\n",
            "RL\n",
            ")\n",
            ".\n",
            "In\n",
            "particular\n",
            ",\n",
            "we\n",
            "use\n",
            "it\n",
            "to\n",
            "establish\n",
            "the\n",
            "ﬁrst-known\n",
            "convergence\n",
            "rate\n",
            "of\n",
            "the\n",
            "V-trace\n",
            "algorithm\n",
            "for\n",
            "off-policy\n",
            "TD-learning\n",
            "[\n",
            "18\n",
            "]\n",
            ".\n",
            "Importantly\n",
            ",\n",
            "our\n",
            "construction\n",
            "results\n",
            "in\n",
            "only\n",
            "a\n",
            "logarithmic\n",
            "dependence\n",
            "of\n",
            "the\n",
            "convergence\n",
            "bound\n",
            "on\n",
            "the\n",
            "size\n",
            "of\n",
            "the\n",
            "state-space\n",
            ".\n",
            "1\n",
            "Abstract\n",
            "To\n",
            "operate\n",
            "effectively\n",
            "in\n",
            "the\n",
            "real\n",
            "world\n",
            ",\n",
            "agents\n",
            "should\n",
            "be\n",
            "able\n",
            "to\n",
            "act\n",
            "from\n",
            "high-\n",
            "dimensional\n",
            "raw\n",
            "sensory\n",
            "input\n",
            "such\n",
            "as\n",
            "images\n",
            "and\n",
            "achieve\n",
            "diverse\n",
            "goals\n",
            "across\n",
            "long\n",
            "time-horizons\n",
            ".\n",
            "Current\n",
            "deep\n",
            "reinforcement\n",
            "and\n",
            "imitation\n",
            "learning\n",
            "methods\n",
            "can\n",
            "learn\n",
            "directly\n",
            "from\n",
            "high-dimensional\n",
            "inputs\n",
            "but\n",
            "do\n",
            "not\n",
            "scale\n",
            "well\n",
            "to\n",
            "long-horizon\n",
            "tasks\n",
            ".\n",
            "In\n",
            "contrast\n",
            ",\n",
            "classical\n",
            "graphical\n",
            "methods\n",
            "like\n",
            "A\n",
            "*\n",
            "search\n",
            "are\n",
            "able\n",
            "to\n",
            "solve\n",
            "long-horizon\n",
            "tasks\n",
            ",\n",
            "but\n",
            "assume\n",
            "that\n",
            "the\n",
            "state\n",
            "space\n",
            "is\n",
            "abstracted\n",
            "away\n",
            "from\n",
            "raw\n",
            "sensory\n",
            "input\n",
            ".\n",
            "Recent\n",
            "works\n",
            "have\n",
            "attempted\n",
            "to\n",
            "combine\n",
            "the\n",
            "strengths\n",
            "of\n",
            "deep\n",
            "learning\n",
            "and\n",
            "classical\n",
            "planning\n",
            ";\n",
            "however\n",
            ",\n",
            "dominant\n",
            "methods\n",
            "in\n",
            "this\n",
            "domain\n",
            "are\n",
            "still\n",
            "quite\n",
            "brittle\n",
            "and\n",
            "scale\n",
            "poorly\n",
            "with\n",
            "the\n",
            "size\n",
            "of\n",
            "the\n",
            "environment\n",
            ".\n",
            "We\n",
            "introduce\n",
            "Sparse\n",
            "Graphical\n",
            "Memory\n",
            "(\n",
            "SGM\n",
            ")\n",
            ",\n",
            "a\n",
            "new\n",
            "data\n",
            "structure\n",
            "that\n",
            "stores\n",
            "states\n",
            "and\n",
            "feasible\n",
            "transitions\n",
            "in\n",
            "a\n",
            "sparse\n",
            "memory\n",
            ".\n",
            "SGM\n",
            "aggregates\n",
            "states\n",
            "according\n",
            "to\n",
            "a\n",
            "novel\n",
            "two-way\n",
            "consistency\n",
            "objective\n",
            ",\n",
            "adapting\n",
            "classic\n",
            "state\n",
            "aggregation\n",
            "criteria\n",
            "to\n",
            "goal-conditioned\n",
            "RL\n",
            ":\n",
            "two\n",
            "states\n",
            "are\n",
            "redundant\n",
            "when\n",
            "they\n",
            "are\n",
            "interchangeable\n",
            "both\n",
            "as\n",
            "goals\n",
            "and\n",
            "as\n",
            "starting\n",
            "states\n",
            ".\n",
            "Theoretically\n",
            ",\n",
            "we\n",
            "prove\n",
            "that\n",
            "merging\n",
            "nodes\n",
            "according\n",
            "to\n",
            "two-way\n",
            "consistency\n",
            "leads\n",
            "to\n",
            "an\n",
            "increase\n",
            "in\n",
            "shortest\n",
            "path\n",
            "lengths\n",
            "that\n",
            "scales\n",
            "only\n",
            "linearly\n",
            "with\n",
            "the\n",
            "merging\n",
            "threshold\n",
            ".\n",
            "Experimentally\n",
            ",\n",
            "we\n",
            "show\n",
            "that\n",
            "SGM\n",
            "signiﬁcantly\n",
            "outperforms\n",
            "current\n",
            "state\n",
            "of\n",
            "the\n",
            "art\n",
            "methods\n",
            "on\n",
            "long\n",
            "horizon\n",
            ",\n",
            "sparse-\n",
            "reward\n",
            "visual\n",
            "navigation\n",
            "tasks\n",
            ".\n",
            "Project\n",
            "video\n",
            "and\n",
            "code\n",
            "are\n",
            "available\n",
            "at\n",
            "https\n",
            ":\n",
            "//mishalaskin.github.io/sgm/\n",
            ".\n",
            "1\n",
            "Abstract\n",
            "The\n",
            "current\n",
            "dominant\n",
            "paradigm\n",
            "in\n",
            "sensorimotor\n",
            "control\n",
            ",\n",
            "whether\n",
            "imitation\n",
            "or\n",
            "reinforcement\n",
            "learning\n",
            ",\n",
            "is\n",
            "to\n",
            "train\n",
            "policies\n",
            "directly\n",
            "in\n",
            "raw\n",
            "action\n",
            "spaces\n",
            "such\n",
            "as\n",
            "torque\n",
            ",\n",
            "joint\n",
            "angle\n",
            ",\n",
            "or\n",
            "end-effector\n",
            "position\n",
            ".\n",
            "This\n",
            "forces\n",
            "the\n",
            "agent\n",
            "to\n",
            "make\n",
            "decision\n",
            "at\n",
            "each\n",
            "point\n",
            "in\n",
            "training\n",
            ",\n",
            "and\n",
            "hence\n",
            ",\n",
            "limit\n",
            "the\n",
            "scalability\n",
            "to\n",
            "continuous\n",
            ",\n",
            "high-dimensional\n",
            ",\n",
            "and\n",
            "long-horizon\n",
            "tasks\n",
            ".\n",
            "In\n",
            "contrast\n",
            ",\n",
            "research\n",
            "in\n",
            "classical\n",
            "robotics\n",
            "has\n",
            ",\n",
            "for\n",
            "a\n",
            "long\n",
            "time\n",
            ",\n",
            "exploited\n",
            "dynamical\n",
            "systems\n",
            "as\n",
            "a\n",
            "policy\n",
            "representation\n",
            "to\n",
            "learn\n",
            "robot\n",
            "behaviors\n",
            "via\n",
            "demonstrations\n",
            ".\n",
            "These\n",
            "techniques\n",
            ",\n",
            "however\n",
            ",\n",
            "lack\n",
            "the\n",
            "ﬂexibility\n",
            "and\n",
            "generalizability\n",
            "provided\n",
            "by\n",
            "deep\n",
            "learning\n",
            "or\n",
            "deep\n",
            "reinforcement\n",
            "learning\n",
            "and\n",
            "have\n",
            "remained\n",
            "under-explored\n",
            "in\n",
            "such\n",
            "settings\n",
            ".\n",
            "In\n",
            "this\n",
            "work\n",
            ",\n",
            "we\n",
            "begin\n",
            "to\n",
            "close\n",
            "this\n",
            "gap\n",
            "and\n",
            "embed\n",
            "dynamics\n",
            "structure\n",
            "into\n",
            "deep\n",
            "neural\n",
            "network-based\n",
            "policies\n",
            "by\n",
            "reparameterizing\n",
            "action\n",
            "spaces\n",
            "with\n",
            "differential\n",
            "equations\n",
            ".\n",
            "We\n",
            "propose\n",
            "Neural\n",
            "Dynamic\n",
            "Policies\n",
            "(\n",
            "NDPs\n",
            ")\n",
            "that\n",
            "make\n",
            "predictions\n",
            "in\n",
            "trajectory\n",
            "distribution\n",
            "space\n",
            "as\n",
            "opposed\n",
            "to\n",
            "prior\n",
            "policy\n",
            "learning\n",
            "methods\n",
            "where\n",
            "action\n",
            "represents\n",
            "the\n",
            "raw\n",
            "control\n",
            "space\n",
            ".\n",
            "The\n",
            "embedded\n",
            "structure\n",
            "allow\n",
            "us\n",
            "to\n",
            "perform\n",
            "end-to-end\n",
            "policy\n",
            "learning\n",
            "under\n",
            "both\n",
            "reinforcement\n",
            "and\n",
            "imitation\n",
            "learning\n",
            "setups\n",
            ".\n",
            "We\n",
            "show\n",
            "that\n",
            "NDPs\n",
            "achieve\n",
            "better\n",
            "or\n",
            "comparable\n",
            "performance\n",
            "to\n",
            "state-of-the-art\n",
            "approaches\n",
            "on\n",
            "many\n",
            "robotic\n",
            "control\n",
            "tasks\n",
            "using\n",
            "both\n",
            "reward-based\n",
            "training\n",
            "and\n",
            "demonstrations\n",
            ".\n",
            "Project\n",
            "video\n",
            "and\n",
            "code\n",
            "are\n",
            "available\n",
            "at\n",
            ":\n",
            "https\n",
            ":\n",
            "//shikharbahl.github.io/\n",
            "neural-dynamic-policies/\n",
            ".\n",
            "1\n",
            "Abstract\n",
            "Reinforcement\n",
            "learning\n",
            "with\n",
            "sparse\n",
            "rewards\n",
            "is\n",
            "challenging\n",
            "because\n",
            "an\n",
            "agent\n",
            "can\n",
            "rarely\n",
            "obtain\n",
            "non-zero\n",
            "rewards\n",
            "and\n",
            "hence\n",
            ",\n",
            "gradient-based\n",
            "optimization\n",
            "of\n",
            "param-\n",
            "eterized\n",
            "policies\n",
            "can\n",
            "be\n",
            "incremental\n",
            "and\n",
            "slow\n",
            ".\n",
            "Recent\n",
            "work\n",
            "demonstrated\n",
            "that\n",
            "using\n",
            "a\n",
            "memory\n",
            "buffer\n",
            "of\n",
            "previous\n",
            "successful\n",
            "trajectories\n",
            "can\n",
            "result\n",
            "in\n",
            "more\n",
            "ef-\n",
            "fective\n",
            "policies\n",
            ".\n",
            "However\n",
            ",\n",
            "existing\n",
            "methods\n",
            "may\n",
            "overly\n",
            "exploit\n",
            "past\n",
            "successful\n",
            "experiences\n",
            ",\n",
            "which\n",
            "can\n",
            "encourage\n",
            "the\n",
            "agent\n",
            "to\n",
            "adopt\n",
            "sub-optimal\n",
            "and\n",
            "myopic\n",
            "behaviors\n",
            ".\n",
            "In\n",
            "this\n",
            "work\n",
            ",\n",
            "instead\n",
            "of\n",
            "focusing\n",
            "on\n",
            "good\n",
            "experiences\n",
            "with\n",
            "limited\n",
            "diversity\n",
            ",\n",
            "we\n",
            "propose\n",
            "to\n",
            "learn\n",
            "a\n",
            "trajectory-conditioned\n",
            "policy\n",
            "to\n",
            "follow\n",
            "and\n",
            "expand\n",
            "diverse\n",
            "past\n",
            "trajectories\n",
            "from\n",
            "a\n",
            "memory\n",
            "buffer\n",
            ".\n",
            "Our\n",
            "method\n",
            "allows\n",
            "the\n",
            "agent\n",
            "to\n",
            "reach\n",
            "diverse\n",
            "regions\n",
            "in\n",
            "the\n",
            "state\n",
            "space\n",
            "and\n",
            "improve\n",
            "upon\n",
            "the\n",
            "past\n",
            "trajectories\n",
            "to\n",
            "reach\n",
            "new\n",
            "states\n",
            ".\n",
            "We\n",
            "empirically\n",
            "show\n",
            "that\n",
            "our\n",
            "approach\n",
            "signiﬁcantly\n",
            "outperforms\n",
            "count-based\n",
            "exploration\n",
            "methods\n",
            "(\n",
            "parametric\n",
            "approach\n",
            ")\n",
            "and\n",
            "self-imitation\n",
            "learning\n",
            "(\n",
            "parametric\n",
            "approach\n",
            "with\n",
            "non-parametric\n",
            "memory\n",
            ")\n",
            "on\n",
            "various\n",
            "complex\n",
            "tasks\n",
            "with\n",
            "local\n",
            "optima\n",
            ".\n",
            "In\n",
            "particular\n",
            ",\n",
            "without\n",
            "using\n",
            "expert\n",
            "demonstrations\n",
            "or\n",
            "resetting\n",
            "to\n",
            "arbitrary\n",
            "states\n",
            ",\n",
            "we\n",
            "achieve\n",
            "the\n",
            "state-of-the-art\n",
            "scores\n",
            "under\n",
            "ﬁve\n",
            "billion\n",
            "number\n",
            "of\n",
            "frames\n",
            ",\n",
            "on\n",
            "challenging\n",
            "Atari\n",
            "games\n",
            "such\n",
            "as\n",
            "Montezuma\n",
            "’\n",
            "s\n",
            "Revenge\n",
            "and\n",
            "Pitfall\n",
            ".\n",
            "Abstract\n",
            "Convolutional\n",
            "Neural\n",
            "Networks\n",
            "(\n",
            "CNNs\n",
            ")\n",
            "have\n",
            "proved\n",
            "exceptional\n",
            "at\n",
            "learning\n",
            "repre-\n",
            "sentations\n",
            "for\n",
            "visual\n",
            "object\n",
            "categorization\n",
            ".\n",
            "However\n",
            ",\n",
            "CNNs\n",
            "do\n",
            "not\n",
            "explicitly\n",
            "encode\n",
            "objects\n",
            ",\n",
            "parts\n",
            ",\n",
            "and\n",
            "their\n",
            "physical\n",
            "properties\n",
            ",\n",
            "which\n",
            "has\n",
            "limited\n",
            "CNNs\n",
            "’\n",
            "success\n",
            "on\n",
            "tasks\n",
            "that\n",
            "require\n",
            "structured\n",
            "understanding\n",
            "of\n",
            "visual\n",
            "scenes\n",
            ".\n",
            "To\n",
            "overcome\n",
            "these\n",
            "lim-\n",
            "itations\n",
            ",\n",
            "we\n",
            "introduce\n",
            "the\n",
            "idea\n",
            "of\n",
            "“\n",
            "Physical\n",
            "Scene\n",
            "Graphs\n",
            "”\n",
            "(\n",
            "PSGs\n",
            ")\n",
            ",\n",
            "which\n",
            "represent\n",
            "scenes\n",
            "as\n",
            "hierarchical\n",
            "graphs\n",
            ",\n",
            "with\n",
            "nodes\n",
            "in\n",
            "the\n",
            "hierarchy\n",
            "corresponding\n",
            "intuitively\n",
            "to\n",
            "object\n",
            "parts\n",
            "at\n",
            "different\n",
            "scales\n",
            ",\n",
            "and\n",
            "edges\n",
            "to\n",
            "physical\n",
            "connections\n",
            "between\n",
            "parts\n",
            ".\n",
            "Bound\n",
            "to\n",
            "each\n",
            "node\n",
            "is\n",
            "a\n",
            "vector\n",
            "of\n",
            "latent\n",
            "attributes\n",
            "that\n",
            "intuitively\n",
            "represent\n",
            "ob-\n",
            "ject\n",
            "properties\n",
            "such\n",
            "as\n",
            "surface\n",
            "shape\n",
            "and\n",
            "texture\n",
            ".\n",
            "We\n",
            "also\n",
            "describe\n",
            "PSGNet\n",
            ",\n",
            "a\n",
            "network\n",
            "architecture\n",
            "that\n",
            "learns\n",
            "to\n",
            "extract\n",
            "PSGs\n",
            "by\n",
            "reconstructing\n",
            "scenes\n",
            "through\n",
            "a\n",
            "PSG-structured\n",
            "bottleneck\n",
            ".\n",
            "PSGNet\n",
            "augments\n",
            "standard\n",
            "CNNs\n",
            "by\n",
            "including\n",
            ":\n",
            "recurrent\n",
            "feedback\n",
            "connections\n",
            "to\n",
            "combine\n",
            "low\n",
            "and\n",
            "high-level\n",
            "image\n",
            "information\n",
            ";\n",
            "graph\n",
            "pooling\n",
            "and\n",
            "vectorization\n",
            "operations\n",
            "that\n",
            "convert\n",
            "spatially-uniform\n",
            "feature\n",
            "maps\n",
            "into\n",
            "object-centric\n",
            "graph\n",
            "structures\n",
            ";\n",
            "and\n",
            "perceptual\n",
            "grouping\n",
            "principles\n",
            "to\n",
            "encourage\n",
            "the\n",
            "identiﬁcation\n",
            "of\n",
            "meaningful\n",
            "scene\n",
            "elements\n",
            ".\n",
            "We\n",
            "show\n",
            "that\n",
            "PSGNet\n",
            "outperforms\n",
            "alternative\n",
            "self-supervised\n",
            "scene\n",
            "representation\n",
            "algorithms\n",
            "at\n",
            "scene\n",
            "segmentation\n",
            "tasks\n",
            ",\n",
            "especially\n",
            "on\n",
            "complex\n",
            "real-world\n",
            "images\n",
            ",\n",
            "and\n",
            "generalizes\n",
            "well\n",
            "to\n",
            "unseen\n",
            "object\n",
            "types\n",
            "and\n",
            "scene\n",
            "arrangements\n",
            ".\n",
            "PSGNet\n",
            "is\n",
            "also\n",
            "able\n",
            "learn\n",
            "from\n",
            "physical\n",
            "motion\n",
            ",\n",
            "enhancing\n",
            "scene\n",
            "estimates\n",
            "even\n",
            "for\n",
            "static\n",
            "images\n",
            ".\n",
            "We\n",
            "present\n",
            "a\n",
            "series\n",
            "of\n",
            "ablation\n",
            "studies\n",
            "illustrating\n",
            "the\n",
            "importance\n",
            "of\n",
            "each\n",
            "component\n",
            "of\n",
            "the\n",
            "PS-\n",
            "GNet\n",
            "architecture\n",
            ",\n",
            "analyses\n",
            "showing\n",
            "that\n",
            "learned\n",
            "latent\n",
            "attributes\n",
            "capture\n",
            "intuitive\n",
            "scene\n",
            "properties\n",
            ",\n",
            "and\n",
            "illustrate\n",
            "the\n",
            "use\n",
            "of\n",
            "PSGs\n",
            "for\n",
            "compositional\n",
            "scene\n",
            "inference\n",
            ".\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYhkCvVIJYQa"
      },
      "source": [
        "df_output.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mf5XuJwa2JG0"
      },
      "source": [
        "# To CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MVbUuRX2Ift"
      },
      "source": [
        "#file_path = '/content/drive/Shared drives/1DeepContextGraph/1DeepContextGraph/code/data/'\n",
        "file_path = './data/'\n",
        "\n",
        "df_output.to_csv(file_path+file_name+str(ngramsCount)+'grams.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z02zK_kceb5-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}